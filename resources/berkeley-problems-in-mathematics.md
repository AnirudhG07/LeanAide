PROBLEM BOOKS IN MAINTAINICS

Paulo Ney de Souza

Jorge-Nuno Silva

Berkeley Problems

in Mathematics

Springer

## Preface

In 1977the Mathematics Department at the University of California, Berkeley, instituted a written examination as one of the first major requirements toward the \(\rm Ph.D.\) degree in Mathematics. This examination replaced a system of standardized Qualifying Exams. Its purpose was to determine whether first-year students in the \(\rm Ph.D.\) program had mastered basic mathematics well enough to continue in the program with a reasonable chance of success.

Historically, any one examination is passed by approximately half of the students taking it and students are allowed three attempts. Since its inception, the exam has become a major hurdle to overcome in the pursuit of the degree and, therefore, a measure of the minimum requirements to successful completion of the program at Berkeley. Even though students are allowed three attempts, most would agree that the ideal time to complete the requirement is during the first month of the program rather than in the middle or end of the first year. This book was conceived on this premise, and its intent is to publicize the material and aid in the preparation for the examination during the undergraduate years, when one is deeply involved with the material that it covers.

The examination is now offered twice a year in the second week of each semester, and consists of **6** hours of written work given over a 2-day period with 9 problems each (10 before 1988). Students select 6 of the **9** problems (7 of 10 before 1988). Most of the examination covers material, mainly in analysis and algebra, that should be a part of a well-prepared mathematics student's undergraduate training. This book is a compilation of the almost 1000 problems which have appeared on the Prelims during the last 20years and currently make up a collection which is a delightful field to plow through, and solutioitis to most of them.

When Berkeley was on the Quarter system, exams were given three times a year: Spring, Summer, and Fall. Since 1986, the exams have been given twice a year, in January and September.

From the first examination through Fall 1981, the policy was: two attempts allowed; each examination **6** hours; total 14/20 problems. From Winter 1982 through Spring 1988, the policy was: two attempts allowed; each examination 8 hours; total 14/20 problems. Starting Fall 1988, the policy was: three attempts allowed; each examination **6** hours; total 12/18 problems. In all cases, the examination must be passed within **13** months of entering the Ph.D. program.

The problems are organized by subject and ordered in increasing level of difficulty, within clusters. Each one is tagged with the academic term of the exam in which it appeared using abbreviations of the type **Fa87** to designate the exam given in the **Fall** semester of **1987.** Problems that have appeared more than once have been merged arid show multiple tags for each exam. Sometimes the merge required slight modifications in the text (a few to make the problem correct!), but the original text has been preserved in an electronic version of the exams (see Appendix A). Other items in the Appendices include the syllabus, passing scores for the exams and a Bibliography used throughout the solutions.

Classifying a collection of problems as vast as this one by subjects is not an easy task. Some of the problems are interdisciplinary and some have solutions as varied as Analysis and Number Theory (1.1.15 comes to mind!), and the choices are invariably hard. In most of these cases, we provide the reader with an alternative classification or pointers to similar problems elsewhere.

We would like to hear about other solutions to the problems here and comments on the existing ones. They can be sent by e-mail to the authors.

This project started many years ago, when one of us (PNdS) came to Berkeley and had to go through the lack of information and uncertainties of the exam and got involved with a problem solving group. First thanks go to the group's members: Dino Lorenzini, Hung The Dinh, Kin Yin Li, and Jorge Zubelli, and then to the many Prelim Workshop leaders, many of whose names escape us now but the list includes, besides ourselves, Matthew Wiener, Dmitry Gokhman, Keith Kearnes, Geon Ho Choe, Mike May, Eliza Sachs, Ben Lotto, Ted Jones, David Cruz-Uribe, and Jonathan Walden. Many thanks to Debbie Craig for swift typesetting of many of the problems and to Janet Yonan for her help with the archeological work of finding many of the old and lost problem sets, and finally to Nefeli's for the best coffee west of Rome, we would not have survived without it!

We thank also the Department of Mathematics and the Portuguese Studies Program of UC Berkeley, University of Lisbon, CMAF, JNICT, PRAXIS XXI, FEDER and project PRAXIS/2/2.1/MAT/125/94, which supportedone of the authors on the Summers of 96 and 97, and CNPq grant 20.1553/82-**MA** that supported the other during the initial phase of this project.

This is a project that could not have been accomplished in any type-setting system other than TeX. The problems and solutions are part of a two-pronged database that is called by sourcing programs that generate several versions (working, final paper version, per-exams list, and the on-line HTML and PDF versions) from a single source. Silvio Levy's TeX support and counseling was a major resource backing our efforts and many thanks also _to_ Noam Shomron for help with non-standard typessetting.

Berkeley, April 10, 1998 Paulo Ney de Souza desouza@math.berkeley.edu Jorge-Nuno Silva jnsilva@math.berkeley.edu

###### Contents

* 1 Problems
* 1 Real Analysis
	* 1.1 Elementary Calculus
	* 1.2 Limits and Continuity
	* 1.3 Sequences, Series. and Products
	* 1.4 Differential Calculus
	* 1.5 Integral Calculus
	* 1.6 Sequences of Functions
	* 1.7 Fourier Series
	* 1.8 Convex Functions
* 2 Multivariable Calculus
	* 2.1 Limits and Continuity
	* 2.2 Differential Calculus
	* 2.3 Intcgral Calculus
* 3 Differential Equations
	* 3.1 First Order Equations
	* 3.2 Second Order Equations
	* 3.3 Higher Order Equations
	* 3.4 Systems of Differential Equations
* 4 Metric Spaces
	* 4.1 Topology of \(\mathbb{R}^{n}\)
	* 4.2 General Theory
	* 4.3 Fixed Point Theorem
* 5 Complex Analysis
	* 5.1 Complex Numbers
	* 5.2 Series and Sequences of Functions
	* 5.3 Conformal Mappings
	* 5.4 Integral Representation of Analytic Functions
	* 5.5 Functions on the Unit Disc
	* 5.6 Growth Conditions
	* 5.7 Analytic and Meromorphic Functions
	* 5.8 Cauchy's Theorem
	* 5.9 Zeros and Singularities
* 5.10 Harmonic Functions
* 5.11 Residue Theory
* 5.12 Integrals Along the Real Axis
* 6 Algebra
	* 6.1 Examples of Groups and General Theory
	* 6.2 Homomorphisms and Subgroups
	* 6.3 Cyclic Groups
	* 6.4 Normality, Quotients, and Homomorphisms
	* 6.5 S., A., D.
	* 6.6 Direct Products
	* 6.7 Free Groups. Products. Generators, and Relations
	* 6.8 Finite Groups
	* 6.9 Rings and Their Homomorphisms
* 6.10 Ideals
* 6.11 Polynomials
* 6.12 Fields and Their Extensions
* 6.13 Elementary Number Theory
* 7 Linear Algebra
	* 7.1 Vector Spaces
	* 7.2 Rank and Determinants
	* 7.3 Systems of Equations
	* 7.4 Linear Transformations
	* 7.5 Eigenvalues and Eigenvectors
	* 7.6 Canonical Forms
	* 7.7 Similarity
* 7.8 Bilinear. Quadratic Forms. and Inner Product Spaces
* 7.9 General Theory of Matrices

## II Solutions

* 1 Real Analysis
	* 1.1 Elementary Calculus
	* 1.2 Limits and Continuity
	* 1.3 Sequences, Series. and Products
	* 1.4 Differential Calculus
	* 1.5 Integral Calculus
	* 1.6 Sequences of Functions
	* 1.7 Fourier Series
	* 1.8 Convex Functions
* 2 Multivariable Calculus
	* 2.1 Limits and Continuity
	* 2.2 Differential Calculus
	* 2.3 Integral Calculus
* 3 Differential Equations
	* 3.1 First Order Equations
	* 3.2 Second Order Equations
	* 3.3 Higher Order Equations
	* 3.4 Systems of Differential Equations
* 4 Metric Spaces
	* 4.1 Topology of \(\mathbb{R}^{n}\)
	* 4.2 General Theory
	* 4.3 Fixed Point Theorem
* 5 Complex Analysis
	* 5.1 Complex Numbers
	* 5.2 Series and sequences of Functions
	* 5.3 Conformal Mappings
	* 5.4 Integral Representation of Analytic Functions
	* 5.5 Functions on the Unit Disc
	* 5.6 Growth Conditions
	* 5.7 Analytic and Meromorphic Functions
	* 5.8 Cauchy's Theorem
	* 5.9 Zeros and Singularities
* 5.10 Harmonic Functions
* 5.11 Residue Theory
* 5.12 Integrals Along the Real Axis

[MISSING_PAGE_EMPTY:8]

[MISSING_PAGE_EMPTY:9]

Real Analysis

### 1.1 Elementary Calculus

**Problem 1.1.1** (Fa87): _Prove that \((\cos\theta)^{p}\leq\cos(p\,\theta)\) for \(0\leq\theta\leq\pi/2\) and \(0<p<1\)._

**Problem 1.1.2** (Fa77): _Let \(f:[0,1]\rightarrow\mathbb{R}\) be continuously differentiable, with \(f(0)=0\). Prove that_

\[\sup_{0\leq x\leq 1}|f(x)|\leq\left(\int_{0}^{1}\left(f^{\prime}(x)\right)^{2} \,dx\right)^{1/2}.\]

**Problem 1.1.3** (Sp81): _Let \(f(x)\) be a real valued function defined for all \(x\geq 1\), satisfying \(f(1)=1\) and_

\[f^{\prime}(x)=\frac{1}{x^{2}+f(x)^{2}}.\]

_Prove that_

\[\lim_{x\rightarrow\infty}f(x)\]

_exists and is less than \(1+\frac{\pi}{4}\)._

**Problem 1.1.4** (Sp95): _Let \(f\), \(g\colon[0,1]\rightarrow[0,\infty)\) be continuous functions satisfying_

\[\sup_{0\leq x\leq 1}f(x)=\sup_{0\leq x\leq 1}g(x).\]

_Prove that there exists \(t\in[0,1]\) with \(f(t)^{2}+3f(t)=g(t)^{2}+3g(t)\)._

**Problem 1.1.5** (Fa86): _For \(f\) a real valued function on the real line, define the function \(\triangle f\) by \(\triangle f(x)=f(x+1)-f(x)\). For \(n\geq 2\), define \(\triangle^{n}f\) recursively by \(\triangle^{n}f=\triangle(\triangle^{n-1}f)\). Prove that \(\triangle^{n}f=0\) if and only if \(f\) has the form \(f(x)=a_{0}(x)+a_{1}(x)x+\cdots+a_{n-1}(x)x^{n-1}\) where \(a_{0},a_{1},\ldots,a_{n-1}\) are periodic functions of period \(1\)._

**Problem 1.1.6** (Fa81): _Either prove or disprove (by a counterexample) each of the following statements:_

1. _Let_ \(f:\mathbb{R}\rightarrow\mathbb{R}\)_,_ \(g:\mathbb{R}\rightarrow\mathbb{R}\) _be such that_ \[\lim_{t\to a}g(t)=b\;\;\text{and}\;\;\lim_{t\to b}f(t)=c.\] _Then_ \[\lim_{t\to a}f\left(g(t)\right)=c.\]
2. _If_ \(f:\mathbb{R}\rightarrow\mathbb{R}\) _is continuous and_ \(U\) _is an open set in_ \(\mathbb{R}\)_, then_ \(f(U)\) _is an open set in_ \(\mathbb{R}\)_._
3. _Let_ \(f\) _be of class_ \(C^{\infty}\) _on the interval -_\(1<x<1\)_. Suppose that_ \(|f^{(n)}(x)|\leq 1\) _for all_ \(n\geq 1\) _and all x in the interval. Then f is_ real analytic_; that is, it has a convergent power series expansion in a neighborhood of each point of the interval._

**Problem 1.1.7** (Su81): _Let_

\[y(h)=1-2\sin^{2}(2\pi h),\;\;\;\;\;f(y)=\frac{2}{1+\sqrt{1-y^{2}}}.\]

_Justify the statement_

\[f\left(y(h)\right)=2-4\sqrt{2}\pi+O(h^{2})\]

_where_

\[\limsup_{h\to 0}\frac{O(h^{2})}{h^{2}}<\infty.\]

**Problem 1.1.8** (Fa82):
1. _Prove that there is no continuous map from the closed interval_ \([0,1]\) _onto the open interval_ \((0,1)\)_._
2. _Find a continuous surjective map from the open interval_ \((0,1)\) _onto the closed interval_ \([0,1]\)_._
3. _Prove that no map in Part 2 can be bijective._

**Problem 1.1.9** (Fa94, Sp98): _Find the maximum area of all triangles that can be inscribed in an ellipse with semiaxes \(a\) and \(b\), and describe the triangles that have maximum area. Hint: Represent the ellipse by means of the parametric equations \(x=a\cos t,\,y=b\sin t,\;\;0\leq t\leq 2\pi\)._

**Problem 1.1.10** (Fa93): _Let \(f\) be a continuous real valued function on \([0,\infty)\). Let \(A\) be the set of real numbers \(a\) that can be expressed as \(a=\lim_{n\to\infty}f(x_{n})\) for some sequence \((x_{n})\) in \([0,\infty)\) such that \(\lim_{n\to\infty}x_{n}=\infty\). Prove that if \(A\) contains the two numbers \(a\) and \(b\), then it contains the entire interval with endpoints \(a\) and \(b\)._

**Problem 1.1.11** (Su81): _Show that the equation_

\[x\left(1+\log\left(\frac{1}{\varepsilon\sqrt{x}}\right)\right)=1,\quad x>0, \quad\varepsilon>0\,\]

_has, for each sufficiently small \(\varepsilon>0\), exactly two solutions. Let \(x(\varepsilon)\) be the smaller one. Show that_

1. \(x(\varepsilon)\to 0\) _as_ \(\varepsilon\to 0+\)_;_
2. \(\varepsilon^{-s}x(\varepsilon)\to\infty\) _as_ \(\varepsilon\to 0+\)_._

**Problem 1.1.12** (Sp82): _Suppose that \(f(x)\) is a polynomial with real coefficients and \(a\) is a real number with \(f(a)\neq 0\). Show that there exists a real polynomial \(g(x)\) such that if we define \(p\) by \(p(x)=f(x)g(x)\), we have \(p(a)=1\), \(p^{\prime}(a)=0\), and \(p^{\prime\prime}(a)=0\)._

**Problem 1.1.13** (Su84): _Let \(p(z)\) be a nonconstant polynomial with real coefficients such that for some real number \(a\), \(p(a)\neq 0\) but \(p^{\prime}(a)=p^{\prime\prime}(a)=0\). Prove that the equation \(p(z)=0\) has a nonreal root._

**Problem 1.1.14** (Fa84): _Let \(f\) be a \(C^{2}\) function on the real line. Assume \(f\) is bounded with bounded second derivative. Let_

\[A=\sup_{x\in\mathbb{R}}|f(x)|,\ \ B=\sup_{x\in\mathbb{R}}|f^{\prime\prime}(x)|.\]

_Prove that_

\[\sup_{x\in\mathbb{R}}|f^{\prime}(x)|\leq 2\sqrt{AB}.\]

**Problem 1.1.15** (Fa90): _Find all pairs of integers \(a\) and \(b\) satisfying \(0<a<b\) and \(a^{b}=b^{a}\)._

**Problem 1.1.16** (Sp92): _For which positive numbers \(a\) and \(b\), with \(a>1\), does the equation \(\log_{a}x=x^{b}\) have a positive solution for \(x\)?_

**Problem 1.1.17** (Sp84): _Which number is larger, \(\pi^{3}\) or \(3^{\pi}\)?_

**Problem 1.1.18** (Sp94): _For which numbers \(a\) in \((1,\infty)\) is it true that \(x^{a}\leq a^{x}\) for all \(x\) in \((1,\infty)\)?_

**Problem 1.1.19** (Sp96): _Show that a positive constant \(t\) can satisfy_

\[e^{x}>x^{t}\quad for\;all\quad x>0\]

_if and only if \(t<e\)._

**Problem 1.1.20** (Su77): _Suppose that \(f(x)\) is defined on \([-1,1]\), and that \(f^{\prime\prime\prime}(x)\) is continuous. Show that the series_

\[\sum_{n=1}^{\infty}\,\left(n\left(f(1/n)-f(-1/n)\right)-2f^{\prime}(0)\right)\]

_converges._

**Problem 1.1.21** (Fa96): _If \(f\) is a \(C^{2}\) function on an open interval, prove that_

\[\lim_{h\to 0}\;\frac{f(x+h)-2f(x)+f(x-h)}{h^{2}}=f^{\prime\prime}(x)\;.\]

**Problem 1.1.22** (Fa97): _Prove that for all \(x>0\), \(\sin x>x-x^{3}/6\)._

**Problem 1.1.23** (Su85):
1. _For_ \(0\leq\theta\leq\frac{\pi}{2}\)_, show that_ \[\sin\theta\geq\frac{2}{\pi}\theta.\]
2. _By using Part 1, or by any other method, show that if_ \(\lambda<1\)_, then_ \[\lim_{R\to\infty}R^{\lambda}\int_{0}^{\frac{\pi}{2}}e^{-R\sin\theta}\,d\theta=0.\]

**Problem 1.1.24** (Su78): _Let \(f:\mathbb{R}\to\mathbb{R}\) be continuous. Suppose that \(\mathbb{R}\) contains a countably infinite subset \(S\) such that_

\[\int_{p}^{q}f(x)\,dx=0\]

_if \(p\) and \(q\) are not in \(S\). Prove that \(f\) is identically \(0\)._

**Problem 1.1.25** (Fa89): _Let the function \(f\) from \([0,1]\) to \([0,1]\) have the following properties:_

* \(f\) _is of class_ \(C^{1}\)_;_
* \(f(0)=f(1)=0\)_;_
* \(f^{\prime}\) _is nonincreasing (i.e.,_ \(f\) _is concave)._

_Prove that the arclength of the graph of \(f\) does not exceed 3._

**Problem 1.1.26** (Sp93): _Let \(f\) be a real valued \(C^{1}\) function on \([0,\infty)\) such that the improper integral \(\int_{1}^{\infty}|f^{\prime}(x)|dx\) converges. Prove that the infinite series \(\sum_{n=1}^{\infty}f(n)\) converges if and only if the integral \(\int_{1}^{\infty}f(x)dx\) converges._

**Problem 1.1.27** (Su82): _Let \(E\) be the set of all continuous real valued functions \(u:[0,1]\to\mathbb{R}\) satisfying_

\[|u(x)-u(y)|\leq|x-y|,\quad 0\leq x,y\leq 1,\quad u(0)=0.\]

_Let \(\varphi:E\to\mathbb{R}\) be defined by_

\[\varphi(u)=\int_{0}^{1}\big{(}u(x)^{2}-u(x)\big{)}\ dx\,.\]

_Show that \(\varphi\) achieves its maximum value at some element of \(E\)._

**Problem 1.1.28** (Fa87): _Let \(S\) be the set of all real \(C^{1}\) functions \(f\) on \([0,1]\) such that \(f(0)=0\) and_

\[\int_{0}^{1}f^{\prime}(x)^{2}\,dx\leq 1.\]

_Define_

\[J(f)=\int_{0}^{1}f(x)\,dx\,.\]

_Show that the function \(J\) is bounded on \(S\), and compute its supremum. Is there a function \(f_{0}\in S\) at which \(J\) attains its maximum value? If so, what is \(f_{0}\)?_

**Problem 1.1.29** (Fa82, Fa96): _Let f be a real valued continuous nonnegative function on \([0,1]\) such that_

\[f(t)^{2}\leq 1+2\int_{0}^{t}f(s)\,ds\]

_for \(t\in[0,1]\). Show that \(f(t)\leq 1+t\) for \(t\in[0,1]\). Hint: You might consider_

\[u(t)=1+2\int_{0}^{t}f(s)\,ds.\]

**Problem 1.1.30** (Sp96): _Suppose \(\varphi\) is a \(C^{1}\) function on \(\mathbb{R}\) such that_

\[\varphi(x)\to a\quad and\quad\varphi^{\prime}(x)\to b\quad as\quad x\to\infty.\]

_Prove or give a counterexample: \(b\) must be zero._

**Problem 1.1.31** (Su77): _Show that_

\[F(k)=\int_{0}^{\pi/2}\frac{dx}{\sqrt{1-k\cos^{2}x}}\]

\(0\leq k<1\)_, is an increasing function of \(k\)._

**Problem 1.1.32** (Fa79): _Given that_

\[\int_{-\infty}^{\infty}e^{-x^{2}}\,dx=\sqrt{\pi}\,,\]

_find \(f^{\prime}(t)\) explicitly, where_

\[f(t)=\int_{-\infty}^{\infty}e^{-tx^{2}}\,dx,\ \ \ \ t>0.\]

**Problem 1.1.33** (Fa80): _Define_

\[F(x)=\int_{\sin x}^{\cos x}e^{(t^{2}+xt)}\,dt.\]

_Compute \(F^{\prime}(0)\)._

**Problem 1.1.34** (Fa95): _Let \(f:\mathbb{R}\to\mathbb{R}\) be a nonzero \(C^{\infty}\) function such that \(f(x)f(y)=f\left(\sqrt{x^{2}+y^{2}}\right)\) for all \(x\) and \(y\) such that \(f(x)\to 0\) as \(|x|\to\infty\)._

1. _Prove that_ \(f\) _is an even function and that_ \(f(0)\) _is_ \(1\)_._
2. _Prove that_ \(f\) _satisfies the differential equation_ \(f^{\prime}(x)=f^{\prime\prime}(0)xf(x)\)_, and find the most general function satisfying the given conditions._

### 1.2 Limits and Continuity

**Problem 1.2.1** (Fa90): _Suppose that \(f\) maps the compact interval \(I\) into itself and that_

\[|f(x)-f(y)|<|x-y|\]

_for all \(x,y\in I\), \(x\neq y\). Can one conclude that there is some constant \(M<1\) such that, for all \(x,y\in I\),_

\[|f(x)-f(y)|\leq M|x-y|\,?\]

**Problem 1.2.2** (Sp90): _Let the real valued function \(f\) on \([0,1]\) have the following two properties:_* _If_ \([a,b]\subset[0,1]\)_, then_ \(f\left([a,b]\right)\) _contains the interval with endpoints_ \(f(a)\) _and_ \(f(b)\) _(i.e.,_ \(f\) _has the Intermediate Value Property)._
* _For each_ \(c\in\mathbb{R}\)_, the set_ \(f^{-1}(c)\) _is closed._

_Prove that \(f\) is continuous._

**Problem 1.2.3** (Sp83): _Suppose that \(f\) is a continuous function on \(\mathbb{R}\) which is periodic with period \(1\), i.e., \(f(x+1)=f(x)\). Show:_

1. _The function_ \(f\) _is bounded above and below and achieves its maximum and minimum._
2. _The function_ \(f\) _is uniformly continuous on_ \(\mathbb{R}\)_._
3. _There exists a real number_ \(x_{0}\) _such that_ \[f(x_{0}+\pi)=f(x_{0}).\]

**Problem 1.2.4** (Sp77): _Let \(h:[0,1)\to\mathbb{R}\) be a map defined on the half-open interval \([0,1)\). Prove that if \(h\) is uniformly continuous, there exists a unique continuous map \(g:[0,1]\to\mathbb{R}\) such that \(g(x)=h(x)\) for all \(x\in[0,1)\)._

**Problem 1.2.5** (Sp84): _Prove or supply a counterexample: If the function \(f\) from \(\mathbb{R}\) to \(\mathbb{R}\) has both a left limit and a right limit at each point of \(\mathbb{R}\), then the set of discontinuities of \(f\) is, at most, countable._

**Problem 1.2.6** (Fa78): _Let \(f:\mathbb{R}\to\mathbb{R}\) satisfy \(f(x)\leq f(y)\) for \(x\leq y\). Prove that the set where \(f\) is not continuous is finite or countably infinite._

**Problem 1.2.7** (Su85, Fa96): _A function \(f:[0,1]\to\mathbb{R}\) is said to be upper semicontinuous if given \(x\in[0,1]\) and \(\varepsilon>0\), there exists a \(\delta>0\) such that if \(|y-x|<\delta\), then \(f(y)<f(x)+\varepsilon\). Prove that an upper semicontinuous function \(f\) on \([0,1]\) is bounded above and attains its maximum value at some point \(p\in[0,1]\)._

**Problem 1.2.8** (Su83): _Prove that a continuous function from \(\mathbb{R}\) to \(\mathbb{R}\) which maps open sets to open sets must be monotonic._

**Problem 1.2.9** (Fa91): _Let \(f\) be a continuous function from \(\mathbb{R}\) to \(\mathbb{R}\) such that \(|f(x)\) - \(f(y)|\geq|x-y|\) for all \(x\) and \(y\). Prove that the range of \(f\) is all of \(\mathbb{R}\)._

_Note: See also Problem 2.1.8._

**Problem 1.2.10** (Fa81): _Let \(f\) be a continuous function on \([0,1]\). Evaluate the following limits._1. \[\lim_{n\to\infty}\int_{0}^{1}x^{n}f(x)\,dx\,.\]
2. \[\lim_{n\to\infty}n\int_{0}^{1}x^{n}f(x)\,dx\,.\]

**Problem 1.2.11** (Fa88, Sp97): _Let \(f\) be a function from \([0,1]\) into itself whose graph_

\[G_{f}=\{(x,f(x))\ \mid x\in[0,1]\}\]

_is a closed subset of the unit square. Prove that \(f\) is continuous. Note: See also Problem 2.1.2._

**Problem 1.2.12** (Sp89): _Let f be a continuous real valued function on \([0,1]\times[0,1]\). Let the function g on \([0,1]\) be defined by_

\[g(x)=\max\left\{f(x,y)\mid y\in[0,1]\right\}.\]

_Prove that g is continuous._

### 1.3 Sequences, Series, and Products

**Problem 1.3.1** (Su85): _Let \(A_{1}\geq A_{2}\geq\cdots\geq A_{k}\geq 0\). Evaluate_

\[\lim_{n\to\infty}\left(A_{1}^{n}+A_{2}^{n}+\cdots+A_{k}^{n}\right)^{1/n}.\]

_Note: See also Problem 5.1.10._

**Problem 1.3.2** (Sp96): _Compute_

\[L=\lim_{n\to\infty}\left(\frac{n^{n}}{n!}\right)^{1/n}.\]

**Problem 1.3.3** (Sp92): _Let \(x_{0}=1\) and_

\[x_{n}=\frac{3+2x_{n-1}}{3+x_{n-1}}\]

_for \(n=1,2,\ldots\). Prove that_

\[x_{\infty}=\lim_{n\to\infty}x_{n}\]

_exists, and find its value._

**Problem 1.3.4** (Fa97): _Define a sequence of real numbers \((x_{n})\) by_

\[x_{0}=1,\qquad x_{n+1}=\frac{1}{2+x_{n}}\quad\mathrm{for}\quad n\geq 0.\]

_Show that \((x_{n})\) converges, and evaluate its limit._

**Problem 1.3.5** (Fa89, Sp94): _Let \(\alpha\) be a number in \((0,1)\). Prove that any sequence \((x_{n})\) of real numbers satisfying the recurrence relation_

\[x_{n+1}=\alpha x_{n}+(1-\alpha)x_{n-1}\]

_has a limit, and find an expression for the limit in terms of \(\alpha\), \(x_{0}\) and \(x_{1}\)._

**Problem 1.3.6** (Fa92): _Let \(k\) be a positive integer. Determine those real numbers \(c\) for which every sequence \((x_{n})\) of real numbers satisfying the recurrence relation_

\[\frac{1}{2}\left(x_{n+1}+x_{n-1}\right)=cx_{n}\]

_has period \(k\) (i.e., \(x_{n+k}=x_{n}\) for all \(n\))._

**Problem 1.3.7** (Sp84): _Let \(a\) be a positive real number. Define a sequence \((x_{n})\) by_

\[x_{0}=0,\quad x_{n+1}=a+x_{n}^{2},\quad n\geq 0\,.\]

_Find a necessary and sufficient condition on \(a\) in order that a finite limit \(\lim_{n\to\infty}x_{n}\) should exist._

**Problem 1.3.8** (Fa95): _Let \(x_{1}\) be a real number, \(0<x_{1}<1\), and define a sequence by \(x_{n+1}=x_{n}-x_{n}^{n+1}\). Show that \(\liminf_{n\to\infty}x_{n}>0\)._

**Problem 1.3.9** (Fa80): _Let \(f(x)=\frac{1}{4}+x-x^{2}\). For any real number \(x\), define a sequence \((x_{n})\) by \(x_{0}=x\) and \(x_{n+1}=f(x_{n})\). If the sequence converges, let \(x_{\infty}\) denote the limit._

1. _For_ \(x=0\)_, show that the sequence is bounded and nondecreasing and find_ \(x_{\infty}=\lambda\)_._
2. _Find all_ \(y\in\mathbb{R}\) _such that_ \(y_{\infty}=\lambda\)_._

**Problem 1.3.10** (Fa81): _The Fibonacci numbers \(f_{1},f_{2},\ldots\) are defined recursively by \(f_{1}=1\), \(f_{2}=2\), and \(f_{n+1}=f_{n}+f_{n-1}\) for \(n\geq 2\). Show that_

\[\lim_{n\to\infty}\frac{f_{n+1}}{f_{n}}\]

_exists, and evaluate the limit._

_Note: See also Problem 7.5.14._

**Problem 1.3.11** (Fa79): _Prove that_

\[\lim_{n\to\infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2n}\right)= \log 2.\]

**Problem 1.3.12** (Sp90): _Suppose \(x_{1},x_{2},x_{3},\ldots\) is a sequence of nonnegative real numbers satisfying_

\[x_{n+1}\leq x_{n}+\frac{1}{n^{2}}\]

_for all \(n\geq 1\). Prove that \(\lim_{n\to\infty}x_{n}\) exists._

**Problem 1.3.13** (Sp93): _Let \((a_{n})\) and \((\varepsilon_{n})\) be sequences of positive numbers. Assume that \(\lim_{n\to\infty}\varepsilon_{n}=0\) and that there is a number \(k\) in \((0,1)\) such that \(a_{n+1}\leq ka_{n}+\varepsilon_{n}\) for every \(n\). Prove that \(\lim_{n\to\infty}a_{n}=0\)._

**Problem 1.3.14** (Fa83): _Prove or disprove (by giving a counterexample), the following assertion: Every infinite sequence \(x_{1},x_{2},\ldots\) of real numbers has either a nondecreasing subsequence or a nonincreasing subsequence._

**Problem 1.3.15** (Su83): _Let \(b_{1},b_{2},\ldots\) be positive real numbers with_

\[\lim_{n\to\infty}b_{n}=\infty\;\;\mbox{and}\;\;\;\lim_{n\to\infty}(b_{n}/b_{n+ 1})=1.\]

_Assume also that \(b_{1}<b_{2}<b_{3}<\cdots\). Show that the set of quotients \((b_{m}/b_{n})_{1\leq n<m}\) is dense in \((1,\infty)\)._

**Problem 1.3.16** (Sp81): _Which of the following series converges?_

1. \[\sum_{n=1}^{\infty}\frac{(2n)!(3n)!}{n!(4n)!}\;.\]
2. \[\sum_{n=1}^{\infty}\frac{1}{n^{1+1/n}}\;.\]

**Problem 1.3.17** (Fa91): _Let \(a_{1},a_{2},a_{3},\ldots\) be positive numbers._

1. _Prove that_ \(\sum a_{n}<\infty\) _implies_ \(\sum\sqrt{a_{n}a_{n+1}}<\infty\)_._
2. _Prove that the converse of the above statement is false._

**Problem 1.3.18** (Su80, Sp97): _For each \((a,b,c)\in\mathbb{R}^{3}\), consider the series_

\[\sum_{n=3}^{\infty}\frac{a^{n}}{n^{b}(\log n)^{c}}.\]

_Determine the values of \((a,b,c)\) for which the series_1. _converges absolutely;_
2. _converges but not absolutely;_
3. _diverges._

**Problem 1.3.19** (Sp91): _For which real numbers x does the infinite series_

\[\sum_{n=1}^{\infty}\frac{\sqrt{n+1}-\sqrt{n}}{n^{x}}\]

_converge?_

**Problem 1.3.20** (Fa94): _For which values of the real number \(a\) does the series_

\[\sum_{n=1}^{\infty}\left(\frac{1}{n}-\sin\frac{1}{n}\right)^{a}\]

_converge?_

**Problem 1.3.21** (Sp91): _Let \(A\) be the set of positive integers that do not contain the digit \(9\) in their decimal expansions. Prove that_

\[\sum_{a\in A}\frac{1}{a}<\infty;\]

_that is, \(A\) defines a convergent subseries of the harmonic series._

**Problem 1.3.22** (Sp89): _Let \(a_{1},a_{2},\ldots\) be positive numbers such that_

\[\sum_{n=1}^{\infty}a_{n}<\infty\,.\]

_Prove that there are positive numbers \(c_{1},c_{2},\ldots\) such that_

\[\lim_{n\to\infty}c_{n}=\infty\quad\text{and}\quad\sum_{n=1}^{\infty}c_{n}a_{n} <\infty\,.\]

**Problem 1.3.23** (Fa90): _Evaluate the limit_

\[\lim_{n\to\infty}\cos\frac{\pi}{2^{2}}\cos\frac{\pi}{2^{3}}\cdots\cos\frac{\pi }{2^{n}}\cdot\]

### 1.4 Differential Calculus

**Problem 1.4.1** (Su83): _Outline a proof, starting from basic properties of the real numbers, of the following theorem: Let \(f:[a,b]\to\mathbb{R}\) be a continuous function such that \(f^{\prime}(x)=0\) for all \(x\in(a,b)\). Then \(f(b)=f(a)\)._

**Problem 1.4.2** (Sp84): _Let \(f(x)=x\log\left(1+x^{-1}\right)\), \(0<x<\infty\)._

1. _Show that_ \(f\) _is strictly monotonically increasing._
2. _Compute_ \(\lim f(x)\) _as_ \(x\to 0\) _and_ \(x\to\infty\)_._

**Problem 1.4.3** (Sp85): _Let \(f(x)\), \(0\leq x<\infty\), be continuous and differentiable and suppose that \(f(0)=0\) and that \(f^{\prime}(x)\) is an increasing function of \(x\) for \(x\geq 0\). Prove that_

\[g(x)=\left\{\begin{array}{ll}f(x)/x,&x>0\\ f^{\prime}(0),&x=0\end{array}\right.\]

_is an increasing function of \(x\). Interpret the result pictorially._

**Problem 1.4.4** (Sp90): _Let \(y:\mathbb{R}\to\mathbb{R}\) be a \(C^{\infty}\) function that satisfies the differential equation_

\[y^{\prime\prime}+y^{\prime}-y=0\]

_for \(x\in[0,L]\), where \(L\) is a positive real number. Suppose that \(y(0)=y(L)=0\). Prove that \(y\equiv 0\) on \([0,L]\)._

**Problem 1.4.5** (Su85): _Let \(u(x),\,0\leq x\leq 1\), be a real valued \(C^{2}\) function which satisfies the differential equation_

\[u^{\prime\prime}(x)=e^{x}u(x).\]

1. _Show that if_ \(0<x_{0}<1\)_, then_ \(u\) _cannot have a positive local maximum at_ \(x_{0}\)_. Similarly, show that_ \(u\) _cannot have a negative local minimum at_ \(x_{0}\)_._
2. _Now suppose that_ \(u(0)=u(1)=0\)_. Prove that_ \(u(x)\equiv 0\)_,_ \(0\leq x\leq 1\)_._

**Problem 1.4.6** (Sp98): _Let \(K\) be a real constant. Suppose that \(y(t)\) is a positive differentiable function satisfying \(y^{\prime}(t)\leq Ky(t)\) for \(t\geq 0\). Prove that \(y(t)\leq e^{Kt}y(0)\) for \(t\geq 0\)._

**Problem 1.4.7** (Sp90, Fa91): _Let \(f\) be an infinitely differentiable function from \(\mathbb{R}\) to \(\mathbb{R}\). Suppose that, for some positive integer \(n\),_

\[f(1)=f(0)=f^{\prime}(0)=f^{\prime\prime}(0)=\cdots=f^{(n)}(0)=0.\]

_Prove that \(f^{(n+1)}(x)=0\) for some \(x\) in \((0,1)\)._

**Problem 1.4.8** (Fa97): _Let \(f:\mathbb{R}\to\mathbb{R}\) be twice differentiable, and suppose that for all \(x\in\mathbb{R}\), \(|f(x)|\leq 1\) and \(|f^{\prime\prime}(x)|\leq 1\). Prove that \(|f^{\prime}(x)|\leq 2\) for all \(x\in\mathbb{R}\)._

**Problem 1.4.9** (Sp86): _Let \(f\) be a positive differentiable function on \((0,\infty)\). Prove that_

\[\lim_{\delta\to 0}\left(\frac{f(x+\delta x)}{f(x)}\right)^{1/\delta}\]

_exists (finitely) and is nonzero for each x._

**Problem 1.4.10** (Sp88): _Suppose that \(f(x)\), \(-\infty<x<\infty\), is a continuous real valued function, that \(f^{\prime}(x)\) exists for \(x\neq 0\), and that \(\lim_{x\to 0}f^{\prime}(x)\) exists. Prove that \(f^{\prime}(0)\) exists._

**Problem 1.4.11** (Sp88): _For each real value of the parameter \(t\), determine the number of real roots, counting multiplicities, of the cubic polynomial \(p_{t}(x)=(1+t^{2})x^{3}-3t^{3}x+t^{4}\)._

**Problem 1.4.12** (Sp91): _Let the real valued function \(f\) be defined in an open interval about the point \(a\) on the real line and be differentiable at \(a\). Prove that if \((x_{n})\) is an increasing sequence and \((y_{n})\) is a decreasing sequence in the domain of \(f\), and both sequences converge to \(a\), then_

\[\lim_{n\to\infty}\frac{f(y_{n})-f(x_{n})}{y_{n}-x_{n}}=f^{\prime}(a).\]

**Problem 1.4.13** (Fa86): _Let \(f\) be a continuous real valued function on \([0,1]\) such that, for each \(x_{0}\in[0,1)\),_

\[\limsup_{x\to x_{0}^{+}}\frac{f(x)-f(x_{0})}{x-x_{0}}\geq 0.\]

_Prove that \(f\) is nondecreasing._

**Problem 1.4.14** (Sp84): _Let \(I\) be an open interval in \(\mathbb{R}\) containing zero. Assume that \(f^{\prime}\) exists on a neighborhood of zero and \(f^{\prime\prime}(0)\) exists. Show that_

\[f(x)=f(0)+f^{\prime}(0)\sin x+\frac{1}{2}f^{\prime\prime}(0)\sin^{2}x+o(x^{2})\]

_(\(o(x^{2})\) denotes a quantity such that \(o(x^{2})/x^{2}\to 0\) as \(x\to 0\))._

**Problem 1.4.15** (Sp84): _Prove that the Taylor coefficients at the origin of the function_

\[f(z)=\frac{z}{e^{z}-1}\]

_are rational numbers._

**Problem 1.4.16** (Sp79): _Give an example of a function \(f:\mathbb{R}\to\mathbb{R}\) having all three of the following properties:_

* \(f(x)=0\) _for_ \(x<0\) _and_ \(x>2\)* \(f^{\prime}(1)=1\)_,_
* \(f\) _has derivatives of all orders._

_Hint: If the third property is too hard, change it to: \(f\) has n continuous derivatives, where n is as large as you can make it._

**Problem 1.4.17** (Su83): _Let \(f:\mathbb{R}\rightarrow\mathbb{R}\) be continuously differentiable, periodic of period \(1\), and nonnegative. Show that_

\[\frac{d}{dx}\left(\frac{f(x)}{1+cf(x)}\right)\to 0\quad(\text{as }c\rightarrow\infty)\]

_uniformly in \(x\)._

**Problem 1.4.18** (Fa83, Fa84): _Prove or supply a counterexample: If \(f\) and \(g\) are \(C^{1}\) real valued functions on \((0,1)\), if_

\[\lim_{x\to 0}f(x)=\lim_{x\to 0}g(x)=0,\]

_if \(g\) and \(g^{\prime}\) never vanish, and if_

\[\lim_{x\to 0}\frac{f(x)}{g(x)}=c,\]

_then_

\[\lim_{x\to 0}\frac{f^{\prime}(x)}{g^{\prime}(x)}=c.\]

**Problem 1.4.19** (Sp77, Su82): _Suppose \(f\) is a differentiable function from the reals into the reals. Suppose \(f^{\prime}(x)>f(x)\) for all \(x\in\mathbb{R}\), and \(f(x_{0})=0\). Prove that \(f(x)>0\) for all \(x>x_{0}\)._

**Problem 1.4.20** (Sp87): _Show that the equation \(ae^{x}=1+x+x^{2}/2\), where \(a\) is a positive constant, has exactly one real root._

**Problem 1.4.21** (Sp85): _Let \(v_{1}\) and \(v_{2}\) be two real valued continuous functions on \(\mathbb{R}\) such that \(v_{1}(x)<v_{2}(x)\) for all \(x\in\mathbb{R}\). Let \(\varphi_{1}(t)\) and \(\varphi_{2}(t)\) be, respectively, solutions of the differential equations_

\[\frac{dx}{dt}=v_{1}(x)\quad\text{and}\quad\frac{dx}{dt}=v_{2}(x)\]

_for \(a<t<b\). If \(\varphi_{1}(t_{0})=\varphi_{2}(t_{0})\) for some \(t_{0}\in(a,b)\), show that \(\varphi_{1}(t)\leq\varphi_{2}(t)\) for all \(t\in(t_{0},b)\)._

**Problem 1.4.22** (Su78, Fa89): _Suppose \(f:[0,1]\rightarrow\mathbb{R}\) is continuous with \(f(0)=0\), and for \(0<x<1\)\(f\) is differentiable and \(0\leq f^{\prime}(x)\leq 2f(x)\). Prove that \(f\) is identically \(0\)._

**Problem 1.4.23** (Su79, Fa97):
1. _Give an example of a differentiable map_ \(f:\mathbb{R}\to\mathbb{R}\) _whose derivative_ \(f^{\prime}\) _is not continuous._
2. _Let_ \(f\) _be as in Part 1. If_ \(f^{\prime}(0)<2<f^{\prime}(1)\)_, prove that_ \(f^{\prime}(x)=2\) _for some_ \(x\in[0,1]\)_._

**Problem 1.4.24** (Su81): _Let \(A\subset\mathbb{R}\) be the open interval from \(0\) to \(1\). Let \(f:A\to\mathbb{C}\) be \(C^{1}\) (i.e., the real and imaginary parts are continuously differentiable). Suppose that \(f(t)\to 0,\ f^{\prime}(t)\to C\neq 0\) as \(t\to 0+\). Show that the function \(g(t)=|f(t)|\) is \(C^{1}\) for sufficiently small \(t>0\) and that \(\lim_{t\to 0+}g^{\prime}(t)\) exists, and evaluate the limit._

**Problem 1.4.25** (Sp84): _Let \(f:[0,1]\to\mathbb{R}\) be continuous, with \(f(0)=f(1)=0\). Assume that \(f^{\prime\prime}\) exists on \(0<x<1\), with \(f^{\prime\prime}+2f^{\prime}+f\geq 0\). Show that \(f(x)\leq 0\) for all \(0\leq x\leq 1\)._

**Problem 1.4.26** (Fa95): _Let \(f:\mathbb{R}\to\mathbb{R}\) be a \(C^{\infty}\) function. Assume that \(f(x)\) has a local minimum at \(x=0\). Prove there is a disc centered on the \(y\) axis which lies above the graph of \(f\) and touches the graph at \((0,f(0))\)._

### 1.5 Integral Calculus

**Problem 1.5.1** (Sp98): _Using the properties of the Riemann integral, show that if \(f\) is a non-negative continuous function on \([0,1]\), and \(\int_{0}^{1}f(x)dx=0\), then \(f(x)=0\) for all \(x\in[0,1]\)._

**Problem 1.5.2** (Fa90): _Suppose \(f\) is a continuous real valued function. Show that_

\[\int_{0}^{1}f(x)x^{2}\,dx=\frac{1}{3}f(\xi)\]

_for some \(\xi\in[0,1]\)._

**Problem 1.5.3** (Sp77): _Suppose that \(f\) is a real valued function of one real variable such that_

\[\lim_{x\to c}f(x)\]

_exists for all \(c\in[a,b]\). Show that \(f\) is Riemann integrable on \([a,b]\)._

**Problem 1.5.4** (Sp78): _Let \(f:[0,1]\to\mathbb{R}\) be Riemann integrable over \([b,1]\) for all \(b\) such that \(0<b\leq 1\)._

1. _If f is bounded, prove that f is Riemann integrable over_ \([0,1]\)_._
2. _What if f is not bounded?_

**Problem 1.5.5** (Su81): _Let \(f:\mathbb{R}\to\mathbb{R}\) be continuous, with_

\[\int_{-\infty}^{\infty}|f(x)|\,dx<\infty.\]

_Show that there is a sequence \((x_{n})\) such that \(x_{n}\to\infty\), \(x_{n}f(x_{n})\to 0\), and \(x_{n}f(-x_{n})\to 0\) as \(n\to\infty\)._

**Problem 1.5.6** (Su85): _Let_

\[f(x)=e^{x^{2}/2}\int_{x}^{\infty}e^{-t^{2}/2}\,dt\]

_for \(x>0\)._

1. _Show that_ \(0<f(x)<\frac{1}{x}\)_._ _Hint: In the integral, make the change of variable_ \(t=x+s\)_._
2. _Show that_ \(f(x)\) _is strictly decreasing as_ \(x\) _increases,_ \(x>0\)_._

**Problem 1.5.7** (Su84): _Let \(\varphi(s)\) be a \(C^{2}\) function on \([1,2]\) with \(\varphi\) and \(\varphi^{\prime}\) vanishing at \(s=1,2\). Prove that there is a constant \(C>0\) such that for any \(\lambda>1\),_

\[\left|\int_{1}^{2}e^{i\lambda x}\varphi(x)\,dx\right|\leq\frac{C}{\lambda^{2}}.\]

**Problem 1.5.8** (Fa85): _Let \(0\leq a\leq 1\) be given. Determine all nonnegative continuous functions \(f\) on \([0,1]\) which satisfy the following three conditions:_

\[\int_{0}^{1}f(x)\,dx=1,\]

\[\int_{0}^{1}xf(x)\,dx=a,\]

\[\int_{0}^{1}x^{2}f(x)\,dx=a^{2}.\]

**Problem 1.5.9** (Fa85, Sp90): _Let \(f\) be a differentiable function on \([0,1]\) and let_

\[\sup_{0<x<1}|f^{\prime}(x)|=M<\infty.\]

_Let \(n\) be a positive integer. Prove that_

\[\left|\sum_{j=0}^{n-1}\frac{f(j/n)}{n}-\int_{0}^{1}f(x)\,dx\right|\leq\frac{M} {2n}.\]

**Problem 1.5.10** (Fa83): _Let \(f:[0,\infty)\to\mathbb{R}\) be a uniformly continuous function with the property that_

\[\lim_{b\to\infty}\int_{0}^{b}f(x)\,dx\]

_exists (as a finite limit). Show that_

\[\lim_{x\to\infty}f(x)=0.\]

**Problem 1.5.11** (Fa86): _Let \(f\) be a real valued continuous function on \([0,\infty)\) such that_

\[\lim_{x\to\infty}\left(f(x)+\int_{0}^{x}f(t)\,dt\right)\]

_exists. Prove that_

\[\lim_{x\to\infty}f(x)=0.\]

**Problem 1.5.12** (Sp83): _Let \(f:\mathbb{R}_{+}\to\mathbb{R}_{+}\) be a monotone decreasing function, defined on the positive real numbers with_

\[\int_{0}^{\infty}f(x)\,dx<\infty.\]

_Show that_

\[\lim_{x\to\infty}xf(x)=0.\]

**Problem 1.5.13** (Fa90, Sp97): _Let \(f\) be a continuous real valued function satisfying \(f(x)\geq 0\), for all x, and_

\[\int_{0}^{\infty}f(x)\,dx<\infty.\]

_Prove that_

\[\frac{1}{n}\int_{0}^{n}xf(x)\,dx\to 0\]

_as \(n\to\infty\)._

**Problem 1.5.14** (Sp87): _Evaluate the integral_

\[I=\int_{0}^{1/2}\frac{\sin x}{x}\,dx\]

_to an accuracy of two decimal places; that is, find a number \(I^{*}\) such that \(|I-I^{*}|<0.005\)._

**Problem 1.5.15** (Fa87): _Show that the following limit exists and is finite:_

\[\lim_{t\to 0^{+}}\left(\int_{0}^{1}\frac{dx}{\left(x^{4}+t^{4}\right)^{1/4}}+ \log t\right).\]

**Problem 1.5.16** (Fa95): _Let \(f\) and \(f^{\prime}\) be continuous on \([0,\infty)\) and \(f(x)=0\) for \(x\geq 10^{10}\). Show that_

\[\int_{0}^{\infty}f(x)^{2}dx\leq 2\sqrt{\int_{0}^{\infty}x^{2}f(x)^{2}dx}\ \sqrt{\int_{0}^{\infty}f^{\prime}(x)^{2}dx}\ \.\]

**Problem 1.5.17** (Fa88): _Let \(f\) be a continuous, strictly increasing function from \([0,\infty)\) onto \([0,\infty)\) and let \(g=f^{-1}\). Prove that_

\[\int_{0}^{a}f(x)\,dx+\int_{0}^{b}g(y)\,dy\geq ab\]

_for all positive numbers \(a\) and \(b\), and determine the condition for equality._

**Problem 1.5.18** (Sp94): _Let f be a continuous real valued function on \(\mathbb{R}\) such that the improper Riemann integral \(\int_{-\infty}^{\infty}|f(x)|\,dx\) converges. Define the function g on \(\mathbb{R}\) by_

\[g(y)=\int_{-\infty}^{\infty}f(x)\cos(xy)\,dx\,.\]

_Prove that g is continuous._

**Problem 1.5.19** (Sp88): _Prove that the integrals_

\[\int_{0}^{\infty}\cos(x^{2})\,dx\ \ \ \ \text{and}\ \ \ \ \int_{0}^{\infty}\sin(x^{2})\,dx\]

_converge._

**Problem 1.5.20** (Fa85): _Let \(f(x)\), \(0\leq x\leq 1\), be a real valued continuous function. Show that_

\[\lim_{n\to\infty}(n+1)\int_{0}^{1}x^{n}f(x)\,dx=f(1).\]

**Problem 1.5.21** (Su83, Sp84, Fa89): _Compute_

\[\int_{0}^{\infty}\frac{\log x}{x^{2}+a^{2}}\,dx\]

_where \(a>0\) is a constant. Hint: It might be helpful to write the integral as_

\[\int_{0}^{a}+\int_{a}^{\infty}.\]

**Problem 1.5.22** (Sp85): _Show that_

\[I=\int_{0}^{\pi}\log(\sin x)\,dx\]

_converges as an improper Riemann integral. Evaluate \(I\). Hint: The identity \(\sin 2x=2\sin x\cos x\) may be useful._

### 1.6 Sequences of Functions

**Problem 1.6.1** (Fa84): _Prove or supply a counterexample: If \(f\) is a nondecreasing real valued function on \([0,1]\), then there is a sequence of continuous functions on \([0,1]\), \(\{f_{n}\}\), such that for each \(x\in[0,1]\),_

\[\lim_{n\to\infty}f_{n}(x)=f(x).\]

**Problem 1.6.2** (Fa77, Sp80): _Let \(f_{n}:\mathbb{R}\to\mathbb{R}\) be differentiable for each \(n=1,2,\ldots\) with \(|f^{\prime}_{n}(x)|\leq 1\) for all n and x. Assume_

\[\lim_{n\to\infty}f_{n}(x)=g(x)\]

_for all x. Prove that \(g:\mathbb{R}\to\mathbb{R}\) is continuous._

**Problem 1.6.3** (Sp81):
1. _Give an example of a sequence of_ \(C^{1}\) _functions_ \[f_{k}:[0,\infty)\to\mathbb{R},\quad k=0,1,2,\ldots\] _such that_ \(f_{k}(0)=0\) _for all k, and_ \(f^{\prime}_{k}(x)\to f^{\prime}_{0}(x)\) _for all_ \(x\) _as_ \(k\to\infty\)_, but_ \(f_{k}(x)\) _does not converge to_ \(f_{0}(x)\) _for all_ \(x\) _as_ \(k\to\infty\)_._
2. _State an extra condition which would imply that_ \(f_{k}(x)\to f_{0}(x)\) _for all_ \(x\) _as_ \(k\to\infty\)_._

**Problem 1.6.4** (Fa79, Fa80): _Let \(\{P_{n}\}\) be a sequence of real polynomials of degree \(\leq D\), a fixed integer. Suppose that \(P_{n}(x)\to 0\) pointwise for \(0\leq x\leq 1\). Prove that \(P_{n}\to 0\) uniformly on \([0,1]\)._

**Problem 1.6.5** (Fa84): _Show that if \(f\) is a homeomorphism of \([0,1]\) onto itself, then there is a sequence \(\{p_{n}\}\), \(n=1,2,3,\ldots\) of polynomials such that \(p_{n}\to f\) uniformly on \([0,1]\) and each \(p_{n}\) is a homeomorphism of \([0,1]\) onto itself._

_Hint: First assume that \(f\) is \(C^{1}\)._

**Problem 1.6.6** (Sp95): _Let \(f_{n}\colon[0,1]\to[0,\infty)\) be a continuous function, for \(n=1,2,\ldots\). Suppose that one has_

\[(*)\quad\ f_{1}(x)\geq f_{2}(x)\geq f_{3}(x)\geq\cdots\ \ for\ all\ x\in[0,1].\]

_Let \(f(x)=\lim_{n\to\infty}f_{n}(x)\) and \(M=\sup_{0\leq x\leq 1}f(x)\)._

1. _Prove that there exists_ \(t\in[0,1]\) _with_ \(f(t)=M\)_._
2. _Show by example that the conclusion of Part 1 need not hold if instead of_ \((*)\) _we merely know that for each_ \(x\in[0,1]\) _there exists_ \(n_{x}\) _such that for all_ \(n\geq n_{x}\) _one has_ \(f_{n}(x)\geq f_{n+1}(x)\)

**Problem 1.6.7** (Fa82): _Let \(f_{1},f_{2},\ldots\) be continuous functions on \([0,1]\) satisfying \(f_{1}\geq f_{2}\geq\cdots\) and such that \(\lim_{n\to\infty}f_{n}(x)=0\) for each x. Must the sequence \(\{f_{n}\}\) converge to \(0\) uniformly on \([0,1]\)?_

**Problem 1.6.8** (Sp78): _Let \(k\geq 0\) be an integer and define a sequence of maps_

\[f_{n}:\mathbb{R}\to\mathbb{R},\ \ \ \ f_{n}(x)=\frac{x^{k}}{x^{2}+n},\ \ \ \ n=1,2,\ldots.\]

_For which values of k does the sequence converge uniformly on \(\mathbb{R}\)? On every bounded subset of \(\mathbb{R}\)?_

**Problem 1.6.9** (Fa87): _Suppose that \(\{f_{n}\}\) is a sequence of nondecreasing functions which map the unit interval into itself. Suppose that_

\[\lim_{n\to\infty}f_{n}(x)=f(x)\]

_pointwise and that \(f\) is a continuous function. Prove that \(f_{n}(x)\to f(x)\) uniformly as n - \(\infty\), \(0\leq x\leq 1\). Note that the functions \(f_{n}\) are not necessarily continuous._

**Problem 1.6.10** (Fa85): _Let \(f\) and \(f_{n}\), \(n=1,2,\ldots\), be functions from \(\mathbb{R}\) to \(\mathbb{R}\). Assume that \(f_{n}(x_{n})\to f(x)\) as \(n\to\infty\) whenever \(x_{n}\to x\). Show that \(f\) is continuous. Note: The functions \(f_{n}\) are not assumed to be continuous._

**Problem 1.6.11** (Sp81): _Let \(f:[0,1]\to\mathbb{R}\) be continuous. Prove that there is a real polynomial \(P(x)\) of degree \(\leq 10\) which minimizes (for all such polynomials)_

\[\sup_{0\leq x\leq 1}|f(x)-P(x)|.\]

**Problem 1.6.12** (Su85): _Let f be a real valued continuous function on a compact interval \([a,b]\). Given \(\varepsilon>0\), show that there is a polynomial p such that \(p(a)=f(a)\), \(p^{\prime}(a)=0\), and \(|p(x)-f(x)|<\varepsilon\) for \(x\in[a,b]\)._

**Problem 1.6.13** (Sp95): _For each positive integer \(n\), define \(f_{n}:\mathbb{R}\to\mathbb{R}\) by \(f_{n}(x)=\cos(nx)\). Prove that the sequence of functions \(\{f_{n}\}\) has no uniformly convergent subsequence._

**Problem 1.6.14** (Fa86): _The Arzela-Ascoli Theorem asserts that the sequence \(\{f_{n}\}\) of continuous real valued functions on a metric space \(\Omega\) is precompact (i.e., has a uniformly convergent subsequence) if_

1. \(\Omega\) _is compact,_
2. \(\sup\|f_{n}\|<\infty\) _(where_ \(\|f_{n}\|=\sup\{|f_{n}(x)|\mid x\in\Omega\}\)_),_
3. _the sequence is equicontinuous.__Give examples of sequences which are not precompact such that: (i) and (ii) hold but (iii) fails; (i) and (iii) hold but (ii) fails; (ii) and (iii) hold but (i) fails. Take \(\Omega\) to be a subset of the real line. Sketch the graph of a typical member of the sequence in each case._

**Problem 1.6.15** (Fa92): _Let \(\{f_{n}\}\) be a sequence of real valued \(C^{1}\) functions on \([0,1]\) such that, for all \(n\),_

\[|f^{\prime}_{n}(x)|\leq\ x^{-\frac{1}{2}}\ \ \ (0<x\leq 1),\]

\[\int_{0}^{1}\ f_{n}(x)\ dx=0.\]

_Prove that the sequence has a subsequence that converges uniformly on \([0,1]\)._

**Problem 1.6.16** (Fa96): _Let \(M\) be the set of real valued continuous functions \(f\) on \([0,1]\) such that \(f^{\prime}\) is continuous on \([0,1]\), with the norm_

\[\|f\|=\sup_{0\leq x\leq 1}|f(x)|+\sup_{0\leq x\leq 1}|f^{\prime}(x)|\.\]

_Which subsets of \(M\) are compact?_

**Problem 1.6.17** (Su80): _Let \((a_{n})\) be a sequence of nonzero real numbers. Prove that the sequence of functions \(f_{n}:\mathbb{R}\to\mathbb{R}\)_

\[f_{n}(x)=\frac{1}{a_{n}}\sin(a_{n}x)+\cos(x+a_{n})\]

_has a subsequence converging to a continuous function._

**Problem 1.6.18** (Sp82, Sp93): _Let \(\{g_{n}\}\) be a sequence of twice differentiable functions on \([0,1]\) such that \(g_{n}(0)=g^{\prime}_{n}(0)=0\) for all n. Suppose also that \(|g^{\prime\prime}_{n}(x)|\leq 1\) for all n and all \(x\in[0,1]\). Prove that there is a subsequence of \(\{g_{n}\}\) which converges uniformly on \([0,1]\)._

**Problem 1.6.19** (Sp82): _Let \(\{f_{n}\}\) be a sequence of continuous functions from \([0,1]\) to \(\mathbb{R}\). Suppose that \(f_{n}(x)\to 0\) as \(n\to\infty\) for each \(x\in[0,1]\) and also that, for some constant \(K\), we have_

\[\left|\int_{0}^{1}f_{n}(x)\,dx\right|\leq K<\infty\]

_for all n. Does_

\[\lim_{n\to\infty}\int_{0}^{1}f_{n}(x)\,dx=0\,?\]

**Problem 1.6.20** (Fa93): _Let \(K\) be a continuous real valued function on \([0,1]\times[0,1].\) Let \(F\) be the family of functions \(f\) on \([0,1]\) of the form_

\[f(x)=\int_{0}^{1}\ g(y)K(x,y)\,dy\]

_with \(g\) a real valued continuous function on \([0,1]\) satisfying \(|g|\leq 1\) everywhere. Prove that the family \(F\) is equicontinuous._

**Problem 1.6.21** (Fa78): _Let \(\{g_{n}\}\) be a sequence of Riemann integrable functions from \([0,1]\) into \(\mathbb{R}\) such that \(|g_{n}(x)|\leq 1\) for all \(n,x.\) Define_

\[G_{n}(x)=\int_{0}^{x}g_{n}(t)\,dt\,.\]

_Prove that a subsequence of \(\{G_{n}\}\) converges uniformly._

**Problem 1.6.22** (Su79): _Let \(\{f_{n}\}\) be a sequence of continuous maps \([0,1]\to\mathbb{R}\) such that_

\[\int_{0}^{1}\left(f_{n}(y)\right)^{2}\,dy\leq 5\]

_for all n. Define \(g_{n}:[0,1]\to\mathbb{R}\) by_

\[g_{n}(x)=\int_{0}^{1}\sqrt{x+y}f_{n}(y)\,dy.\]

_1. Find a constant \(K\geq 0\) such that \(|g_{n}(x)|\leq K\) for all n._

_2. Prove that a subsequence of the sequence \(\{g_{n}\}\) converges uniformly._

**Problem 1.6.23** (Su81): _Let \(\{f_{n}\}\) be a sequence of continuous maps \([0,1]\to\mathbb{R}\) such that_

\[\int_{0}^{1}\left(f_{n}(x)-f_{m}(x)\right)^{2}\,dx\to 0\ \ as\ \ n,m\to\infty.\]

_Let \(K:[0,1]\times[0,1]\to\mathbb{R}\) be continuous. Define \(g_{n}:[0,1]\to\mathbb{R}\) by_

\[g_{n}(x)=\int_{0}^{1}K(x,y)f_{n}(y)\,dy.\]

_Prove that the sequence \(\{g_{n}\}\) converges uniformly._

**Problem 1.6.24** (Fa82): _Let \(\varphi_{1},\varphi_{2},\ldots,\varphi_{n},\ldots\) be nonnegative continuous functions on \([0,1]\) such that the limit_

\[\lim_{n\to\infty}\int_{0}^{1}x^{k}\varphi_{n}(x)\,dx\]exists for every \(k=0,1,\ldots\). Show that the limit_

\[\lim_{n\to\infty}\int_{0}^{1}f(x)\varphi_{n}(x)\,dx\]

_exists for every continuous function \(f\) on \([0,1]\)._

**Problem 1.6.25** (Sp83): _Let \(\lambda_{1},\lambda_{2},\ldots,\lambda_{n},\ldots\) be real numbers. Show that the infinite series_

\[\sum_{n=1}^{\infty}\frac{e^{i\lambda_{n}x}}{n^{2}}\]

_converges uniformly over \(\mathbb{R}\) to a continuous limit function \(f:\mathbb{R}\to\mathbb{C}\). Show, further, that the limit_

\[\lim_{T\to\infty}\frac{1}{2T}\int_{-T}^{T}f(x)\,dx\]

_exists._

**Problem 1.6.26** (Sp85): _Define the function \(\zeta\) by_

\[\zeta(x)=\sum_{n=1}^{\infty}\frac{1}{n^{x}}.\]

_Prove that \(\zeta(x)\) is defined and has continuous derivatives of all orders in the interval \(1<x<\infty\)._

**Problem 1.6.27** (Sp85): _Let f be continuous on \(\mathbb{R}\), and let_

\[f_{n}(x)=\frac{1}{n}\sum_{k=0}^{n-1}f\left(x+\frac{k}{n}\right).\]

_Prove that \(f_{n}(x)\) converges uniformly to a limit on every finite interval \([a,b]\)._

**Problem 1.6.28** (Sp87): _Let \(f\) be a continuous real valued function on \(\mathbb{R}\) satisfying_

\[|f(x)|\leq C/(1+x^{2}),\]

_where \(C\) is a positive constant. Define the function \(F\) on \(\mathbb{R}\) by_

\[F(x)=\sum_{n=-\infty}^{\infty}f(x+n)\,.\]

1. _Prove that_ \(F\) _is continuous and periodic with period_ \(1\)_._
2. _Prove that if_ \(G\) _is continuous and periodic with period_ \(1\)_, then_ \[\int_{0}^{1}F(x)G(x)\,dx=\int_{-\infty}^{\infty}f(x)G(x)\,dx\,.\]

**Problem 1.6.29** (Sp79): _Show that for any continuous function \(f:[0,1]\to\mathbb{R}\) and \(\varepsilon>0\), there is a function of the form_

\[g(x)=\sum_{k=0}^{n}C_{k}x^{4k}\]

_for some \(n\in\mathbb{Z}\), where \(C_{0},\ldots,C_{n}\in\mathbb{Q}\) and \(|g(x)-f(x)|<\varepsilon\) for all \(x\) in \([0,1]\)._

### 1.7 Fourier Series

**Problem 1.7.1** (Sp80): _Let \(f:\mathbb{R}\to\mathbb{R}\) be the unique function such that \(f(x)=x\) if \(-\pi\leq x<\pi\) and \(f(x+2n\pi)=f(x)\) for all \(n\in\mathbb{Z}\)._

1. _Prove that the Fourier series of_ \(f\) _is_ \[\sum_{n=1}^{\infty}\frac{(-1)^{n+1}2\sin nx}{n}.\]
2. _Prove that the series does not converge uniformly._
3. _For each_ \(x\in\mathbb{R}\)_, find the sum of the series._

**Problem 1.7.2** (Su81): _Let \(f:\mathbb{R}\to\mathbb{R}\) be the function of period \(2\pi\) such that \(f(x)=x^{3}\) for \(-\pi\leq x<\pi\)._

1. _Prove that the Fourier series for_ \(f\) _has the form_ \(\sum_{1}^{\infty}b_{n}\sin nx\) _and write an integral formula for_ \(b_{n}\) _(do not evaluate it)._
2. _Prove that the Fourier series converges for all_ \(x\)_._
3. _Prove_ \[\sum_{n=1}^{\infty}b_{n}^{2}=\frac{2\pi^{6}}{7}.\]

**Problem 1.7.3** (Su82): _Let \(f:[0,\pi]\to\mathbb{R}\) be continuous and such that_

\[\int_{0}^{\pi}f(x)\sin(nx)\,dx=0\]

_for all integers \(n\geq 1\). Is \(f(x)\) is identically \(0\)?_

**Problem 1.7.4** (Sp86): _Let \(f\) be a continuous real valued function on \(\mathbb{R}\) such that_

\[f(x)=f(x+1)=f\left(x+\sqrt{2}\right)\]

_for all x. Prove that f is constant._

**Problem 1.7.5** (Sp88): _Does there exist a continuous real valued function \(f(x)\), \(0\leq x\leq 1\), such that_

\[\int_{0}^{1}xf(x)\,dx=1\quad\text{and}\quad\int_{0}^{1}x^{n}f(x)\,dx=0\]

_for \(n=0,2,3,4,\ldots\)? Give an example or a proof that no such \(f\) exists._

**Problem 1.7.6** (Fa80): _Let g be continuous and periodic on \([-\pi,\pi]\) and have Fourier series_

\[\frac{a_{0}}{2}+\sum_{n=1}^{\infty}(a_{n}\cos nx+b_{n}\sin nx).\]

_Let \(f\) be periodic on \([-\pi,\pi]\) and satisfy the differential equation_

\[f^{\prime\prime}(x)+kf(x)=g(x)\]

_where \(k\neq n^{2},n=1,2,3,\ldots\). Find the Fourier series of \(f\) and prove that it converges everywhere._

**Problem 1.7.7** (Su83): _Let \(f\) be a twice differentiable real valued function on \([0,2\pi]\), with \(\int_{0}^{2\pi}f(x)dx=0=f(2\pi)\) - \(f(0)\). Show that_

\[\int_{0}^{2\pi}\left(f(x)\right)^{2}\,dx\leq\int_{0}^{2\pi}\left(f^{\prime}(x) \right)^{2}\,dx\,.\]

**Problem 1.7.8** (Fa81): _Let \(f\) and \(g\) be continuous functions on \(\mathbb{R}\) such that \(f(x+1)=f(x)\), \(g(x+1)=g(x)\), for all \(x\in\mathbb{R}\). Prove that_

\[\lim_{n\to\infty}\int_{0}^{1}f(x)g(nx)\,dx=\int_{0}^{1}f(x)\,dx\,\int_{0}^{1}g( x)\,dx\,.\]

### Convex Functions

**Problem 1.8.1** (Sp81): _Let \(f:[0,1]\to\mathbb{R}\) be continuous with \(f(0)=0\). Show there is a continuous concave function \(g:[0,1]\to\mathbb{R}\) such that \(g(0)=0\) and \(g(x)\geq f(x)\) for all \(x\in[0,1]\). Note: A function \(g:I\to\mathbb{R}\) is concave if_

\[g\left(tx+(1-t)y\right)\geq tg(x)+(1-t)g(y)\]

_for all \(x\) and \(y\) in \(I\) and \(0\leq t\leq 1\)._

**Problem 1.8.2** (Sp82): _Let \(f:I\to\mathbb{R}\) (where \(I\) is an interval of \(\mathbb{R}\)) be such that \(f(x)>0,\ x\in I.\) Suppose that \(e^{cx}f(x)\) is convex in \(I\) for every real number c. Show that \(\log f(x)\) is convex in \(I\). Note: A function \(g:I\to\mathbb{R}\) is convex if_

\[g\left(tx+(1-t)y\right)\leq tg(x)+(1-t)g(y)\]

_for all \(x\) and \(y\) in \(I\) and \(0\leq t\leq 1\)._

**Problem 1.8.3** (Sp86): _Let \(f\) be a real valued continuous function on \(\mathbb{R}\) satisfying the mean value inequality below:_

\[f(x)\leq\frac{1}{2h}\int_{x-h}^{x+h}f(y)\,dy,\ \ \ \ \ x\in\mathbb{R},\ \ \ \ h>0.\]

_Prove:_

1. _The maximum of_ \(f\) _on any closed interval is assumed at one of the endpoints._
2. \(f\) _is convex._

_Hint: If \(f\) is linear, the inequality above and the convexity one hold and are, in fact, equalities._

## 1 Introduction

In this paper we study the following properties of the following properties:

1. _For each_ \(y_{0}\) _in_ \(\mathbb{R}\)_, the function_ \(x\mapsto f(x,y_{0})\) _is continuous._
2. _For each_ \(y_{0}\) _in_ \(\mathbb{R}\)_, the function_ \(x\mapsto f(x,y_{0})\) _is continuous._

**Problem 1.1** (Sq89): _Let \(f\) be a real valued function on \(\mathbb{R}^{2}\) with the following properties:_

1. _For each_ \(y_{0}\) _in_ \(\mathbb{R}\)_, the function_ \(x\mapsto f(x,y_{0})\) _is continuous._2. Multivariable Calculus
2. For each \(x_{0}\) in \(\mathbb{R}\), the function \(y\mapsto f(x_{0},y)\) is continuous.
3. \(f(K)\) is compact whenever \(K\) is a compact subset of \(\mathbb{R}^{2}\).

Prove that \(f\) is continuous.

**Problem 2.1.5** (Sp91): _Let \(f\) be a continuous function from \(B_{n}=\{x\in\mathbb{R}^{n}\ |\ \|x\|<1\}\) into itself. (Here, \(\|\cdot\|\) denotes the Euclidean norm.) Assume \(\|f(x)\|<\|x\|\) for all nonzero \(x\in B_{n}\). Let \(x_{0}\) be a nonzero point of \(B_{n}\), and define the sequence \((x_{k})\) by setting \(x_{k}=f(x_{k-1})\). Prove that \(\lim x_{k}=0\)._

**Problem 2.1.6** (Su78): _Let \(N\) be a norm on the vector space \(\mathbb{R}^{n}\); that is, \(N:\mathbb{R}^{n}\to\mathbb{R}\) satisfies_

\[\begin{array}{l}N(x)\geq 0\ \ \mbox{and}\ \ N(x)=0\ \ \mbox{only}\ \ if\ \ x=0,\\ N(x+y)\leq N(x)+N(y),\\ N(\lambda x)=|\lambda|N(x)\end{array}\]

_for all \(x,y\in\mathbb{R}^{n}\) and \(\lambda\in\mathbb{R}\)._

1. _Prove that_ \(N\) _is bounded on the unit sphere._
2. _Prove that_ \(N\) _is continuous._
3. _Prove that there exist constants_ \(A>0\) _and_ \(B>0\)_, such that for all_ \(x\in\mathbb{R}^{n},A|x|\leq N(x)\leq B|x|\)_._

**Problem 2.1.7** (Fa97): _A map \(f:\mathbb{R}^{m}\to\mathbb{R}^{n}\) is proper if it is continuous and \(f^{-1}(B)\) is compact for each compact subset \(B\) of \(\mathbb{R}^{n}\); \(f\) is closed if it is continuous and \(f(A)\) is closed for each closed subset \(A\) of \(\mathbb{R}^{m}\)._

1. _Prove that every proper map_ \(f:\mathbb{R}^{m}\to\mathbb{R}^{n}\) _is closed._
2. _Prove that every one-to-one closed map_ \(f:\mathbb{R}^{m}\to\mathbb{R}^{n}\) _is proper._

**Problem 2.1.8** (Sp83): _Suppose that \(F:\mathbb{R}^{n}\to\mathbb{R}^{n}\) is continuous and satisfies_

\[\|F(x)-F(y)\|\geq\lambda\|x-y\|\]

_for all \(x,y\in\mathbb{R}^{n}\) and some \(\lambda>0\). Prove that \(F\) is one-to-one, onto, and has a continuous inverse._

_Note: See also Problem 1.2.9._

### Differential Calculus

**Problem 2.2.1** (Sp93): _Prove that \(\frac{x^{2}+y^{2}}{4}\leq e^{x+y-2}\) for \(x\geq 0\,,\ y\geq 0\,.\)_

**Problem 2.2.2** (Fa86): _Let \(f:\mathbb{R}^{2}\to\mathbb{R}\) be defined by:_

\[f(x,y)=\left\{\begin{array}{ll}x^{4/3}\sin(y/x)&if\quad x\neq 0\\ 0&if\quad x=0\,.\end{array}\right.\]

_Determine all points at which \(f\) is differentiable and all points at which \(f\) is not differentiable._

**Problem 2.2.3** (Sp80, Fa92): _Let \(f:\mathbb{R}^{n}\to\mathbb{R}^{n}\) be continuously differentiable. Assume the Jacobian matrix \((\partial f_{i}/\partial x_{j})\) has rank n everywhere. Suppose \(f\) is proper; that is, \(f^{-1}(K)\) is compact whenever \(K\) is compact. Prove \(f(\mathbb{R}^{n})=\mathbb{R}^{n}\)._

**Problem 2.2.4** (Sp89): _Suppose f is a continuously differentiable function of \(\mathbb{R}^{2}\) into \(\mathbb{R}^{2}\). Assume that f has only finitely many singular points, and that for each positive number \(M\), the set \(\{z\in\mathbb{R}^{2}\mid|f(z)|\leq M\}\) is bounded. Prove that f maps \(\mathbb{R}^{2}\) onto \(\mathbb{R}^{2}\)._

**Problem 2.2.5** (Fa81): _Let \(f\) be a real valued function on \(\mathbb{R}^{n}\) of class \(C^{2}\). A point \(x\in\mathbb{R}^{n}\) is a critical point of f if all the partial derivatives of f vanish at x; a critical point is nondegenerate if the \(n\times n\) matrix_

\[\left(\frac{\partial^{2}f}{\partial x_{i}\partial x_{j}}(x)\right)\]

_is nonsingular._

_Let x be a nondegenerate critical point of f. Prove that there is an open neighborhood of x which contains no other critical points (i.e., the nondegenerate critical points are isolated)._

**Problem 2.2.6** (Su80): _Let \(f:\mathbb{R}^{n}\to\mathbb{R}\) be a function whose partial derivatives of order \(\leq 2\) are everywhere defined and continuous._

1. _Let_ \(a\in\mathbb{R}^{n}\) _be a critical point of f (i.e.,_ \(\frac{\partial f}{\partial x_{j}}(a)=0,\;i=1,\ldots,n\)_). Prove that a is a local minimum provided the Hessian matrix_ \[\left(\frac{\partial^{2}f}{\partial x_{i}\partial x_{j}}\right)\] _is positive definite at x_ \(=a\)_._
2. _Assume the Hessian matrix is positive definite at all x. Prove that f has, at most, one critical point._

**Problem 2.2.7** (Fa88): _Prove that a real valued \(C^{3}\) function \(f\) on \(\mathbb{R}^{2}\) whose Laplacian,_

\[\frac{\partial^{2}f}{\partial x^{2}}+\frac{\partial^{2}f}{\partial y^{2}}\,,\]

_is everywhere positive cannot have a local maximum._

**Problem 2.2.8** (Su82): _Let \(f:\mathbb{R}^{3}\to\mathbb{R}^{2}\) and assume that \(0\) is a regular value of \(f\) (i.e., the differential of \(f\) has rank \(2\) at each point of \(f^{-1}(0)\)). Prove that \(\mathbb{R}^{3}\setminus f^{-1}(0)\) is arcwise connected._

**Problem 2.2.9** (Sp87): _Let the transformation \(T\) from the subset \(U=\{(u,v)\mid u>v\}\) of \(\mathbb{R}^{2}\) into \(\mathbb{R}^{2}\) be defined by \(T(u,v)=(u+v,u^{2}+v^{2})\)._

1. _Prove that_ \(T\) _is locally one-to-one._
2. _Determine the range of_ \(T\)_, and show that_ \(T\) _is globally one-to-one._

**Problem 2.2.10** (Fa91): _Let \(f\) be a \(C^{1}\) function from the interval \((-1,1)\) into \(\mathbb{R}^{2}\) such that \(f(0)=0\) and \(f^{\prime}(0)\neq 0\). Prove that there is a number \(\varepsilon\) in \((0,1)\) such that \(\|f(t)\|\) is an increasing function of \(t\) on \((0,\varepsilon)\)._

**Problem 2.2.11** (Fa80): _For a real 2\(\times\)2 matrix_

\[X=\left(\begin{array}{cc}x&y\\ z&t\end{array}\right),\]

_let \(\|X\|=x^{2}+y^{2}+z^{2}+t^{2}\), and define a metric by \(d(X,Y)=\|X-Y\|\). Let \(\Sigma=\{X\mid\det(X)=0\}\). Let_

\[A=\left(\begin{array}{cc}1&0\\ 0&2\end{array}\right).\]

_Find the minimum distance from \(A\) to \(\Sigma\) and exhibit an \(S\in\Sigma\) that achieves this minimum._

**Problem 2.2.12** (Su80): _Let \(S\subset\mathbb{R}^{3}\) denote the ellipsoidal surface defined by_

\[2x^{2}+(y-1)^{2}+(z-10)^{2}=1.\]

_Let \(T\subset\mathbb{R}^{3}\) denote the surface defined by_

\[z=\frac{1}{x^{2}+y^{2}+1}.\]

_Prove that there exist points in \(p\in S,\ q\in T\), such that the line \(\overline{pq}\) is perpendicular to \(S\) at \(p\) and to \(T\) at \(q\)._

**Problem 2.2.13** (Sp80): _Let \(P_{2}\) denote the set of real polynomials of degree \(\leq 2\). Define the map \(J:P_{2}\to\mathbb{R}\) by_

\[J(f)=\int_{0}^{1}f(x)^{2}\,dx\,.\]

_Let \(Q=\{f\in P_{2}\mid f(1)=1\}\). Show that \(J\) attains a minimum value on \(Q\) and determine where the minimum occurs._

**Problem 2.2.14** (Fa78): _Let \(W\subset\mathbb{R}^{n}\) be an open connected set and \(f\) a real valued function on \(W\) such that all partial derivatives of \(f\) are \(0\). Prove that \(f\) is constant._

**Problem 2.2.15** (Sp77): _In \(\mathbb{R}^{2}\), consider the region \(\mathcal{A}\) defined by \(x^{2}+y^{2}>1\). Find differentiable real valued functions \(f\) and \(g\) on \(\mathcal{A}\) such that \(\frac{\partial f}{\partial x}=\frac{\partial g}{\partial y}\) but there is no real valued function \(h\) on \(\mathcal{A}\) such that \(f=\frac{\partial h}{\partial y}\) and \(g=\frac{\partial h}{\partial x}\)._

_Hint: Why would Green's Theorem fail to apply?_

**Problem 2.2.16** (Sp77): _Suppose that \(u(x,t)\) is a continuous function of the real variables x and t with continuous second partial derivatives. Suppose that \(u\) and its first partial derivatives are periodic in x with period \(1\), and that_

\[\frac{\partial^{2}u}{\partial x^{2}}=\frac{\partial^{2}u}{\partial t^{2}}.\]

_Prove that_

\[E(t)=\frac{1}{2}\int_{0}^{1}\left(\left(\frac{\partial u}{\partial t}\right)^{ 2}+\left(\frac{\partial u}{\partial x}\right)^{2}\right)\,dx\]

_is a constant independent of \(t\)._

**Problem 2.2.17** (Su77): _Let \(f(x,t)\) be a \(C^{1}\) function such that \(\frac{\partial f}{\partial x}=\frac{\partial f}{\partial t}\). Suppose that \(f(x,0)>0\) for all \(x\). Prove that \(f(x,t)>0\) for all x and t._

**Problem 2.2.18** (Fa77): _Let \(f:\mathbb{R}^{n}\rightarrow\mathbb{R}\) have continuous partial derivatives and satisfy_

\[\left|\frac{\partial f}{\partial x_{j}}(x)\right|\leq K\]

_for all \(x=(x_{1},\ldots,x_{n})\), \(j=1,\ldots,n\). Prove that_

\[|f(x)-f(y)|\leq\sqrt{n}K\|x-y\|\]

_(where \(\|u\|=\sqrt{u_{1}^{2}+\cdots+u_{n}^{2}}\) )._

**Problem 2.2.19** (Fa83, Sp87): _Let \(f:\mathbb{R}^{n}\setminus\{0\}\rightarrow\mathbb{R}\) be a function which is continuously differentiable and whose partial derivatives are uniformly bounded:_

\[\left|\frac{\partial f}{\partial x_{i}}(x_{1},\ldots,x_{n})\right|\leq M\]

_for all \((x_{1},\ldots,x_{n})\neq(0,\ldots,0)\). Show that if \(n\geq 2\), then \(f\) can be extended to a continuous function defined on all of \(\mathbb{R}^{n}\). Show that this is false if \(n=1\) by giving a counterexample._

**Problem 2.2.20** (Sp79): _Let \(f:\mathbb{R}^{n}\setminus\{0\}\rightarrow\mathbb{R}\) be differentiable. Suppose_

\[\lim_{x\to 0}\frac{\partial f}{\partial x_{j}}(x)\]exists for each \(j=1,\ldots,n\)._

1. _Can_ \(f\) _be extended to a continuous map from_ \(\mathbb{R}^{n}\) _to_ \(\mathbb{R}\)_?_
2. _Assuming continuity at the origin, is_ \(f\) _differentiable from_ \(\mathbb{R}^{n}\) _to_ \(\mathbb{R}\)_?_

**Problem 2.2.21** (Sp82): _Let \(f:\mathbb{R}^{2}\to\mathbb{R}\) have directional derivatives in all directions at the origin. Is \(f\) differentiable at the origin? Prove or give a counterexample._

**Problem 2.2.22** (Fa78): _Let \(f:\mathbb{R}^{n}\to\mathbb{R}\) have the following properties: f is differentiable on \(\mathbb{R}^{n}\setminus\{0\}\), f is continuous at \(0\), and_

\[\lim_{p\to 0}\frac{\partial f}{\partial x_{i}}(p)=0\]

_for \(i=1,\ldots,n\). Prove that \(f\) is differentiable at \(0\)._

**Problem 2.2.23** (Su78): _Let \(U\subset\mathbb{R}^{n}\) be a convex open set and \(f:U\to\mathbb{R}^{n}\) a differentiable function whose partial derivatives are uniformly bounded but not necessarily continuous. Prove that f has a unique continuous extension to the closure of \(U\)._

**Problem 2.2.24** (Fa78):
1. _Show that if_ \(u,v:\mathbb{R}^{2}\to\mathbb{R}\) _are continuously differentiable and_ \(\frac{\partial u}{\partial y}=\frac{\partial y}{\partial x}\)_, then_ \(u=\frac{\partial f}{\partial x}\)_,_ \(v=\frac{\partial f}{\partial y}\) _for some_ \(f:\mathbb{R}^{2}\to\mathbb{R}\)_._
2. _Prove there is no_ \(f:\mathbb{R}^{2}\setminus\{0\}\to\mathbb{R}\) _such that_ \[\frac{\partial f}{\partial x}=\frac{-y}{x^{2}+y^{2}}\quad\text{and}\quad\frac{ \partial f}{\partial y}=\frac{x}{x^{2}+y^{2}}.\]

**Problem 2.2.25** (Su79): _Let \(f:\mathbb{R}^{3}\to\mathbb{R}\) be such that_

\[f^{-1}(0)=\{x\in\mathbb{R}^{3}\mid\|x\|=1\}.\]

_Suppose \(f\) has continuous partial derivatives of orders \(\leq 2\). Is there a \(y\in\mathbb{R}^{3}\) with \(\|y\|\leq 1\) such that_

\[\frac{\partial^{2}f}{\partial x_{1}^{2}}(y)+\frac{\partial^{2}f}{\partial x_{ 2}^{2}}(y)+\frac{\partial^{2}f}{\partial x_{3}^{2}}(y)\geq 0\ \?\]

**Problem 2.2.26** (Sp92): _Let \(f\) be a differentiable function from \(\mathbb{R}^{n}\) to \(\mathbb{R}^{n}\). Assume that there is a differentiable function \(g\) from \(\mathbb{R}^{n}\) to \(\mathbb{R}\) having no critical points such that \(g\circ f\) vanishes identically. Prove that the Jacobian determinant of \(f\) vanishes identically._

**Problem 2.2.27** (Fa83): _Let \(f,g:\mathbb{R}\to\mathbb{R}\) be smooth functions with \(f(0)=0\) and \(f^{\prime}(0)\neq 0\). Consider the equation \(f(x)=tg(x)\), \(t\in\mathbb{R}\)._1. _Show that in a suitably small interval_ \(|t|<\delta\)_, there is a unique continuous function_ \(x(t)\) _which solves the equation and satisfies_ \(x(0)=0\)_._
2. _Derive the first order Taylor expansion of_ \(x(t)\) _about_ \(t=0\)_._

**Problem 2.2.28** (Sp78): _Consider the system of equations_

\[\begin{array}{c}3x+y-z+u^{4}=0\\ x-y+2z+u=0\\ 2x+2y-3z+2u=0\end{array}\]

1. _Prove that for some_ \(\varepsilon>0\)_, the system can be solved for_ \((x,y,u)\) _as a function of_ \(z\in[-\varepsilon,\varepsilon]\)_, with_ \(x(0)=y(0)=u(0)=0\)_. Are such functions_ \(x(z)\)_,_ \(y(z)\) _and_ \(u(z)\) _continuous? Differentiable? Unique?_
2. _Show that the system cannot be solved for_ \((x,y,z)\) _as a function of_ \(u\in[-\delta,\delta]\)_, for all_ \(\delta>0\)_._

**Problem 2.2.29** (Sp81): _Describe the two regions in \((a,b)\)-space for which the function_

\[f_{a,b}(x,y)=ay^{2}+bx\,;\]

_restricted to the circle \(x^{2}+y^{2}=1\), has exactly two, and exactly four critical points, respectively._

**Problem 2.2.30** (Fa87): _Let \(u\) and v be two real valued \(C^{1}\) functions on \(\mathbb{R}^{2}\) such that the gradient \(\nabla u\) is never \(0\), and such that, at each point, \(\nabla v\) and \(\nabla u\) are linearly dependent vectors. Given \(p_{0}=(x_{0},y_{0})\in\mathbb{R}^{2}\), show that there is a \(C^{1}\) function \(F\) of one variable such that \(v(x,y)=F\left(u(x,y)\right)\) in some neighborhood of \(p_{0}\)._

**Problem 2.2.31** (Fa94): _Let \(f\) be a continuously differentiable function from \(\mathbb{R}^{2}\) into \(\mathbb{R}\). Prove that there is a continuous one-to-one function \(g\) from \([0,1]\) into \(\mathbb{R}^{2}\) such that the composite function \(f\circ g\) is constant._

**Problem 2.2.32** (Su84): _Let \(f:\mathbb{R}\rightarrow\mathbb{R}\) be \(C^{1}\) and let_

\[\begin{array}{l}u=f(x)\\ v=-y+xf(x).\end{array}\]

_If \(f^{\prime}(x_{0})\neq 0\), show that this transformation is locally invertible near \((x_{0},y_{0})\) and the inverse has the form_

\[\begin{array}{l}x=g(u)\\ y=-v+ug(u).\end{array}\]

**Problem 2.2.33** (Su79): _Let \(X\) be the space of orthogonal real \(n\times n\) matrices. Let \(v_{0}\in\mathbb{R}^{n}\). Locate and describe the elements of \(X\), where the map_

\[f:X\rightarrow\mathbb{R},\qquad\quad f(A)=\langle v_{0},Av_{0}\rangle\]

_takes its maximum and minimum values._

**Problem 2.2.34** (Su78): _Let \(M_{n\times n}\) denote the vector space of real n\(\times\)n matrices. Define a map \(f:M_{n\times n}\to M_{n\times n}\) by \(f(A)=A^{2}\). Find the derivative of \(f\) at \(B\in M_{n\times n}\)._

**Problem 2.2.35** (Su82): _Let \(M_{2\times 2}\) be the four-dimensional vector space of all 2\(\times\)2 real matrices and define \(f:M_{2\times 2}\to M_{2\times 2}\) by \(f(X)=X^{2}\)._

1. _Show that_ \(f\) _has a local inverse near the point_ \[X=\left(\begin{array}{cc}1&0\\ 0&1\end{array}\right).\]
2. _Show that_ \(f\) _does not have a local inverse near the point_ \[X=\left(\begin{array}{cc}1&0\\ 0&-1\end{array}\right).\]

**Problem 2.2.36** (Fa80): _Show that there is an \(\varepsilon>0\) such that if \(A\) is any real 2\(\times\)2 matrix satisfying \(|a_{ij}|\leq\varepsilon\) for all entries \(a_{ij}\) of \(A\), then there is a real 2\(\times\)2 matrix \(X\) such that \(X^{2}+X^{t}=A\), where \(X^{t}\) is the transpose of \(X\). Is \(X\) unique?_

**Problem 2.2.37** (Sp96): _Let \(M_{2\times 2}\) be the space of 2\(\times\)2 matrices over \(\mathbb{R}\), identified in the usual way with \(\mathbb{R}^{4}\). Let the function \(F\) from \(M_{2\times 2}\) into \(M_{2\times 2}\) be defined by_

\[F(X)=X+X^{2}.\]

_Prove that the range of \(F\) contains a neighborhood of the origin._

**Problem 2.2.38** (Fa78): _Let \(M_{n\times n}\) denote the vector space of \(n\times n\) real matrices (identified with \(\mathbb{R}^{n^{2}}\)). Prove that there are neighborhoods \(U\) and \(V\) in \(M_{n\times n}\) of the identity matrix such that for every \(A\) in \(U\), there is a unique \(X\) in \(V\) such that \(X^{4}=A\)._

**Problem 2.2.39** (Sp79, Fa93): _Let \(M_{n\times n}\) denote the vector space of \(n\times n\) real matrices for \(n\geq 2\). Let \(\det:M_{n\times n}\to\mathbb{R}\) be the determinant map._

1. _Show that_ \(\det\) _is_ \(C^{\infty}\)_._
2. _Show that the derivative of_ \(\det\) _at_ \(A\in M_{n\times n}\) _is zero if and only if_ \(A\) _has rank_ \(\leq n-2\)_._

**Problem 2.2.40** (Fa81): _Let \(A=(a_{ij})\) be an \(n\times n\) matrix whose entries \(a_{ij}\) are real valued differentiable functions defined on \(\mathbb{R}\). Assume that the determinant \(\det(A)\) of \(A\) is everywhere positive. Let \(B=(b_{ij})\) be the inverse matrix of \(A\). Prove the formula_

\[\frac{d}{dt}\log\left(\det(A)\right)=\sum_{i,j=1}^{n}\frac{da_{ij}}{dt}b_{ji}.\]

### 2.3 Integral Calculus

**Problem 2.3.1** (Sp78): _What is the volume enclosed by the ellipsoid_

\[\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}+\frac{z^{2}}{c^{2}}=1?\]

**Problem 2.3.2** (Sp78): _Evaluate_

\[\int_{\mathcal{A}}e^{-x^{2}-y^{2}}\,dxdy\,,\]

_where \(\mathcal{A}=\{(x,y)\in\mathbb{R}^{2}\mid x^{2}+y^{2}\leq 1\}\)._

**Problem 2.3.3** (Sp98): _Given the fact that \(\int_{-\infty}^{\infty}e^{-x^{2}}dx=\sqrt{\pi}\), evaluate the integral_

\[I=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(x^{2}+(y-x)^{2}+y^{2})} dx\ dy\.\]

**Problem 2.3.4** (Sp80): _Let \(\mathcal{S}=\{(x,y,z)\in\mathbb{R}^{3}\mid x^{2}+y^{2}+z^{2}=1\}\) denote the unit sphere in \(\mathbb{R}^{3}\). Evaluate the surface integral over S:_

\[\int_{\mathcal{S}}(x^{2}+y+z)\,dA\,.\]

**Problem 2.3.5** (Sp81): _Let \(\vec{i}\), \(\vec{j}\), and \(\vec{k}\) be the usual unit vectors in \(\mathbb{R}^{3}\). Let \(\vec{F}\) denote the vector field_

\[(x^{2}+y-4)\vec{i}+3xy\vec{j}+(2xz+z^{2})\vec{k}.\]

1. _Compute_ \(\nabla\times\vec{F}\) _(the curl of_ \(\vec{F}\)_)._
2. _Compute the integral of_ \(\nabla\times\vec{F}\) _over the surface_ \(x^{2}+y^{2}+z^{2}=16\)_,_ \(z\geq 0\)_._

**Problem 2.3.6** (Fa86): _Evaluate_

\[\int\!\!\int_{\mathcal{R}}(x^{3}-3xy^{2})\,dxdy\,,\]

_where_

\[\mathcal{R}=\{(x,y)\in\mathbb{R}^{2}\mid(x+1)^{2}+y^{2}\leq 9,\ \ (x-1)^{2}+y^ {2}\geq 1\}.\]

**Problem 2.3.7** (Sp91): _Let the vector field \(F\) in \(\mathbb{R}^{3}\) have the form_

\[F(r)=g(\|r\|)r\qquad\qquad(r\neq(0,0,0)),\]_where \(g\) is a real valued smooth function on \((0,\infty)\) and \(\|\cdot\|\) denotes the Euclidean norm. (\(F\) is undefined at \((0,0,0)\).) Prove that_

\[\int_{C}F\cdot ds=0\]

_for any smooth closed path \(C\) in \(\mathbb{R}^{3}\) that does not pass through the origin._

**Problem 2.3.8** (Fa91): _Let \(\mathcal{B}\) denote the unit ball of \(\mathbb{R}^{3}\), \(\mathcal{B}=\{r\in\mathbb{R}^{3}\mid\|r\|\leq 1\}.\) Let \(J=(J_{1},J_{2},J_{3})\) be a smooth vector field on \(\mathbb{R}^{3}\) that vanishes outside of \(\mathcal{B}\) and satisfies \(\vec{\nabla}\cdot\vec{J}=0\)._

1. _For_ \(f\) _a smooth, scalar-valued function defined on a neighborhood of_ \(\mathcal{B}\)_, prove that_ \[\int_{\mathcal{B}}\left(\vec{\nabla}f\right)\cdot\vec{J}\,dxdydz=0.\]
2. _Prove that_ \[\int_{\mathcal{B}}J_{1}\,dxdydz=0.\]

**Problem 2.3.9** (Fa94): _Let \(\mathcal{D}\) denote the open unit disc in \(\mathbb{R}^{2}\). Let \(u\) be an eigenfunction for the Laplacian in \(\mathcal{D}\); that is, a real valued function of class \(C^{2}\) defined in \(\overline{\mathcal{D}}\), zero on the boundary of \(\mathcal{D}\) but not identically zero, and satisfying the differential equation_

\[\frac{\partial^{2}u}{\partial x^{2}}+\frac{\partial^{2}u}{\partial y^{2}}= \lambda u\,,\]

_where \(\lambda\) is a constant. Prove that_

\[(*)\qquad\int\!\!\int_{\mathcal{D}}\left|\operatorname{grad}u\right|^{2}dxdy+ \lambda\int\!\!\int_{\mathcal{D}}u^{2}dxdy=0\,,\]

_and hence that \(\lambda<0\)._

**Problem 2.3.10** (Sp92): _Let \(f\) be a one-to-one \(C^{1}\) map of \(\mathbb{R}^{3}\) into \(\mathbb{R}^{3}\), and let \(J\) denote its Jacobian determinant. Prove that if \(x_{0}\) is any point of \(\mathbb{R}^{3}\) and \(Q_{r}(x_{0})\) denotes the cube with center \(x_{0}\), side length \(r\), and edges parallel to the coordinate axes, then_

\[|J(x_{0})|=\lim_{r\to 0}r^{-3}\mathrm{vol}\left(f(Q_{r}(x_{0}))\right)\leq \limsup_{x\to x_{0}}\frac{\|f(x)-f(x_{0})\|^{3}}{\|x-x_{0}\|^{3}}.\]

_Here, \(\|\cdot\|\) is the Euclidean norm in \(\mathbb{R}^{3}\)._Differential Equations

### 3.1 First Order Equations

**Problem 3.1.1** (Fa93): _Let \(n\) be an integer larger than \(1\). Is there a differentiable function on \([0,\infty)\) whose derivative equals its \(n^{th}\) power and whose value at the origin is positive?_

**Problem 3.1.2** (Fa77): _Show that the differential equation \(x^{\prime}=3x^{2}\) has no solution such that \(x(0)=1\) and \(x(t)\) is defined for all real numbers t._

**Problem 3.1.3** (Sp78): _Consider the differential equation_

\[\frac{dx}{dt}=x^{2}+t^{2},\quad x(0)=1.\]

1. _Prove that for some_ \(b>0\)_, there is a solution defined for_ \(t\in[0,b]\)_._
2. _Find an explicit value of_ \(b\) _having the property in Part 1._
3. _Find a_ \(c>0\) _such that there is no solution on_ \([0,c]\)_._

**Problem 3.1.4** (Sp78):
1. _For which real numbers_ \(\alpha>0\) _does the differential equation_ \[(*)\qquad\frac{dx}{dt}=x^{\alpha},\quad\ x(0)=0\,,\] _have a solution on some interval_ \([0,b],\,b>0\)2. _For which values of_ \(\alpha\) _are there intervals on which two solutions of_ \((*)\) _are defined?_

**Problem 3.1.5** (Su78): _Solve the differential equation \(g^{\prime}=2g\), \(g(0)=a\), where \(a\) is a real constant._

**Problem 3.1.6** (Fa78): _Solve the differential equation_

\[\frac{dy}{dx}=x^{2}y-3x^{2},\ \ \ \ y(0)=1.\]

**Problem 3.1.7** (Sp79): _Find all differentiable solutions to the differential equation_

\[y^{\prime}=\sqrt{y},\ \ \ \ \ \ y(0)=0\,.\]

**Problem 3.1.8** (Sp80): _Consider the differential equation_

\[x^{\prime}=\frac{x^{3}-x}{1+e^{x}}.\]

1. _Find all its constant solutions._
2. _Discuss_ \(\lim_{t\to\infty}x(t)\)_, where_ \(x(t)\) _is the solution such that_ \(x(0)=\frac{1}{2}\)_._

**Problem 3.1.9** (Su77, Su80, Sp82, Sp83): _Prove that the initial value problem_

\[\frac{dx}{dt}=3x+85\cos x,\ \ \ \ x(0)=77\,,\]

_has a solution \(x(t)\) defined for all \(t\in\mathbb{R}\)._

**Problem 3.1.10** (Fa82): _Let \(f:\mathbb{R}\to\mathbb{R}\) be a continuous nowhere vanishing function, and consider the differential equation_

\[(*)\ \ \ \ \ \ \frac{dy}{dx}=f(y).\]

1. _For each real number_ \(c\)_, show that_ \((*)\) _has a unique, continuously differentiable solution_ \(y=y(x)\) _on a neighborhood of_ \(0\) _which satisfies the initial condition_ \(y(0)\) _=_ \(c\)_._
2. _Deduce the conditions on_ \(f\) _under which the solution_ \(y\) _exists for all_ \(x\in\mathbb{R}\)_, for every initial value_ \(c\)_._

**Problem 3.1.11** (Fa82): _Find all pairs of \(C^{\infty}\) functions \(x(t)\) and \(y(t)\) on \(\mathbb{R}\) satisfying_

\[x^{\prime}(t)=2x(t)-y(t),\ \ \ \ \ \ y^{\prime}(t)=x(t).\]

**Problem 3.1.12** (Sp83): _Find all solutions \(y:\mathbb{R}\to\mathbb{R}\) to_

\[\frac{dy}{dx}=\left(y(y-2)\right)^{1/2},\ \ \ \ \ y(0)=0.\]

**Problem 3.1.13** (Su83): _Find all real valued \(C^{1}\) solutions \(u\) of the differential equation_

\[x\frac{du}{dx}+u=x\ \ \ \ (-1<x<1).\]

**Problem 3.1.14** (Fa83):
1. _Let_ \(u(t)\) _be a real valued differentiable function of a real variable_ \(t\) _which satisfies an inequality of the form_ \[u^{\prime}(t)\leq au(t),\ \ \ t\geq 0,\ \ \ u(0)\leq b,\] _where_ \(a\) _and_ \(b\) _are positive constants. Starting from first principles, derive an upper bound for_ \(u(t)\) _for_ \(t>0\)_._
2. _Let_ \(x(t)=(x_{1}(t),x_{2}(t),\ldots,x_{n}(t))\) _be a differentiable function from_ \(\mathbb{R}\) _to_ \(\mathbb{R}^{n}\) _which satisfies a differential equation of the form_ \[x^{\prime}(t)=f(x(t)),\] _where_ \(f:\mathbb{R}^{n}\to\mathbb{R}^{n}\) _is a continuous function. Assuming that_ \(f\) _satisfies the condition_ \[\langle f(y),y\rangle\leq\|y\|^{2},\ \ \ y\in\mathbb{R}^{n}\] _(where_ \(\langle\cdot,\cdot\rangle\) _and_ \(\|\cdot\|\) _denote the Euclidean inner product and norm), derive an inequality showing that the norm_ \(\|x(t)\|\) _grows, at most, exponentially._

**Problem 3.1.15** (Sp84): _Consider the equation_

\[\frac{dy}{dx}=y-\sin y.\]

_Show that there is an \(\varepsilon>0\) such that if \(|y_{0}|<\varepsilon\), then the solution \(y=f(x)\) with \(f(0)=y_{0}\) satisfies_

\[\lim_{x\to-\infty}f(x)=0.\]

**Problem 3.1.16** (Fa84): _Consider the differential equation_

\[\frac{dy}{dx}=3xy+\frac{y}{1+y^{2}}.\]

_Prove_

1. _For each_ \(n=1,2,\ldots\)_, there is a unique solution_ \(y=f_{n}(x)\) _defined for_ \(0\leq x\leq 1\) _such that_ \(f_{n}(0)=1/n\)_._
2. \(\lim_{n\to\infty}f_{n}(1)=0\)

**Problem 3.1.17** (Fa85): _Let \(y(t)\) be a real valued solution, defined for \(0<t<\infty\) of the differential equation_

\[\frac{dy}{dt}=e^{-y}-e^{-3y}+e^{-5y}.\]

_Show that \(y(t)\rightarrow+\infty\) as \(t\rightarrow+\infty\)._

**Problem 3.1.18** (Fa86): _Prove the following theorem, or find a counterexample: If \(p\) and \(q\) are continuous real valued functions on \(\mathbb{R}\) such that \(|q(x)|\leq|p(x)|\) for all \(x\), and if every solution \(f\) of the differential equation_

\[f^{\prime}+qf=0\]

_satisfies \(\lim_{x\rightarrow+\infty}f(x)=0\), then every solution \(f\) of the differential equation_

\[f^{\prime}+pf=0\]

_satisfies \(\lim_{x\rightarrow+\infty}f(x)=0\)._

**Problem 3.1.19** (Fa86): _Discuss the solvability of the differential equation_

\[(e^{x}\sin y)(y^{\prime})^{3}+(e^{x}\cos y)y^{\prime}+e^{y}\tan x=0\]

_with the initial condition \(y(0)=0\). Does a solution exist in some interval about \(0\)? If so, is it unique?_

**Problem 3.1.20** (Fa92): _Let \(f\) and \(g\) be positive continuous functions on \(\mathbb{R}\), with \(g\leq f\) everywhere. Assume the initial value problem_

\[\frac{dx}{dt}=f(x),\quad x(0)=0,\]

_has a solution defined on all of \(\mathbb{R}\). Prove that the initial value problem_

\[\frac{dx}{dt}=g(x),\quad x(0)=0,\]

_also has a solution defined on all of \(\mathbb{R}\)._

**Problem 3.1.21** (Sp93): _Prove that every solution \(x(t)\)\((t\geq 0)\) of the differential equation_

\[\frac{dx}{dt}=x^{2}-x^{6}\]

_with \(x(0)>0\) satisfies \(\lim_{t\rightarrow\infty}x(t)=1\)._

**Problem 3.1.22** (Sp95): _Let \(f:\mathbb{R}\rightarrow\mathbb{R}\) be a bounded continuously differentiable function. Show that every solution of \(y^{\prime}(x)=f\left(y(x)\right)\) is monotone._

**Problem 3.1.23** (Fa87): _Find a curve \(C\) in \(\mathbb{R}^{2}\), passing through the point \((3,2)\), with the following property: Let \(L(x_{0},y_{0})\) be the segment of the tangent line to \(C\) at \((x_{0},y_{0})\) which lies in the first quadrant. Then each point \((x_{0},y_{0})\) of \(C\) is the midpoint of \(L(x_{0},y_{0})\)._

### Second Order Equations

**Problem 3.2.1** (Sp97): _Suppose that \(f^{\prime\prime}(x)=(x^{2}-1)f(x)\) for all \(x\in\mathbb{R}\), and that \(f(0)=1\), \(f^{\prime}(0)=0\). Show that \(f(x)\to 0\) as \(x\to\infty\)._

**Problem 3.2.2** (Sp77): _Find the solution of the differential equation_

\[y^{\prime\prime}-2y^{\prime}+y=0,\]

_subject to the conditions_

\[y(0)=1,\ \ \ \ y^{\prime}(0)=1.\]

**Problem 3.2.3** (Fa77): _Find all solutions of the differential equation_

\[\frac{d^{2}x}{dt^{2}}-2\frac{dx}{dt}+x=\sin t\]

_subject to the condition \(x(0)=1\) and \(x^{\prime}(0)=0\)._

**Problem 3.2.4** (Su79): _Let \(x:\mathbb{R}\to\mathbb{R}\) be a solution to the differential equation_

\[5x^{\prime\prime}+10x^{\prime}+6x=0.\]

_Prove that the map \(f:\mathbb{R}\to\mathbb{R}\),_

\[f(t)=\frac{x(t)^{2}}{1+x(t)^{4}}\]

_attains a maximum value._

**Problem 3.2.5** (Su84): _Let \(x(t)\) be the solution of the differential equation_

\[x^{\prime\prime}(t)+8x^{\prime}(t)+25x(t)=2\cos t\]

_with initial conditions \(x(0)=0\) and \(x^{\prime}(0)=0\). Show that for suitable constants \(\alpha\) and \(\delta\),_

\[\lim_{t\to\infty}(x(t)-\alpha\cos(t-\delta))=0.\]

**Problem 3.2.6** (Fa79, Su81, Fa92): _Let \(y=y(x)\) be a solution of the differential equation \(y^{\prime\prime}=-|y|\) with \(-\infty<x<\infty\), \(y(0)=1\) and \(y^{\prime}(0)=0\)._

1. _Show that_ \(y\) _is an even function._
2. _Show that_ \(y\) _has exactly one zero on the positive real axis._

**Problem 3.2.7** (Fa80): _Consider the differential equation \(x^{\prime\prime}+x^{\prime}+x^{3}=0\) and the function \(f(x,x^{\prime})=(x+x^{\prime})^{2}+(x^{\prime})^{2}+x^{4}\)._

1. _Show that_ \(f\) _decreases along trajectories of the differential equation._
2. _Show that if_ \(x(t)\) _is any solution, then_ \((x(t),x^{\prime}(t))\) _tends to_ \((0,0)\) _as_ \(t\to\infty\)_._

**Problem 3.2.8** (Fa95): _Determine all real numbers \(L>1\) so that the boundary value problem_

\[x^{2}y^{\prime\prime}(x)+y(x)=0,\qquad 1\leq x\leq L\]

\[y(1)=y(L)=0\]

_has a nonzero solution._

**Problem 3.2.9** (Fa83): _For which real values of \(p\) does the differential equation_

\[y^{\prime\prime}+2py^{\prime}+y=3\]

_admit solutions \(y=f(x)\) with infinitely many critical points?_

**Problem 3.2.10** (Sp87): _Let \(p\), \(q\) and \(r\) be continuous real valued functions on \(\mathbb{R}\), with \(p>0\). Prove that the differential equation_

\[p(t)x^{\prime\prime}(t)+q(t)x^{\prime}(t)+r(t)x(t)=0\]

_is equivalent to (i.e., has exactly the same solutions as) a differential equation of the form_

\[\left(a(t)x^{\prime}(t)\right)^{\prime}+b(t)x(t)=0,\]

_where a is continuously differentiable and \(b\) is continuous._

**Problem 3.2.11** (Fa93): _Let the function \(x(t)\)\((-\infty<t<\infty)\) be a solution of the differential equation_

\[\frac{d^{2}x}{dt^{2}}-2b\,\frac{dx}{dt}+cx=0\]

_such that \(x(0)=x(1)=0\). (Here, \(b\) and \(c\) are real constants.) Prove that \(x(n)=0\) for every integer \(n\)._

**Problem 3.2.12** (Sp93): _Let \(k\) be a positive integer. For which values of the real number \(c\) does the differential equation_

\[\frac{d^{2}x}{dt^{2}}-2c\frac{dx}{dt}+x=0\]

_have a solution satisfying \(x(0)=x(2\pi k)=0\)?_

**Problem 3.2.13** (Sp85): _Let \(h>0\) be given. Consider the linear difference equation_

\[(\star)\quad\quad\frac{y\left((n+2)h\right)-2y\left((n+1)h\right)+y(nh)}{h^{2} }=-y(nh),\quad n=0,1,2,\ldots.\]

_(Note the analogy with the differential equation \(y^{\prime\prime}=-y\).)_

1. _Find the general solution of_ \((\star)\) _by trying suitable exponential substitutions._
2. _Find the solution with_ \(y(0)=0\) _and_ \(y(h)=h\)_. Denote it by_ \(S_{h}(nh)\)_,_ \(n=1,2,\ldots\)_._
3. _Let_ \(x\) _be fixed and_ \(h=x/n\)_. Show that_ \[\lim_{n\to\infty}S_{x/n}(nx/n)=\sin(x).\]

[MISSING_PAGE_FAIL:53]

### Systems of Differential Equations

**Problem 3.4.1** (Sp79): _Consider the system of differential equations:_

\[\frac{dx}{dt} =y+tz\] \[\frac{dy}{dt} =z+t^{2}x\] \[\frac{dz}{dt} =x+e^{t}y.\]

_Prove there exists a solution defined for all \(t\in[0,1]\), such that_

\[\left(\begin{array}{ccc}1&2&3\\ 4&5&6\\ 7&8&9\end{array}\right)\ \ \left(\begin{array}{c}x(0)\\ y(0)\\ z(0)\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ 0\end{array}\right)\]

_and also_

\[\int_{0}^{1}\left(x(t)^{2}+y(t)^{2}+z(t)^{2}\right)dt=1.\]

**Problem 3.4.2** (Su79): _Find real valued functions of a real variable, \(x(t)\), \(y(t)\), and \(z(t)\), such that_

\[x^{\prime}=y,\qquad y^{\prime}=z,\qquad z^{\prime}=y\]

_and_

\[x(0)=1,\qquad y(0)=2,\qquad z(0)=3.\]

**Problem 3.4.3** (Fa79, Su85): _Solve the differential equations_

\[\frac{dx}{dt}=-3x+10y,\]

\[\frac{dy}{dt}=-3x+8y.\]

**Problem 3.4.4** (Su80): _Consider the differential equation_

\[\frac{dx}{dt}=-x+y,\ \ \ \ \frac{dy}{dt}=\log(20+x)-y.\]

_Let \(x(t)\) and \(y(t)\) be a solution defined for all \(t\geq 0\) with \(x(0)>0\) and \(y(0)>0\). Prove that \(x(t)\) and \(y(t)\) are bounded._

**Problem 3.4.5** (Sp81): _Consider the system of differential equations_

\[\frac{dx}{dt} =y+x(1-x^{2}-y^{2})\] \[\frac{dy}{dt} =-x+y(1-x^{2}-y^{2}).\]1. _Show that for any_ \(x_{0}\) _and_ \(y_{0}\)_, there is a unique solution_ \((x(t),y(t))\) _defined for all_ \(t\in\mathbb{R}\) _such that_ \(x(0)=x_{0}\)_,_ \(y(0)=y_{0}\)_._
2. _Show that if_ \(x_{0}\neq 0\) _and_ \(y_{0}\neq 0\)_, the solution referred to in Part 1 approaches the circle_ \(x^{2}+y^{2}=1\) _as_ \(t\to\infty\)_._

**Problem 3.4.6** (Fa81): _Consider an autonomous system of differential equations_

\[\frac{dx_{i}}{dt}=F_{i}(x_{1},\ldots,x_{n}),\]

_where \(F=(F_{1},\ldots,F_{n}):\mathbb{R}^{n}\to\mathbb{R}^{n}\) is a \(C^{1}\) vector field._

1. _Let_ \(U\) _and_ \(V\) _be two solutions on_ \(a<t<b\)_. Assuming that_ \[\langle DF(x)z,z\rangle\leq 0\] _for all x, z in_ \(\mathbb{R}^{n}\)_, show that_ \(|U(t)-V(t)|^{2}\) _is a decreasing function of_ \(t\)_._
2. _Let_ \(W(t)\) _be a solution defined for_ \(t>0\)_. Assuming that_ \[\langle DF(x)z,z\rangle\leq-|z|^{2},\] _show that there exists_ \(C\in\mathbb{R}^{n}\) _such that_ \[\lim_{t\to\infty}W(t)=C.\]

**Problem 3.4.7** (Fa81): _Let \(V:\mathbb{R}^{n}\to\mathbb{R}\) be a \(C^{1}\) function and consider the system of second order differential equations_

\[x_{i}^{\prime\prime}(t)=f_{i}\left(x(t)\right),\ \ \ \ 1\leq i\leq n,\]

_where_

\[f_{i}=-\frac{\partial V}{\partial x_{i}}.\]

_Let \(x(t)=(x_{1}(t),\ldots,x_{n}(t))\) be a solution of this system on a finite interval \(a<t<b\)._

1. _Show that the function_ \[H(t)=\frac{1}{2}\langle x^{\prime}(t),x^{\prime}(t)\rangle+V(x(t))\] _is constant for_ \(a<t<b\)_._
2. _Assuming that_ \(V(x)\geq M>-\infty\) _for all_ \(x\in\mathbb{R}^{n}\)_, show that_ \(x(t)\)_,_ \(x^{\prime}(t)\)_, and_ \(x^{\prime\prime}(t)\) _are bounded on_ \(a<t<b\)_, and then prove all three limits_ \[\lim_{t\to b}x(t),\ \ \ \lim_{t\to b}x^{\prime}(t),\ \ \ \lim_{t\to b}x^{\prime\prime}(t)\] _exist._

**Problem 3.4.8** (Sp84): _Show that the system of differential equations_

\[\frac{d}{dt}\left(\begin{array}{c}x\\ y\\ z\end{array}\right)=\left(\begin{array}{ccc}0&1&0\\ 2&0&0\\ 0&0&3\end{array}\right)\left(\begin{array}{c}x\\ y\\ z\end{array}\right)\]

_has a solution which tends to \(\infty\) as \(t\rightarrow-\infty\) and tends to the origin as \(t\rightarrow+\infty\)._

**Problem 3.4.9** (Sp91): _Let x(t) be a nontrivial solution to the system_

\[\frac{dx}{dt}=Ax,\]

_where_

\[A=\left(\begin{array}{ccc}1&6&1\\ -4&4&11\\ -3&-9&8\end{array}\right).\]

_Prove that \(\|x(t)\|\) is an increasing function of t. (Here, \(\|\cdot\|\) denotes the Euclidean norm.)_

**Problem 3.4.10** (Su84): _Consider the solution curve \((x(t),y(t))\) to the equations_

\[\frac{dx}{dt}=1+\frac{1}{2}x^{2}\sin y\] \[\frac{dy}{dt}=3-x^{2}\]

_with initial conditions \(x(0)=0\) and \(y(0)=0\). Prove that the solution must cross the line \(x=1\) in the \(xy\) plane by the time \(t=2\)._

**Problem 3.4.11** (Fa84): _Consider the differential equation_

\[\frac{dx}{dt}=y,\;\;\;\frac{dy}{dt}=-ay-x^{3}-x^{5},\;\;where\;\;a>0.\]

1. _Show that_ \[F(x,y)=\frac{y^{2}}{2}+\frac{x^{4}}{4}+\frac{x^{6}}{6}\] _decreases along solutions._
2. _Show that for any_ \(\varepsilon>0\)_, there is a_ \(\delta>0\) _such that whenever_ \(\|\left(x(0),y(0)\right)\|<\delta\)_, there is a unique solution_ \((x(t),y(t))\) _of the given equations with the initial condition_ \((x(0),y(0))\) _which is defined for all_ \(t\geq 0\) _and satisfies_ \(\|\left(x(t),y(t)\right)\|<\varepsilon\)

**Problem 3.4.12** (Sp86): _For \(\lambda\) a real number, find all solutions of the integral equations_

\[\varphi(x)=e^{x}+\lambda\int_{0}^{x}e^{(x-y)}\varphi(y)\,dy,\ \ \ \ \ 0\leq x\leq 1,\]

\[\psi(x)=e^{x}+\lambda\int_{0}^{1}e^{(x-y)}\psi(y)\,dy,\ \ \ \ \ 0\leq x\leq 1.\]

**Problem 3.4.13** (Sp86): _Let \(V\) be a finite-dimensional vector space (over \(\mathbb{C}\) ) of \(C^{\infty}\) complex valued functions on \(\mathbb{R}\) (the linear operations being defined pointwise). Prove that if \(V\) is closed under differentiation (i.e., if \(f^{\prime}(x)\) belongs to \(V\) whenever \(f(x)\) does), then \(V\) is closed under translations (i.e., \(f(x+a)\) belongs to \(V\) whenever \(f(x)\) does, for all real numbers \(a\))._

**Problem 3.4.14** (Fa88): _Let the real valued functions \(f_{1},\ldots,f_{n+1}\) on \(\mathbb{R}\) satisfy the system of differential equations_

\[\begin{array}{l}f^{\prime}_{k+1}+f^{\prime}_{k}=(k+1)f_{k+1}-kf_{k},\ \ k=1,\ldots,n\\ f^{\prime}_{n+1}=-(n+1)f_{n+1}.\end{array}\]

_Prove that for each \(k\),_

\[\lim_{t\to\infty}f_{k}(t)=0.\]

**Problem 3.4.15** (Fa91): _Consider the vector differential equation_

\[\frac{dx(t)}{dt}=A(t)x(t)\]

_where \(A\) is a smooth \(n\times n\) function on \(\mathbb{R}\). Assume \(A\) has the property that \(\langle\Lambda(t)y,y\rangle\leq c\|y\|^{2}\) for all \(y\) in \(\mathbb{R}^{n}\) and all \(t\), where \(c\) is a fixed real number. Prove that any solution \(x(t)\) of the equation satisfies \(\|x(t)\|\leq e^{ct}\|x(0)\|\) for all \(t>0\). Hint: Consider first the case \(n=1\)._

**Problem 3.4.16** (Sp94): _Let \(W\) be a real 3\(\times\)3 antisymmetric matrix (i.e., \(W^{t}=-W\)). Let the function_

\[X(t)=\left(\begin{array}{c}x_{1}(t)\\ x_{2}(t)\\ x_{3}(t)\end{array}\right)\]

_be a real solution of the vector differential equation \(dX/dt=WX\)._

1. _Prove that_ \(\|X(t)\|\)_, the Euclidean norm of_ \(X(t)\)_, is independent of_ \(t\)_._
2. _Prove that if_ \(v\) _is a vector in the null space of_ \(W\)_, then_ \(X(t)\cdot v\) _is independent of_ \(t\)3. _Prove that the values_ \(X(t)\) _all lie on a fixed circle in_ \(\mathbb{R}^{3}\)_._

**Problem 3.4.17** (Sp80): _For each \(t\in\mathbb{R}\), let P(t) be a symmetric real \(n\times n\) matrix whose entries are continuous functions of \(t\). Suppose for all \(t\) that the eigenvalues of \(P(t)\) are all \(\leq-1\). Let \(x(t)=(x_{1}(t),\ldots,x_{n}(t))\) be a solution of the vector differential equation_

\[\frac{dx}{dt}=P(t)x.\]

_Prove_

\[\lim_{t\to\infty}x(t)=0.\]

_Hint: First prove that if \(u(t)\geq 0\) and \(u^{\prime}(t)\leq-u(t)\) for all \(t\), then \(u(t)\to 0\) as \(t\to\infty\)._

**Problem 3.4.18** (Sp89): _Let_

\[A=\left(\begin{array}{cccc}0&0&0&0\\ 1&0&0&0\\ 0&1&0&0\\ 0&0&1&0\end{array}\right),\qquad\qquad B=\left(\begin{array}{cccc}0&1&0&0\\ 0&0&1&0\\ 0&0&0&1\\ 0&0&0&0\end{array}\right)\]

_Find the general solution of the matrix differential equation \(dX/dt=AXB\) for the unknown 4\(\times\)4 matrix function \(X(t)\)._

## 4 Metric Spaces

### 4.1 Topology of \(\mathbb{R}^{n}\)

**Problem 4.1.1** (Sp86, Sp94, Sp96): _Let \(K\) be a compact subset of \(\mathbb{R}^{n}\) and \(\{B_{j}\}\) a sequence of open balls that covers \(K\). Prove that there is a positive number \(\varepsilon\) such that each \(\varepsilon\)-ball centered at a point of \(K\) is contained in one of the balls \(B_{j}\)._

**Problem 4.1.2** (Su81): _Prove or disprove: The set \(\mathbb{Q}\) of rational numbers is the intersection of a countable family of open subsets of \(\mathbb{R}\)._

**Problem 4.1.3** (Fa77): _Let \(X\subset\mathbb{R}\) be a nonempty connected set of real numbers. If every element of \(X\) is rational, prove \(X\) has only one element._

**Problem 4.1.4** (Su80): _Give an example of a subset of \(\mathbb{R}\) having uncountably many connected components. Can such a subset be open? Closed?_

**Problem 4.1.5** (Sp83): _Show that the interval \([0,1]\) cannot be written as a countably infinite disjoint union of closed subintervals of \([0,1]\)._

**Problem 4.1.6** (Su78): _Let \(X\) and \(Y\) be nonempty subsets of \(\mathbb{R}^{n}\). Define_

\[d(X,Y)=\inf\{|x-y|\mid x\in X,y\in Y\}.\]

1. _Suppose_ \(X\) _contains only one point_ \(x\)_, and_ \(Y\) _is closed. Prove_ \[d(X,Y)=|x-y|\] _for some_ \(y\in Y\)2. _Suppose_ \(X\) _is compact and_ \(Y\) _is closed. Prove_ \[d(X,Y)=|x-y|\] _for some_ \(x\in X,\,y\in Y\)_._
3. _Show by example that the conclusion of Part 2 can be false if_ \(X\) _and_ \(Y\) _are closed but not compact._

**Problem 4.1.7** (Sp82): _Let \(S\subset\mathbb{R}^{n}\) be a subset which is uncountable. Prove that there is a sequence of distinct points in \(S\) converging to a point of \(S\)._

**Problem 4.1.8** (Fa89): _Let \(X\subset\mathbb{R}^{n}\) be a closed set and r a fixed positive real number. Let \(Y=\{y\in\mathbb{R}^{n}\,|\,|x-y|=r\ for\ some\ x\in X\}\). Show that \(Y\) is closed._

**Problem 4.1.9** (Sp92): _Let \(A\) be a closed infinite subset of \(\mathbb{R}^{n}\). Prove that there is a countable set whose closure is \(A\)._

**Problem 4.1.10** (Fa86): _Let \(\{U_{1},U_{2},\ldots\}\) be a cover of \(\mathbb{R}^{n}\) by open sets. Prove that there is a cover \(\{V_{1},V_{2},\ldots\}\) such that_

1. \(V_{j}\subset U_{j}\) _for each_ \(j\)_;_
2. _each compact subset of_ \(\mathbb{R}^{n}\) _is disjoint from all but finitely many of the_ \(V_{j}\)_._

**Problem 4.1.11** (Sp87): _A standard theorem states that a continuous real valued function on a compact set is bounded. Prove the converse: If \(K\) is a subset of \(\mathbb{R}^{n}\) and if every continuous real valued function on \(K\) is bounded, then \(K\) is compact._

**Problem 4.1.12** (Su77): _Let \(A\subset\mathbb{R}^{n}\) be compact, \(x\in A\); let \((x_{i})\) be a sequence in \(A\) such that every convergent subsequence of \((x_{i})\) converges to \(x\)._

1. _Prove that the entire sequence_ \((x_{i})\) _converges._
2. _Give an example to show that if_ \(A\) _is not compact, the result in Part 1 is not necessarily true._

**Problem 4.1.13** (Fa89): _Let \(X\subset\mathbb{R}^{n}\) be compact and let \(f:X\rightarrow\mathbb{R}\) be continuous. Given \(\varepsilon>0\), show there is an \(M\) such that for all \(x,y\in X\),_

\[|f(x)-f(y)|\leq M|x-y|+\varepsilon.\]

**Problem 4.1.14** (Su78): _Let \(\{S_{\alpha}\}\) be a family of connected subsets of \(\mathbb{R}^{2}\) all containing the origin. Prove that \(\bigcup_{\alpha}S_{\alpha}\) is connected._

**Problem 4.1.15** (Fa79): _Consider the following properties of a map \(f:\mathbb{R}^{n}\to\mathbb{R}\):_

1. \(f\) _is continuous._
2. _The graph of_ \(f\) _is connected in_ \(\mathbb{R}^{n}\times\mathbb{R}\)_._

_Prove or disprove the implications 1_ \(\Rightarrow\)_2, 2_ \(\Rightarrow\)_1._

**Problem 4.1.16** (Sp82): _Prove or give a counterexample: Every connected, locally pathwise connected set in \(\mathbb{R}^{n}\) is pathwise connected._

**Problem 4.1.17** (Sp81): _The set of real 3\(\times\)3 symmetric matrices is a real, finite-dimensional vector space isomorphic to \(\mathbb{R}^{6}\). Show that the subset of such matrices of signature \((2,1)\) is an open connected subspace in the usual topology on \(\mathbb{R}^{6}\)._

**Problem 4.1.18** (Fa78): _Let \(M_{n\times n}\) be the vector space of real \(n\times n\) matrices, identified with \(\mathbb{R}^{n^{2}}\). Let \(X\subset M_{n\times n}\) be a compact set. Let \(S\subset\mathbb{C}\) be the set of all numbers that are eigenvalues of at least one element of \(X\). Prove that \(S\) is compact._

**Problem 4.1.19** (Su81): _Let \(S\mathbb{O}(3)\) denote the group of orthogonal transformations of \(\mathbb{R}^{3}\) of determinant \(1\). Let \(Q\subset S\mathbb{O}(3)\) be the subset of symmetric transformations \(\neq I\). Let \(P^{2}\) denote the space of lines through the origin in \(\mathbb{R}^{3}\)._

1. _Show that_ \(P^{2}\) _and_ \(S\mathbb{O}(3)\) _are compact metric spaces (in their usual topologies)._
2. _Show that_ \(P^{2}\) _and_ \(Q\) _are homeomorphic._

**Problem 4.1.20** (Fa83): _Let m and n be positive integers, with \(m<n\). Let \(M_{m\times n}\) be the space of linear transformations of \(\mathbb{R}^{m}\) into \(\mathbb{R}^{n}\) (considered as \(n\times m\) matrices) and let \(L\) be the set of transformations in \(M_{m\times n}\) which have rank m._

1. _Show that_ \(L\) _is an open subset of_ \(M_{m\times n}\)_._
2. _Show that there is a continuous function_ \(T:L\to M_{m\times n}\) _such that_ \(T(A)A=I_{m}\) _for all_ \(A\)_, where_ \(I_{m}\) _is the identity on_ \(\mathbb{R}^{m}\)_._

**Problem 4.1.21** (Fa91): _Let \(M_{n\times n}\) be the space of real n\(\times\)n matrices. Regard it as a metric space with the distance function_

\[d(A,B)=\sum_{i,j=1}^{n}|a_{ij}-b_{ij}|\qquad\left(A=(a_{ij}),B=(b_{ij})\right).\]

_Prove that the set of nilpotent matrices in \(M_{n\times n}\) is a closed set._

### General Theory

**Problem 4.2.1** (Fa93): _Let \(X\) be a metric space and \((x_{n})\) a convergent sequence in \(X\) with limit \(x_{0}\). Prove that the set \(C=\{x_{0},x_{1},x_{2},...\}\) is compact._

**Problem 4.2.2** (Sp79): _Prove that every compact metric space has a countable dense subset._

**Problem 4.2.3** (Fa80): _Let \(X\) be a compact metric space and \(f:X\to X\) an isometry. Show that \(f(X)=X\)._

**Problem 4.2.4** (Sp97): _Let \(M\) be a metric space with metric \(d\). Let \(C\) be a nonempty closed subset of \(M\). Define \(f:M\rightarrow\mathbb{R}\) by_

\[f(x)=\inf\{d(x,y)\,|\,y\in C\}.\]

_Show that \(f\) is continuous, and that \(f(x)=0\) if and only if \(x\in C\)._

**Problem 4.2.5** (Su84): _Let \(C^{1/3}\) be the set of real valued functions f on the closed interval \([0,1]\) such that_

1. \(f(0)=0\)_;_
2. \(\|f\|\) _is finite, where by definition_ \[\|f\|=\sup\left\{\frac{|f(x)-f(y)|}{|x-y|^{1/3}}\mid x\neq y\right\}.\]

_Verify that \(\|\cdot\|\) is a norm for the space \(C^{1/3}\), and prove that \(C^{1/3}\) is complete with respect to this norm._

**Problem 4.2.6** (Sp87): _Let \(\mathcal{F}\) be a uniformly bounded, equicontinuous family of real valued functions on the metric space \((X,d)\). Prove that the function_

\[g(x)=\sup\{f(x)\mid f\in\mathcal{F}\}\]

_is continuous._

**Problem 4.2.7** (Fa91): _Let \(X\) and \(Y\) be metric spaces and \(f\) a continuous map of \(X\) into \(Y\). Let \(K_{1},K_{2},\ldots\) be nonempty compact subsets of \(X\) such that \(K_{n+1}\subset K_{n}\) for all \(n\), and let \(K=\bigcap K_{n}\). Prove that \(f(K)=\bigcap f(K_{n})\)._

**Problem 4.2.8** (Fa92): _Let \((X_{1},d_{1})\) and \((X_{2},d_{2})\) be metric spaces and \(f:X_{1}\to X_{2}\) a continuous surjective map such that \(d_{1}(p,q)\leq d_{2}(f(p),f(q))\) for every pair of points \(p,q\) in \(X_{1}\)._

1. _If_ \(X_{1}\) _is complete, must_ \(X_{2}\) _be complete? Give a proof or a counterexample._
2. _If_ \(X_{2}\) _is complete, must_ \(X_{1}\) _be complete? Give a proof or a counterexample._

### 4.3 Fixed Point Theorem

**Problem 4.3.1** (Fa79): _An accurate map of California is spread out flat on a table in Evans Hall, in Berkeley. Prove that there is exactly one point on the map lying directly over the point it represents._

**Problem 4.3.2** (Fa87): _Define a sequence of positive numbers as follows. Let \(x_{0}>0\) be any positive number, and let \(x_{n+1}=(1+x_{n})^{-1}\). Prove that this sequence converges, and find its limit._

**Problem 4.3.3** (Su80): _Let \(f:\mathbb{R}\to\mathbb{R}\) be monotonically increasing (perhaps discontinuous). Suppose \(0<f(0)\) and \(f(100)<100\). Prove \(f(x)=x\) for some \(x\)._

**Problem 4.3.4** (Su82, Sp95): _Let \(K\) be a nonempty compact set in a metric space with distance function \(d\). Suppose that \(\varphi\colon K\to K\) satisfies_

\[d(\varphi(x),\varphi(y))<d(x,y)\]

_for all \(x\neq y\) in \(K\). Show there exists precisely one point \(x\in K\) such that \(x=\varphi(x)\)._

**Problem 4.3.5** (Fa82): _Let \(K\) be a continuous function on the unit square \(0\leq x,y\leq 1\) satisfying \(|K(x,y)|<1\) for all \(x\) and \(y\). Show that there is a continuous function \(f(x)\) on \([0,1]\) such that we have_

\[f(x)+\int_{0}^{1}K(x,y)f(y)\,dy=e^{x^{2}}\,.\]

_Can there be more than one such function \(f\)?_

**Problem 4.3.6** (Fa88): _Let \(g\) be a continuous real valued function on \([0,1]\). Prove that there exists a continuous real valued function \(f\) on \([0,1]\) satisfying the equation_

\[f(x)-\int_{0}^{x}f(x-t)e^{-t^{2}}\,dt=g(x).\]

**Problem 4.3.7** (Su84): _Show that there is a unique continuous function \(f:[0,1]\to\mathbb{R}\) such that_

\[f(x)=\sin x+\int_{0}^{1}\frac{f(y)}{e^{x+y+1}}\,dy.\]

**Problem 4.3.8** (Fa85, Sp98): _Let \((M,d)\) be a nonempty complete metric space. Let \(S\) map \(M\) into \(M\), and write \(S^{2}\) for \(S\circ S\); that is, \(S^{2}(x)=S\,(S(x))\). Suppose that \(S^{2}\) is a strict contraction; that is, there is a constant \(\lambda<1\) such that for all points \(x,y\in M,d\left(S^{2}(x),S^{2}(y)\right)\leq\lambda d(x,y)\). Show that \(S\) has a unique fixed point in \(M\)._

## 5 Complex Analysis

### Complex Numbers

**Problem 5.1.1** (Fa77): _If \(a\) and \(b\) are complex numbers and \(a\neq 0\), the set \(a^{b}\) consists of those complex numbers \(c\) having a logarithm of the form \(b\alpha\), for some logarithm \(\alpha\) of \(a\). (That is, \(e^{b\alpha}=c\) and \(e^{\alpha}=a\) for some complex number \(\alpha\).) Describe set \(a^{b}\) when \(a=1\) and \(b=1/3+i\)._

**Problem 5.1.2** (Su77): _Write all values of \(i^{i}\) in the form \(a+bi\)._

**Problem 5.1.3** (Sp85): _Show that a necessary and sufficient condition for three points \(a\), \(b\), and \(c\) in the complex plane to form an equilateral triangle is that_

\[a^{2}+b^{2}+c^{2}=bc+ca+ab.\]

**Problem 5.1.4** (Fa86): _Let the points \(a\), \(b\), and \(c\) lie on the unit circle of the complex plane and satisfy \(a+b+c=0\). Prove that \(a\), \(b\), and \(c\) form the vertices of an equilateral triangle._

**Problem 5.1.5** (Sp77):
1. _Evaluate_ \(P_{n-1}(1)\)_, where_ \(P_{n-1}(x)\) _is the polynomial_ \[P_{n-1}(x)=\frac{x^{n}-1}{x-1}.\]
2. _Consider a circle of radius_ \(1\)_, and let_ \(Q_{1},Q_{2},\ldots,Q_{n}\) _be the vertices of a regular_ \(n\)_-gon inscribed in the circle. Join_ \(Q_{1}\) _to_ \(Q_{2},Q_{3},\ldots,Q_{n}\) _by segments of a straight line. You obtain_ \((n-1)\) _segments of lengths

**Problem 5.1.6** (Sp90): _Let \(z_{1},z_{2},\ldots,z_{n}\) be complex numbers. Prove that there exists a subset \(J\subset\{1,2,\ldots,n\}\) such that_

\[\left|\sum_{j\in J}z_{j}\right|\geq\frac{1}{4\sqrt{2}}\sum_{j=1}^{n}|z_{j}|.\]

**Problem 5.1.7** (Sp94): _Let \(a_{1},a_{2},\ldots,a_{n}\) be complex numbers. Prove that there is a point \(x\) in \([0,1]\) such that_

\[\left|1-\sum_{k=1}^{n}\ a_{k}e^{2\pi ikx}\right|\geq 1.\]

**Problem 5.1.8** (Fa82): _Let \(a\) and \(b\) be complex numbers whose real parts are negative or \(0\). Prove the inequality \(|e^{a}-e^{b}|\leq|a-b|\)._

**Problem 5.1.9** (Fa95): _Let \(A\) be a finite subset of the unit disc in the plane, and let \(N(A,r)\) be the set of points at distance \(\leq r\) from \(A\), where \(0<r<1\). Show that the length of the boundary \(N(A,r)\) is, at most, \(C/r\) for some constant \(C\) independent of \(A\)._

[MISSING_PAGE_EMPTY:66]

**Problem 5.2.5** (Sp77): _Let the sequence \(a_{0},a_{1},\ldots\) be defined by the equation_

\[1-x^{2}+x^{4}-x^{6}+\cdots=\sum_{n=0}^{\infty}a_{n}(x-3)^{n}\quad(0<x<1).\]

_Find_

\[\limsup_{n\to\infty}\left(|a_{n}|^{\frac{1}{n}}\right).\]

**Problem 5.2.6** (Su78): _Suppose the power series_

\[\sum_{n=0}^{\infty}a_{n}z^{n}\]

_converges for \(|z|<\)R where \(z\) and the \(a_{n}\) are complex numbers. If \(b_{n}\in\mathbb{C}\) are such that \(|b_{n}|<n^{2}|a_{n}|\) for all \(n\), prove that_

\[\sum_{n=0}^{\infty}b_{n}z^{n}\]

_converges for \(|z|<\)R._

**Problem 5.2.7** (Sp79): _For which \(z\in\mathbb{C}\) does_

\[\sum_{n=0}^{\infty}\left(\frac{z^{n}}{n!}+\frac{n^{2}}{z^{n}}\right)\]

_converge?_

**Problem 5.2.8** (Su79): _Show that_

\[\sum_{n=0}^{\infty}\frac{z}{\left(1+z^{2}\right)^{n}}\]

_converges for all complex numbers \(z\) exterior to the lemniscate_

\[\left|1+z^{2}\right|=1.\]

**Problem 5.2.9** (Su82): _Determine the complex numbers \(z\) for which the power series_

\[\sum_{n=1}^{\infty}\frac{z^{n}}{n^{\log n}}\]

_and its term by term derivatives of all orders converge absolutely._

**Problem 5.2.10** (Su84): _Suppose_

\[f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}\]

_has radius of convergence \(R>0\). Show that_

\[h(z)=\sum_{n=0}^{\infty}\frac{a_{n}z^{n}}{n!}\]

_is entire and that for \(0<r<R\), there is a constant \(M\) such that_

\[|h(z)|\leq Me^{|z|/r}.\]

**Problem 5.2.11** (Sp85): _Let \(R>1\) and let \(f\) be analytic on \(|z|<R\) except at \(z=1\), where \(f\) has a simple pole. If_

\[f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}\qquad(|z|<1)\]

_is the Maclaurin series for \(f\), show that \(\lim_{n\to\infty}a_{n}\) exists._

**Problem 5.2.12** (Fa95): _Find the radius of convergence \(R\) of the Taylor series about \(z=1\) of the function \(f(z)=1/(1+z^{2}+z^{4}+z^{6}+z^{8}+z^{10})\). Express your answer in terms of real numbers and square roots only._

**Problem 5.2.13** (Sp78): _Prove that the uniform limit of a sequence of complex analytic functions is complex analytic. Is the analogous theorem true for real analytic functions?_

**Problem 5.2.14** (Su79): _Let \(g_{n}(z)\) be an entire function having only real zeros, \(n=1,2,\ldots\). Suppose_

\[\lim_{n\to\infty}g_{n}(z)=g(z)\]

_uniformly on compact sets in \(\mathbb{C}\), with \(g\) not identically zero. Prove that \(g(z)\) has only real zeros._

**Problem 5.2.15** (Sp86): _Let \(f\), \(g_{1}\), \(g_{2},\ldots\) be entire functions. Assume that_

1. \(|g_{n}^{(k)}(0)|\leq|f^{(k)}(0)|\) _for all_ \(n\) _and_ \(k\)_;_
2. \(\lim_{n\to\infty}g_{n}^{(k)}(0)\) _exists for all_ \(k\)_._

_Prove that the sequence \(\{g_{n}\}\) converges uniformly on compact sets and that its limit is an entire function._

### Conformal Mappings

**Problem 5.3.1** (Fa77): _Consider the following four types of transformations:_

\[z\mapsto z+b,\quad z\mapsto 1/z,\quad z\mapsto kz\quad(where\ k\neq 0),\]

\[z\mapsto\frac{az+b}{cz+d}\quad(where\ ad-bc\neq 0).\]

_Here, \(z\) is a variable complex number and the other letters denote constant complex numbers. Show that each transformation takes circles to either circles or straight lines._

**Problem 5.3.2** (Fa78): _Give examples of conformal maps as follows:_

1. _from_ \(\{z\mid|z|<1\}\) _onto_ \(\{z\mid\Re z<0\}\)_,_
2. _from_ \(\{z\mid|z|<1\}\) _onto itself, with_ \(f(0)=0\) _and_ \(f(1/2)=i/2\)_,_
3. _from_ \(\{z\mid z\neq 0,0<\arg z<\frac{3\pi}{2}\}\) _onto_ \(\{z\mid z\neq 0,0<\arg z<\frac{\pi}{2}\}\)_._

**Problem 5.3.3** (Sp83): _A fractional linear transformation maps the annulus \(r<|z|<1\) (where \(r>0\)) onto the domain bounded by the two circles \(|z-\frac{1}{4}|=\frac{1}{4}\) and \(|z|=1\). Find \(r\)._

**Problem 5.3.4** (Sp80): _Does there exist an analytic function mapping the annulus_

\[A=\{z\mid 1\leq|z|\leq 4\}\]

_onto the annulus_

\[B=\{z\mid 1\leq|z|\leq 2\}\]

_and taking \(C_{1}\to C_{1},C_{4}\to C_{2}\), where \(C_{r}\) is the circle of radius \(r\)?_

_Hint: Consider \(g(z)=f(z)^{2}/z\)._

**Problem 5.3.5** (Su80): _Exhibit a conformal map from the set \(\{z\in\mathbb{C}\ \mid|z|<1,\Re z>0\}\) onto \(\mathbb{D}=\{z\in\mathbb{C}\ \mid|z|<1\}\)._

**Problem 5.3.6** (Sp90): _Find a one-to-one conformal map of the semidisc_

\[\{z\in\mathbb{C}\ |\Im z>0,\,|z-1/2|<1/2\}\]

_onto the upper half-plane._

**Problem 5.3.7** (Fa97): _Conformally map the region inside the disc \(\{z\in\mathbb{C}\ \mid|z-1|\leq 1\}\) and outside the disc \(\{z\in\mathbb{C}\ \mid|z-\frac{1}{2}|\leq\frac{1}{2}\}\) onto the upper half-plane._

**Problem 5.3.8** (Sp95): _Prove that there is no one-to-one conformal map of the punctured disc \(G=\{z\in\mathbb{C}\ |\ 0<|z|<1\}\) onto the annulus \(A=\{z\in\mathbb{C}\ |\ 1<|z|<2\}\)._

### 5.4 Integral Representation of Analytic Functions

**Problem 5.4.1** (Sp96): _Let \(f=u+iv\) be analytic in a connected open set \(D\), where \(u\) and \(v\) are real valued. Suppose there are real constants \(a\), \(b\) and \(c\) such that \(a^{2}+b^{2}\neq 0\) and_

\[au+bv=c\]

_in \(D\). Show that \(f\) is constant in \(D\)._

**Problem 5.4.2** (Fa93): _Let \(f\) be a continuous real valued function on \([0,1]\), and let the function \(h\) in the complex plane be defined by_

\[h(z)=\int_{0}^{1}\ f(t)\cos(zt)\ dt.\]

1. _Prove that_ \(h\) _is analytic in the entire plane._
2. _Prove that_ \(h\) _is the zero function only if_ \(f\) _is the zero function._

**Problem 5.4.3** (Su79, Sp82, Sp91, Sp96): _Let \(f\) be a continuous complex valued function on \([0,1]\), and define the function \(g\) by_

\[g(z)=\int_{0}^{1}f(t)e^{tz}\,dt\qquad\quad(z\in\mathbb{C}\ ).\]

_Prove that \(g\) is analytic in the entire complex plane._

**Problem 5.4.4** (Fa84, Fa95): _Let \(f\) and \(g\) be analytic functions in the open unit disc, and let \(C_{r}\) denote the circle with center \(0\) and radius \(r\), oriented counterclockwise._

1. _Prove that the integral_ \[\frac{1}{2\pi i}\int_{C_{r}}\frac{1}{w}f(w)g\left(\frac{z}{w}\right)\,dw\] _is independent of_ \(r\) _as long as_ \(|z|<r<1\) _and that it defines an analytic function_ \(h(z)\)_,_ \(|z|<1\)_._
2. _Prove or supply a counterexample: If_ \(f\not\equiv 0\) _and_ \(g\not\equiv 0\)_, then_ \(h\not\equiv 0\)_._

**Problem 5.4.5** (Sp84): _Let \(F\) be a continuous complex valued function on the interval \([0,1]\). Let_

\[f(z)=\int_{0}^{1}\frac{F(t)}{t-z}\,dt,\]

_for \(z\) a complex number not in \([0,1]\)._

1. _Prove that_ \(f\) _is an analytic function._
2. _Express the coefficients of the Laurent series of_ \(f\) _about_ \(\infty\) _in terms of_ \(F\)_. Use your result to show that_ \(F\) _is uniquely determined by_ \(f\)

### Functions on the Unit Disc

**Problem 5.5.1** (Fa82): _Let \(a\) and \(b\) be nonzero complex numbers and \(f(z)=az+bz^{-1}\). Determine the image under \(f\) of the unit circle \(\{z\mid|z|=1\}\)._

**Problem 5.5.2** (Su83, Fa96): _Let \(f\) be analytic on and inside the unit circle \(C=\{z\mid|z|=1\}\). Let \(L\) be the length of the image of \(C\) under \(f\). Show that \(L\geq 2\pi|f^{\prime}(0)|\)._

**Problem 5.5.3** (Sp80): _Let_

\[f(z)=\sum_{n=0}^{\infty}c_{n}z^{n}\]

_be analytic in the disc \(\mathbb{D}=\{z\in\mathbb{C}\ \mid|z|<1\}\). Assume \(f\) maps \(\mathbb{D}\) one-to-one onto a domain \(G\) having area \(A\). Prove_

\[A=\pi\sum_{n=1}^{\infty}n|c_{n}|^{2}.\]

**Problem 5.5.4** (Su83): _Compute the area of the image of the unit disc \(\{z\mid|z|<1\}\) under the map \(f(z)=z+z^{2}/2\)._

**Problem 5.5.5** (Sp80): _Let_

\[f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}\]

_be an analytic function in the open unit disc \(\mathbb{D}\). Assume that_

\[\sum_{n=2}^{\infty}n|a_{n}|\leq|a_{1}|\quad\text{with}\quad a_{1}\neq 0.\]

_Prove that \(f\) is injective or constant._

**Problem 5.5.6** (Su85): _For each \(k>0\), let \(X_{k}\) be the set of analytic functions \(f(z)\) on the open unit disc \(\mathbb{D}\) such that_

\[\sup_{z\in\mathbb{D}}\left\{(1-|z|)^{k}\left|f(z)\right|\right\}\]

_is finite. Show that \(f\in X_{k}\) if and only if \(f^{\prime}\in X_{k+1}\)._

**Problem 5.5.7** (Sp88): _Let the function \(f\) be analytic in the open unit disc of the complex plane and real valued on the radii \([0,1)\) and \([0,e^{i\pi\sqrt{2}})\). Prove that \(f\) is constant._

**Problem 5.5.8** (Fa91): _Let the function \(f\) be analytic in the disc \(|z|<1\) of the complex plane. Assume that there is a positive constant \(M\) such that_

\[\int_{0}^{2\pi}|f^{\prime}(re^{i\theta})|\,d\theta\leq M,\qquad(0\leq r<1).\]

_Prove that_

\[\int_{[0,1)}|f(x)|\,dx<\infty.\]

**Problem 5.5.9** (Fa78): _Suppose \(h(z)\) is analytic in the whole plane, \(h(0)=3+4i\), and \(|h(z)|\leq 5\) if \(|z|<1\). What is \(h^{\prime}(0)\)?_

**Problem 5.5.10** (Fa79, Fa90): _Suppose that \(f\) is analytic on the open upper half-plane and satisfies \(|f(z)|\leq 1\) for all \(z\), \(f(i)=0\). How large can \(|f(2i)|\) be under these conditions?_

**Problem 5.5.11** (Fa85): _Let \(f(z)\) be analytic on the right half-plane \(H=\{z\mid\Re z>0\}\) and suppose \(|f(z)|\leq 1\) for \(z\in H\). Suppose also that \(f(1)=0\). What is the largest possible value of \(|f^{\prime}(1)|\)?_

**Problem 5.5.12** (Su82): _Let \(f(z)\) be analytic on the open unit disc \(\mathbb{D}=\{z\mid|z|<1\}\). Prove that there is a sequence \((z_{n})\) in \(\mathbb{D}\) such that \(|z_{n}|\to 1\) and \((f(z_{n}))\) is bounded._

**Problem 5.5.13** (Sp93): _Let \(f\) be an analytic function in the unit disc, \(|z|<1\)._

1. _Prove that there is a sequence_ \((z_{n})\) _in the unit disc with_ \(\lim_{n\to\infty}|z_{n}|=1\) _and_ \(\lim_{n\to\infty}f(z_{n})\) _exists (finitely)._
2. _Assume_ \(f\) _nonconstant. Prove that there are two sequences_ \((z_{n})\) _and_ \((w_{n})\) _in the disc such that_ \(\lim_{n\to\infty}|z_{n}|=\lim_{n\to\infty}|w_{n}|=1\)_, and such that both limits_ \(\lim_{n\to\infty}f(z_{n})\) _and_ \(\lim_{n\to\infty}f(w_{n})\) _exist (finitely) and are not equal._

**Problem 5.5.14** (Fa81, Sp89, Fa97): _Let \(f\) be a holomorphic map of the unit disc \(\mathbb{D}=\{z\mid|z|<1\}\) into itself, which is not the identity map \(f(z)=z\). Show that \(f\) can have, at most, one fixed point._

**Problem 5.5.15** (Sp85): _Let \(f(z)\) be an analytic function that maps the open disc \(|z|<1\) into itself. Show that \(|f^{\prime}(z)|\leq(1-|z|^{2})^{-1}\)._

**Problem 5.5.16** (Sp87, Fa89): _Let \(f\) be an analytic function in the open unit disc of the complex plane such that \(|f(z)|\leq C/(1-|z|)\) for all \(z\) in the disc, where \(C\) is a positive constant. Prove that \(|f^{\prime}(z)|\leq 4C/(1-|z|)^{2}\)._

**Problem 5.5.17** (Fa87): _If \(f(z)\) is analytic in the open disc \(|z|<1\), and \(|f(z)|\leq 1/(1-|z|)\), show that_

\[|a_{n}|=|f^{(n)}(0)/n!|\leq(n+1)(1+1/n)^{n}<e(n+1).\]

**Problem 5.5.18** (Sp88):
1. _Let_ \(f\) _be an analytic function that maps the open unit disc,_ \(\mathbb{D}\)_, into itself and vanishes at the origin. Prove that_ \(|f(z)+f(-z)|\leq 2|z|^{2}\) _in_ \(\mathbb{D}\)_._
2. _Prove that the inequality in Part 1 is strict, except at the origin, unless_ \(f\) _has the form_ \(f(z)=\lambda z^{2}\) _with_ \(\lambda\) _a constant of absolute value one._

**Problem 5.5.19** (Sp91): _Let the function \(f\) be analytic in the unit disc, with \(|f(z)|\leq 1\) and \(f(0)=0\). Assume that there is a number \(r\) in \((0,1)\) such that \(f(r)=f(-r)=0\). Prove that_

\[|f(z)|\leq|z|\left|\frac{z^{2}-r^{2}}{1-r^{2}z^{2}}\right|.\]

### Growth Conditions

**Problem 5.6.1** (Fa90): _Let the function \(f\) be analytic in the entire complex plane, and suppose that \(f(z)/z\to 0\) as \(|z|\to\infty\). Prove that \(f\) is constant._

**Problem 5.6.2** (Fa97): _Let \(f\) be an entire analytic function such that, for all \(z\), \(|f(z)|=|\sin z|\). Prove that there is a constant \(C\) of modulus \(1\) such that \(f(z)=C\sin z\)._

**Problem 5.6.3** (Fa79, Su81): _Suppose \(f\) and \(g\) are entire functions with \(|f(z)|\leq|g(z)|\) for all \(z\). Prove that \(f(z)=cg(z)\) for some constant \(c\)._

**Problem 5.6.4** (Sp97): _Let \(f\) and \(g\) be two entire functions such that, for all \(z\in\mathbb{C}\), \(\Re f(z)\leq k\Re g(z)\) for some real constant \(k\) (independent of \(z\)). Show that there are constants \(a\), \(b\) such that_

\[f(z)=ag(z)+b\,.\]

**Problem 5.6.5** (Su78): _Let \(f:\mathbb{C}\,\to\mathbb{C}\) be an entire function and let \(a>0\) and \(b>0\) be constants._

1. _If_ \(|f(z)|\leq a\sqrt{|z|}+b\) _for all z, prove that f is a constant._
2. _What can you prove about f if_ \[|f(z)|\leq a|z|^{5/2}+b\] _for all z?_

**Problem 5.6.6** (Fa90): _Let the function \(f\) be analytic in the entire complex plane and satisfy_

\[\int_{0}^{2\pi}\left|f(re^{i\theta})\right|d\theta\leq r^{17/3}\]

_for all \(r>0\). Prove that \(f\) is the zero function._

**Problem 5.6.7** (Fa96): _Does there exist a function \(f\), analytic in the punctured plane \(\mathbb{C}\,\setminus\{0\}\), such that_

\[\left|f(z)\right|\geq\frac{1}{\sqrt{\left|z\right|}}\]

_for all nonzero \(z\)?_

**Problem 5.6.8** (Fa91): _Let the function \(f\) be analytic in the entire complex plane and satisfy the inequality \(\left|f(z)\right|\leq\left|\Re z\right|^{-1/2}\) off the imaginary axis. Prove that \(f\) is constant._

### 5.7 Analytic and Meromorphic Functions

**Problem 5.7.1** (Sp88): _True or false: A function \(f(z)\) analytic on \(\left|z-a\right|<r\) and continuous on \(\left|z-a\right|\leq r\) extends, for some \(\delta>0\), to a function analytic on \(\left|z-a\right|<r+\delta\)? Give a proof or a counterexample._

**Problem 5.7.2** (Fa80): _Do there exist functions \(f(z)\) and \(g(z)\) that are analytic at \(z=0\) and that satisfy_

1. \(f\left(1/n\right)=f\left(-1/n\right)=1/n^{2}\)_,_ \(n=1,2,\ldots\)_,_
2. \(g\left(1/n\right)=g\left(-1/n\right)=1/n^{3}\)_,_ \(n=1,2,\ldots\)_?_

**Problem 5.7.3** (Su78):
1. _Suppose f is analytic on a connected open set_ \(U\subset\mathbb{C}\,\) _and f takes only real values. Prove that f is constant._
2. _Suppose_ \(W\subset\mathbb{C}\,\) _is open, g is analytic on_ \(W\)_, and_ \(g^{\prime}(z)\neq 0\) _for all_ \(z\in\mathbb{C}\,\)_. Show that_ \[\{\Re g(z)+\Im g(z)\mid z\in W\}\subset\mathbb{R}\] _is an open subset of_ \(\mathbb{R}\)_._

**Problem 5.7.4** (Sp78): _Let \(f:\mathbb{C}\,\rightarrow\mathbb{C}\,\) be a nonconstant entire function. Prove that \(f(\mathbb{C}\,)\) is dense in \(\mathbb{C}\,\)._

**Problem 5.7.5** (Su82): _Let \(s(y)\) and \(t(y)\) be real differentiable functions of \(y\), \(-\infty<y<\infty\), such that the complex function_

\[f(x+iy)=e^{x}\left(s(y)+it(y)\right)\]

_is complex analytic with \(s(0)=1\) and \(t(0)=0\). Determine \(s(y)\) and \(t(y)\)._

**Problem 5.7.6** (Sp83): _Determine all the complex analytic functions \(f\) defined on the unit disc \(\mathbb{D}\) which satisfy_

\[f^{\prime\prime}\left(\frac{1}{n}\right)+f\left(\frac{1}{n}\right)=0\]

_for \(n=2,3,4,\ldots\)._

**Problem 5.7.7** (Su83): _Let \(\Omega\) be an open subset of \(\mathbb{R}^{2}\), and let \(f:\Omega\rightarrow\mathbb{R}^{2}\) be a smooth map. Assume that \(f\) preserves orientation and maps any pair of orthogonal curves to a pair of orthogonal curves. Show that \(f\) is holomorphic. Note: Here we identify \(\mathbb{R}^{2}\) with \(\mathbb{C}\)._

**Problem 5.7.8** (Fa84): _Prove or supply a counterexample: If \(f\) is a continuous complex valued function defined on a connected open subset of the complex plane and if \(f^{2}\) is analytic, then \(f\) is analytic._

**Problem 5.7.9** (Sp87): _Let \(f\) be a complex valued function in the open unit disc, \(\mathbb{D}\), of the complex plane such that the functions \(g=f^{2}\) and \(h=f^{3}\) are both analytic. Prove that \(f\) is analytic in \(\mathbb{D}\)._

**Problem 5.7.10** (Sp88):
1. _Let_ \(G\) _be an open connected subset of the complex plane,_ \(f\) _an analytic function in_ \(G\)_, not identically_ \(0\)_, and n a positive integer. Assume that f has an analytic_ \(n^{th}\) _root in_ \(G\)_; that is, there is an analytic function g in_ \(G\) _such that_ \(g^{n}=f\)_. Prove that f has exactly n analytic_ \(n^{th}\) _roots in_ \(G\)_._
2. _Give an example of a continuous real valued function on_ \([0,1]\) _that has more than two continuous square roots on_ \([0,1]\)_._

**Problem 5.7.11** (Fa92): _Let the function \(f\) be analytic in the region \(|z|>1\) of the complex plane. Prove that if \(f\) is real valued on the interval \((1,\infty)\) of the real axis, then \(f\) is also real valued on the interval \((-\infty,-1)\)._

**Problem 5.7.12** (Fa94): _Let the function \(f\) be analytic in the complex plane, real on the real axis, \(0\) at the origin, and not identically \(0\). Prove that if \(f\) maps the imaginary axis into a straight line, then that straight line must be either the real axis or the imaginary axis._

**Problem 5.7.13** (Fa87): _Let \(f(z)\) be analytic for \(z\neq 0\), and suppose that \(f(1/z)=f(z)\). Suppose also that \(f(z)\) is real for all \(z\) on the unit circle \(|z|=1\). Prove that \(f(z)\) is real for all real \(z\neq 0\)._

**Problem 5.7.14** (Fa91): _Let \(p\) be a nonconstant complex polynomial whose zeros are all in the half-plane \(\Im z>0\)._

1. _Prove that_ \(\Im(p^{\prime}/p)>0\) _on the real axis._
2. _Find a relation between_ \(\deg p\) _and_ \[\int_{-\infty}^{\infty}\Im\frac{p^{\prime}(x)}{p(x)}\,dx\,.\]

**Problem 5.7.15** (Sp92): _Let \(f\) be an analytic function in the connected open subset \(G\) of the complex plane. Assume that for each point \(z\) in \(G\), there is a positive integer \(n\) such that the \(n^{th}\) derivative of \(f\) vanishes at \(z\). Prove that \(f\) is a polynomial._

**Problem 5.7.16** (Sp92): _Find a Laurent series that converges in the annulus \(1<|z|<2\) to a branch of the function \(\log\left(\frac{z(2-z)}{1-z}\right)\)._

**Problem 5.7.17** (Sp92): _Let the function \(f\) be analytic in the entire complex plane, real valued on the real axis, and of positive imaginary part in the upper half-plane. Prove \(f^{\prime}(x)>0\) for \(x\) real._

**Problem 5.7.18** (Sp93): _Prove that for any fixed complex number \(\zeta\),_

\[\frac{1}{2\pi}\int_{0}^{2\pi}e^{2\zeta\cos\theta}d\theta=\sum_{n=0}^{\infty} \left(\frac{\zeta^{n}}{n!}\right)^{2}.\]

**Problem 5.7.19** (Sp94):
1. _Let_ \(U\) _and_ \(V\) _be open connected subsets of the complex plane, and let_ \(f\) _be an analytic function in_ \(U\) _such that_ \(f(U)\subset V\)_. Assume_ \(f^{-1}(K)\) _is compact whenever_ \(K\) _is a compact subset of_ \(V\)_. Prove that_ \(f(U)=V\)_._
2. _Prove that the last equality can fail if_ analytic _is replaced by_ continuous _in the preceding statement._

**Problem 5.7.20** (Sp94): _Let \(f=u+iv\) and \(g=p+iq\) be analytic functions defined in a neighborhood of the origin in the complex plane. Assume \(|g^{\prime}(0)|<|f^{\prime}(0)|\). Prove that there is a neighborhood of the origin in which the function \(h=f+\overline{g}\) is one-to-one._

**Problem 5.7.21** (Sp87): _Prove or disprove: If the function \(f\) is analytic in the entire complex plane, and if \(f\) maps every unbounded sequence to an unbounded sequence, then \(f\) is a polynomial._

**Problem 5.7.22** (Fa88, Sp97): _Determine the group \(\operatorname{Aut}(\mathbb{C}\,)\) of all one-to-one analytic maps of \(\mathbb{C}\,\) onto \(\mathbb{C}\,\)._

**Problem 5.7.23** (Sp77): _Let \(f(z)\) be a nonconstant meromorphic function. A complex number \(w\) is called a period of \(f\) if \(f(z+w)=f(z)\) for all \(z\)._

1. _Show that if_ \(w_{1}\) _and_ \(w_{2}\) _are periods, so are_ \(n_{1}w_{1}+n_{2}w_{2}\) _for all integers_ \(n_{1}\) _and_ \(n_{2}\)_._
2. _Show that there are, at most, a finite number of periods of_ \(f\) _in any bounded region of the complex plane._

**Problem 5.7.24** (Sp91): _Let the function \(f\) be analytic in the punctured disc \(0<|z|<r_{0}\), with Laurent series_

\[f(z)=\sum_{-\infty}^{\infty}c_{n}z^{n}.\]

_Assume there is a positive number \(M\) such that_

\[r^{4}\int_{0}^{2\pi}|f(re^{i\theta})|^{2}\,d\theta<M,\qquad\qquad 0<r<r_{0}.\]

_Prove that \(c_{n}=0\) for \(n<-2\)._

**Problem 5.7.25** (Sp98): _Let \(a>0\). Show that the complex function_

\[f(z)=\frac{1+z+az^{2}}{1-z+az^{2}}\]

_satisfies \(|f(z)|<1\) for all \(z\) in the open left half plane \(\Re z<0\)._

### Cauchy's Theorem

**Problem 5.8.1** (Fa85): _Evaluate_

\[\int_{0}^{2\pi}e^{e^{i\theta}}\,d\theta.\]

**Problem 5.8.2** (Su78): _Evaluate_

\[\int_{0}^{2\pi}e^{(e^{i\theta}-i\theta)}\,d\theta.\]

**Problem 5.8.3** (Sp98): _Let \(a\) be a complex number with \(|a|<1\). Evaluate the integral_

\[\int_{|z|=1}\frac{|dz|}{|z-a|^{2}}\]

**Problem 5.8.4** (Sp77, Sp82): _Prove the Fundamental Theorem of Algebra: Every nonconstant polynomial with complex coefficients has a complex root._

**Problem 5.8.5** (Su77): _Let \(f\) be continuous on \(\mathbb{C}\) and analytic on \(\{z\mid\Im z\neq 0\}.\) Prove that \(f\) must be analytic on \(\mathbb{C}\)._

**Problem 5.8.6** (Fa78, Su79): _Let \(f(z)=a_{0}+a_{1}z+\cdots+a_{n}z^{n}\) be a complex polynomial of degree \(n>0\). Prove_

\[\frac{1}{2\pi i}\int_{|z|=R}z^{n-1}|f(z)|^{2}\,dz=a_{0}\bar{a}_{n}R^{2n}.\]

**Problem 5.8.7** (Fa95): _Let \(f(z)=u(z)+iv(z)\) be holomorphic in \(|z|<1\), \(u\) and \(v\) real. Show that_

\[\int_{0}^{2\pi}u(re^{i\theta})^{2}d0\ =\ \int_{0}^{2\pi}v(re^{i\theta})^{2}d0\]

_for \(0<r<1\) if \(u(0)^{2}=v(0)^{2}\)._

**Problem 5.8.8** (Su83): _Let \(f:\mathbb{C}\ \twoheadrightarrow\mathbb{C}\) be an analytic function such that_

\[\left(1+|z|^{k}\right)^{-1}\frac{d^{m}f}{dz^{m}}\]

_is bounded for some k and m. Prove that \(d^{n}f/dz^{n}\) is identically zero for sufficiently large n. How large must n be, in terms of k and m?_

**Problem 5.8.9** (Su83): _Suppose \(\Omega\) is a bounded domain in \(\mathbb{C}\) with a boundary consisting of a smooth Jordan curve \(\gamma\). Let \(f\) be holomorphic in a neighborhood of the closure of \(\Omega\), and suppose that \(f(z)\neq 0\) for \(z\in\gamma\). Let \(z_{1},\ldots,z_{k}\) be the zeros of \(f\) in \(\Omega\), and let \(n_{j}\) be the order of the zero of \(f\) at \(z_{j}\) (for \(j=1,\ldots,k\))._

1. _Use Cauchy's integral formula to show that_ \[\frac{1}{2\pi i}\int_{\gamma}\frac{f^{\prime}(z)}{f(z)}\,dz=\sum_{j=1}^{k}n_{j}.\]
2. _Suppose that_ \(f\) _has only one zero_ \(z_{1}\) _in_ \(\Omega\) _with multiplicity_ \(n_{1}=1\)_. Find a boundary integral involving_ \(f\) _whose value is the point_ \(z_{1}\)_._

**Problem 5.8.10** (Fa88): _Let \(f\) be an analytic function on a disc \(D\) whose center is the point \(z_{0}\). Assume that \(|f^{\prime}(z)-f^{\prime}(z_{0})|<|f^{\prime}(z_{0})|\) on D. Prove that \(f\) is one-to-one on \(D\)._

**Problem 5.8.11** (Fa89): _Let \(f(z)\) be analytic in the annulus \(\Omega=\{1<|z|<2\}.\) Assume that \(f\) has no zeros in \(\Omega.\) Show that there exists an integer \(n\) and an analytic function \(g\) in \(\Omega\) such that, for all \(z\in\Omega\), \(f(z)=z^{n}e^{g(z)}\)._

**Problem 5.8.12** (Sp90): _Let the function \(f\) be analytic and bounded in the complex half-plane \(\Re z>0.\) Prove that for any positive real number \(c\), the function \(f\) is uniformly continuous in the half-plane \(\Re z>c.\)_

### 5.9 Zeros and Singularities

**Problem 5.9.1** (Fa77, Fa96): _Let \(\mathbb{C}\,^{3}\) denote the set of ordered triples of complex numbers. Define a map \(F:\mathbb{C}\,^{3}\to\mathbb{C}\,^{3}\) by_

\[F(u,v,w)=(u+v+w,uv+vw+wu,uvw).\]

_Prove that \(F\) is onto but not one-to-one._

**Problem 5.9.2** (Fa79, Fa89): _Prove that the polynomial_

\[p(z)=z^{47}-z^{23}+2z^{11}-z^{5}+4z^{2}+1\]

_has at least one root in the disc \(|z|<1\)._

**Problem 5.9.3** (Fa80): _Suppose that \(f\) is analytic inside and on the unit circle \(|z|=1\) and satisfies \(|f(z)|<1\) for \(|z|=1.\) Show that the equation \(f(z)=z^{3}\) has exactly three solutions (counting multiplicities) inside the unit circle._

**Problem 5.9.4** (Fa81):
1. _How many zeros does the function_ \(f(z)=3z^{100}-e^{z}\) _have inside the unit circle (counting multiplicities)?_
2. _Are the zeros distinct?_

**Problem 5.9.5** (Fa92):
1. _How many roots does the polynomial_ \(p(z)=2z^{5}+4z^{2}+1\) _have in the disc_ \(|z|<1\)_?_
2. _How many roots does the same polynomial have on the real axis?_

**Problem 5.9.6** (Su80): _How many zeros does the complex polynomial_

\[3z^{9}+8z^{6}+z^{5}+2z^{3}+1\]

_have in the annulus \(1<|z|<2\)?_

**Problem 5.9.7** (Fa83): _Consider the polynomial_

\[p(z)=z^{5}+z^{3}+5z^{2}+2.\]

_How many zeros (counting multiplicities) does \(p\) have in the annular region \(1<|z|<2\)?_

**Problem 5.9.8** (Sp84, Fa87, Fa96): _Find the number of roots of_

\[z^{7}-4z^{3}-11=0\]

_which lie between the two circles \(|z|=1\) and \(|z|=2\)._

**Problem 5.9.9** (Sp96): _Let \(r<1<R\). Show that for all sufficiently small \(\varepsilon>0\), the polynomial_

\[p(z)=\varepsilon z^{7}+z^{2}+1\]

_has exactly five roots (counted with their multiplicities) inside the annulus_

\[r\varepsilon^{-1/5}<|z|<R\varepsilon^{-1/5}.\]

**Problem 5.9.10** (Sp86): _Let the 3\(\times\)3 matrix function \(A\) be defined on the complex plane by_

\[A(z)=\left(\begin{array}{ccc}4z^{2}&1&-1\\ -1&2z^{2}&0\\ 3&0&1\end{array}\right).\]

_How many distinct values of \(z\) are there such that \(|z|<1\) and \(A(z)\) is not invertible?_

**Problem 5.9.11** (Fa85): _How many roots has the polynomial \(z^{4}+3z^{2}+z+1\) in the right half \(z\)-plane?_

**Problem 5.9.12** (Sp87): _Prove that if the nonconstant polynomial \(p(z)\), with complex coefficients, has all of its roots in the half-plane \(\Re z>0\), then all of the roots of its derivative are in the same half-plane._

**Problem 5.9.13** (Sp92): _Let \(p\) be a nonconstant polynomial with real coefficients and only real roots. Prove that for each real number \(r\), the polynomial \(p-rp^{\prime}\) has only real roots._

**Problem 5.9.14** (Sp79, Su85, Sp89): _Prove that if \(1<\lambda<\infty\), the function_

\[f_{\lambda}(z)=z+\lambda-e^{z}\]

_has only one zero in the half-plane \(\Re z<0\), and this zero is on the real axis._

**Problem 5.9.15** (Fa85): _Prove that for every \(\lambda>1\), the equation \(ze^{\lambda-z}=1\) has exactly one root in the disc \(|z|<1\) and that this root is real._

**Problem 5.9.16** (Sp85): _Prove that for any \(a\in\mathbb{C}\) and any integer \(n\geq 2\), the equation \(1+z+az^{n}=0\) has at least one root in the disc \(|z|\leq\ 2\)._

**Problem 5.9.17** (Sp89): _Prove that the polynomial \(z^{4}+z^{3}+1\) has exactly one root in the quadrant \(\{z=x+iy\,|\,x,y>0\}\)._

**Problem 5.9.18** (Sp89): _Let \(f\) be analytic in an open set containing the closed unit disc. Suppose that \(|f(z)|>m\) for \(|z|=1\) and \(|f(0)|<m\). Prove that \(f(z)\) has at least one zero in the open unit disc \(|z|<1\)._

**Problem 5.9.19** (Su82): _Let \(0<a_{0}\leq a_{1}\leq\cdots\leq a_{n}\). Prove that the equation_

\[a_{0}z^{n}+a_{1}z^{n-1}+\cdots+a_{n}=0\]

_has no roots in the disc \(|z|<1\)._

**Problem 5.9.20** (Fa86): _Show that the polynomial \(p(z)=z^{5}-6z+3\) has five distinct complex roots, of which exactly three (and not five) are real._

**Problem 5.9.21** (Sp90): _Let \(c_{0},c_{1},\ldots,c_{n-1}\) be complex numbers. Prove that all the zeros of the polynomial_

\[z^{n}+c_{n-1}z^{n-1}+\cdots+c_{1}z+c_{0}\]

_lie in the open disc with center \(0\) and radius_

\[\sqrt{1+|c_{n-1}|^{2}+\cdots+|c_{1}|^{2}+|c_{0}|^{2}}\,.\]

**Problem 5.9.22** (Sp95): _Let \(P(x)\) be a polynomial with real coefficients and with leading coefficient \(1\). Suppose that \(P(0)=-1\) and that \(P(x)\) has no complex zeros inside the unit circle. Prove that \(P(1)=0\)._

**Problem 5.9.23** (Su81): _Prove that the number of roots of the equation \(z^{2n}+\alpha^{2}z^{2n-1}+\beta^{2}=0\) (\(n\) a natural number, \(\alpha\) and \(\beta\) real, nonzero) that have positive real part is_

1. \(n\) _if_ \(n\) _is even, and_
2. \(n-1\) _if_ \(n\) _is odd._

**Problem 5.9.24** (Su84): _Let \(\rho>0\). Show that for \(n\) large enough, all the zeros of_

\[f_{n}(z)=1+\frac{1}{z}+\frac{1}{2!z^{2}}+\cdots+\frac{1}{n!z^{n}}\]

_lie in the circle \(|z|<\rho\)._

**Problem 5.9.25** (Fa88): _Do the functions \(f(z)=e^{z}+z\) and \(g(z)=ze^{z}+1\) have the same number of zeros in the strip \(-\frac{\pi}{2}<\Im z<\frac{\pi}{2}\)

**Problem 5.9.26** (Sp93): _Let \(a\) be a complex number and \(\varepsilon\) a positive number. Prove that the function \(f(z)=\sin z+\frac{1}{z-a}\) has infinitely many zeros in the strip \(|\Im z|<\varepsilon\)._

**Problem 5.9.27** (Su77, Sp81): _Let \(\hat{a}_{0}+\hat{a}_{1}z+\cdots+\hat{a}_{n}z^{n}\) be a polynomial having \(\hat{z}\) as a simple root. Show that there is a continuous function \(r:U\to\mathbb{C}\), where \(U\) is a neighborhood of \((\hat{a}_{0},\ldots,\hat{a}_{n})\) in \(\mathbb{C}^{\,n+1}\), such that \(r(a_{0},\ldots,a_{n})\) is always a root of \(a_{0}+a_{1}z+\cdots+a_{n}z^{n}\), and \(r(\hat{a}_{0},\ldots,\hat{a}_{n})=\hat{z}\)._

**Problem 5.9.28** (Su85): _Let_

\[f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}\]

_where all the \(a_{n}\) are nonnegative reals, and the series has radius of convergence \(1\). Prove that \(f(z)\) cannot be analytically continued to a function analytic in a neighborhood of \(z=1\)._

**Problem 5.9.29** (Su80): _Let \(f\) be a meromorphic function on \(\mathbb{C}\) which is analytic in a neighborhood of \(0\). Let its Taylor series at \(0\) be_

\[\sum_{k=0}^{\infty}a_{k}z^{k}\]

_with all \(a_{k}\geq 0\). Suppose there is a pole of norm \(r>0\) and no pole has norm \(<r\). Prove there is a pole at \(z=r\)._

**Problem 5.9.30** (Sp82):
1. _Decide, without too much computation, whether a finite limit_ \[\lim_{z\to 0}\left((\tan z)^{-2}-z^{-2}\right)\] _exists, where z is a complex variable._
2. _If yes, compute the limit._

**Problem 5.9.31** (Sp89): _Let f and g be analytic functions in the entire complex plane with the property that the function \(h(z)=f\left(g(z)\right)\) is a nonconstant polynomial. Prove that f and g are polynomials._

### Harmonic Functions

**Problem 5.10.1** (Fa77, Fa81): _Let \(u:\mathbb{R}^{2}\to\mathbb{R}\) be the function defined by \(u(x,y)=x^{3}-3xy^{2}\). Show that \(u\) is harmonic and find \(v:\mathbb{R}^{2}\to\mathbb{R}\) such that the function \(f:\mathbb{C}\to\mathbb{C}\) defined by_

\[f(x+iy)=u(x,y)+iv(x,y)\]

_is analytic._

**Problem 5.10.2** (Fa80): _Let \(f(z)\) be an analytic function defined for \(|z|\leq 1\) and let_

\[u(x,y)=\Re f(z),\ \ \ \ z=x+iy.\]

_Prove that_

\[\int_{C}\frac{\partial u}{\partial y}\,dx-\frac{\partial u}{\partial x}\,dy=0\]

_where \(C\) is the unit circle, \(x^{2}+y^{2}=1\)._

**Problem 5.10.3** (Fa83):
1. _Let_ \(f\) _be a complex function which is analytic on an open set containing the disc_ \(|z|\leq 1\)_, and which is real valued on the unit circle. Prove that_ \(f\) _is constant._
2. _Find a nonconstant function which is analytic at every point of the complex plane except for a single point on the unit circle_ \(|z|=1\)_, and which is real valued at every other point of the unit circle._

**Problem 5.10.4** (Fa92): _Let \(s\) be a real number, and let the function \(u\) be defined in \(\mathbb{C}\backslash(-\infty,0]\) by_

\[u(re^{i\theta})=r^{s}\cos s\theta\qquad(r>0,\quad-\pi<\theta<\pi).\]

_Prove that \(u\) is a harmonic function._

**Problem 5.10.5** (Fa87): _Let \(u\) be a positive harmonic function on \(\mathbb{R}^{2}\); that is,_

\[\frac{\partial^{2}u}{\partial x^{2}}+\frac{\partial^{2}u}{\partial y^{2}}=0.\]

_Show that \(u\) is constant._

**Problem 5.10.6** (Sp94): _Let \(u\) be a real valued harmonic function in the complex plane such that_

\[u(z)\leq a\,|\log|z||+b\]

_for all z, where a and \(b\) are positive constants. Prove that \(u\) is constant._

### 5.11 Residue Theory

**Problem 5.11.1** (Fa83): _Let \(r_{1},r_{2},\ldots,r_{n}\) be distinct complex numbers. Show that a rational function of the form_

\[f(z)=\frac{b_{0}+b_{1}z+\cdots+b_{n-2}z^{n-2}+b_{n-1}z^{n-1}}{(z-r_{1})(z-r_{2 })\cdots(z-r_{n})}\]

_can be written as a sum_

\[f(z)=\frac{A_{1}}{z-r_{1}}+\frac{A_{2}}{z-r_{2}}+\cdots+\frac{A_{n}}{z-r_{n}}\]

_for suitable constants \(A_{1},\ldots,A_{n}\)._

**Problem 5.11.2** (Fa82): _Let_

\[\cot(\pi z)=\sum_{n=-\infty}^{\infty}a_{n}z^{n}\]

_be the Laurent expansion for \(\cot(\pi z)\) on the annulus \(1<|z|<2\). Compute the \(a_{n}\) for \(n<0\). Hint: Recall that \(\cot(\pi z)\) has simple poles at all integers z, with residues \(\pi^{-1}\), and no other singularities._

**Problem 5.11.3** (Sp78): _Show that there is a complex analytic function defined on the set \(U=\{z\in\mathbb{C}\ \mid|z|>4\}\) whose derivative is_

\[\frac{z}{(z-1)(z-2)(z-3)}.\]

_Is there a complex analytic function on \(U\) whose derivative is_

\[\frac{z^{2}}{(z-1)(z-2)(z-3)}\;?\]

**Problem 5.11.4** (Fa88): _Let \(n\) be a positive integer. Prove that the polynomial_

\[f(x)=\sum_{i=0}^{n}\frac{x^{i}}{i!}=1+x+\frac{x^{2}}{2}+\cdots+\frac{x^{n}}{n!}\]

_in \(\mathbb{R}[x]\) has \(n\) distinct complex zeros, \(z_{1},z_{2},\ldots,z_{n}\), and that they satisfy_

\[\sum_{i=1}^{n}z_{i}^{-j}=0\quad for\quad 2\leq j\leq n.\]

**Problem 5.11.5** (Sp79, Sp83): _Let \(P\) and \(Q\) be complex polynomials with the degree of \(Q\) at least two more than the degree of \(P\). Prove there is an \(r>0\) such that if \(C\) is a closed curve outside \(|z|=r\), then_

\[\int_{C}\frac{P(z)}{Q(z)}\,dz=0.\]

**Problem 5.11.6** (Sp80): _Let \(a>0\) be a constant \(\neq 2\). Let \(C_{a}\) denote the circle of radius a centered at the origin. Evaluate_

\[\int_{C_{a}}\frac{z^{2}+e^{z}}{z^{2}(z-2)}\,dz.\]

**Problem 5.11.7** (Su80): _Let \(C\) denote the circle \(|z|=2\), \(z\in\mathbb{C}\). Evaluate the integral_

\[\int_{C}\sqrt{z^{2}-1}\,dz\]

_where the branch of the square root is chosen so that \(\sqrt{2^{2}-1}>0\)._

**Problem 5.11.8** (Su81): _Compute_

\[\frac{1}{2\pi i}\int_{C}\frac{dz}{\sin\frac{1}{z}},\]

_where \(C\) is the circle \(|z|=1/5\), positively oriented._

**Problem 5.11.9** (Su84):
1. _Show that there is a unique analytic branch outside the unit circle of the function_ \(f(z)=\sqrt{z^{2}+z+1}\) _such that_ \(f(t)\) _is positive when_ \(t>1\)_._
2. _Using the branch determined in Part 1, calculate the integral_ \[\frac{1}{2\pi i}\int_{C_{r}}\frac{dz}{\sqrt{z^{2}+z+1}}\] _where_ \(C_{r}\) _is the circle_ \(|z|=r\) _and_ \(r>1\)_._

**Problem 5.11.10** (Sp86): _Let \(C\) be a simple closed contour enclosing the points \(0,1,2,\ldots,k\) in the complex plane. Evaluate the integrals_

\[I_{k}=\int_{C}\frac{dz}{z(z-1)\cdots(z-k)},\ \ \ \ \ k=0,1,\ldots,\]

\[J_{k}=\int_{C}\frac{(z-1)\cdots(z-k)}{z}\,dz,\ \ \ \ \ k=0,1,\ldots.\]

**Problem 5.11.11** (Sp86): _Evaluate_

\[\int_{|z|=1}(e^{2\pi z}+1)^{-2}\,dz\]

_where the integral is taken in counterclockwise direction._

**Problem 5.11.12** (Fa86): _Evaluate_

\[\frac{1}{2\pi i}\int_{|z|=1}\frac{z^{11}}{12z^{12}-4z^{9}+2z^{6}-4z^{3}+1}\,dz\]

_where the direction of integration is counterclockwise._

**Problem 5.11.13** (Sp89): _Evaluate_

\[\int_{C}(2z-1)e^{z/(z-1)}\,dz\]

_where \(C\) is the circle \(|z|=2\) with counterclockwise orientation._

**Problem 5.11.14** (Fa90): _Evaluate the integral_

\[I=\frac{1}{2\pi i}\int_{C}\frac{dz}{(z-2)(1+2z)^{2}(1-3z)^{3}}\]

_where \(C\) is the circle \(|z|=1\) with counterclockwise orientation._

**Problem 5.11.15** (Fa91): _Evaluate the integral_

\[I=\frac{1}{2\pi i}\int_{C}\frac{z^{n-1}}{3z^{n}-1}\,dz,\]

_where n is a positive integer, and \(C\) is the circle \(|z|=1\), with counterclockwise orientation._

**Problem 5.11.16** (Fa92): _Evaluate_

\[\int_{C}\ \frac{e^{z}}{z(2z+1)^{2}}\ dz,\]

_where \(C\) is the unit circle with counterclockwise orientation._

**Problem 5.11.17** (Fa93): _Evaluate \(\frac{1}{2\pi i}\int_{\gamma}f(z)\ dz\) for the function \(f(z)=z^{-2}(1-z^{2})^{-1}e^{z}\) and the curve \(\gamma\) depicted by._

**Problem 5.11.18** (Sp81): _Evaluate_

\[\int_{C}\frac{e^{z}-1}{z^{2}(z-1)}\,dz\]

_where \(C\) is the closed curve shown below:_

**Problem 5.11.19** (Sp95): _Let n be a positive integer and \(0<\theta<\pi\). Prove that_

\[\frac{1}{2\pi i}\int_{|z|=2}\frac{z^{n}}{1-2z\cos\theta+z^{2}}dz=\frac{\sin(n \theta)}{\sin\theta}\]

_where the circle \(|z|=2\) is oriented counterclockwise._

**Problem 5.11.20** (Su77, Fa84, Sp94, Sp96): _Use the Residue Theorem to evaluate the integral_

\[I(a)=\int_{0}^{2\pi}\frac{d\theta}{a+\cos\theta}\]

_where \(a\) is real and \(a>1\). Explain why the formula obtained for I(\(a\)) is also valid for certain complex (nonreal) values of \(a\)._

**Problem 5.11.21** (Fa78): _Evaluate_

\[\int_{0}^{2\pi}\frac{d\theta}{1-2r\cos\theta+r^{2}}\]

_where \(r^{2}\neq 1\)._

**Problem 5.11.22** (Sp87): _Evaluate_

\[I=\int_{0}^{\pi}\frac{\cos 4\theta}{1+\cos^{2}\theta}\,d\theta\,.\]

**Problem 5.11.23** (Fa87): _Evaluate the integral_

\[I=\int_{0}^{2\pi}\frac{\cos^{2}3\theta}{5-4\cos 2\theta}\,d\theta.\]

**Problem 5.11.24** (Sp95): _Let \(n\) be a positive integer. Compute_

\[\int_{0}^{2\pi}\frac{1-\cos(n\theta)}{1-\cos\theta}d\theta.\]

**Problem 5.11.25** (Fa94): _Evaluate the integrals_

\[\int_{-\pi}^{\pi}\frac{\sin n\theta}{\sin\theta}d\theta,\quad n=1,2,\ldots.\]

**Problem 5.11.26** (Sp88): _For \(a>1\) and \(n=0,1,2,\ldots\), evaluate the integrals_

\[C_{n}(a)=\int_{-\pi}^{\pi}\frac{\cos(n\theta)}{a-\cos\theta}\,d\theta,\qquad \quad S_{n}(a)=\int_{-\pi}^{\pi}\frac{\sin(n\theta)}{a-\cos\theta}\,d\theta.\]

### 5.12 Integrals Along the Real Axis

**Problem 5.12.1** (Sp86): _Let the complex valued functions \(f_{n}\), \(n\in\mathbb{Z}\), be defined on \(\mathbb{R}\) by_

\[f_{n}(x)=\pi^{-1/2}(x-i)^{n}/(x+i)^{n+1}.\]

_Prove that these functions are orthonormal; that is,_

\[\int_{-\infty}^{\infty}f_{m}(x)\overline{f_{n}(x)}\,dx=\left\{\begin{array}[] {cc}1&\mbox{\rm if}\quad m=n\\ 0&\mbox{\rm if}\quad m\neq n.\end{array}\right.\]

**Problem 5.12.2** (Fa85): _Evaluate the integral_

\[\int_{0}^{\infty}\frac{1-\cos(ax)}{x^{2}}\,dx\]

_for \(a\in\mathbb{R}\)._

**Problem 5.12.3** (Sp78, Sp83, Sp97): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{\sin^{2}x}{x^{2}}\,dx\,.\]

**Problem 5.12.4** (Fa82, Sp92): _Evaluate_

\[I=\int_{-\infty}^{\infty}\frac{\sin^{3}x}{x^{3}}\,dx\,.\]

**Problem 5.12.5** (Sp93): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{x^{3}\sin x}{(1+x^{2})^{2}}\,dx\,.\]

**Problem 5.12.6** (Sp81): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{x\sin x}{(1+x^{2})^{2}}\,dx\,.\]

**Problem 5.12.7** (Sp90, Fa92): _Let \(a\) be a positive real number. Evaluate the improper integral_

\[\int_{0}^{\infty}\frac{\sin x}{x(x^{2}+a^{2})}\,dx\,.\]

**Problem 5.12.8** (Sp91): _Prove that_

\[\lim_{R\to\infty}\int_{-R}^{R}\frac{\sin x}{x-3i}\,dx\]

_exists and find its value._

**Problem 5.12.9** (Sp83): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{\sin x}{x(x-\pi)}\,dx\,.\]

**Problem 5.12.10** (Fa97): _Evaluate the integral_

\[\int_{-\infty}^{\infty}\frac{\cos kx}{1+x+x^{2}}\,dx\]

_where \(k\geq 0\)._

**Problem 5.12.11** (Fa82): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{\cos(\pi x)}{4x^{2}-1}\,dx\,.\]

**Problem 5.12.12** (Sp77, Fa81, Sp82): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{\cos nx}{x^{4}+1}\,dx\,.\]

**Problem 5.12.13** (Sp79): _Evaluate_

\[\int_{0}^{\infty}\frac{x^{2}+1}{x^{4}+1}\,dx\,.\]

**Problem 5.12.14** (Su84): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{x\sin x}{x^{2}+4x+20}\,dx\,.\]

**Problem 5.12.15** (Fa84): _Evaluate_

\[\int_{0}^{\infty}\frac{x-\sin x}{x^{3}}\,dx\,.\]

**Problem 5.12.16** (Fa84): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{dx}{(1+x+x^{2})^{2}}\;.\]

**Problem 5.12.17** (Fa79, Fa80, Sp85, Su85): _Prove that_

\[\int_{0}^{\infty}\frac{x^{\alpha-1}}{1+x}\,dx=\frac{\pi}{\sin(\pi\alpha)}.\]

_What restrictions must be placed on \(\alpha\)?_

**Problem 5.12.18** (Fa96): _Evaluate the integral_

\[I=\int_{0}^{\infty}\frac{\sqrt{x}}{1+x^{2}}\ dx\,.\]

**Problem 5.12.19** (Fa77, Su82, Fa97): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{dx}{1+x^{2n}}\]

_where \(n\) is a positive integer._

**Problem 5.12.20** (Fa88): _Prove that_

\[\int_{0}^{\infty}\frac{x}{e^{x}-e^{-x}}\,dx=\frac{\pi^{2}}{8}.\]

**Problem 5.12.21** (Fa93): _Evaluate_

\[\int_{-\infty}^{\infty}\frac{e^{-ix}}{x^{2}-2x+4}\ dx\,.\]

**Problem 5.12.22** (Fa86): _Evaluate_

\[\int_{0}^{\infty}\frac{\log x}{(x^{2}+1)(x^{2}+4)}\,dx\,.\]

**Problem 5.12.23** (Fa94): _Evaluate_

\[\int_{0}^{\infty}\frac{(\log x)^{2}}{x^{2}+1}\,dx\,.\]

**Problem 5.12.24** (Fa83): _Evaluate_

\[\int_{0}^{\infty}(\operatorname{sech}x)^{2}\cos\lambda x\,dx\]

_where \(\lambda\) is a real constant and_

\[\operatorname{sech}x=\frac{2}{e^{x}+e^{-x}}.\]

**Problem 5.12.25** (Sp85): _Prove that_

\[\int_{0}^{\infty}e^{-x^{2}}\cos(2bx)\,dx=\frac{1}{2}\sqrt{\pi}e^{-b^{2}}.\]

_What restrictions, if any, need be placed on \(b^{2}\)_

**Problem 5.12.26** (Sp97): _Prove that_

\[\int_{-\infty}^{\infty}\frac{e^{-(t-i\gamma)^{2}/2}}{\sqrt{2\pi}}dt\]

_is independent of the real parameter \(\gamma\)._

## Chapter 6 Algebra

### 6.1 Examples of Groups and General Theory

**Problem 6.1.1** (Sp77): _Let \(G\) be the collection of 2\(\times\)2 real matrices with nonzero determinant. Define the product of two elements in \(G\) as the usual matrix product. group,\(\lambda\)center_

1. _Show that_ \(G\) _is a group._
2. _Find the_ center \(Z\) _of_ \(G\)_; that is, the set of all elements_ \(z\) _of_ \(G\) _such that_ \(az=za\) _for all_ \(a\in G\)_._
3. _Show that the set_ \(O\) _of real orthogonal matrices is a subgroup of_ \(G\) _(a matrix is_ orthogonal _if_ \(AA^{t}=I\)_, where_ \(A^{t}\) _denotes the transpose of A). Show by example that_ \(O\) _is not a normal subgroup._
4. _Find a nontrivial homomorphism from_ \(G\) _onto an abelian group._

**Problem 6.1.2** (Fa77): _Let \(G\) be the set of 3\(\times\)3 real matrices with zeros below the diagonal and ones on the diagonal._

1. _Prove_ \(G\) _is a group under matrix multiplication._
2. _Determine the center of_ \(G\)_._

**Problem 6.1.3** (Su78): _For each of the following either give an example or else prove that no such example is possible._

1. _A nonabelian group._2. _A finite abelian group that is not cyclic._
3. _An infinite group with a subgroup of index_ \(5\)_._
4. _Two finite groups that have the same order but are not isomorphic._
5. _A group_ \(G\) _with a subgroup_ \(H\) _that is_ not _normal._
6. _A nonabelian group with no normal subgroups except the whole group and the unit element._
7. _A group_ \(G\) _with a normal subgroup_ \(H\) _such that the factor group_ \(G/H\) _is_ not _isomorphic to any subgroup of_ \(G\)_._
8. _A group_ \(G\) _with a subgroup_ \(H\) _which has index_ \(2\) _but is_ not _normal._

**Problem 6.1.4** (Fa80): _Let \(R\) be a ring with multiplicative identity \(1\). Call \(x\in R\) a unit if \(xy=1\) for some \(y\in R\). Let \(G(R)\) denote the set of units._

1. _Prove_ \(G(R)\) _is a multiplicative group._
2. _Let_ \(R\) _be the ring of complex numbers_ \(a+bi\)_, where_ \(a\) _and_ \(b\) _are integers. Prove_ \(G(R)\) _is isomorphic to_ \(\mathbb{Z}_{4}\) _(the additive group of integers modulo_ \(4\)_)._

**Problem 6.1.5** (Sp83): _In the triangular network in \(\mathbb{R}^{2}\) which is depicted below, the points \(P_{0}\), \(P_{1}\), \(P_{2}\), and \(P_{3}\) are respectively \((0,0)\), \((1,0)\), \((0,1)\), and \((1,1)\). Describe the structure of the group of all Euclidean transformations of \(\mathbb{R}^{2}\) which leave this network invariant._

**Problem 6.1.6** (Fa90): _Does the set \(G=\{a\in\mathbb{R}\mid a>0,a\neq 1\}\) form a group with the operation \(a*b=a^{\log b}\)?_

**Problem 6.1.7** (Sp81): _Let \(G\) be a finite group. A conjugacy class is a set of the form_

\[C(a)=\{bab^{-1}\mid b\in G\}\]

_for some \(a\in G\)._

1. _Prove that the number of elements in a conjugacy class divides the order of_ \(G\)_._
2. _Do all conjugacy classes have the same number of elements?_
3. _If_ \(G\) _has only two conjugacy classes, prove_ \(G\) _has order_ \(2\)_._

**Problem 6.1.8** (Sp91): _Let \(G\) be a finite nontrivial group with the property that for any two elements \(a\) and \(b\) in \(G\) different from the identity, there is an element \(c\) in \(G\) such that \(b=c^{-1}ac\). Prove that \(G\) has order \(2\)._

**Problem 6.1.9** (Sp84): _For a \(p\)-group of order \(p^{4}\), assume the center of \(G\) has order \(p^{2}\). Determine the number of conjugacy classes of \(G\)._

**Problem 6.1.10** (Sp85): _In a commutative group \(G\), let the element \(a\) have order \(r\), let \(b\) have order \(s\)\((r,s<\infty)\), and assume that the greatest common divisor of \(r\) and \(s\) is \(1\). Show that \(ab\) has order \(rs\)._

**Problem 6.1.11** (Fa85): _Let \(G\) be a group. For any subset \(X\) of \(G\), define its centralizer \(C(X)\) to be \(\{y\in G\mid xy=yx,\forall x\in X\}\). Prove the following:_

1. _If_ \(X\subset Y\)_, then_ \(C(Y)\subset C(X)\)_._
2. \(X\subset C\left(C(X)\right)\)_._
3. \(C(X)=C\left(C\left(C(X)\right)\right)\)_._

**Problem 6.1.12** (Sp88): _Let \(D\) be a group of order \(2n\), where \(n\) is odd, with a subgroup \(H\) of order \(n\) satisfying \(xhx^{-1}=h^{-1}\) for all \(h\) in \(H\) and all \(x\) in \(D\setminus H\). Prove that \(H\) is commutative and that every element of \(D\setminus H\) is of order \(2\)._

### Homomorphisms and Subgroups

**Problem 6.2.1** (Fa78): _How many homomorphisms are there from the group \(\mathbb{Z}_{2}\times\mathbb{Z}_{2}\) to the symmetric group on three letters?_

**Problem 6.2.2** (Sp90): _Let \(\mathbb{C}\)\({}^{*}\) be the multiplicative group of nonzero complex numbers. Suppose that \(H\) is a subgroup of finite index of \(\mathbb{C}\)\({}^{*}\). Prove that \(H=\mathbb{C}\)\({}^{*}\)._

**Problem 6.2.3** (Su80): _Let \(G\) be a finite group and \(H\subset G\) a subgroup._1. _Show that the number of subgroups of_ \(G\) _of the form_ \(xHx^{-1}\) _for some_ \(x\in G\) _is_ \(\leq\) _the index of_ \(H\) _in_ \(G\)_._
2. _Prove that some element of_ \(G\) _is not in any subgroup of the form_ \(xHx^{-1}\)_,_ \(x\in G\)_._

**Problem 6.2.4** (Su79): _Prove that the group of automorphisms of a cyclic group of prime order \(p\) is cyclic and find its order._

**Problem 6.2.5** (Su81): _Let \(G\) be a finite group, and let \(\varphi\) be an automorphism of \(G\) which leaves fixed only the identity element of \(G\)._

1. _Show that every element of_ \(G\) _may be written in the form_ \(g^{-1}\varphi(g)\)_._
2. _If_ \(\varphi\) _has order_ \(2\) _(i.e.,_ \(\varphi\cdot\varphi=\mathrm{id}\)_) show that_ \(\varphi\) _is given by the formula_ \(g\mapsto g^{-1}\) _and that_ \(G\) _is an abelian group whose order is odd._

**Problem 6.2.6** (Fa79, Sp88, Fa91): _Prove that every finite group of order \(>2\) has a nontrivial automorphism._

**Problem 6.2.7** (Su81): _Let \(G\) be an additive group, and \(u,v:G\to G\) homomorphisms. Show that the map \(f:G\to G\), \(f(x)=x-v\left(u(x)\right)\) is surjective if the map \(h:G\to G\), \(h(x)=x-u\left(v(x)\right)\) is surjective._

**Problem 6.2.8** (Sp83): _Let \(H\) be the group of integers \(\mathrm{mod}p\), under addition, where \(p\) is a prime number. Suppose that \(n\) is an integer satisfying \(1\leq n\leq p\), and let \(G\) be the group \(H\times H\times\cdots\times H\) (\(n\) factors). Show that \(G\) has no automorphism of order \(p^{2}\)._

**Problem 6.2.9** (Fa84): _Let \(G\) be a group and \(H\) a subgroup of index \(n<\infty\). Prove or disprove the following statements:_

1. _If_ \(a\in G\)_, then_ \(a^{n}\in H\)_._
2. _If_ \(a\in G\)_, then for some_ \(k\)_,_ \(0<k\leq n\)_, we have_ \(a^{k}\in H\)_._

**Problem 6.2.10** (Fa78): _Find all automorphisms of the additive group of rational numbers._

**Problem 6.2.11** (Fa87, Fa93): _Let \(A\) be the group of rational numbers under addition, and let \(M\) be the group of positive rational numbers under multiplication. Determine all homomorphisms \(\varphi:A\to M\)._

**Problem 6.2.12** (Fa90): _Let \(A\) be an additively written abelian group, and \(f,g:A\to A\) two group homomorphisms. Define the group homomorphisms \(i,j:A\to A\) by_

\[i(a)=a-g\left(f(a)\right),\ \ \ \ j(a)=a-f\left(g(a)\right)\ \ \ \ \ (a\in A).\]

_Prove that the kernel of \(i\) is isomorphic to the kernel of \(j\)._

**Problem 6.2.13** (Fa92): _Let \(G\) be a group and \(H\) and \(K\) subgroups such that \(H\) has a finite index in \(G\). Prove that \(K\cap H\) has a finite index in \(K\)._

**Problem 6.2.14** (Fa94): _Suppose the group \(G\) has a nontrivial subgroup \(H\) which is contained in every nontrivial subgroup of \(G\). Prove that \(H\) is contained in the center of \(G\)._

**Problem 6.2.15** (Fa95): _Let \(G\) be a group generated by \(n\) elements. Find an upper bound \(N(n,k)\) for the number of subgroups \(H\) of \(G\) with the index \([G:H]=k\)._

### Cyclic Groups

**Problem 6.3.1** (Su77, Sp92):
1. _Prove that every finitely generated subgroup of_ \(\mathbb{Q}\)_, the additive group of rational numbers, is cyclic._
2. _Does the same conclusion hold for finitely generated subgroups of_ \(\mathbb{Q}\left/\mathbb{Z}\right.\)_, where_ \(\mathbb{Z}\) _is the group of integers?_

_Note: See also Problems 6.6.2 and 6.7.2._

**Problem 6.3.2** (Sp98): _Let \(G\) be the group \(\mathbb{Q}\left/\mathbb{Z}\right.\). Show that for every positive integer \(\iota\), \(G\) has a unique cyclic subgroup of order \(t\)._

**Problem 6.3.3** (Su85):
1. _Let_ \(G\) _be a cyclic group, and let_ \(a,b\in G\) _be elements which are not squares. Prove that_ \(ab\) _is a square._
2. _Give an example to show that this result is false if the group is not cyclic._

**Problem 6.3.4** (Sp82): _Prove that any group of order \(77\) is cyclic._

**Problem 6.3.5** (Fa91): _Let \(G\) be a group of order \(2p\), where \(p\) is an odd prime. Assume that \(G\) has a normal subgroup of order \(2\). Prove that \(G\) is cyclic._

**Problem 6.3.6** (Fa97): _A finite abelian group \(G\) has the property that for each positive integer \(n\) the set \(\{x\in G\,|\,x^{n}=1\}\) has at most \(n\) elements. Prove that \(G\) is cyclic, and deduce that every finite field has cyclic multiplicative group._

### Normality, Quotients, and Homomorphisms

**Problem 6.4.1** (Fa78): _Let \(H\) be a subgroup of a finite group \(G\)._

1. _Show that_ \(H\) _has the same number of left cosets as right cosets._

[MISSING_PAGE_FAIL:97]

**Problem 6.4.10** (Fa97): _Suppose \(H_{i}\) is a normal subgroup of a group \(G\) for \(1\leq i\leq k\), such that \(H_{i}\cap H_{j}=\{1\}\) for \(i\neq j\). Prove that \(G\) contains a subgroup isomorphic to \(H_{1}\times H_{2}\times\cdots\times H_{k}\) if \(k=2\), but not necessarily if \(k\geq 3\)._

**Problem 6.4.11** (Sp80): \(G\) _is a group of order \(n\), \(H\) a proper subgroup of order \(m\), and \((n/m)!<2n\). Prove \(G\) has a proper normal subgroup different from the identity._

**Problem 6.4.12** (Sp82, Sp93): _Prove that if \(G\) is a group containing no subgroup of index \(2\), then any subgroup of index \(3\) in \(G\) is a normal subgroup._

**Problem 6.4.13** (Sp89): _Let \(G\) be a group whose order is twice an odd number. For \(g\) in \(G\), let \(\lambda_{g}\) denote the permutation of \(G\) given by \(\lambda_{g}(x)=gx\) for \(x\in G\)._

1. _Let_ \(g\) _be in_ \(G\)_. Prove that the permutation_ \(\lambda_{g}\) _is even if and only if the order of_ \(g\) _is odd._
2. _Let_ \(N=\{g\in G\mid\operatorname{order}(g)\text{ is odd}\}\)_. Prove that_ \(N\) _is a normal subgroup of_ \(G\) _of index_ \(2\)_._

**Problem 6.4.14** (Fa89): _Let \(G\) be a group, \(G^{\prime}\) its commutator subgroup, and \(N\) a normal subgroup of \(G\). Suppose that \(N\) is cyclic. Prove that \(gn=ng\) for all \(g\in G^{\prime}\) and all \(n\in N\)._

**Problem 6.4.15** (Fa90): _Let \(G\) be a group and \(N\) be a normal subgroup of \(G\) with \(N\neq G\). Suppose that there does not exist a subgroup \(H\) of \(G\) satisfying \(N\subset H\subset G\) and \(N\neq H\neq G\). Prove that the index of \(N\) in \(G\) is finite and equal to a prime number._

**Problem 6.4.16** (Sp94): _Let \(G\) be a group having a subgroup \(A\) of finite index. Prove that there is a normal subgroup \(N\) of \(G\) contained in \(A\) such that \(N\) is of finite index in \(G\)._

**Problem 6.4.17** (Sp97): _Let \(H\) be the quotient of an abelian group \(G\) by a subgroup \(K\). Prove or disprove each of the following statements:_

1. _If_ \(H\) _is finite cyclic then_ \(G\) _is isomorphic to the direct product of_ \(H\) _and_ \(K\)_._
2. _If_ \(H\) _is a direct product of infinite cyclic groups then_ \(G\) _is isomorphic to the direct product of_ \(H\) _and_ \(K\)_._

### \(S_{n}\), \(A_{n}\), \(D_{n}\),...

**Problem 6.5.1** (Fa80): _Let \(\mathbf{F}_{2}=\{0,1\}\) be the field with two elements. Let \(G\) be the group of invertible 2\(\times\)2 matrices with entries in \(\mathbf{F}_{2}\). Show that \(G\) is isomorphic to \(S_{3}\), the group of permutations of three objects._

**Problem 6.5.2** (Su84): _Let \(S_{n}\) denote the group of permutations of \(n\) letters. Find four different subgroups of \(S_{4}\) isomorphic to \(S_{3}\) and nine isomorphic to \(S_{2}\)._

**Problem 6.5.3** (Fa86): _Let \(G\) be a subgroup of \(S_{5}\), the group of all permutations on the set \(\{1,2,3,4,5\}\). Prove that if \(G\) contains a \(5\)-cycle and a \(2\)-cycle, then \(G=S_{5}\)._

_Hint: Recall that if \((i_{1}\,i_{2}\,\cdots\,i_{n})\) is a cycle and \(\sigma\) is any permutation, then_

\[\sigma(i_{1}\,i_{2}\,\cdots\,i_{n})\sigma^{-1}=\left(\sigma(i_{1})\,\sigma(i_{ 2})\,\cdots\,\sigma(i_{n})\right).\]

**Problem 6.5.4** (Fa85): _Let \(G\) be a subgroup of the symmetric group on six letters, \(\mathrm{S}_{6}\). Assume that \(G\) has an element of order \(6\). Prove that \(G\) has a normal subgroup \(H\) of index \(2\)._

**Problem 6.5.5** (Sp79): _Let \(S_{7}\) be the group of permutations of a set of seven elements. Find all \(n\) such that some element of \(S_{7}\) has order \(n\)._

**Problem 6.5.6** (Sp80): \(S_{9}\) _is the group of permutations of the set of integers from \(1\) to \(9\)._

1. _Exhibit an element of_ \(S_{9}\) _of order_ \(20\)_._
2. _Prove that no element of_ \(S_{9}\) _has order_ \(18\)_._

**Problem 6.5.7** (Sp88): _Let \(S_{9}\) denote the group of permutations of \(\{1,2,\ldots,9\}\) and let \(A_{9}\) be the subgroup consisting of all even permutations. Denote by \(1\in S_{9}\) the identity permutation. Determine the minimum of all positive integers \(m\) such that every \(\sigma\in S_{9}\) satisfies \(\sigma^{m}=1\). Determine also the minimum of all positive integers \(m\) such that every \(\sigma\in A_{9}\) satisfies \(\sigma^{m}=1\)._

**Problem 6.5.8** (Sp92): _Let \(S_{999}\) denote the group of all permutations of \(\{1,\ldots,999\}\), and let \(G\subset S_{999}\) be an abelian subgroup of order \(1111\). Prove that there exists \(i\in\{1,\ldots,999\}\) such that for all \(\sigma\in G\), one has \(\sigma(i)=i\)._

**Problem 6.5.9** (Fa81, Sp95): _Let \(\mathrm{S}_{n}\) be the group of all permutations of \(n\) objects and let \(G\) be a subgroup of \(\mathrm{S}_{n}\) of order \(p^{k}\), where \(p\) is a prime not dividing \(n\). Show that \(G\) has a fixed point; that is, one of the objects is left fixed by every element of \(G\)._

**Problem 6.5.10** (Sp80): _Let \(G\) be a group of permutations of a set \(S\) of \(n\) elements. Assume \(G\) is transitive; that is, for any \(x\) and \(y\) in \(S\), there is some \(\sigma\in G\) with \(\sigma(x)=y\)._

1. _Prove that_ \(n\) _divides the order of_ \(G\)_._
2. _Suppose_ \(n=4\)_. For which integers_ \(k\geq 1\) _can such a_ \(G\) _have order_ \(4k\)

**Problem 6.5.11** (Su83): _Let \(G\) be a transitive subgroup of the group \(S_{n}\) of permutations of the set \(\{1,\ldots,n\}.\) Suppose that \(G\) is a simple group and that \(\sim\) is an equivalence relation on \(\{1,\ldots,n\}\) such that \(i\sim j\) implies that \(\sigma(i)\sim\sigma(j)\) for all \(\sigma\in G\). What can you conclude about the relationship \(\sim\)?_

**Problem 6.5.12** (Sp89): _Let \(D_{n}\) be the dihedral group, the group of rigid motions of a regular n-gon \((n\geq 3).\) (It is a noncommutative group of order \(2n\).) Determine its center \(C=\{c\in D_{n}\mid cx=xc\ for\ all\ x\in D_{n}\}.\)_

**Problem 6.5.13** (Fa92): _How many Sylow \(2\)-subgroups does the dihedral group \(D_{n}\) of order \(2n\) have, when \(n\) is odd?_

### 6.6 Direct Products

**Problem 6.6.1** (Fa83): _Let \(G\) be a finite group and \(G_{1}=G\times G\). Suppose that \(G_{1}\) has exactly four normal subgroups. Show that \(G\) is simple and nonabelian._

**Problem 6.6.2** (Sp91): _Prove that \(\mathbb{Q}\), the additive group of rational numbers, cannot be written as the direct sum of two nontrivial subgroups. Note: See also Problems 6.3.1 and 6.7.2._

**Problem 6.6.3** (Su79, Fa93): _Let \(A\), \(B\), and \(C\) be finite abelian groups such that \(A\times B\) and \(A\times C\) are isomorphic. Prove that \(B\) and \(C\) are isomorphic._

**Problem 6.6.4** (Su83): _Let \(G_{1}\), \(G_{2}\), and \(G_{3}\) be finite groups, each of which is generated by its commutators (elements of the form \(xyx^{-1}y^{-1}\)). Let \(A\) be a subgroup of \(G_{1}\times G_{2}\times G_{3}\), which maps surjectively, by the natural projection map, to the partial products \(G_{1}\times G_{2}\), \(G_{1}\times G_{3}\) and \(G_{2}\times G_{3}\). Show that \(A\) is equal to \(G_{1}\times G_{2}\times G_{3}\)._

**Problem 6.6.5** (Fa82): _Let \(A\) be a subgroup of an abelian group \(B\). Assume that \(A\) is a direct summand of \(B\), i.e., there exists a subgroup \(X\) of \(B\) such that \(A\cap X=0\) and such that \(B=X+A\). Suppose that \(C\) is a subgroup of \(B\) satisfying \(A\subset C\subset B\). Is \(A\) necessarily a direct summand of \(C\)?_

**Problem 6.6.6** (Fa87, Sp96): _Let \(G\) and \(H\) be finite groups of relatively prime order. Show that \(\operatorname{Aut}(G\times H)\), the group of automorphisms of \(G\times H\), is isomorphic to the direct product of \(\operatorname{Aut}(G)\) and \(\operatorname{Aut}(H)\)._

### Free Groups, Products, Generators, and Relations

**Problem 6.7.1** (Sp77): _Let \(\mathbb{Q}_{+}\) be the multiplicative group of positive rational numbers._

1. _Is_ \(\mathbb{Q}_{+}\) _torsion free?_
2. _Is_ \(\mathbb{Q}_{+}\) _free?_

**Problem 6.7.2** (Sp86): _Prove that the additive group of \(\mathbb{Q}\), the rational number field, is not finitely generated._

_Note: See also Problems 6.3.1 and 6.6.2._

**Problem 6.7.3** (Fa79, Fa82): _Let \(G\) be the abelian group defined by generators \(x\), \(y\), and \(z\), and relations_

\[15x+3y =0\] \[3x+7y+4z =0\] \[18x+14y+8z =0.\]

1. _Express_ \(G\) _as a direct product of two cyclic groups._
2. _Express_ \(G\) _as a direct product of cyclic groups of prime power order._
3. _How many elements of_ \(G\) _have order_ \(2\)_?_

**Problem 6.7.4** (Sp82, Sp93): _Suppose that the group \(G\) is generated by elements \(x\) and \(y\) that satisfy \(x^{5}y^{3}=x^{8}y^{5}=1\). Is \(G\) the trivial group?_

**Problem 6.7.5** (Su82): _Let \(G\) be a group with generators \(a\) and \(b\) satisfying_

\[a^{-1}b^{2}a=b^{3},\qquad b^{-1}a^{2}b=a^{3}.\]

_Is \(G\) trivial?_

**Problem 6.7.6** (Fa88, Fa97): _Let the group \(G\) be generated by two elements, \(a\) and \(b\), both of order \(2\). Prove that \(G\) has a subgroup of index \(2\)._

**Problem 6.7.7** (Fa89): _Let \(G_{n}\) be the free group on \(n\) generators. Show that \(G_{2}\) and \(G_{3}\) are not isomorphic._

**Problem 6.7.8** (Sp83): _Let \(G\) be an abelian group which is generated by, at most, \(n\) elements. Show that each subgroup of \(G\) is again generated by, at most, \(n\) elements._

**Problem 6.7.9** (Sp84): _Determine all finitely generated abelian groups \(G\) which have only finitely many automorphisms._

**Problem 6.7.10** (Fa89): _Let \(A\) be a finite abelian group, and \(m\) the maximum of the orders of the elements of \(A\). Put \(S=\{a\in A\mid|a|=m\}\). Prove that \(A\) is generated by \(S\)._

### 6.8 Finite Groups

**Problem 6.8.1** (Sp91): _List, to within isomorphism, all the finite groups whose orders do not exceed \(5\). Explain why your list is complete and why no two groups on the list are isomorphic._

**Problem 6.8.2** (Fa84): _Show that all groups of order \(\leq 5\) are commutative. Give an example of a noncommutative group of order \(6\)._

**Problem 6.8.3** (Fa80): _Prove that any group of order \(6\) is isomorphic to either \(\mathbb{Z}_{6}\) or \(S_{3}\) (the group of permutations of three objects)._

**Problem 6.8.4** (Sp87):
1. _Show that, to within isomorphism, there is just one noncyclic group_ \(G\) _of order_ \(4\)_._
2. _Show that the group of automorphisms of_ \(G\) _is isomorphic to the permutation group_ \(S_{3}\)_._

**Problem 6.8.5** (Fa88): _Find all abelian groups of order \(8\), up to isomorphism. Then identify which type occurs in each of_

1. \(\left(\mathbb{Z}_{15}\right)^{\star}\)_,_
2. \(\left(\mathbb{Z}_{17}\right)^{\star}/(\pm 1)\)_,_
3. _the roots of_ \(z^{8}-1\) _in_ \(\mathbb{C}\)_,_
4. \(\mathbf{F}_{8}^{+}\)_,_
5. \(\left(\mathbb{Z}_{16}\right)^{\star}\)_._

\(\mathbf{F}_{8}\) _is the field of eight elements, and_ \(\mathbf{F}_{8}^{+}\) _is its underlying additive group;_ \(R^{\star}\) _is the group of invertible elements in the ring_ \(R\)_, under multiplication._

**Problem 6.8.6** (Sp90, Fa93, Sp94): _Show that there are at least two nonisomorphic nonabelian groups of order \(24\), of order \(30\) and order \(40\)._

**Problem 6.8.7** (Fa97): _Prove that if \(p\) is prime then every group of order \(p^{2}\) is abelian._

**Problem 6.8.8** (Sp93): _Classify up to isomorphism all groups of order \(45\)._

**Problem 6.8.9** (Sp97): _Classify abelian groups of order \(80\) up to isomorphism._

**Problem 6.8.10** (Sp79): _Let \(S\) be a collection of abelian groups, each of order \(720\), no two of which are isomorphic. What is the maximum cardinality \(S\) can have?_

**Problem 6.8.11** (Fa88): _Find (up to isomorphism) all groups of order \(2p\), where \(p\) is a prime (\(p\geq 2\))._

**Problem 6.8.12** (Sp87): _Prove that any finite group of order \(n\) is isomorphic to a subgroup of \(\mathbb{O}(n)\), the group of \(n\times n\) orthogonal real matrices._

**Problem 6.8.13** (Su80, Fa96): _Prove that every finite group is isomorphic to_

1. _A group of permutations;_
2. _A group of even permutations._

### Rings and Their Homomorphisms

**Problem 6.9.1** (Fa80): _Let \(M\) be the ring of real 2\(\times\)2 matrices and \(S\subset M\) the subring of matrices of the form_

\[\left(\begin{array}{cc}a&-b\\ b&a\end{array}\right).\]

1. _Exhibit (without proof) an isomorphism between_ \(S\) _and_ \(\mathbb{C}\) _._
2. _Prove that_ \[A=\left(\begin{array}{cc}0&3\\ -4&1\end{array}\right)\] _lies in a subring isomorphic to_ \(S\)_._
3. _Prove that there is an_ \(X\in M\) _such that_ \(X^{4}+13X=A\)_._

**Problem 6.9.2** (Sp86): _Prove that there exists only one automorphism of the field of real numbers; namely the identity automorphism._

**Problem 6.9.3** (Sp86): _Suppose addition and multiplication are defined on \(\mathbb{C}\,^{n}\), complex \(n\)-space, coordinatewise, making \(\mathbb{C}\,^{n}\) into a ring. Find all ring homomorphisms of \(\mathbb{C}\,^{n}\) onto \(\mathbb{C}\)._

**Problem 6.9.4** (Fa88): _Let \(R\) be a finite ring. Prove that there are positive integers m and n with \(m>n\) such that \(x^{m}=x^{n}\) for every x in \(R\)._

**Problem 6.9.5** (Sp89): _Let \(R\) be a ring with at least two elements. Suppose that for each nonzero \(a\) in \(R\) there is a unique \(b\) in \(R\) (depending on \(a\)) with \(aba=a\). Show that \(R\) is a division ring._

_Hint: Show first that \(R\) has no zero divisors, then find a multiplicative indentity in \(R\), then prove the existence of inverses._

**Problem 6.9.6** (Sp91): _Let \(p\) be a prime number and \(R\) a ring with identity containing \(p^{2}\) elements. Prove that \(R\) is commutative._

**Problem 6.9.7** (Fa93): _Let \(R\) be a commutative ring with identity. Let \(G\) be a finite subgroup of \(R^{*}\), the group of units of \(R\). Prove that if \(R\) is an integral domain, then \(G\) is cyclic._

**Problem 6.9.8** (Fa94): _Let \(R\) be a ring with an identity, and let \(u\) be an element of \(R\) with a right inverse. Prove that the following conditions on \(u\) are equivalent:_

1. \(u\) _has more than one right inverse;_
2. \(u\) _is a zero divisor;_
3. \(u\) _is not a unit._

**Problem 6.9.9** (Su81, Sp93): _Show that no commutative ring with identity has additive group isomorphic to \(\mathbb{Q}\) /\(\mathbb{Z}\)._

**Problem 6.9.10** (Sp81): _Let \(D\) be an ordered integral domain and \(a\in D\). Prove that_

\[a^{2}-a+1>0.\]

**Problem 6.9.11** (Fa95): _Prove that \(\mathbb{Q}\left[x,y\right]/\langle x^{2}+y^{2}-1\rangle\) is an integral domain and that its field of fractions is isomorphic to the field of rational functions \(\mathbb{Q}\left(t\right)\)._

### Ideals

**Problem 6.10.1** (Sp98): _Let \(A\) be the ring of real 2\(\times\)2 matrices of the form \(\left(\begin{smallmatrix}a&b\\ 0&c\end{smallmatrix}\right)\). What are the 2-sided ideals in \(A\)? Justify your answer._

**Problem 6.10.2** (Fa79, Fa87): _Let \(M_{n\times n}(\mathbf{F})\) be the ring of \(n\times n\) matrices over a field \(\mathbf{F}\). Prove that it has no 2-sided ideals except \(M_{n\times n}(\mathbf{F})\) and \(\{0\}\)._

**Problem 6.10.3** (Fa83, Su85): _Let \(M_{n\times n}(\mathbf{F})\) denote the ring of \(n\times n\) matrices over a field \(\mathbf{F}\). For \(n\geq 1\) does there exist a ring homomorphism from \(M_{(n+1)\times(n+1)}(\mathbf{F})\) onto \(M_{n\times n}(\mathbf{F})\)?_

**Problem 6.10.4** (Sp84): _Let \(\mathbf{F}\) be a field and let \(X\) be a finite set. Let \(R(X,\mathbf{F})\) be the ring of all functions from \(X\) to \(\mathbf{F}\), endowed with the pointwise operations. What are the maximal ideals of \(R(X,\mathbf{F})\)?_

**Problem 6.10.5** (Sp88): _Let \(R\) be a commutative ring with unit element and \(a\in R\). Let \(n\) and \(m\) be positive integers, and write \(d=\gcd\{n,m\}\). Prove that the ideal of \(R\) generated by \(a^{n}-1\) and \(a^{m}-1\) is the same as the ideal generated by \(a^{d}-1\)._

**Problem 6.10.6** (Sp89):
1. _Let_ \(R\) _be a commutative ring with_ \(1\) _containing an element_ \(a\) _with_ \(a^{3}=a+1\)_. Further, let_ \(\mathfrak{I}\) _be an ideal of_ \(R\) _of index_ \(<5\) _in_ \(R\)_. Prove that_ \(\mathfrak{I}=R\)_._
2. _Show that there exists a commutative ring with_ \(1\) _that has an element_ \(a\) _with_ \(a^{3}=a+1\) _and that contains an ideal of index_ \(5\)_._

_Note: The term index is used here exactly as in group theory; namely the index of \(\mathfrak{I}\) in \(R\) means the order of \(R/\mathfrak{I}\)._

**Problem 6.10.7** (Sp90):
1. _Let_ \(R\) _be a commutative ring with_ \(1\)_, and_ \(R^{*}\) _be its group of units. Suppose that the additive group of_ \(R\) _is generated by_ \(\{u^{2}\mid u\in R^{*}\}\)_. Prove that_ \(R\) _has, at most, one ideal_ \(\mathfrak{I}\) _for which_ \(R/\mathfrak{I}\) _has cardinality_ \(3\)_._

**Problem 6.10.8** (Fa90):
1. _Let_ \(R\) _be a ring with_ \(1\)_, and let_ \(\mathfrak{I}\) _be the left ideal of_ \(R\) _generated by_ \(\{ab-ba\mid a,b\in R\}\)_. Prove that_ \(\mathfrak{I}\) _is a two-sided ideal._

**Problem 6.10.9** (Sp95):
1. _Suppose that_ \(R\) _is a subring of a commutative ring_ \(S\) _and that_ \(R\) _is of finite index_ \(n\) _in_ \(S\)_. Let_ \(m\) _be an integer that is relatively prime to_ \(n\)_. Prove that the natural map_ \(R/mR\to S/mS\) _is a ring isomorphism._

**Problem 6.10.10** (Sp81):
1. _Let_ \(\mathbf{M}\) _be one of the following fields:_ \(\mathbb{R}\)_,_ \(\mathbb{C}\) _,_ \(\mathbb{Q}\) _, and_ \(\mathbf{F}_{9}\) _(the field with nine elements). Let_ \(\mathfrak{I}\subset\mathbf{M}[x]\) _be the ideal generated by_ \(x^{4}+2x-2\)_. For which choices of_ \(\mathbf{M}\) _is the ring_ \(\mathbf{M}[x]/\mathfrak{I}\) _a field?_

**Problem 6.10.11** (Sp84):
1. _Let_ \(R\) _be a principal ideal domain and let_ \(\mathfrak{I}\) _and_ \(\mathfrak{I}\) _be nonzero ideals in_ \(R\)_. Show that_ \(\mathfrak{I}\mathfrak{I}=\mathfrak{I}\cap\mathfrak{I}\) _if and only if_ \(\mathfrak{I}+\mathfrak{I}=R\)_._

### Polynomials

**Problem 6.11.1** (Su85):
1. _By the Fundamental Theorem of Algebra, the polynomial_ \(x^{3}+2x^{2}+7x+1\) _has three complex roots,_ \(\alpha_{1}\)_,_ \(\alpha_{2}\)_, and_ \(\alpha_{3}\)_. Compute_ \(\alpha_{1}^{3}+\alpha_{2}^{3}+\alpha_{3}^{3}\)_._

**Problem 6.11.2** (Fa77):
1. _Suppose the complex number_ \(\alpha\) _is a root of a polynomial of degree_ \(n\) _with rational coefficients. Prove that_ \(1/\alpha\) _is also a root of a polynomial of degree_ \(n\) _with rational coefficients._

**Problem 6.11.3** (Sp85):
1. _Let_ \(\zeta=e^{\frac{2\pi i}{\zeta}}\) _be a primitive_ \(7^{th}\) _root of unity. Find a cubic polynomial with integer coefficients having_ \(\alpha=\zeta+\zeta^{-1}\) _as a root._

**Problem 6.11.4** (Sp92, Su77, Fa81):
1. _Prove that_ \(\alpha=\sqrt{5}+\sqrt{7}\) _is algebraic over_ \(\mathbb{Q}\) _, by explicitly finding a polynomial_ \(f(x)\) _in_ \(\mathbb{Q}\)__\([x]\) _of degree_ \(4\) _having_ \(\alpha\) _as a root._2. _Prove that_ \(f(x)\) _is irreducible over_ \(\mathbb{Q}\) _._

**Problem 6.11.5** (Fa90): _Prove that \(\sqrt{2}+\sqrt[3]{3}\) is irrational._

**Problem 6.11.6** (Su85): _Let \(P(z)\) be a polynomial of degree \(<k\) with complex coefficients. Let \(\omega_{1},\ldots,\omega_{k}\) be the \(k^{th}\) roots of unity in \(\mathbb{C}\). Prove that_

\[\frac{1}{k}\sum_{i=1}^{k}P(\omega_{i})=P(0).\]

**Problem 6.11.7** (Fa95): _Let \(f(x)\in\mathbb{Q}\left[x\right]\) be a polynomial with rational coefficients. Show that there is a \(g(x)\in\mathbb{Q}\left[x\right]\), \(g\neq\ 0\), such that \(f(x)g(x)=a_{2}x^{2}+a_{3}x^{3}+a_{5}x^{5}+\cdots+a_{p}x^{p}\) is a polynomial in which only prime exponents appear._

**Problem 6.11.8** (Fa91): _Let \(\mathfrak{I}\) be the ideal in the ring \(\mathbb{Z}[x]\) generated by \(x-7\) and \(15\). Prove that the quotient ring \(\mathbb{Z}[x]/\mathfrak{I}\) is isomorphic to \(\mathbb{Z}_{15}\)._

**Problem 6.11.9** (Fa92): _Let \(\mathfrak{I}\) denote the ideal in \(\mathbb{Z}[x]\), the ring of polynomials with coefficients in \(\mathbb{Z}\), generated by \(x^{3}+x+1\) and \(5\). Is \(\mathfrak{I}\) a prime ideal?_

**Problem 6.11.10** (Su77): _In the ring \(\mathbb{Z}[x]\) of polynomials in one variable over the integers, show that the ideal \(\mathfrak{I}\) generated by \(5\) and \(x^{2}+2\) is a maximal ideal._

**Problem 6.11.11** (Sp78): _let \(\mathbb{Z}_{n}\) denote the ring of integers modulo n. Let \(\mathbb{Z}_{n}[x]\) be the ring of polynomials with coefficients in \(\mathbb{Z}_{n}\). Let \(\mathfrak{I}\) denote the ideal in \(\mathbb{Z}_{n}[x]\) generated by \(x^{2}+x+1\)._

1. _For which values of n,_ \(1\leq n\leq 10\)_, is the quotient ring_ \(\mathbb{Z}_{n}[x]/\mathfrak{I}\) _a field?_
2. _Give the multiplication table for_ \(\mathbb{Z}_{2}/\mathfrak{I}\)_._

**Problem 6.11.12** (Sp86): _Let \(\mathbb{Z}\) be the ring of integers, \(p\) a prime, and \(\mathbf{F}_{p}=\mathbb{Z}/p\mathbb{Z}\) the field of p elements. Let \(x\) be an indeterminate, and set \(R_{1}=\mathbf{F}_{p}[x]/\langle x^{2}-2\rangle\), \(R_{2}=\mathbf{F}_{p}[x]/\langle x^{2}-3\rangle\). Determine whether the rings \(R_{1}\) and \(R_{2}\) are isomorphic in each of the cases \(p=2,5,11\)._

**Problem 6.11.13** (Fa79, Su80, Fa82): _Consider the polynomial ring \(\mathbb{Z}[x]\) and the ideal \(\mathfrak{I}\) generated by \(7\) and \(x-3\)._

1. _Show that for each_ \(r\in\mathbb{Z}[x]\)_, there is an integer_ \(\alpha\) _satisfying_ \(0\leq\alpha\leq 6\) _such that_ \(r-\alpha\in\mathfrak{I}\)_._
2. _Find_ \(\alpha\) _in the special case_ \(r=x^{250}+15x^{14}+x^{2}+5\)

**Problem 6.11.14** (Fa96): _Let \(\mathbb{Z}[x]\) be the ring of polynomials in the indeterminate \(x\) with coefficients in the ring \(\mathbb{Z}\) of integers. Let \(\mathcal{I}\subset\mathbb{Z}[x]\) be the ideal generated by \(13\) and \(x\mathchar 144\relax 4\). Find an integer \(m\) such that \(0\leq m\leq 12\) and_

\[(x^{26}+x+1)^{73}-m\in\mathcal{I}\.\]

**Problem 6.11.15** (Sp77):
1. _In_ \(\mathbb{R}[x]\)_, consider the set of polynomials_ \(f(x)\) _for which_ \(f(2)=f^{\prime}(2)=f^{\prime\prime}(2)=0\)_. Prove that this set forms an ideal and find its monic generator._
2. _Do the polynomials such that_ \(f(2)=0\) _and_ \(f^{\prime}(3)=0\) _form an ideal?_

**Problem 6.11.16** (Sp94): _Find all automorphisms of \(\mathbb{Z}[x]\), the ring of polynomials over \(\mathbb{Z}\)._

**Problem 6.11.17** (Su78): _Let \(R\) denote the ring of polynomials over a field \(\mathbf{F}\). Let \(p_{1},\ldots,p_{n}\) be elements of \(R\). Prove that the greatest common divisor of \(p_{1},\ldots,p_{n}\) is \(1\) if and only if there is an \(n\times n\) matrix over \(R\) of determinant \(1\) whose first row is \((p_{1},\ldots,p_{n})\)._

**Problem 6.11.18** (Sp79): _Let \(f(x)\) be a polynomial over \(\mathbb{Z}_{p}\), the field of integers mod \(p\). Let \(g(x)=x^{p}-x\). Show that the greatest common divisor of \(f(x)\) and \(g(x)\) is the product of the distinct linear factors of \(f(x)\)._

**Problem 6.11.19** (Su79): _Let \(\mathbf{F}\) be a subfield of a field \(\mathbf{K}\). Let \(p\) and \(q\) be polynomials over \(\mathbf{F}\). Prove that their \(\gcd\) (greatest common divisor) in the ring of polynomials over \(\mathbf{F}\) is the same as their \(\gcd\) in the ring of polynomials over \(\mathbf{K}\)._

**Problem 6.11.20** (Su81, Su82): _Show that \(x^{10}+x^{9}+x^{8}+\cdots+x+1\) is irreducible over \(\mathbb{Q}\). How about \(x^{11}+x^{10}+\cdots+x+1\)?_

**Problem 6.11.21** (Su84): _Let \(\mathbb{Z}\) be the ring of integers and \(\mathbb{Z}[x]\) the polynomial ring over \(\mathbb{Z}\). Show that_

\[x^{6}+539x^{5}-511x+847\]

_is irreducible in \(\mathbb{Z}[x]\)._

**Problem 6.11.22** (Sp82): _Prove that the polynomial \(x^{4}+x+1\) is irreducible over \(\mathbb{Q}\)._

**Problem 6.11.23** (Fa83, Fa86): _Prove that if \(p\) is a prime number, then the polynomial_

\[f(x)=x^{p-1}+x^{p-2}+\cdots+1\]

_is irreducible in \(\mathbb{Q}[x]\)._

**Problem 6.11.24** (Sp96): _Prove that \(f(x)=x^{4}+x^{3}+x^{2}+6x+1\) is irreducible over \(\mathbb{Q}\)._

**Problem 6.11.25** (Su84): _Let \(\mathbb{Z}_{3}\) be the field of integers \(\bmod 3\) and \(\mathbb{Z}_{3}[x]\) the corresponding polynomial ring. Decompose \(x^{3}+x+2\) into irreducible factors in \(\mathbb{Z}_{3}[x]\)._

**Problem 6.11.26** (Sp85): _Factor \(x^{4}+x^{3}+x+3\) completely in \(\mathbb{Z}_{5}[x]\)._

**Problem 6.11.27** (Fa85):
1. _How many different monic irreducible polynomials of degree_ \(2\) _are there over the field_ \(\mathbb{Z}_{5}\)_?_
2. _How many different monic irreducible polynomials of degree_ \(3\) _are there over the field_ \(\mathbb{Z}_{5}\)_?_

**Problem 6.11.28** (Sp78): _Is \(x^{4}+1\) irreducible over the field of real numbers? The field of rational numbers? A field with \(16\) elements?_

**Problem 6.11.29** (Sp81): _Decompose \(x^{4}-4\) and \(x^{3}-2\) into irreducibles over \(\mathbb{R}\), over \(\mathbb{Z}\), and over \(\mathbb{Z}_{3}\) (the integers modulo \(3\))._

**Problem 6.11.30** (Fa84): _Let \(a\) be an element in a field \(\mathbf{F}\) and let \(p\) be a prime. Assume \(a\) is not a \(p^{th}\) power. Show that the polynomial \(x^{p}-a\) is irreducible in \(\mathbf{F}[x]\)._

**Problem 6.11.31** (Sp92): _Let \(p\) be a prime integer, \(p\equiv 3\pmod{4}\), and let \(\mathbf{F}_{p}=\mathbb{Z}/p\mathbb{Z}\). If \(x^{4}+1\) factors into a product \(g(x)h(x)\) of two quadratic polynomials in \(\mathbf{F}_{p}[x]\), prove that \(g(x)\) and \(h(x)\) are both irreducible over \(\mathbf{F}_{p}\)._

**Problem 6.11.32** (Fa88): _Let n be a positive integer and let \(f\) be a polynomial in \(\mathbb{R}[x]\) of degree \(n\). Prove that there are real numbers \(a_{0},a_{1},\ldots,a_{n}\), not all equal to zero, such that the polynomial_

\[\sum_{i=0}^{n}a_{i}x^{2^{i}}\]

_is divisible by f._

**Problem 6.11.33** (Fa89): _Let \(\mathbf{F}\) be a field, \(\mathbf{F}[x]\) the polynomial ring in one variable over \(\mathbf{F}\), and \(R\) a subring of \(\mathbf{F}[x]\) with \(\mathbf{F}\subset R\). Prove that there exists a finite set \(\{f_{1},f_{2},\ldots,f_{n}\}\) of elements of \(\mathbf{F}[x]\) such that \(R=\mathbf{F}[f_{1},f_{2},\ldots,f_{n}]\)._

**Problem 6.11.34** (Sp87): _Let \(\mathbf{F}\) be a finite field with \(q\) elements and let \(x\) be an indeterminate. For \(f\) a polynomial in \(\mathbf{F}[x]\), let \(\varphi_{f}\) denote the corresponding function of \(\mathbf{F}\) into \(\mathbf{F}\), defined by \(\varphi_{f}(a)=f(a)\), \((a\in\mathbf{F})\). Prove that if \(\varphi\) is any function of \(\mathbf{F}\) into \(\mathbf{F}\), then there is an \(f\) in \(\mathbf{F}[x]\) such that \(\varphi=\varphi_{f}\). Prove that \(f\) is uniquely determined by \(\varphi\) to within addition of a multiple of \(x^{q}-x\)._

### 6.12 Fields and Their Extensions

**Problem 6.12.1** (Su78, Fa87, Sp93): _Let \(R\) be the set of 2\(\times\)2 matrices of the form_

\[\left(\begin{array}{cc}a&-b\\ b&a\end{array}\right)\]

_where a, b are elements of a given field \(\mathbf{F}\). Show that with the usual matrix operations, \(R\) is a commutative ring with identity. For which of the following fields \(\mathbf{F}\) is \(R\) a field: \(\mathbf{F}=\mathbb{Q}\,,\,\mathbb{C}\,,\,\mathbb{Z}_{5},\,\mathbb{Z}_{7}\)?_

**Problem 6.12.2** (Fa83): _Prove that every finite integral domain is a field._

**Problem 6.12.3** (Sp77, Sp78): _Let \(\mathbf{F}\subset\mathbf{K}\) be fields, and \(a\) and \(b\) elements of \(\mathbf{K}\) which are algebraic over \(\mathbf{F}\). Show that \(a+b\) is algebraic over \(\mathbf{F}\)._

**Problem 6.12.4** (Fa78, Fa85): _Prove that every finite multiplicative group of complex numbers is cyclic._

**Problem 6.12.5** (Sp87, Fa95): _Let \(\mathbf{F}\) be a field. Prove that every finite subgroup of the multiplicative group of nonzero elements of \(\mathbf{F}\) is cyclic._

**Problem 6.12.6** (Sp85): _Let \(\mathbf{F}=\{a+b\sqrt[3]{2}+c\sqrt[3]{4}\,\,|\,\,a,b,c\in\mathbb{Q}\,\}\). Prove that \(\mathbf{F}\) is a field and each element in \(\mathbf{F}\) has a unique representation as \(a+b\sqrt[3]{2}+c\sqrt[3]{4}\) with \(a,b,c\in\mathbb{Q}\,\). Find \(\left(1-\sqrt[3]{2}\right)^{-1}\) in \(\mathbf{F}\)._

**Problem 6.12.7** (Sp85): _Let \(\mathbf{F}\) be a finite field. Give a complete proof of the fact that the number of elements of \(\mathbf{F}\) is of the form \(p^{r}\), where \(p\geq 2\) is a prime number and \(r\) is an integer \(\geq 1\)._

**Problem 6.12.8** (Su85): _Let \(\mathbf{F}\) be a field of characteristic \(p>0\), \(p\neq 3\). If \(\alpha\) is a zero of the polynomial \(f(x)=x^{p}-x+3\) in an extension field of \(\mathbf{F}\), show that \(f(x)\) has p distinct zeros in the field \(\mathbf{F}(\alpha)\)._

**Problem 6.12.9** (Fa85): _Let \(f(x)=x^{5}-8x^{3}+9x-3\) and \(g(x)=x^{4}-5x^{2}-6x+3\). Prove that there is an integer \(d\) such that the polynomials \(f(x)\) and \(g(x)\) have a common root in the field \(\mathbb{Q}\left(\sqrt{d}\,\right)\). What is d?_

**Problem 6.12.10** (Fa86): _Let \(\mathbf{F}\) be a field containing \(\mathbb{Q}\) such that \(\left[\mathbf{F}:\mathbb{Q}\,\right]=2\). Prove that there exists a unique integer \(m\) such that \(m\) has no multiple prime factors and \(\mathbf{F}\) is isomorphic to \(\mathbb{Q}\left(\sqrt{m}\,\right)\)._

**Problem 6.12.11** (Sp96): _Exhibit infinitely many pairwise nonisomorphic quadratic extensions of \(\mathbb{Q}\) and show they are pairwise nonisomorphic._

**Problem 6.12.12** (Fa94): _Let \(\mathbb{Q}\) be the field of rational numbers. For \(\theta\) a real number, let \(\mathbf{F}_{\theta}=\mathbb{Q}(\sin\theta)\) and \(\mathbf{E}_{\theta}=\mathbb{Q}\left(\sin\frac{\theta}{3}\right)\). Show that \(\mathbf{E}_{\theta}\) is an extension field of \(\mathbf{F}_{\theta}\), and determine all possibilities for \(\dim_{\mathbf{F}_{\theta}}\mathbf{E}_{\theta}\)._

**Problem 6.12.13** (Sp95): _Let \(\mathbf{F}\) be a finite field of cardinality \(p^{n}\), with \(p\) prime and \(n>0\), and let \(G\) be the group of invertible 2\(\times\)2 matrices with coefficients in \(\mathbf{F}\)._

1. _Prove that_ \(G\) _has order_ \((p^{2n}-1)(p^{2n}-p^{n})\)_._
2. _Show that any p-Sylow subgroup of_ \(G\) _is isomorphic to the additive group of_ \(\mathbf{F}\)_._

**Problem 6.12.14** (Fa94): _Let \(p\) be an odd prime and \(\mathbf{F}_{p}\) the field of \(p\) elements. How many elements of \(\mathbf{F}_{p}\) have square roots in \(\mathbf{F}_{p}\)? How many have cube roots in \(\mathbf{F}_{p}\)?_

**Problem 6.12.15** (Sp94): _Let \(\mathbf{F}\) be a finite field with q elements. Say that a function \(f:\mathbf{F}\rightarrow\mathbf{F}\) is a polynomial function if there are elements \(a_{0},a_{1},\ldots,a_{n}\) of \(\mathbf{F}\) such that \(f(x)=a_{0}+a_{1}x+\cdots+a_{n}x^{n}\) for all \(x\in\mathbf{F}\). How many polynomial functions are there?_

**Problem 6.12.16** (Sp95): _Let \(\mathbf{F}\) be a finite field, and suppose that the subfield of \(\mathbf{F}\) generated by \(\{x^{3}\mid x\in\mathbf{F}\}\) is different from \(\mathbf{F}\). Show that \(\mathbf{F}\) has cardinality \(4\)._

**Problem 6.12.17** (Sp97): _Suppose that \(A\) is a commutative algebra with identity over \(\mathbb{C}\) (i.e., \(A\) is a commutative ring containing \(\mathbb{C}\) as a subring with identity). Suppose further that \(a^{2}\neq 0\) for all nonzero elements \(a\in A\). Show that if the dimension of \(A\) as a vector space over \(\mathbb{C}\) is finite and at least two, then the equations \(a^{2}=a\) is satisfied by at least three distinct elements \(a\in A\)._

### Elementary Number Theory

**Problem 6.13.1** (Fa86): _Prove that if six people are riding together in an Evans Hall elevator, there is either a three-person subset of mutual friends (each knows the other two) or a three-person subset of mutual strangers (each knows neither of the other two)._

**Problem 6.13.2** (Sp98): _Let \(m\geq 0\) be an integer. Let \(a_{1},a_{2},\ldots,a_{m}\) be integers and let_

\[f(x)=\sum_{i=1}^{m}\frac{a_{i}x^{i}}{i!}\]

_Show that if \(d\geq 0\) is an integer then \(f(x)^{d}/d!\) can be expressed in the form_

\[\sum_{i=0}^{md}\frac{b_{i}x_{i}}{i!}\]

_where the \(b_{i}\) are integers._

**Problem 6.13.3** (Sp77): _Let \(p\) be an odd prime. Let \(Q(p)\) be the set of integers \(a\), \(0\leq a\leq p-1\), for which the congruence_

\[x^{2}\equiv a\pmod{p}\]

_has a solution. Show that \(Q(p)\) has cardinality \((p+1)/2\)._

**Problem 6.13.4** (Su77): _Let \(p\) be an odd prime. If the congruence \(x^{2}\equiv-1\pmod{p}\) has a solution, show that \(p\equiv 1\pmod{4}\)._

**Problem 6.13.5** (Sp80): _Let \(n\geq 2\) be an integer such that \(2^{n}+n^{2}\) is prime. Prove that_

\[n\equiv 3\pmod{6}.\]

**Problem 6.13.6** (Fa77):
1. _Show that the set of all units in a ring form a group under multiplication. (A unit is an element having a multiplicative inverse.)_
2. _In the ring_ \(\mathbb{Z}_{n}\) _of integers_ \(\bmod n\)_, show that_ \(k\) _is a unit if and only if_ \(k\) _and_ \(n\) _are relatively prime._
3. _Suppose_ \(n=pq\)_, where_ \(p\) _and_ \(q\) _are primes. Prove that the number of units in_ \(\mathbb{Z}_{n}\) _is_ \((p-1)(q-1)\)_._

**Problem 6.13.7** (Su79): _Which rational numbers \(t\) are such that_

\[3t^{3}+10t^{2}-3t\]

_is an integer?_

**Problem 6.13.8** (Fa96): _Show the denominator of \(\left(\begin{array}{c}1/2\\ n\end{array}\right)\) is a power of \(2\) for all integers \(n\)._

**Problem 6.13.9** (Su82): _Let n be a positive integer._

1. _Show that the binomial coefficient_ \[c_{n}=\left(\begin{array}{c}2n\\ n\end{array}\right)\] _is even._
2. _Prove that_ \(c_{n}\) _is divisible by_ \(4\) _if and only if n is not a power of_ \(2\)_._

**Problem 6.13.10** (Sp83): _Suppose that \(n>1\) is an integer. Prove that the sum_

\[1+\frac{1}{2}+\cdots+\frac{1}{n}\]

_is not an integer._

**Problem 6.13.11** (Fa84, Fa96): _Let \(\gcd\) abbreviate greatest common divisor and \(\operatorname{lcm}\) abbreviate least common multiple. For three nonzero integers \(a\), \(b\), \(c\), show that_

\[\gcd\left\{a,\operatorname{lcm}\{b,c\}\right\}=\operatorname{lcm}\left\{\gcd\{a, b\},\gcd\{a,c\}\right\}.\]

**Problem 6.13.12** (Sp92): _Let \(a_{1},a_{2},\ldots,a_{10}\) be integers with \(1\leq a_{i}\leq 25\), for \(1\leq i\leq 10\). Prove that there exist integers \(n_{1},n_{2},\ldots,n_{10}\), not all zero, such that_

\[\prod_{i=1}^{10}a_{i}^{n_{i}}=1.\]

**Problem 6.13.13** (Su83): _The number \(21982145917308330487013369\) is the thirteenth power of a positive integer. Which positive integer?_

**Problem 6.13.14** (Sp96): _Determine the rightmost decimal digit of_

\[A=17^{17^{17}}.\]

**Problem 6.13.15** (Sp88): _Determine the last digit of_

\[23^{23^{23}}\]

_in the decimal system._

**Problem 6.13.16** (Sp88): _Show that you can represent the set of non-negative integers, \(\mathbb{Z}_{+}\), as the union of two disjoint subsets \(N_{1}\) and \(N_{2}\)\((N_{1}\cap N_{2}=\emptyset,\ N_{1}\cup N_{2}=\mathbb{Z}_{+})\) such that neither \(N_{1}\) nor \(N_{2}\) contains an infinite arithmetic progression._

**Problem 6.13.17** (Fa89): _Let \(\varphi\) be Euler's totient function; so if \(n\) is a positive integer, then \(\varphi(n)\) is the number of integers \(m\) for which \(1\leq m\leq n\) and \(\gcd\{n,m\}=1\). Let \(a\) and \(k\) be two integers, with \(a>1\), \(k>0\). Prove that \(k\) divides \(\varphi(a^{k}-1)\)._

**Problem 6.13.18** (Sp90): _Determine the greatest common divisor of the elements of the set \(\{n^{13}-n\mid n\in\mathbb{Z}\}\)._

**Problem 6.13.19** (Sp91): _For \(n\) a positive integer, let \(d(n)\) denote the number of positive integers that divide \(n\). Prove that \(d(n)\) is odd if and only if n is a perfect square._Linear Algebra

### 7.1 Vector Spaces

**Problem 7.1.1** (Su79, Sp82, Sp83, Su84, Fa91): _Let \(\mathbf{F}\) be a finite field with \(q\) elements and let \(V\) be an \(n\)-dimensional vector space over \(\mathbf{F}\)._

1. _Determine the number of elements in_ \(V\)_._
2. _Let_ \(GL_{n}(\mathbf{F})\) _denote the group of all_ \(n\times n\) _nonsingular matrices over_ \(\mathbf{F}\)_. Determine the order of_ \(GL_{n}(\mathbf{F})\)_._
3. _Let_ \(SL_{n}(\mathbf{F})\) _denote the subgroup of_ \(GL_{n}(\mathbf{F})\) _consisting of matrices with determinant one. Find the order of_ \(SL_{n}(\mathbf{F})\)_._

**Problem 7.1.2** (Sp97): _Let \(GL_{2}(\mathbb{Z}_{m})\) denote the multiplicative group of invertible \(2\times 2\) matrices over the ring of integers modulo \(m\). Find the order of \(GL_{2}(\mathbb{Z}_{p^{n}})\) for each prime \(p\) and positive integer \(n\)._

**Problem 7.1.3** (Sp96): _Let \(G\) be the group of 2\(\times\)2 matrices with determinant \(1\) over the four-element field \(\mathbf{F}\). Let \(S\) be the set of lines through the origin in \(\mathbf{F}^{2}\). Show that \(G\) acts faithfully on \(S\). (The action is faithful if the only element of \(G\) which fixes every element of \(S\) is the identity.)_

**Problem 7.1.4** (Su77): _Prove the following statements about the polynomial ring \(\mathbf{F}[x]\), where \(\mathbf{F}\) is any field._

1. \(\mathbf{F}[x]\) _is a vector space over_ \(\mathbf{F}\)2. _The subset_ \(\mathbf{F}_{n}[x]\) _of polynomials of degree_ \(\leq n\) _is a subspace of dimension_ \(n+1\) _in_ \(\mathbf{F}[x]\)_._
3. _The polynomials_ \(1,x-a,\ldots,(x-a)^{n}\) _form a basis of_ \(\mathbf{F}_{n}[x]\) _for any_ \(a\in\mathbf{F}\)_._

**Problem 7.1.5** (Su84): _Suppose \(V\) is an \(n\)-dimensional vector space over the field \(\mathbf{F}\). Let \(W\subset V\) be a subspace of dimension \(r<n\). Show that_

\[W=\bigcap\,\left\{U\mid U\,is\,an\,(n-1)-dimensional\,\,subspace\,of\,\,V\,and\, \,W\subset U\right\}.\]

**Problem 7.1.6** (Sp80, Fa89): _Show that a vector space over an infinite field cannot be the union of a finite number of proper subspaces._

**Problem 7.1.7** (Fa88): _Let \(A\) be a complex \(n\times n\) matrix, and let \(C(A)\) be the commutant of \(A\); that is, the set of complex \(n\times n\) matrices \(B\) such that \(AB=BA\). (It is obviously a subspace of \(M_{n\times n}\), the vector space of all complex \(n\times n\) matrices.) Prove that \(\dim C(A)\geq n\)._

**Problem 7.1.8** (Sp89, Fa97): _Let \(S\) be the subspace of \(M_{n\times n}\) (the vector space of all real \(n\times n\) matrices) generated by all matrices of the form \(AB-BA\) with \(A\) and \(B\) in \(M_{n\times n}\). Prove that \(\dim(S)=n^{2}-1\)._

**Problem 7.1.9** (Sp90): _Let \(A\) and \(B\) be subspaces of a finite-dimensional vector space \(V\) such that \(A+B=V\). Write \(n=\dim V\), \(a=\dim A\), and \(b=\dim B\). Let \(S\) be the set of those endomorphisms \(f\) of \(V\) for which \(f(A)\subset\ A\) and \(f(B)\subset B\). Prove that \(S\) is a subspace of the set of all endomorphisms of \(V\), and express the dimension of \(S\) in terms of \(n\), \(a\), and \(b\)._

**Problem 7.1.10** (Sp81): _Let \(T\) be a linear transformation of a vector space \(V\) into itself. Suppose \(x\in V\) is such that \(T^{m}x=0\), \(T^{m-1}x\neq 0\) for some positive integer \(m\). Show that \(x,\,Tx,\ldots,T^{m-1}x\) are linearly independent._

**Problem 7.1.11** (Fa97): _Let \(\alpha_{1},\alpha_{2},\ldots,\alpha_{n}\) be distinct real numbers. Show that the \(n\) exponential functions \(e^{\alpha_{1}t},e^{\alpha_{2}t},\ldots,e^{\alpha_{n}t}\) are linearly independent over the real numbers._

**Problem 7.1.12** (Su83): _Let \(V\) be a real vector space of dimension \(n\) with a positive definite inner product. We say that two bases \((a_{i})\) and \((b_{i})\) have the same orientation if the matrix of the change of basis from \((a_{i})\) to \((b_{i})\) has a positive determinant. Suppose now that \((a_{i})\) and \((b_{i})\) are orthonormal bases with the same orientation. Show that \((a_{i}+2b_{i})\) is again a basis of \(V\) with the same orientation as \((a_{i})\)._

### Rank and Determinants

**Problem 7.2.1** (Sp78, Fa82, Fa86): _Let \(M\) be a matrix with entries in a field \(\mathbf{F}\). The row rank of \(M\) over \(\mathbf{F}\) is the maximal number of rows which are linearly independent (as vectors) over \(\mathbf{F}\). The column rank is similarly defined using columns instead of rows._

1. _Prove row rank = column rank._
2. _Find a maximal linearly independent set of columns of_ \[\left(\begin{array}{cccc}1&0&3&-2\\ 2&1&2&0\\ 0&1&-4&4\\ 1&1&1&2\\ 1&0&1&2\end{array}\right)\] _taking_ \(\mathbf{F}=\mathbb{R}\)_._
3. _If_ \(\mathbf{F}\) _is a subfield of_ \(\mathbf{K}\)_, and_ \(M\) _has entries in_ \(\mathbf{F}\)_, how is the row rank of_ \(M\) _over_ \(\mathbf{F}\) _related to the row rank of_ \(M\) _over_ \(\mathbf{K}\)_?_

**Problem 7.2.2** (Su85, Fa89): _Let \(A\) be an \(n\times n\) real matrix and \(A^{t}\) its transpose. Show that \(A^{t}A\) and \(A^{t}\) have the same range._

**Problem 7.2.3** (Sp97): _Suppose that \(P\) and \(Q\) are \(n\times n\) matrices such that \(P^{2}=P\), \(Q^{2}=Q\), and \(1-(P+Q)\) is invertible. Show that \(P\) and \(Q\) have the same rank._

**Problem 7.2.4** (Sp91): _Let \(T\) be a real, symmetric, \(n\times n\), tridiagonal matrix:_

\[T=\left(\begin{array}{ccccccc}a_{1}&b_{1}&0&0&\cdots&0&0\\ b_{1}&a_{2}&b_{2}&0&\cdots&0&0\\ 0&b_{2}&a_{3}&b_{3}&\cdots&0&0\\ \vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ 0&0&0&0&\cdots&a_{n-1}&b_{n-1}\\ 0&0&0&0&\cdots&b_{n-1}&a_{n}\end{array}\right)\]

_(All entries not on the main diagonal or the diagonals just above and below the main one are zero.) Assume \(b_{j}\neq 0\) for all \(j\)._

_Prove:_

1. \(\operatorname{rank}T\geq n-1\)_._
2. \(T\) _has_ \(n\) _distinct eigenvalues._

**Problem 7.2.5** (Sp83): _Let \(A=(a_{ij})\) be an \(n\times n\) real matrix satisfying the conditions:_

\[a_{ii}>0\quad(1\leq i\leq n),\]\[a_{ij}\leq 0\quad(i\neq j,\,1\leq i,j\leq n),\] \[\sum_{i=1}^{n}a_{ij}>0\quad(1\leq j\leq n).\]

_Show that \(\det(A)>0\)._

**Problem 7.2.6**: **(Sp91)** _Let \(A=(a_{ij})_{i,j=1}^{r}\) be a square matrix with integer entries._

1. _Prove that if an integer_ \(n\) _is an eigenvalue of_ \(A\)_, then_ \(n\) _is a divisor of_ \(\det A\)_, the determinant of_ \(A\)_._
2. _Suppose that_ \(n\) _is an integer and that each row of_ \(A\) _has sum_ \(n\)_:_ \[\sum_{j=1}^{r}a_{ij}=n,\qquad 1\leq i\leq r.\] _Prove that_ \(n\) _is a divisor of_ \(\det A\)_._

**Problem 7.2.7** (Fa84): _Let \(\mathbb{R}[x_{1},\ldots,x_{n}]\) be the polynomial ring over the real field \(\mathbb{R}\) in the \(n\) variables \(x_{1},\ldots,x_{n}\). Let the matrix \(A\) be the \(n\times n\) matrix whose \(i^{th}\) row is \((1,x_{i},x_{i}^{2},\ldots,x_{i}^{n-1})\), \(i=1,\ldots,n\). Show that_

\[\det A=\prod_{i>j}(x_{i}-x_{j}).\]

**Problem 7.2.8** (Sp77): _A matrix of the form_

\[\left(\begin{array}{cccc}1&a_{0}&a_{0}^{2}&\ldots&a_{0}^{n}\\ 1&a_{1}&a_{1}^{2}&\ldots&a_{1}^{n}\\ \vdots&\vdots&\vdots&\ddots&\vdots\\ 1&a_{n}&a_{n}^{2}&\ldots&a_{n}^{n}\end{array}\right)\]

_where the \(a_{i}\) are complex numbers, is called a Vandermonde matrix._

1. _Prove that the Vandermonde matrix is invertible if_ \(a_{0},a_{1},\ldots,a_{n}\) _are all different._
2. _If_ \(a_{0},a_{1},\ldots,a_{n}\) _are all different, and_ \(b_{0},b_{1},\ldots,b_{n}\) _are complex numbers, prove that there is a unique polynomial_ \(f\) _of degree_ \(n\) _with complex coefficients such that_ \(f(a_{0})=b_{0}\)_,_ \(f(a_{1})=b_{1}\)_,...,_ \(f(a_{n})=b_{n}\)_._

**Problem 7.2.9** (Sp90): _Given an example of a continuous function \(v:\mathbb{R}\to\mathbb{R}^{3}\) with the property that \(v(t_{1})\), \(v(t_{2})\), and \(v(t_{3})\) form a basis for \(\mathbb{R}^{3}\) whenever \(t_{1}\), \(t_{2}\), and \(t_{3}\) are distinct points of \(\mathbb{R}\)._

**Problem 7.2.10** (Fa95): _Let \(f_{1},f_{2},\ldots,f_{n}\) be continuous real valued functions on \([a,b]\). Show that the set \(\{f_{1},\ldots,f_{n}\}\) is linearly dependent on \([a,b]\) if and only if_

\[\det\left(\int_{a}^{b}f_{i}(x)f_{j}(x)dx\right)=0\;.\]

**Problem 7.2.11** (Fa81): _Let \(M_{2\times 2}\) be the vector space of all real 2\(\times\)2 matrices. Let_

\[A=\left(\begin{array}{cc}1&2\\ -1&3\end{array}\right)\qquad\quad B=\left(\begin{array}{cc}2&1\\ 0&4\end{array}\right)\]

_and define a linear transformation \(L:M_{2\times 2}\to M_{2\times 2}\) by L(X) = AXB. Compute the trace and the determinant of \(L\)._

**Problem 7.2.12** (Su82): _Let \(V\) be the vector space of all real 3\(\times\)3 matrices and let \(A\) be the diagonal matrix_

\[\left(\begin{array}{ccc}1&0&0\\ 0&2&0\\ 0&0&1\end{array}\right).\]

_Calculate the determinant of the linear transformation \(T\) on \(V\) defined by \(T(X)=\frac{1}{2}(AX+XA)\)._

**Problem 7.2.13** (Sp80): _Let \(M_{3\times 3}\) denote the vector space of real 3\(\times\)3 matrices. For any matrix \(A\in M_{3\times 3}\), define the linear operator \(L_{A}:M_{3\times 3}\to M_{3\times 3}\), \(L_{A}(B)=AB\). Suppose that the determinant of \(A\) is \(32\) and the minimal polynomial is \((t-4)(t-2)\). What is the trace of \(L_{A}\)?_

**Problem 7.2.14** (Su81): _Let \(S\) denote the vector space of real \(n\times n\) skew-symmetric matrices. For a nonsingular matrix \(A\), compute the determinant of the linear map \(T_{A}:S\to S\), \(T_{A}(X)=AXA^{-1}\)._

_Hint: First consider the special cases where (i) \(A\) is orthogonal and (ii) \(A\) is symmetric._

**Problem 7.2.15** (Fa94): _Let \(M_{7\times 7}\) denote the vector space of real 7\(\times\)7 matrices. Let \(A\) be a diagonal matrix in \(M_{7\times 7}\) that has \(+1\) in four diagonal positions and \(-1\) in three diagonal positions. Define the linear transformation \(T\) on \(M_{7\times 7}\) by \(T(X)=AX-XA\). What is the dimension of the range of \(T\)?_

**Problem 7.2.16** (Fa93): _Let \(\mathbf{F}\) be a field. For m and n positive integers, let \(M_{m\times n}\) be the vector space of \(m\times n\) matrices over \(\mathbf{F}\). Fix \(m\) and \(n\), and fix matrices \(A\) and \(B\) in \(M_{m\times n}\). Define the linear transformation \(T\) from \(M_{n\times m}\) to \(M_{m\times n}\) by_

\[T(X)=AXB.\]

_Prove that if \(m\neq n\), then \(T\) is not invertible._

### Systems of Equations

**Problem 7.3.1** (Su77): _Determine all solutions to the following infinite system of linear equations in the infinitely many unknowns \(x_{1},x_{2},\ldots\):_

\[\begin{array}{ccccccc}x_{1}&+&x_{3}&+&x_{5}&=&0\\ x_{2}&+&x_{4}&+&x_{6}&=&0\\ x_{3}&+&x_{5}&+&x_{7}&=&0\\ \vdots&&\vdots&&\vdots&&\vdots\\ \end{array}\]

_How many free parameters are required?_

**Problem 7.3.2** (Fa77, Su78):
1. _Using only the axioms for a field_ \(\mathbf{F}\)_, prove that a system of m homogeneous linear equations in n unknowns with_ \(m<n\) _and coefficients in_ \(\mathbf{F}\) _has a nonzero solution._
2. _Use Part 1 to show that if_ \(V\) _is a vector space over_ \(\mathbf{F}\) _which is spanned by a finite number of elements, then every maximal linearly independent subset of_ \(V\) _has the same number of elements._

**Problem 7.3.3** (Sp88, Sp96): _If a finite homogeneous system of linear equations with rational coefficients has a nontrivial complex solution, need it have a nontrivial rational solution? Give a proof or a counterexample._

**Problem 7.3.4** (Sp84, Sp87): _Let \(A\) be a real \(m\times n\) matrix with rational entries and let b be an \(m\)-tuple of rational numbers. Assume that the system of equations Ax = b has a solution x in complex \(n\)-space \(\mathbb{C}\,^{n}\). Show that the equation has a solution vector with rational components, or give a counterexample._

### Linear Transformations

**Problem 7.4.1** (Fa77): _Let \(E\) and \(F\) be vector spaces (not assumed to be finite-dimensional). Let \(S:E\to F\) be a linear transformation._

1. _Prove_ \(S(E)\) _is a vector space._
2. _Show_ \(S\) _has a kernel_ \(\{0\}\) _if and only if_ \(S\) _is injective (i.e., one-to-one)._
3. _Assume_ \(S\) _is injective; prove_ \(S^{-1}:S(E)\to E\) _is linear._

**Problem 7.4.2** (Sp82): _Let \(T:V\to W\) be a linear transformation between finite-dimensional vector spaces. Prove that_

\[\dim(\ker T)+\dim(\operatorname{range}T)=\dim V\,.\]

**Problem 7.4.3** (Sp95): _Suppose that \(W\subset V\) are finite-dimensional vector spaces over a field, and let \(L\colon V\to V\) be a linear transformation with \(L(V)\subset W\). Denote the restriction of \(L\) to \(W\) by \(L_{W}\). Prove that \(\det(1-tL)=\det(1-tL_{W})\)._

**Problem 7.4.4** (Sp95): _Let \(V\) be a finite-dimensional vector space over a field \(\mathbf{F}\), and let \(L:V\to V\) be a linear transformation. Suppose that the characteristic polynomial \(\chi\) of \(L\) is written as \(\chi=\chi_{1}\chi_{2}\), where \(\chi_{1}\) and \(\chi_{2}\) are two relatively prime polynomials with coefficients in \(\mathbf{F}\). Show that \(V\) can be written as the direct sum of two subspaces \(V_{1}\) and \(V_{2}\) with the property that \(\chi_{i}(L)V_{i}=0\) (for \(i=1\) and \(2\))._

**Problem 7.4.5** (Su79): _Let \(E\) be a three-dimensional vector space over \(\mathbb{Q}\). Suppose \(T:E\to E\) is a linear transformation and \(Tx=y\), \(Ty=z\), \(Tz=x+y\), for certain \(x,y,z\in E\), \(x\neq 0\). Prove that \(x\), \(y\), and \(z\) are linearly independent._

**Problem 7.4.6** (Su80): _Let \(T:V\to V\) be an invertible linear transformation of a vector space \(V\). Denote by \(G\) the group of all maps \(f_{k,a}:V\to V\) where \(k\in\mathbb{Z}\), \(a\in V\), and for \(x\in V\),_

\[f_{k,a}(x)=T^{k}x+a\ \ \ \ (x\in V).\]

_Prove that the commutator subgroup \(G^{\prime}\) of \(G\) is isomorphic to the additive group of the vector space \((T-I)V\), the image of \(T-I\). (\(G^{\prime}\) is generated by all \(ghg^{-1}h^{-1}\), \(g\) and \(h\) in \(G\).)_

**Problem 7.4.7** (Sp86): _Let \(V\) be a finite-dimensional vector space and \(A\) and \(B\) two linear transformations of \(V\) into itself such that \(A^{2}=B^{2}=0\) and \(AB+BA=I\)._

1. _Prove that if_ \(N_{A}\) _and_ \(N_{B}\) _are the respective null spaces of_ \(A\) _and_ \(B\)_, then_ \(N_{A}=AN_{B}\)_,_ \(N_{B}=BN_{A}\)_, and_ \(V=N_{A}\oplus N_{B}\)_._
2. _Prove that the dimension of_ \(V\) _is even._
3. _Prove that if the dimension of_ \(V\) _is_ \(2\)_, then_ \(V\) _has a basis with respect to which_ \(A\) _and_ \(B\) _are represented by the matrices_ \[\left(\begin{array}{cc}0&1\\ 0&0\end{array}\right)\ \ \ and\ \ \ \left(\begin{array}{cc}0&0\\ 1&0\end{array}\right).\]

**Problem 7.4.8** (Su84): _Let \(f:\mathbb{R}^{m}\to\mathbb{R}^{n},\ n\geq 2\), be a linear transformation of rank \(n-1\). Let \(f(v)=(f_{1}(v),f_{2}(v),\ldots,f_{n}(v))\) for \(v\in\mathbb{R}^{m}\). Show that a necessary and sufficient condition for the system of inequalities \(f_{i}(v)>0\), \(i=1,\ldots,n\), to have no solution is that there exist real numbers \(\lambda_{i}\geq 0\), not all zero, such that_

\[\sum_{i=1}^{n}\lambda_{i}f_{i}=0.\]

**Problem 7.4.9** (Sp95): _Let \(n\) be a positive integer, and let \(S\subset\mathbb{R}^{n}\) a finite subset with \(0\in S\). Suppose that \(\varphi:S\to S\) is a map satisfying_

\[\varphi(0) =0,\] \[d(\varphi(s),\varphi(t)) =d(s,t)\qquad\text{for all}\quad\ s,t\in S,\]

_where \(d(\,\ )\) denotes Euclidean distance. Prove that there is a linear map \(f:\mathbb{R}^{n}\to\mathbb{R}^{n}\) whose restriction to \(S\) is \(\varphi\)._

**Problem 7.4.10** (Sp86): _Consider \(\mathbb{R}^{2}\) be equipped with the Euclidean metric \(d(x,y)=\|x-y\|\). Let \(T\) be an isometry of \(\mathbb{R}^{2}\) into itself. Prove that \(T\) can be represented as \(T(x)=a+U(x)\), where \(a\) is a vector in \(\mathbb{R}^{2}\) and \(U\) is an orthogonal linear transformation._

**Problem 7.4.11** (Sp88): _Let \(X\) be a set and \(V\) a real vector space of real valued functions on \(X\) of dimension \(n\), \(0<n<\infty\). Prove that there are \(n\) points \(x_{1},x_{2},\ldots,x_{n}\) in \(X\) such that the map \(f\to(f(x_{1}),\ldots,f(x_{n}))\) of \(V\) to \(\mathbb{R}^{n}\) is an isomorphism (i.e., one-to-one and onto). (The operations of addition and scalar multiplication in \(V\) are assumed to be the natural ones.)_

**Problem 7.4.12** (Sp97): _Suppose that \(X\) is a topological space and \(V\) is a finite-dimensional subspace of the vector space of continuous real valued functions on \(X\). Prove that there exist a basis \((f_{1},\ldots,f_{n})\) for \(V\) and points \(x_{1},\ldots,x_{n}\) in \(X\) such that \(f_{i}(x_{j})=\delta_{ij}\)._

**Problem 7.4.13** (Fa90): _Let \(n\) be a positive integer and let \(P_{2n+1}\) be the vector space of real polynomials whose degrees are, at most, \(2n+1\). Prove that there exist unique real numbers \(c_{1},\ldots,c_{n}\) such that_

\[\int_{-1}^{1}p(x)\,dx=2p(0)+\sum_{k=1}^{n}c_{k}(p(k)+p(-k)-2p(0))\]

_for all \(p\in P_{2n+1}\)._

**Problem 7.4.14** (Sp94): _Let \(T:\mathbb{R}^{n}\to\mathbb{R}^{n}\) be a diagonalizable linear transformation. Prove that there is an orthonormal basis for \(\mathbb{R}^{n}\) with respect to which \(T\) has an upper-triangular matrix._

**Problem 7.4.15** (Fa77): _Let \(P\) be a linear operator on a finite-dimensional vector space over a finite field. Show that if \(P\) is invertible, then \(P^{n}=I\) for some positive integer \(n\)._

**Problem 7.4.16** (Fa82): _Let \(A\) be an \(n\times n\) complex matrix, and let \(B\) be the Hermitian transpose of \(A\) (i.e., \(b_{ij}=\overline{a}_{ji}\)). Suppose that \(A\) and \(B\) commute with each other. Consider the linear transformations \(\alpha\) and \(\beta\) on \(\mathbb{C}\,^{n}\) defined by \(A\) and \(B\). Prove that \(\alpha\) and \(\beta\) have the same image and the same kernel._

**Problem 7.4.17** (Su79, Fa96): _Prove that a linear transformation \(T:\mathbb{R}^{3}\to\mathbb{R}^{3}\) has_

1. _a one-dimensional invariant subspace, and_
2. _a two-dimensional invariant subspace._

**Problem 7.4.18** (Fa83): _Let \(A\) be a linear transformation on \(\mathbb{R}^{3}\) whose matrix (relative to the usual basis for \(\mathbb{R}^{3}\)) is both symmetric and orthogonal. Prove that \(A\) is either plus or minus the identity, or a rotation by \(180^{\circ}\) about some axis in \(\mathbb{R}^{3}\), or a reflection about some two-dimensional subspace of \(\mathbb{R}^{3}\)._

**Problem 7.4.19** (Fa84): _Let \(\theta\) and \(\varphi\) be fixed, \(0\leq\theta\leq 2\pi\), \(0\leq\varphi\leq 2\pi\) and let \(R\) be the linear transformation from \(\mathbb{R}^{3}\) to \(\mathbb{R}^{3}\) whose matrix in the standard basis \(\vec{i}\), \(\vec{j}\), and \(\vec{k}\) is_

\[\left(\begin{array}{ccc}1&0&0\\ 0&\cos\theta&\sin\theta\\ 0&-\sin\theta&\cos\theta\end{array}\right)\]

_Let \(S\) be the linear transformation of \(\mathbb{R}^{3}\) to \(\mathbb{R}^{3}\) whose matrix in the basis_

\[\frac{1}{\sqrt{2}}(\vec{i}+\vec{k}),\ \ \vec{j},\ \ \frac{1}{\sqrt{2}}(\vec{i} -\vec{k})\]

_is_

\[\left(\begin{array}{ccc}\cos\varphi&\sin\varphi&0\\ -\sin\varphi&\cos\varphi&0\\ 0&0&1\end{array}\right)\]

_Prove that \(T=R\circ S\) leaves a line invariant._

**Problem 7.4.20** (Sp86): _Let \(e=(a,b,c)\) be a unit vector in \(\mathbb{R}^{3}\) and let \(T\) be the linear transformation on \(\mathbb{R}^{3}\) of rotation by \(180^{\circ}\) about e. Find the matrix for \(T\) with respect to the standard basis \(e_{1}=(1,0,0)\), \(e_{2}=(0,1,0)\), and \(e_{3}=(0,0,1)\)._

**Problem 7.4.21** (Su80): _Exhibit a real 3\(\times\)3 matrix having minimal polynomial \((t^{2}+1)(t-10)\), which, as a linear linear transformation of \(\mathbb{R}^{3}\), leaves invariant the line \(L\) through \((0,0,0)\) and \((1,1,1)\) and the plane through \((0,0,0)\) perpendicular to \(L\)._

**Problem 7.4.22** (Su77): _Show that every rotation of \(\mathbb{R}^{3}\) has an axis; that is, given a 3\(\times\)3 real matrix \(A\) such that \(A^{t}=A^{-1}\) and \(\det A>0\), prove that there is a nonzero vector \(v\) such that \(Av\) = \(v\)._

**Problem 7.4.23** (Sp93): _Let \(P\) be the vector space of polynomials over \(\mathbb{R}\). Let the linear transformation \(E:P\to P\) be defined by \(Ef=f+f^{\prime}\), where \(f^{\prime}\) is the derivative of \(f\). Prove that \(E\) is invertible._

**Problem 7.4.24** (Fa84): _Let \(P_{n}\) be the vector space of all real polynomials with degrees at most n. Let \(D:P_{n}\to P_{n}\) be given by differentiation: \(D(p)=p^{\prime}\). Let \(\pi\) be a real polynomial. What is the minimal polynomial of the transformation \(\pi(D)\)?_

**Problem 7.4.25** (Su77): _Let \(V\) be the vector space of all polynomials of degree \(\leq 10\), and let \(D\) be the differentiation operator on \(V\) (i.e., \(Dp(x)=p^{\prime}(x)\))._

1. _Show that_ \(\operatorname{tr}D=0\)_._
2. _Find all eigenvectors of_ \(D\) _and_ \(e^{D}\)_._

### Eigenvalues and Eigenvectors

**Problem 7.5.1** (Fa77): _Let \(M\) be a real 3\(\times\)3 matrix such that \(M^{3}=I\), \(M\neq I\)._

1. _What are the eigenvalues of_ \(M\)_?_
2. _Give an example of such a matrix._

**Problem 7.5.2** (Fa79): _Let \(N\) be a linear operator on an \(n\)-dimensional vector space, \(n>1\), such that \(N^{n}=0,\ N^{n-1}\ \neq 0.\) Prove there is no operator X with \(X^{2}=N\)._

**Problem 7.5.3** (Sp89): _Let \(\mathbf{F}\) be a field, \(n\) and \(m\) positive integers, and \(A\) an \(n\times n\) matrix with entries in \(\mathbf{F}\) such that \(A^{m}=0\). Prove that \(A^{n}=0\)._

**Problem 7.5.4** (Su81, Su82): _Let \(V\) be a finite-dimensional vector space over the rationals \(\mathbb{Q}\) and let \(M\) be an automorphism of \(V\) such that \(M\) fixes no nonzero vector in \(V\). Suppose that \(M^{p}\) is the identity map on \(V\), where \(p\) is a prime number. Show that the dimension of \(V\) is divisible by \(p-1\)._

**Problem 7.5.5** (Fa92): _Let \(\mathbf{F}\) be a field, \(V\) a finite-dimensional vector space over \(\mathbf{F}\), and \(T\) a linear transformation of \(V\) into \(V\) whose minimum polynomial, \(\mu\), is irreducible over \(\mathbf{F}\)._

1. _Let_ \(v\) _be a nonzero vector in_ \(V\) _and let_ \(V_{1}\) _be the subspace spanned by_ \(v\) _and its images under the positive powers of_ \(T\)_. Prove that_ \(\dim V_{1}=\deg\mu\)_._
2. _Prove that_ \(\deg\mu\) _divides_ \(\dim V\)_._

**Problem 7.5.6** (Su79, Fa93): _Prove that the matrix_

\[\left(\begin{array}{cccc}0&5&1&0\\ 5&0&5&0\\ 1&5&0&5\\ 0&0&5&0\end{array}\right)\]has two positive and two negative eigenvalues (counting multiplicities)._

**Problem 7.5.7** (Fa94): _Prove that the matrix_

\[\left(\begin{array}{ccc}1&1.00001&1\\ 1.00001&1&1.00001\\ 1&1.00001&1\end{array}\right)\]

_has one positive eigenvalue and one negative eigenvalue._

**Problem 7.5.8** (Sp85): _For arbitrary elements \(a\), \(b\), and \(c\) in a field \(\mathbf{F}\), compute the minimal polynomial of the matrix_

\[\left(\begin{array}{ccc}0&0&a\\ 1&0&b\\ 0&1&c\end{array}\right).\]

**Problem 7.5.9** (Fa85, Sp97): _Suppose that \(A\) and \(B\) are endomorphisms of a finite-dimensional vector space \(V\) over a field \(\mathbf{F}\). Prove or disprove the following statements:_

1. _Every eigenvector of_ \(AB\) _is also an eigenvector of_ \(BA\)_._
2. _Every eigenvalue of_ \(AB\) _is also an eigenvalue of_ \(BA\)_._

**Problem 7.5.10** (Sp78, Sp88): _Let \(A\) and \(B\) denote real \(n\times n\) symmetric matrices such that \(AB=BA\). Prove that \(A\) and \(B\) have a common eigenvector in \(\mathbb{R}^{n}\)._

**Problem 7.5.11** (Sp86): _Let \(S\) be a nonempty commuting set of \(n\times n\) complex matrices \((n\geq 1)\). Prove that the members of \(S\) have a common eigenvector._

**Problem 7.5.12** (Sp84): _Let \(A\) and \(B\) be complex \(n\times n\) matrices such that \(AB=BA^{2}\), and assume \(A\) has no eigenvalues of absolute value \(1\). Prove that \(A\) and \(B\) have a common (nonzero) eigenvector._

**Problem 7.5.13** (Su78): _Let \(V\) be a finite-dimensional vector space over an algebraically closed field. A linear operator \(T:V\to V\) is called completely reducible if whenever a linear subspace \(E\subset V\) is invariant under \(T\) (i.e., \(T(E)\subset E\)), there is a linear subspace \(F\subset V\) which is invariant under \(T\) and such that \(V=E\oplus F\). Prove that \(T\) is completely reducible if and only if \(V\) has a basis of eigenvectors._

**Problem 7.5.14** (Fa79, Su81): _Let \(V\) be the vector space of sequences \((a_{n})\) of complex numbers. The shift operator \(S:V\to V\) is defined by_

\[S\left((a_{1},a_{2},a_{3},\ldots)\right)=(a_{2},a_{3},a_{4},\ldots).\]

1. _Find the eigenvectors of_ \(S\)_._
2. _Show that the subspace_ \(W\) _consisting of the sequences_ \((x_{n})\) _with_ \(x_{n+2}=x_{n+1}+x_{n}\) _is a two-dimensional,_ \(S\)_-invariant subspace of_ \(V\) _and exhibit an explicit basis for_ \(W\)_._
3. _Find an explicit formula for the_ \(n^{th}\) _Fibonacci number_ \(f_{n}\)_, where_ \(f_{2}=f_{1}=1\)_,_ \(f_{n+2}=f_{n+1}+f_{n}\) _for_ \(n\geq 1\)_._

_Note: See also Problem 1.3.10._

**Problem 7.5.15** (Fa82): _Let \(T\) be a linear transformation on a finite-dimensional \(\mathbb{C}\) -vector space V, and let \(f\) be a polynomial with coefficients in \(\mathbb{C}\). If \(\lambda\) is an eigenvalue of \(T\), show that \(f(\lambda)\) is an eigenvalue of \(f(T)\). Is every eigenvalue of \(f(T)\) necessarily obtained in this way?_

**Problem 7.5.16** (Fa83, Sp96): _Let \(A\) be the \(n\times n\) matrix which has zeros on the main diagonal and ones everywhere else. Find the eigenvalues and eigenspaces of \(A\) and compute \(\det(A)\)._

**Problem 7.5.17** (Sp85): _Let \(A\) and \(B\) be two \(n\times n\) self-adjoint (i.e., Hermitian) matrices over \(\mathbb{C}\)  and assume \(A\) is positive definite. Prove that all eigenvalues of \(AB\) are real._

**Problem 7.5.18** (Fa84): _Let \(a\), \(b\), \(c\), and \(d\) be real numbers, not all zero. Find the eigenvalues of the following 4\(\times\)4 matrix and describe the eigenspace decomposition of \(\mathbb{R}^{4}\):_

\[\left(\begin{array}{cccc}aa&ab&ac&ad\\ ba&bb&bc&bd\\ ca&cb&cc&cd\\ da&db&dc&dd\end{array}\right).\]

**Problem 7.5.19** (Sp81): _Show that the following three conditions are all equivalent for a real 3\(\times\)3 symmetric matrix \(A\), whose eigenvalues are \(a\), \(b\), and \(c\):_

1. \(\mathrm{tr}A\) _is not an eigenvalue of_ \(A\)_._
2. \((a+b)(b+c)(a+c)\neq 0\)_._
3. _The map_ \(L:S\to S\) _is an isomorphism, where_ \(S\) _is the space of 3_\(\times\)_3 real skew-symmetric matrices and_ \(L(W)=AW+WA\)_._

**Problem 7.5.20** (Su84): _Let_

\[A=\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)\]

_be a real matrix with \(a,b,c,d>0\). Show that \(A\) has an eigenvector_

\[\left(\begin{array}{c}x\\ y\end{array}\right)\in\mathbb{R}^{2}\]

_with \(x,y>0\)._

**Problem 7.5.21** (Sp90): _Let \(n\) be a positive integer, and let \(A=(a_{ij})_{i,j=1}^{n}\) be the n\(\times\,n\) matrix with \(a_{ii}=2,\,a_{i\,i\pm 1}=-1\), and \(a_{ij}=0\) otherwise; that is,_

\[A=\left(\begin{array}{cccccccc}2&-1&0&0&\cdots&0&0&0\\ -1&2&-1&0&\cdots&0&0&0\\ 0&-1&2&-1&\cdots&0&0&0\\ 0&0&-1&2&\cdots&0&0&0\\ \vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots\\ 0&0&0&0&\cdots&2&-1&0\\ 0&0&0&0&\cdots&-1&2&-1\\ 0&0&0&0&\cdots&0&-1&2\end{array}\right).\]

_Prove that every eigenvalue of \(A\) is a positive real number._

**Problem 7.5.22** (Sp92): _Let \(A\) be a real symmetric \(n\times n\) matrix with nonnegative entries. Prove that \(A\) has an eigenvector with nonnegative entries._

**Problem 7.5.23** (Fa91): _Let \(A=(a_{ij})_{i,j=1}^{n}\) be a real \(n\times n\) matrix with nonnegative entries such that_

\[\sum_{j=1}^{n}a_{ij}=1\qquad\qquad(1\leq i\leq n).\]

_Prove that no eigenvalue of \(A\) has an absolute value greater than \(1\)._

**Problem 7.5.24** (Sp85, Fa88): _Let \(A\) and \(B\) be two \(n\times n\) self-adjoint (i.e., Hermitian) matrices over \(\mathbb{C}\,\) such that all eigenvalues of \(A\) lie in \([a,a^{\prime}]\) and all eigenvalues of \(B\) lie in \([b,b^{\prime}].\) Show that all eigenvalues of \(A+B\) lie in \([a+b,a^{\prime}+b^{\prime}].\)_

**Problem 7.5.25** (Fa85): _Let \(k\) be real, \(n\) an integer \(\geq 2\), and let \(A=(a_{ij})\) be the \(n\times n\) matrix such that all diagonal entries \(a_{ii}=k\), all entries \(a_{i\,i\pm 1}\) immediately above or below the diagonal equal \(1\), and all other entries equal \(0\). For example, if \(n=5\),_

\[A=\left(\begin{array}{ccccc}k&1&0&0&0\\ 1&k&1&0&0\\ 0&1&k&1&0\\ 0&0&1&k&1\\ 0&0&0&1&k\end{array}\right)\]

_Let \(\lambda_{min}\) and \(\lambda_{max}\) denote the smallest and largest eigenvalues of \(A\), respectively. Show that \(\lambda_{min}\leq k-1\) and \(\lambda_{max}\geq k+1\)._

**Problem 7.5.26** (Fa87): _Let \(A\) and \(B\) be real n\(\times\,n\) symmetric matrices with \(B\) positive definite. Consider the function defined for \(x\neq 0\) by_

\[G(x)=\frac{\langle Ax,x\rangle}{\langle Bx,x\rangle}.\]1. _Show that_ \(G\) _attains its maximum value._
2. _Show that any maximum point_ \(U\) _for_ \(G\) _is an eigenvector for a certain matrix related to_ \(A\) _and_ \(B\) _and show which matrix._

**Problem 7.5.27** (Fa90): _Let \(A\) be a real symmetric \(n\times n\) matrix that is positive definite. Let \(y\in\mathbb{R}^{n}\), \(y\neq 0\). Prove that the limit_

\[\lim_{m\to\infty}\frac{y^{t}A^{m+1}y}{y^{t}A^{m}y}\]

_exists and is an eigenvalue of \(A\)._

### Canonical Forms

**Problem 7.6.1** (Sp90, Fa93): _Let \(A\) be a complex \(n\times n\) matrix that has finite order; that is, \(A^{k}=I\) for some positive integer \(k\). Prove that \(A\) is diagonalizable._

**Problem 7.6.2** (Sp84): _Prove, or supply a counterexample: If \(A\) is an invertible \(n\times n\) complex matrix and some power of \(A\) is diagonal, then \(A\) can be diagonalized._

**Problem 7.6.3** (Fa96): _Let_

\[A=\left(\begin{array}{rrr}2&-1&0\\ -1&2&-1\\ 0&-1&2\end{array}\right)\.\]

_Show that every real matrix \(B\) such that \(AB=BA\) has the form_

\[B=aI+bA+cA^{2}\]

_for some real numbers \(a\), \(b\), and \(c\)._

**Problem 7.6.4** (Fa78): _Let_

\[A=\left(\begin{array}{rrr}1&2\\ 1&-1\end{array}\right).\]

_Express \(A^{-1}\) as a polynomial in \(A\) with real coefficients._

**Problem 7.6.5** (Sp81): _For \(x\in\mathbb{R}\), let_

\[A_{x}=\left(\begin{array}{rrr}x&1&1&1\\ 1&x&1&1\\ 1&1&x&1\\ 1&1&1&x\end{array}\right).\]1. _Prove that_ \(\det(A_{x})=(x-1)^{3}(x+3)\)_._
2. _Prove that if_ \(x\neq 1,-3\)_, then_ \(A_{x}^{-1}=-(x-1)^{-1}(x+3)^{-1}A_{-x-2}\)_._

**Problem 7.6.6** (Sp88): _Compute \(A^{10}\) for the matrix_

\[A=\left(\begin{array}{ccc}3&1&1\\ 2&4&2\\ -1&-1&1\end{array}\right).\]

**Problem 7.6.7** (Fa87): _Calculate \(A^{100}\) and \(A^{-7}\), where_

\[A=\left(\begin{array}{cc}3/2&1/2\\ -1/2&1/2\end{array}\right).\]

**Problem 7.6.8** (Sp96): _Prove or disprove: For any 2\(\times\)2 matrix \(A\) over \(\mathbb{C}\), there is a 2\(\times\)2 matrix \(B\) such that \(A=B^{2}\)._

**Problem 7.6.9** (Su85):
1. _Show that a real 2\(\times\)2 matrix_ \(A\) _satisfies_ \(A^{2}=-I\) _if and only if_ \[A=\left(\begin{array}{cc}\pm\sqrt{pq-1}&-p\\ q&\mp\sqrt{pq-1}\end{array}\right)\] _where_ \(p\) _and_ \(q\) _are real numbers such that_ \(pq\geq 1\) _and both upper or both lower signs should be chosen in the double signs._
2. _Show that there is no real 2\(\times\)2 matrix_ \(A\) _such that_ \[A^{2}=\left(\begin{array}{cc}-1&0\\ 0&-1-\varepsilon\end{array}\right)\] _with_ \(\varepsilon>0\)_._

**Problem 7.6.10** (Fa96): _Is there a real 2\(\times\)2 matrix \(A\) such that_

\[A^{20}=\left(\begin{array}{cc}-1&0\\ 0&-1-\varepsilon\end{array}\right)\,?\]

_Exhibit such an \(A\) or prove there is none._

**Problem 7.6.11** (Sp88): _For which positive integers \(n\) is there a 2\(\times\)2 matrix_

\[A=\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)\]

_with integer entries and order \(n\); that is, \(A^{n}=I\) but \(A^{k}\neq I\) for \(0<k<n\)?_

_See also Problem 7.7.9._

**Problem 7.6.12** (Sp92): _Find a square root of the matrix_

\[\left(\begin{array}{ccc}1&3&-3\\ 0&4&5\\ 0&0&9\end{array}\right).\]

_How many square roots does this matrix have?_

**Problem 7.6.13** (Sp92): _Let \(A\) denote the matrix_

\[\left(\begin{array}{ccc}0&0&0&1\\ 0&0&0&0\\ 0&0&0&0\\ 0&0&0&0\end{array}\right).\]

_For which positive integers \(n\) is there a complex 4\(\times\)4 matrix \(X\) such that \(X^{n}=A\)?_

**Problem 7.6.14** (Sp88): _Prove or disprove: There is a real \(n\times n\) matrix \(A\) such that_

\[A^{2}+2A+5I=0\]

_if and only if \(n\) is even._

**Problem 7.6.15** (Su83): _Let \(A\) be an \(n\times n\) Hermitian matrix satisfying the condition_

\[A^{5}+A^{3}+A=3I\]

_Show that \(A=I\)._

**Problem 7.6.16** (Su80): _Which of the following matrix equations have a real matrix solution \(X\)? (It is not necessary to exhibit solutions.)_

_1._

\[X^{3}=\left(\begin{array}{ccc}0&0&0\\ 1&0&0\\ 2&3&0\end{array}\right),\]

_2._

\[2X^{5}+X=\left(\begin{array}{ccc}3&5&0\\ 5&1&9\\ 0&9&0\end{array}\right),\]

_3._

\[X^{6}+2X^{4}+10X=\left(\begin{array}{cc}0&-1\\ 1&0\end{array}\right),\]_._
4. \[X^{4}=\left(\begin{array}{ccc}3&4&0\\ 0&3&0\\ 0&0&-3\end{array}\right).\]

**Problem 7.6.17** (Sp80): _Find a real matrix \(B\) such that_

\[B^{4}=\left(\begin{array}{ccc}2&0&0\\ 0&2&0\\ 0&-1&1\end{array}\right).\]

**Problem 7.6.18** (Fa87): _Let \(V\) be a finite-dimensional vector space and \(T:V\to V\) a diagonalizable linear transformation. Let \(W\subset V\) be a linear subspace which is mapped into itself by \(T\). Show that the restriction of \(T\) to \(W\) is diagonalizable._

**Problem 7.6.19** (Fa89): _Let \(A\) and \(B\) be diagonalizable linear transformations of \(\mathbb{R}^{n}\) into itself such that \(AB=BA\). Let \(E\) be an eigenspace of \(A\). Prove that the restriction of \(B\) to \(E\) is diagonalizable._

**Problem 7.6.20** (Fa83, Sp87): _Let \(V\) be a finite-dimensional complex vector space and let \(A\) and \(B\) be linear operators on \(V\) such that \(AB=BA\). Prove that if \(A\) and \(B\) can each be diagonalized, then there is a basis for \(V\) which simultaneously diagonalizes \(A\) and \(B\)._

**Problem 7.6.21** (Sp80): _Let \(A\) and \(B\) be \(n\times n\) complex matrices. Prove or disprove each of the following statements:_

1. _If_ \(A\) _and_ \(B\) _are diagonalizable, so is_ \(A+B\)_._
2. _If_ \(A\) _and_ \(B\) _are diagonalizable, so is_ \(AB\)_._
3. _If_ \(A^{2}=A\)_, then_ \(A\) _is diagonalizable._
4. _If_ \(A\) _is invertible and_ \(A^{2}\) _is diagonalizable, then_ \(A\) _is diagonalizable._

**Problem 7.6.22** (Fa77): _Let_

\[A=\left(\begin{array}{ccc}7&15\\ -2&-4\end{array}\right).\]

_Find a real matrix \(B\) such that \(B^{-1}AB\) is diagonal._

**Problem 7.6.23** (Su77): _Let \(A:\mathbb{R}^{6}\rightarrow\mathbb{R}^{6}\) be a linear transformation such that \(A^{26}=I\). Show that \(\mathbb{R}^{6}=V_{1}\oplus V_{2}\oplus V_{3}\), where \(V_{1}\), \(V_{2}\), and \(V_{3}\) are two-dimensional invariant subspaces for \(A\)._

**Problem 7.6.24** (Sp78, Sp82, Su82, Fa90): _Determine the Jordan Canonical Form of the matrix_

\[A=\left(\begin{array}{ccc}1&2&3\\ 0&4&5\\ 0&0&4\end{array}\right).\]

**Problem 7.6.25** (Su83): _Find the eigenvalues, eigenvectors, and the Jordan Canonical Form of_

\[A=\left(\begin{array}{ccc}2&1&1\\ 1&2&1\\ 1&1&2\end{array}\right),\]

_considered as a matrix with entries in \(\mathbf{F}_{3}=\mathbb{Z}/3\mathbb{Z}\)._

**Problem 7.6.26** (Su83): _Let \(A\) be an \(n\times n\) complex matrix, and let \(\chi\) and \(\mu\) be the characteristic and minimal polynomials of \(A\). Suppose that_

\[\chi(x)=\mu(x)(x-i),\]

\[\mu(x)^{2}=\chi(x)(x^{2}+1).\]

_Determine the Jordan Canonical Form of \(A\)._

**Problem 7.6.27** (Fa78, Fa84): _Let \(M\) be the \(n\times n\) matrix over a field \(\mathbf{F}\), all of whose entries are equal to \(1\)._

1. _Find the characteristic polynomial of_ \(M\)_._
2. _Is_ \(M\) _diagonalizable?_
3. _Find the Jordan Canonical Form of_ \(M\) _and discuss the extent to which the Jordan form depends on the characteristic of the field_ \(\mathbf{F}\)_._

**Problem 7.6.28** (Fa86): _Let \(M_{2\times 2}\) denote the vector space of complex 2\(\times\)2 matrices. Let_

\[A=\left(\begin{array}{ccc}0&1\\ 0&0\end{array}\right)\]

_and let the linear transformation \(T:M_{2\times 2}\to M_{2\times 2}\) be defined by \(T(X)=XA-AX\). Find the Jordan Canonical Form for \(T\)._

**Problem 7.6.29** (Fa88): _Find the Jordan Canonical Form of the matrix_

\[\left(\begin{array}{cccccc}1&0&0&0&0&0\\ 1&1&0&0&0&0\\ 1&0&1&0&0&0\\ 1&0&0&1&0&0\\ 1&0&0&0&1&0\\ 1&1&1&1&1&1\end{array}\right).\]

**Problem 7.6.30** (Fa89): _Let \(A\) be a real, upper-triangular, \(n\times n\) matrix that commutes with its transpose. Prove that \(A\) is diagonal._

**Problem 7.6.31** (Su78):
1. _Prove that a linear operator_ \(T:\mathbb{C}\,^{n}\to\mathbb{C}\,^{n}\) _is diagonalizable if for all_ \(\lambda\in\mathbb{C}\,,\,\ker(T-\lambda I)^{n}=\ker(T-\lambda I)\)_, where_ \(I\) _is the_ \(n\times n\) _identity matrix._
2. _Show that_ \(T\) _is diagonalizable if_ \(T\) _commutes with its conjugate transpose_ \(T^{*}\) _(i.e.,_ \((T^{*})_{jk}=\overline{T_{kj}}\)_)._

**Problem 7.6.32** (Fa79): _Let \(A\) be an \(n\times n\) complex matrix. Prove there is a unitary matrix \(U\) such that \(B=UAU^{-1}\) is upper triangular: \(B_{jk}=0\) for \(j>k\)._

**Problem 7.6.33** (Sp81): _Let \(b\) be a real nonzero \(n\times 1\) matrix (a column vector). Set \(M=bb^{t}\) (an \(n\times n\) matrix) where \(b^{t}\) denotes the transpose of \(b\)._

1. _Prove that there is an orthogonal matrix_ \(Q\) _such that_ \(QMQ^{-1}=D\) _is diagonal, and find_ \(D\)_._
2. _Describe geometrically the linear transformation_ \(M:\mathbb{R}^{n}\to\mathbb{R}^{n}\)_._

**Problem 7.6.34** (Sp83): _Let \(M\) be an invertible real \(n\times n\) matrix. Show that there is a decomposition \(M=UT\) in which \(U\) is an \(n\times n\) real orthogonal matrix and \(T\) is upper triangular with positive diagonal entries. Is this decomposition unique?_

**Problem 7.6.35** (Su85): _Let \(A\) be a nonsingular real \(n\times n\) matrix. Prove that there exists a unique orthogonal matrix \(Q\) and a unique positive definite symmetric matrix \(B\) such that \(A=QB\)._

**Problem 7.6.36** (Sp95): _Let \(A\) be the 3\(\times\)3 matrix_

\[\left(\begin{array}{ccc}1&-1&0\\ -1&2&-1\\ 0&-1&1\end{array}\right).\]

_Determine all real numbers a for which the limit \(\lim_{n\to\infty}a^{n}A^{n}\) exists and is nonzero (as a matrix)._

**Problem 7.6.37** (Fa96): _Suppose \(p\) is a prime. Show that every element of \(GL_{2}(\mathbf{F}_{p})\) has order dividing either \(p^{2}-1\) or \(p(p-1)\)._

### Similarity

**Problem 7.7.1** (Fa80, Fa92): _Let_

\[\mathrm{A}=\left(\begin{array}{ccc}1&0&0\\ -1&1&1\\ -1&0&2\end{array}\right).\]_Is A similar to_

\[{\rm B}=\left(\begin{array}{ccc}1&1&0\\ 0&1&0\\ 0&0&2\end{array}\right)?\]

**Problem 7.7.2** (Fa78): _Which pairs of the following matrices are similar?_

\[\left(\begin{array}{cc}1&0\\ 0&1\end{array}\right),\ \ \ \ \left(\begin{array}{cc}0&1\\ 1&0\end{array}\right),\ \ \ \ \left(\begin{array}{cc}1&0\\ 1&1\end{array}\right),\ \ \ \ \left(\begin{array}{cc}0&-1\\ 1&0\end{array}\right),\]

\[\left(\begin{array}{cc}1&0\\ 1&-1\end{array}\right),\ \ \ \ \left(\begin{array}{cc}1&5\\ 0&-1\end{array}\right),\ \ \ \ \left(\begin{array}{cc}1&5\\ 0&1\end{array}\right).\]

**Problem 7.7.3** (Sp79): _Which of the following matrices are similar as matrices over \(\mathbb{R}\)?_

\[(a)\left(\begin{array}{ccc}1&0&0\\ 0&1&0\\ 0&0&1\end{array}\right),\ \ (b)\left(\begin{array}{ccc}0&0&1\\ 0&1&0\\ 1&0&0\end{array}\right),\ \ (c)\left(\begin{array}{ccc}1&0&0\\ 1&1&0\\ 0&0&1\end{array}\right),\]

\[(d)\left(\begin{array}{ccc}1&0&0\\ 1&1&0\\ 0&1&1\end{array}\right),\ \ (e)\left(\begin{array}{ccc}1&1&0\\ 0&1&0\\ 0&0&1\end{array}\right),\ \ (f)\left(\begin{array}{ccc}0&1&1\\ 0&1&0\\ 1&0&0\end{array}\right).\]

**Problem 7.7.4** (Sp79): _Let \(M\) be an \(n\times n\) complex matrix. Let \(G_{M}\) be the set of complex numbers \(\lambda\) such that the matrix \(\lambda M\) is similar to \(M\)._

_1. What is \(G_{M}\) if_

\[M=\left(\begin{array}{ccc}0&0&4\\ 0&0&0\\ 0&0&0\end{array}\right)?\]

_2. Assume \(M\) is not nilpotent. Prove \(G_{M}\) is finite._

**Problem 7.7.5** (Su80, Fa96): _Let \(A\) and \(B\) be real 2\(\times\)2 matrices with \(A^{2}=B^{2}=I,\ AB+BA=0\). Prove there exists a real nonsingular matrix \(T\) with_

\[TAT^{-1}=\left(\begin{array}{cc}1&0\\ 0&-1\end{array}\right)\ \ \ \ TBT^{-1}=\left(\begin{array}{cc}0&1\\ 1&0\end{array}\right).\]

**Problem 7.7.6** (Su79, Fa82): _Let \(A\) and \(B\) be \(n\times n\) matrices over a field \(\mathbb{F}\) such that \(A^{2}=A\) and \(B^{2}=B\). Suppose that \(A\) and \(B\) have the same rank. Prove that \(A\) and \(B\) are similar._

**Problem 7.7.7** (Fa97): _Prove that if \(A\) is a 2\(\times\)2 matrix over the integers such that \(A^{n}=I\) for some strictly positive integer \(n\), then \(A^{12}=I\)._

**Problem 7.7.8** (Fa80): _Exhibit a set of 2\(\times\)2 real matrices with the following property: A matrix \(A\) is similar to exactly one matrix in \(S\) provided \(A\) is a 2\(\times\)2 invertible matrix of integers with all the roots of its characteristic polynomial on the unit circle._

**Problem 7.7.9** (Su78): _Let \(G\) be a finite multiplicative group of 2\(\times\)2 integer matrices._

1. _Let_ \(A\in G\)_. What can you prove about_ 1. \(\det A\)_?_ 2. _the (real or complex) eigenvalues of A?_ 3. _the Jordan or Rational Canonical Form of A?_ 4. _the order of A?_
2. _Find all such groups up to isomorphism._

_See also Problem 7.6.11._

**Problem 7.7.10** (Fa81, Su81, Sp84, Fa87, Fa95): _Let \(A\) and \(B\) be two real \(n\times n\) matrices. Suppose there is a complex invertible \(n\times n\) matrix \(U\) such that \(A=UBU^{-1}\). Show that there is a real invertible \(n\times n\) matrix \(V\) such that \(A=VBV^{-1}\). (In other words, if two real matrices are similar over \(\mathbb{C}\), then they are similar over \(\mathbb{R}\).)_

**Problem 7.7.11** (Sp91): _Let \(A\) be a linear transformation on an n-dimensional vector space over \(\mathbb{C}\) such that \(\det(xI-A)=(x-1)^{n}\). Prove that \(A\) is similar to \(A^{-1}\)._

**Problem 7.7.12** (Sp94): _Prove or disprove: A square complex matrix, \(A\), is similar to its transpose, \(A^{t}\)._

**Problem 7.7.13** (Sp79): _Let \(M\) be a real nonsingular 3\(\times\)3 matrix. Prove there are real matrices \(S\) and \(U\) such that \(M=SU=US\), all the eigenvalues of \(U\) equal \(1\), and \(S\) is diagonalizable over \(\mathbb{C}\)._

**Problem 7.7.14** (Sp77, Sp93, Fa94): _Find a list of real matrices, as long as possible, such that_

* _the characteristic polynomial of each matrix is_ \((x-1)^{5}(x+1)\)_,_
* _the minimal polynomial of each matrix is_ \((x-1)^{2}(x+1)\)_,_
* _no two matrices in the list are similar to each other._

**Problem 7.7.15** (Fa95): _Let \(A\) and \(B\) be nonsingular \(n\times n\) complex matrices with the same minimal and the same characteristic polynomial. Show that \(n\geq 4\) and the minimal polynomial is not equal to the characteristic polynomial._

**Problem 7.7.16** (Sp98): _Let \(A\) be an \(n\times n\) complex matrix with \(\operatorname{trace}(A)=0\). Show that \(A\) is similar to a matrix with all \(0\)'s along the main diagonal._

### 7.8 Bilinear, Quadratic Forms, and Inner Product Spaces

**Problem 7.8.1** (Sp98): _Let \(A,B,\ldots,F\) be real coefficients. Show that the quadratic form_

\[Ax^{2}+2Bxy+Cy^{2}+2Dxz+2Eyz+Fz^{2}\]

_is positive definite if and only if_

\[A>0,\qquad\left|\begin{array}{cc}A&B\\ B&C\end{array}\right|>0,\qquad\left|\begin{array}{ccc}A&B&D\\ B&C&E\\ D&E&F\end{array}\right|>0.\]

**Problem 7.8.2** (Fa90): _Let \(\mathbb{R}^{3}\) be 3-space with the usual inner product, and \((a,b,c)\in\mathbb{R}^{3}\) a vector of length \(1\). Let \(W\) be the plane defined by \(ax+by+cz=0\). Find, in the standard basis, the matrix representing the orthogonal projection of \(\mathbb{R}^{3}\) onto \(W\)._

**Problem 7.8.3** (Fa93): _Let \(w\) be a positive continuous function on \([0,1]\), \(n\) a positive integer, and \(P_{n}\) the vector space of real polynomials whose degrees are at most \(n\), equipped with the inner product_

\[\langle p,q\rangle=\int_{0}^{1}\ p(t)q(t)w(t)\ dt\,.\]

1. _Prove that_ \(P_{n}\) _has an orthonormal basis_ \(p_{0},p_{1},\ldots,p_{n}\) _(i.e.,_ \(\langle p_{j},p_{k}\rangle=1\) _for_ \(j=k\) _and_ \(0\) _for_ \(j\neq k\)_) such that_ \(\deg p_{k}=k\) _for each_ \(k\)_._
2. _Prove that_ \(\langle p_{k},p_{k}^{\prime}\rangle=0\) _for each_ \(k\)_._

**Problem 7.8.4** (Sp98): _For continuous real valued functions \(f,g\) on the interval \([-1,1]\) define the inner product \(\langle f,g\rangle=\int_{-1}^{1}f(x)g(x)dx\). Find that polynomial of the form \(p(x)=a+bx^{2}-x^{4}\) which is orthogonal on \([-1,1]\) to all lower order polynomials._

**Problem 7.8.5** (Su80, Fa92): _Let \(E\) be a finite-dimensional vector space over a field \(\mathbf{F}\). Suppose \(B:E{\times}E{\rightarrow}\)\(\mathbf{F}\) is a bilinear map (not necessarily symmetric). Define subspaces_

\[E_{1}=\{x\in E\mid B(x,y)=0\ for\ all\ y\in E\},\]

\[E_{2}=\{y\in E\mid B(x,y)=0\ for\ all\ x\in E\}\]

_Prove that \(\dim E_{1}=\dim E_{2}\)._

**Problem 7.8.6** (Su82): _Let \(A\) be a real \(n\times n\) matrix such that \(\langle Ax,x\rangle\geq 0\) for every real \(n\)-vector \(x\). Show that \(Au=0\) if and only if \(A^{t}u=0\)._

**Problem 7.8.7** (Fa85): _An \(n\times n\) real matrix \(T\) is positive definite if \(T\) is symmetric and \(\langle Tx,x\rangle>0\) for all nonzero vectors \(x\in\mathbb{R}^{n}\), where \(\langle u,v\rangle\) is the standard inner product. Suppose that \(A\) and \(B\) are two positive definite real matrices._

1. _Show that there is a basis_ \(\{v_{1},v_{2},\ldots,v_{n}\}\) _of_ \(\mathbb{R}^{n}\) _and real numbers_ \(\lambda_{1},\lambda_{2},\ldots,\lambda_{n}\) _such that, for_ \(1\leq i,j\leq n\)_:_ \[\langle Av_{i},v_{j}\rangle=\left\{\begin{array}{ll}1&i=j\\ 0&i\neq j\end{array}\right.\] _and_ \[\langle Bv_{i},v_{j}\rangle=\left\{\begin{array}{ll}\lambda_{i}&i=j\\ 0&i\neq j\end{array}\right.\]
2. _Deduce from Part 1 that there is an invertible real matrix_ \(U\) _such that_ \(U^{t}AU\) _is the identity matrix and_ \(U^{t}BU\) _is diagonal._

**Problem 7.8.8** (Sp83): _Let \(V\) be a real vector space of dimension \(n\), and let \(S:V\times V\to\mathbb{R}\) be a nondegenerate bilinear form. Suppose that \(W\) is a linear subspace of \(V\) such that the restriction of \(S\) to \(W\times W\) is identically \(0\). Show that we have \(\dim W\leq n/2\)._

**Problem 7.8.9** (Fa85): _Let \(A\) be the symmetric matrix_

\[\frac{1}{6}\left(\begin{array}{ccc}13&-5&-2\\ -5&13&-2\\ -2&-2&10\end{array}\right).\]

_Let x denote the column vector_

\[\left(\begin{array}{c}x_{1}\\ x_{2}\\ x_{3}\end{array}\right)\]

\(x_{i}\in\mathbb{R}\)_, and let_ \(x^{t}\) _denote its transpose_ \((x_{1},x_{2},x_{3})\)_. Let_ \(|x|\) _denote the length of the vector_ \(x\)_. As_ \(x\) _ranges over the set of vectors for which_ \(x^{t}Ax=1\)_, show that_ \(|x|\) _is bounded, and determine its least upper bound._

**Problem 7.8.10** (Fa97): _Define the index of a real symmetric matrix \(A\) to be the number of strictly positive eigenvalues of \(A\) minus the number of strictly negative eigenvalues. Suppose \(A\), and \(B\) are real symmetric \(n\times n\) matrices such that \(x^{t}Ax\leq x^{t}Bx\) for all \(n\times 1\) matrices \(x\). Prove the the index of \(A\) is less than or equal to the index of \(B\)._

**Problem 7.8.11** (Fa78): _For \(x,y\in\mathbb{C}\,^{n}\), let \(\langle x,y\rangle\) be the Hermitian inner product \(\sum_{j}x_{j}\overline{y}_{j}\). Let \(T\) be a linear operator on \(\mathbb{C}\,^{n}\) such that \(\langle Tx,Ty\rangle=0\) if \(\langle x,y\rangle=0\). Prove that \(T=kS\) for some scalar \(k\) and some operator \(S\) which is unitary: \(\langle Sx,Sy\rangle=\langle x,y\rangle\) for all \(x\) and \(y\)._

**Problem 7.8.12** (Sp79): _Let \(E\) denote a finite-dimensional complex vector space with a Hermitian inner product \(\langle x,y\rangle\)._

1. _Prove that_ \(E\) _has an orthonormal basis._
2. _Let_ \(f:E\to\mathbb{C}\) _be such that_ \(f(x,y)\) _is linear in_ \(x\) _and conjugate linear in_ \(y\)_. Show there is a linear map_ \(A:E\to E\) _such that_ \(f(x,y)=\langle Ax,y\rangle\)_._

**Problem 7.8.13** (Fa86): _Let \(a\) and \(b\) be real numbers. Prove that there are mutually orthogonal unit vectors \(u\) and \(v\) in \(\mathbb{R}^{3}\) such that \(u=(u_{1},u_{2},a)\) and \(v=(v_{1},v_{2},b)\) if and only if \(a^{2}+b^{2}\leq 1\)._

### General Theory of Matrices

**Problem 7.9.1** (Fa81): _Prove the following three statements about real \(n\times n\) matrices._

1. _If_ \(A\) _is an orthogonal matrix whose eigenvalues are all different from_ \(-1\)_, then_ \(I_{n}+A\) _is nonsingular and_ \(S=(I_{n}-A)(I_{n}+A)^{-1}\) _is skew-symmetric._
2. _If_ \(S\) _is a skew-symmetric matrix, then_ \(A=(I_{n}-S)(I_{n}+S)^{-1}\) _is an orthogonal matrix with no eigenvalue equal to_ \(-1\)_._
3. _The correspondence_ \(A\leftrightarrow S\) _from Parts 1 and 2 is one-to-one._

**Problem 7.9.2** (Fa79): _Let \(B\) denote the matrix_

\[\left(\begin{array}{ccc}a&0&0\\ 0&b&0\\ 0&0&c\end{array}\right)\]

_where \(a\), \(b\), and \(c\) are real and \(|a|\), \(|b|\), and \(|c|\) are distinct. Show that there are exactly four symmetric matrices of the form \(BQ\), where \(Q\) is a real orthogonal matrix of determinant \(1\)._

**Problem 7.9.3** (Sp79): _Let \(P\) be a 9\(\times\)9 real matrix such that \(x^{t}Py=y^{t}Px\) for all column vectors \(x,y\) in \(\mathbb{R}^{9}\). Prove that \(P\) is singular._

**Problem 7.9.4** (Fa79): _Let \(A\) be a real skew-symmetric matrix \((A_{ij}=-A_{ji})\). Prove that \(A\) has even rank._

**Problem 7.9.5** (Fa80, Sp96): _Suppose that \(A\) and \(B\) are real matrices such that \(A^{t}=A\),_

\[v^{t}Av\geq 0\]for all \(v\in\mathbb{R}^{n}\) and_

\[AB+BA=0.\]

_Show that \(AB=BA=0\) and give an example where neither \(A\) nor \(B\) is zero._

**Problem 7.9.6** (Sp78): _Suppose \(A\) is a real \(n\times n\) matrix._

1. _Is it true that_ \(A\) _must commute with its transpose?_
2. _Suppose the columns of_ \(A\) _(considered as vectors) form an orthonormal set; is it true that the rows of_ \(A\) _must also form an orthonormal set?_

**Problem 7.9.7** (Sp98): _Let \(M_{1}=\left(\begin{smallmatrix}3&2\\ 1&4\end{smallmatrix}\right)\), \(M_{2}=\left(\begin{smallmatrix}5&7\\ -3&-4\end{smallmatrix}\right)\), \(M_{3}=\left(\begin{smallmatrix}5&6.9\\ -3&-4\end{smallmatrix}\right)\). For which (if any) \(i\), \(1\leq i\leq 3\), is the sequence \((M_{i}^{n})\) bounded away from \(\infty\)? For which \(i\) is the sequence bounded away from \(0\)?_

**Problem 7.9.8** (Su83): _Let \(A\) be an \(n\times n\) complex matrix, all of whose eigenvalues are equal to \(1\). Suppose that the set \(\{A^{n}\mid n=1,2,\ldots\}\) is bounded. Show that \(A\) is the identity matrix._

**Problem 7.9.9** (Fa81): _Consider the complex 3\(\times\)3 matrix_

\[A=\left(\begin{array}{ccc}a_{0}&a_{1}&a_{2}\\ a_{2}&a_{0}&a_{1}\\ a_{1}&a_{2}&a_{0}\end{array}\right),\]

_where \(a_{0},a_{1},a_{2}\in\mathbb{C}\)._

1. _Show that_ \(A=a_{0}I_{3}+a_{1}E+a_{2}E^{2}\)_, where_ \[E=\left(\begin{array}{ccc}0&1&0\\ 0&0&1\\ 1&0&0\end{array}\right).\]
2. _Use Part 1 to find the complex eigenvalues of_ \(A\)_._
3. _Generalize Parts 1 and 2 to_ \(n\times n\) _matrices._

**Problem 7.9.10** (Su78): _Let \(A\) be a \(n\times n\) real matrix._

1. _If the sum of each column element of_ \(A\) _is_ \(1\) _prove that there is a nonzero column vector_ \(x\) _such that_ \(Ax=x\)_._
2. _Suppose that_ \(n=2\) _and all entries in_ \(A\) _are positive. Prove there is a nonzero column vector_ \(y\) _and a number_ \(\lambda>0\) _such that_ \(Ay=\lambda y\)

**Problem 7.9.11** (Sp89): _Let the real \(2n\times 2n\) matrix \(X\) have the form_

\[\left(\begin{array}{cc}A&B\\ C&D\end{array}\right)\]

_where \(A\), \(B\), \(C\), and \(D\) are \(n\times n\) matrices that commute with one another. Prove that \(X\) is invertible if and only if \(AD-BC\) is invertible._

**Problem 7.9.12** (Sp89): _Let \(B=(b_{ij})_{i,j=1}^{20}\) be a real \(20\times 20\) matrix such that_

\[b_{ii}=0\quad for\quad 1\leq i\leq 20,\]

\[b_{ij}\in\{1,-1\}\quad for\quad 1\leq i,j\leq 20,\ \ i\neq j.\]

_Prove that \(B\) is nonsingular._

**Problem 7.9.13** (Sp80): _Let_

\[A=\left(\begin{array}{cc}1&2\\ 3&4\end{array}\right).\]

_Show that every real matrix \(B\) such that \(AB=BA\) has the form \(sI+tA\), where \(s,t\in\mathbb{R}\)._

**Problem 7.9.14** (Su84): _Let \(A\) be a 2\(\times\)2 matrix over \(\mathbb{C}\) which is not a scalar multiple of the identity matrix \(I\). Show that any 2\(\times\)2 matrix \(X\) over \(\mathbb{C}\) commuting with \(A\) has the form \(X=\alpha I+\beta A\), where \(\alpha,\beta\in\mathbb{C}\)._

**Problem 7.9.15** (Sp77, Su82): _A square matrix \(A\) is nilpotent if \(A^{k}=0\) for some positive integer \(k\)._

1. _If_ \(A\) _and_ \(B\) _are nilpotent, is_ \(A+B\) _nilpotent?_
2. _Prove: If_ \(A\) _and_ \(B\) _are nilpotent matrices and_ \(AB=BA\)_, then_ \(A+B\) _is nilpotent._
3. _Prove: If_ \(A\) _is nilpotent then_ \(I+A\) _and_ \(I-A\) _are invertible._

**Problem 7.9.16** (Sp77): _Consider the family of square matrices \(A(\theta)\) defined by the solution of the matrix differential equation_

\[\frac{dA(\theta)}{d\theta}=BA(\theta)\]

_with the initial condition \(A(0)=I\), where \(B\) is a constant square matrix._

1. _Find a property of_ \(B\) _which is necessary and sufficient for_ \(A(\theta)\) _to be orthogonal for all_ \(\theta\)_; that is,_ \(A(\theta)^{t}=A(\theta)^{-1}\)_, where_ \(A(\theta)^{t}=\)transpose of \(A(\theta)\)_._ _Hint: What is_ \(\frac{d}{d\theta}A^{-1}(\theta)\)2. _Find the matrices_ \(A(\theta)\) _corresponding to_ \[B=\left(\begin{array}{cc}0&1\\ -1&0\end{array}\right)\] _and give a geometric interpretation._

**Problem 7.9.17** (Su77): _Let \(A\) be an \(r\times r\) matrix of real numbers. Prove that the infinite sum_

\[e^{A}=I+A+\frac{A^{2}}{2}+\cdots+\frac{A^{n}}{n!}+\cdots\]

_of matrices converges (i.e., for each \(i,j\), the sum of \((i,j)^{th}\) entries converges), and hence that \(e^{A}\) is a well-defined matrix._

**Problem 7.9.18** (Sp97): _Show that_

\[\det(\exp(M))=e^{\operatorname{tr}(M)}\]

_for any complex \(n\times n\) matrix \(M\), where \(\exp(M)\) is defined as in Problem 7.9.17._

**Problem 7.9.19** (Fa77): _Let \(T\) be an \(n\times n\) complex matrix. Show that_

\[\lim_{k\to\infty}T^{k}=0\]

_if and only if all the eigenvalues of \(T\) have absolute value less than \(1\)._

**Problem 7.9.20** (Sp82): _Let \(A\) and \(B\) be n\(\times\)n complex matrices. Prove that_

\[|\operatorname{tr}(AB^{*})|^{2}\leq\operatorname{tr}(AA^{*})\operatorname{tr }(BB^{*}).\]

**Problem 7.9.21** (Fa83): _Let \(F(t)=(f_{ij}(t))\) be an n\(\times\)n matrix of continuously differentiable functions \(f_{ij}:\mathbb{R}\to\mathbb{R}\), and let_

\[u(t)=\operatorname{tr}\left(F(t)^{3}\right).\]

_Show that \(u\) is differentiable and_

\[u^{\prime}(t)=3\operatorname{tr}\left(F(t)^{2}F^{\prime}(t)\right).\]

**Problem 7.9.22** (Fa84): _Let \(A\) and \(B\) be n\(\times\)n real matrices, and k a positive integer. Find_

1. \[\lim_{t\to 0}\frac{1}{t}\left((A+tB)^{k}-A^{k}\right).\]2. \[\frac{d}{dt}\mathrm{tr}\left(A+tB\right)^{k}\bigg{|}_{t=0}.\]

**Problem 7.9.23** (Fa91):
1. _Prove that any real_ \(n\times n\) _matrix_ \(M\) _can be written as_ \(M=A+S+cI\)_, where_ \(A\) _is antisymmetric,_ \(S\) _is symmetric,_ \(c\) _is a scalar,_ \(I\) _is the identity matrix, and_ \(\mathrm{tr}\,S=0\)_._
2. _Prove that with the above notation,_ \[\mathrm{tr}(M^{2})=\mathrm{tr}(A^{2})+\mathrm{tr}(S^{2})+\frac{1}{n}(\mathrm{ tr}\,M)^{2}.\]

**Problem 7.9.24** (Sp98):
1. _Let_ \(N\) _be a nilpotent complex matrix. Let_ \(r\) _be a positive integer. Show that there is a_ \(n\times n\) _complex matrix_ \(A\) _with_ \[A^{r}=I+N.\]

**Problem 7.9.25** (Fa94):
1. _Let_ \(A=\left(a_{ij}\right)_{i,j=1}^{n}\) _be a real_ \(n\times n\) _matrix such that_ \(a_{ii}\geq 1\) _for all_ \(i\)_, and_ \[\sum_{i\neq j}a_{ij}^{2}<1.\]

_Prove that_ \(A\) _is invertible._

**Problem 7.9.26** (Fa95):
1. _Show that an_ \(n\times n\) _matrix of complex numbers_ \(A\) _satisfying_ \[|a_{ii}|>\sum_{j\neq i}|a_{ij}|\]

_for_ \(1\leq i\leq n\) _must be invertible._

**Problem 7.9.27** (Sp93):
1. _Let_ \(A=\left(a_{ij}\right)\) _be an_ \(n\times n\) _matrix such that_ \(\sum_{j=1}^{n}|a_{ij}|<1\) _for each_ \(i\)_. Prove that_ \(I-A\) _is invertible._

**Problem 7.9.28** (Sp94):
1. _Let_ \(A\) _be a real_ \(n\times n\) _matrix. Let_ \(M\) _denote the maximum of the absolute values of the eigenvalues of_ \(A\)_._
2. _Prove that if_ \(A\) _is symmetric, then_ \(\|Ax\|\leq M\|x\|\) _for all_ \(x\) _in_ \(\mathbb{R}^{n}\)_. (Here,_ \(\|\cdot\|\) _denotes the Euclidean norm.)_
3. _Prove that the preceding inequality can fail if_ \(A\) _is not symmetric._

**Problem 7.9.29** (Sp97):
1. _Let_ \(R\) _be the ring of_ \(n\times n\) _matrices over a field. Suppose_ \(S\) _is a ring and_ \(h:R\to S\) _is a homomorphism. Show that_ \(h\) _is either injective or zero._

[MISSING_PAGE_EMPTY:141]

Real Analysis

### 1.1 Elementary Calculus

**Solution to 1.1.1:** Let \(f(\theta)=\cos p\,\theta-(\cos\theta)^{p}\). We have \(f(0)=0\) and, for \(0<\theta<\pi/2\),

\[f^{\prime}(\theta) =-p\sin p\,\theta+p\cos^{p-1}\theta\sin\theta\] \[=p\left(-\sin p\,\theta+\frac{\sin\theta}{\cos^{1-p}\theta}\right)\] \[>0\]

since \(\sin\) is an increasing function on \([0,\pi/2]\) and \(\cos^{1-p}\theta\in(0,1)\). We conclude that \(f(\theta)\geq 0\) for \(0\leq\theta\leq\pi/2\), which is equivalent to the inequality we wanted to establish.

**Solution to 1.1.2:** Let \(x\in[0,1]\). Using the fact that \(f(0)=0\) and the Cauchy-Schwarz Inequality [1, pag. 69] we have,

\[|f(x)| =\left|\int_{0}^{x}f^{\prime}(t)dt\right|\] \[\leq\left(\int_{0}^{x}|f^{\prime}(t)|^{2}dt\right)^{1/2}\left( \int_{0}^{x}1^{2}dt\right)^{1/2}\] \[\leq\left(\int_{0}^{x}|f^{\prime}(t)|^{2}dt\right)^{1/2}\]and the conclusion follows.

**Solution to 1.1.3:** As \(f^{\prime}\) is positive, \(f\) is an increasing function, so we have, for \(t>1\), \(f(t)>f(1)=1\). Therefore, for \(t>1\),

\[f^{\prime}(t)=\frac{1}{t^{2}+f^{2}(t)}<\frac{1}{t^{2}+1},\]

so

\[f(x) =1+\int_{1}^{x}f^{\prime}(t)dt\] \[<1+\int_{1}^{x}\frac{1}{t^{2}+1}dt\] \[<1+\int_{1}^{\infty}\frac{1}{t^{2}+1}dt\] \[=1+\frac{\pi}{4};\]

hence, \(\lim_{x\to\infty}f(x)\) exists and is, at most, \(1+\frac{\pi}{4}\). The strict inequality holds because

\[\lim_{x\to\infty}f(x)=1+\int_{1}^{\infty}f^{\prime}(t)dt<1+\int_{1}^{\infty} \frac{1}{t^{2}+1}dt=1+\frac{\pi}{4}.\]

**Solution to 1.1.4:** Denote the common supremum of \(f\) and \(g\) by \(M\). Since \(f\) and \(g\) are continuous and \([0,1]\) is compact, there exist \(\alpha\), \(\beta\in[0,1]\) with \(f(\alpha)=g(\beta)=M\). The function \(h\) defined by \(h(x)=f(x)-g(x)\) satisfies \(h(\alpha)=M-g(\alpha)\geq 0\), \(h(\beta)=f(\beta)-M\leq 0\). Since \(h\) is continuous, it has a zero \(t\in[\alpha,\beta]\). We have \(f(t)=g(t)\), so \(f(t)^{2}+3f(t)=g(t)^{2}+3g(t)\).

**Solution to 1.1.5:** Call a function of the desired form a periodic polynomial, and call its degree the largest \(k\) such that \(x^{k}\) occurs with a nonzero coefficient.

If \(a\) is \(1\)-periodic, then \(\triangle(af)=a\triangle f\) for any function \(f\), so, by the Induction Principle [13, pag. 7], \(\triangle^{n}(af)=a\triangle^{n}f\) for all \(n\).

We will use Complete Induction [13, pag. 32]. For \(n=1\), the result holds: \(\triangle f=0\) if and only if \(f\) is \(1\)-periodic. Assume it is true for \(1,\ldots,n-1\). If

\[f=a_{0}+a_{1}x+\cdots+a_{n-1}x^{n-1}\]

is a periodic polynomial of degree, at most, \(n-1\), then

\[\triangle^{n}f=a_{1}\triangle^{n}x+\cdots+a_{n-1}\triangle x^{n-1}\]

and the induction hypothesis implies that all the terms vanish except, maybe, the last. We have \(\triangle^{n}(x^{n-1})=\triangle^{n-1}\triangle(x^{n-1})\), a polynomial of degree \(n-2\) by the Binomial Theorem [1, pag. 15]. So the induction hypothesis also implies \(\triangle^{n}(x^{n-1})=0\) and the first half of the statement is established.

For the other half, assume \(\triangle^{n}f=0\). By the induction hypothesis, \(\triangle f\) is a periodic polynomial of degree, at most, \(n-2\). Suppose we can find a periodic polynomial \(g\), of degree, at most, \(n-1\), such that \(\triangle g=\triangle f\). Then, as \(\triangle(f-g)=0\), the function \(f-g\) will be \(1\)-periodic, implying that \(f\) is a periodic polynomial of degree, at most, \(n-1\), as desired. Thus, it is enough to prove the following claim: _If \(h\) is a periodic polynomial of degree \(n\left(n=0,1,\ldots\right)\), then there is a periodic polynomial \(g\) of degree \(n+1\) such that \(\triangle g=h\)._

If \(n=0\), we can take \(g=hx\). Assume \(h\) has degree \(n>0\) and, as an induction hypothesis, that the claim is true for lower degrees than \(n\). We can then, without loss of generality, assume \(h=ax^{n}\), where \(a\) is \(1\)-periodic. By the Binomial Theorem,

\[h-\triangle\left(\frac{ax^{n+1}}{n+1}\right)\]

is a periodic polynomial of degree \(n-1\), so it equals \(\triangle g_{1}\), for some periodic polynomial \(g_{1}\) of degree \(n\), and we have \(h=\triangle g\), where

\[g=\frac{ax^{n+1}}{n+1}+g_{1}\]

as desired.

**Solution to 1.1.6:**

1. For

\[f(t)=g(t)=\left\{\begin{array}{ll}0&\mbox{for}\quad t\neq 0\\ 1&\mbox{for}\quad l=0\end{array}\right.\]

we have \(\lim_{t\to 0}g(t)=\lim_{t\to 0}f(t)=0\) but \(\lim_{t\to 0}f\left(g(t)\right)=1\).

2. \(f(t)=t^{2}\) maps the open interval \((-1,1)\) onto \([0,1)\), which is not open.

3. Let \(x,x_{0}\in(-1,1)\). By Taylor's Theorem [2, pag. 110], there is \(\xi\in(-1,1)\) such that

\[f(x)=\sum_{k=0}^{n-1}\frac{f^{(k)}(x_{0})}{k!}(x-x_{0})^{k}+\frac{f^{(n)}(\xi) }{n!}(x-x_{0})^{n}\qquad(n\in\mathbb{N}).\]

We have

\[\lim_{n\to\infty}\left|\frac{f^{(n)}(\xi)}{n!}(x-x_{0})^{n}\right|\leq\lim_{n \to\infty}\frac{|x-x_{0}|^{n}}{n!}=0,\]

so

\[f(x)=\sum_{k=0}^{\infty}\frac{f^{(k)}(x_{0})}{k!}(x-x_{0})^{k}\]for any \(x_{0}\in(-1,1)\) and \(f\) is real analytic.

**Solution to 1.1.8:**\(1\). Suppose \(f:[0,1]\to(0,1)\) is a continuous surjection. Consider the sequence \((x_{n})\) such that \(x_{n}\in f^{-1}\left((0,1/n)\right)\). By the Bolzano-Weierstrass Theorem [13, pag. 40], [14, pag. 153], we may assume that \((x_{n})\) converges, to \(x\in[0,1]\), say. By continuity, we have \(f(x)=0\), which is absurd. Therefore, no such a function can exist.

\(2\). \(|\sin 2\pi x|\).

\(3\). Suppose \(g:(0,1)\to[0,1]\) is a continuous bijection. Let \(x_{0}=g^{-1}(0)\) and \(x_{1}=g^{-1}(1)\). Without loss of generality, assume \(x_{0}<x_{1}\) (otherwise consider \(1-g\)). By the Intermediate Value Theorem [13, pag. 93], we have \(g([x_{0},x_{1}])=[0,1]\). As \(x_{0},x_{1}\in(0,1)\), \(g\) is not an injection, which contradicts our assumption.

**Solution to 1.1.9:** Using the parameterization

\[x=a\cos t,\ y=b\sin t,\]

a triple of points on the ellipse is given by

\[(a\cos t_{i},b\sin t_{i}),\ \ i=1,2,3.\]

So the area of an inscribed triangle is given by

\[\frac{1}{2}\left|\begin{array}{ccc}1&a\cos t_{1}&b\sin t_{1}\\ 1&a\cos t_{2}&b\sin t_{2}\\ 1&a\cos t_{3}&b\sin t_{3}\end{array}\right|=\frac{ab}{2}\left|\begin{array}{ ccc}1&\cos t_{1}&\sin t_{1}\\ 1&\cos t_{2}&\sin t_{2}\\ 1&\cos t_{3}&\sin t_{3}\end{array}\right|\]

which is \(ab\) times the area of a triangle inscribed in the unit circle. Hence, the area is maximal when

\[t_{2}=t_{1}+\frac{2\pi}{3}\ \ \text{and}\ \ t_{3}=t_{2}+\frac{2\pi}{3}\]

that is, when the corresponding triangle inscribed in the unit circle is regular.

**Solution to 1.1.10:** Assume that \(a\) and \(b\) are in \(A\) and that \(a<b\). Suppose \(a<c<b\). Let \((x_{n})\) and \((y_{n})\) be sequences in \([0,\infty)\) tending to \(+\infty\) such that \(a=\lim_{n\to\infty}f(x_{n})\) and \(b=\lim_{n\to\infty}f(y_{n})\). Deleting finitely many terms from each sequence, if necessary, we can assume \(f(x_{n})<c\) and \(f(y_{n})>c\) for every \(n\). Then, by the Intermediate Value Theorem [13, pag. 93], there is for each \(n\) a point \(z_{n}\) between \(x_{n}\) and \(y_{n}\) such that \(f(z_{n})=c\). Since obviously \(\lim_{n\to\infty}z_{n}=+\infty\), it follows that \(c\) is in \(A\), as desired.

**Solution to 1.1.12:** Let \(g\) be a polynomial,

\[g(x)=a_{0}+a_{1}(x-a)+a_{2}(x-a)^{2}+\cdots+a_{n}(x-a)^{n}.\]If we take \[a_{0}=\frac{1}{f(a)},\qquad a_{1}=-\frac{f^{\prime}(a)g(a)}{f(a)},\qquad a_{2}=- \frac{f^{\prime\prime}(a)g(a)+f^{\prime}(a)g^{\prime}(a)}{f(a)},\] a calculation shows that the requirements on \(g\) are met. Solution to 1.1.13:Suppose that all the roots of \(p\) are real and let \(\deg p=n\). We have \(p(z)=(z-r_{1})^{n_{1}}(z-r_{2})^{n_{2}}\cdots(z-r_{k})^{n_{k}}\), where \(r_{1}<r_{2}<\cdots<r_{k}\) and \(\sum n_{i}=n\). By differentiating this expression, we see that the \(r_{i}\)'s are roots of \(p^{\prime}\) of order \(n_{i}-1\) when \(n_{i}>1\). Summing these orders, we see that we have accounted for \(n-k\) of the possible \(n-1\) roots of \(p^{\prime}\). Now by Rolle's Theorem [13, pag. 200], for each \(i\), \(1\leq i\leq k-1\), there is a point \(s_{i}\), \(r_{i}<s_{i}<r_{i+1}\), such that \(p^{\prime}(s_{i})=0\). Thus, we have found the remaining \(k-1\) roots of \(p^{\prime}\), and they are distinct. Now we know that \(a\) is a root of \(p^{\prime}\) but not of \(p\), so \(a\neq r_{i}\) for all \(i\). But \(a\) is a root of \(p^{\prime\prime}\), so \(a\) is a multiple root of \(p^{\prime}\); hence, \(a\neq s_{i}\) for all \(i\). Therefore, \(a\) is not a root of \(p^{\prime}\), a contradiction. Solution to 1.1.14:Let \(x\in\mathbb{R}\) and \(h>0\). By the Taylor's Formula [12, pag. 110], there is a \(w\in(x,x+2h)\) such that \[f(x+2h)=f(x)+2hf^{\prime}(x)+2h^{2}f^{\prime\prime}(w),\] or rewriting \[f^{\prime}(x)=\left(f(x+h)-f(x)\right)/2h-hf^{\prime\prime}(w).\] Taking absolute values and applying our hypotheses, we get \[|f^{\prime}(x)|\leq\frac{\Lambda}{h}+hB.\] Using elementary calculus, we see that the right-hand side is, at most, \(2\sqrt{AB}\). Solution to 1.1.15:Consider the function \(f(x)=\log x/x\). We have \(a^{b}=b^{a}\) iff \(f(a)=f(b)\). Now \(f^{\prime}(x)=(1-\log x)/x^{2}\), so \(f\) is increasing for \(x<e\) and decreasing for \(x>e\). For the above equality to hold, we must have \(0<a<e\), so \(a\) is either \(1\) or \(2\), and \(b>e\). For \(a=1\), clearly there are no solutions, and for \(a=2\) and \(b=4\) works; since \(f\) is decreasing, this is the only solution. Solution 2:Clearly, \(a\) and \(b\) have the same prime factors. As \(b>a\), we must have \(b=ka\), with \(k>1\). Now \(b^{a}=(ka)^{a}=a^{b}\) implies that \(k\) is a power of \(a\), so \(b=a^{m}\) for some \(m>1\). Now \(b^{a}=a^{ma}=a^{a^{m}}\) exactly when \(ma=a^{m}\), which can easily be seen to have the unique solution \(a=m=2\). So \(a=2\) and \(b=2^{2}=4\). Solution 3:Let \(b=a(1+t)\), for some positive \(t\). Then the equation \(a^{b}=b^{a}\) is equivalent to any of the following \[(a^{a})^{1+t} =a^{a}(1+t)^{a}\] \[(a^{a})^{t} =(1+t)^{a}\] \[a^{t} =1+t.\]

We have, by the power series expansion of the exponential function, that \(e^{t}>1+t\) for positive \(t\), so \(a<e\). As \(a=1\) is impossible, we conclude \(a=2\). The original equation now becomes

\[2^{b}=b^{2}\]

which, considering the prime decomposition of \(b\), clearly implies \(b=4\).

**Solution to 1.1.16:** The equation can be rewritten as \(a^{x^{b}}=x\), or

\[\frac{\log x}{x^{b}}=\log a.\]

There is thus a solution for \(x\) if and only if \(\log a\) is in the range of \(x\mapsto(\log x)/x^{b}\). Using elementary calculus, we get that the range of this function is \((-\infty,1/be]\). We conclude then that the original equation has a positive solution for \(x\) if and only if \(\log a\leq 1/be\), that is, if and only if \(1<a<e^{1/be}\).

**Solution to 1.1.17:** Let \(f(x)=3^{x}x^{-3}\) for \(x>0\). We have

\[f^{\prime}(x)=\frac{3^{x}(x\log 3-3)}{x^{4}}>0\quad\text{for}\quad x>\frac{3}{ \log 3}.\]

As \(3/\log 3<3<\pi\), we have \(f(3)=1<f(\pi)=3^{\pi}/\pi^{3}\), that is, \(\pi^{3}<3^{\pi}\).

**Solution to 1.1.18:** Fix \(a\) in \((1,\infty)\), and consider the function \(f(x)=a^{x}x^{-a}\) on \((1,\infty)\), which we try to minimize. Since \(\log f(x)=x\log a-a\log x\), we have

\[\frac{f^{\prime}(x)}{f(x)}=\log a-\frac{a}{x}\,\]

showing that \(f^{\prime}(x)\) is negative on \((1,\frac{a}{\log a})\) and positive on \((\frac{a}{\log a}\,\infty)\). Hence, \(f\) attains its minimum on \((1,\infty)\) at the point \(x_{a}=\frac{a}{\log a}\), and

\[\log f(x_{a})=a-a\log\left(\frac{a}{\log a}\right)=a\log\left(\frac{e\log a}{a }\right)\.\]

The number \(a\) thus has the required property if and only if \(\frac{e\log a}{a}\geq 1\). To see which numbers \(a\) in \((1,\infty)\) satisfy this condition, we consider the function \(g(y)=\frac{\log y}{y}\) on \((1,\infty)\). We have

\[g^{\prime}(y)=\frac{1-\log y}{y^{2}}\,\]from which we conclude that \(g\) attains its maximum on \((1,\infty)\) at \(y=e\), the maximum value being \(g(e)=\frac{1}{e}\). Since \(g(y)<\frac{1}{e}\) on \((1,\infty)\backslash\{e\}\), we conclude that \(\frac{e\log a}{a}<1\) for \(a\) in \((1,\infty)\), except for \(a=e\). The number \(a=e\) is thus the only number in \((1,\infty)\) with the required property. Solution to 1.1.19:Let \(g(x)=e^{x}/x^{t}\) for \(x>0\). Since \(g(x)\rightarrow\infty\) as \(x\to 0\) and as \(x\rightarrow\infty\), there must be a minimum value in between. At the minimum,

\[g^{\prime}(x)=e^{x}x^{-t}(1-t/x)=0,\]

so the minimum must occur at \(x=t\), where

\[g(x)=g(t)=e^{t}/t^{t}=(e/t)^{t}.\]

Thus,

\[e^{x}\geq\left(\frac{xe}{t}\right)^{t}\]

and the right-hand side is strictly larger than \(x^{t}\) if and only if \(t<e\). Solution to 1.1.20:\(f\) can be written as its second degree Maclaurin polynomial [13, pag. 127] on this interval:

\[f(x)=f(0)+f^{\prime}(0)x+\frac{f^{\prime\prime}(0)}{2}x^{2}+\frac{f^{(3)}( \xi)}{6}x^{3}\]

where \(\xi\) is between \(0\) and \(x\). Letting \(x=\pm 1/n\) in this formula and combining the results, we get, for \(n\geq 1\),

\[n\left(f(1/n)-f(-1/n)\right)-2f^{\prime}(0) =n\left(\frac{2f^{\prime}(0)}{n}+\frac{f^{(3)}(\alpha_{n})}{6n^{3 }}+\frac{f^{(3)}(\beta_{n})}{6n^{3}}\right)-2f^{\prime}(0)\] \[=\frac{f^{(3)}(\alpha_{n})+f^{(3)}(\beta_{n})}{6n^{2}}\]

for some \(\alpha_{n},\beta_{n}\in[-1,1]\). As \(f^{\prime\prime\prime}\) is continuous, there is some \(M>0\) such that \(|f^{\prime\prime\prime}(x)|<M\) for all \(x\in[-1,1]\). Hence,

\[\left|\sum_{n=1}^{\infty}n\left(f(1/n)-f(-1/n)\right)-2f^{\prime}(0)\right| \leq\frac{M}{3}\sum_{n=1}^{\infty}\frac{1}{n^{2}}<\infty.\]

 Solution to 1.1.21:Using Taylor's Theorem [12, pag. 110],

\[f(x+h)-f(x)=f^{\prime}(x)h+\frac{f^{\prime\prime}(z)}{2}h^{2}\quad\text{for some}\quad z\in(x,x+h)\]

and similarly

\[f(x-h)-f(x)=-f^{\prime}(x)h+\frac{f^{\prime\prime}(w)}{2}h^{2}\quad\text{for some}\quad w\in(x-h,x)\,.\]

[MISSING_PAGE_EMPTY:149]

2. The integral inequality \[J =\int_{0}^{\pi/2}e^{-R\sin\theta}R\,d\theta\] \[\leq\int_{0}^{\pi/2}e^{-2R\theta/\pi}R\,d\theta\] \[=-\pi e^{-2R\theta/\pi}\Big{|}_{0}^{\pi/2}\] \[<\pi\] is called Jordan's Lemma [13, pag. 301]. Our limit is then \[\lim_{R\to\infty}R^{\lambda}\int_{0}^{\pi/2}e^{-R\sin\theta}\,d\theta =\lim_{R\to\infty}R^{\lambda-1}\int_{0}^{\pi/2}e^{-R\sin\theta}R \,d\theta\] \[<\lim_{R\to\infty}R^{\lambda-1}\pi=0.\] _Solution 2._ We have \[R^{\lambda}\int_{0}^{\frac{\pi}{2}}e^{-R\sin\theta}\,d\theta\eqqcolon R^{ \lambda}\int_{0}^{\frac{\pi}{3}}e^{-R\sin\theta}\,d\theta+R^{\lambda}\int_{ \frac{\pi}{3}}^{\frac{\pi}{2}}e^{-R\sin\theta}\,d\theta.\] As \(\cos\theta\geq 1/2\) for \(0\leq\theta\leq\pi/3\), and \(\sin\theta\) is an increasing function on \([0,\pi/2]\), we have \[R^{\lambda}\int_{0}^{\frac{\pi}{2}}e^{-R\sin\theta}\,d\theta \leq 2R^{\lambda}\int_{0}^{\frac{\pi}{3}}e^{-R\sin\theta}\cos \theta\,d\theta+R^{\lambda}\int_{\frac{\pi}{3}}^{\frac{\pi}{2}}e^{-R\sin(\pi/3 )}\,d\theta\] \[=2R^{\lambda-1}\left(1-e^{-R\sin(\pi/3)}\right)+\frac{R^{\lambda} \pi}{6}e^{-R\sin(\pi/3)}\] \[=o(1)\quad(R\to\infty)\]

**Solution to 1.1.24:** Let \(T=\mathbb{R}\setminus S\), \(T\) is dense in \(\mathbb{R}\) because each nonempty interval contains uncountably many numbers.

Fix \(p\in T\) and define \(F:\mathbb{R}\to\mathbb{R}\) by

\[F(x)=\int_{p}^{x}f(t)dt.\]

\(F\) vanishes on \(T\), so, as it is continuous, \(F\) vanishes on \(\mathbb{R}\). Therefore, we have \(F^{\prime}=f\equiv 0\).

**Solution to 1.1.25:**\(f^{\prime}(c)=0\) for some \(c\in(0,1)\), by Rolle's Theorem [13, pag. 200]. The concavity of \(f\) shows that \(f\) is increasing on \((0,c)\)and decreasing on \((c,1)\). The arc length of the graph of \(f\) on \([0,c]\) is

\[L_{(0,c)}=\int_{0}^{c}\sqrt{1+f^{\prime}(x)^{2}}\,dx=\lim_{n\to\infty}\frac{c}{n} \sum_{k=0}^{n-1}\sqrt{1+f^{\prime}(\xi_{k})^{2}}\]

where \(\xi_{k}\in(kc/n,(k+1)c/n)\). By the Mean Value Theorem [Rud87, pag. 108] we can assume the \(\xi_{k}\)'s satisfy

\[f^{\prime}(\xi_{k})=\frac{f\left((k+1)c/n\right)-f(kc/n)}{c/n}.\]

We get

\[L_{(0,c)} =\lim_{n\to\infty}\sum_{k=0}^{n-1}\sqrt{(c/n)^{2}+\left(f\left((k+ 1)c/n\right)-f(kc/n)\right)^{2}}\] \[\leq\lim_{n\to\infty}\sum_{k=0}^{n-1}(c/n)+\left(f\left((k+1)c/n \right)-f(kc/n)\right)\] \[=c+f(c)\]

since \(f\) is increasing. A similar reasoning shows that \(L_{(c,1)}\leq 1-c+f(c)\). So \(L_{[0,1]}\leq c+f(c)+1-c+f(c)\leq 3\).

**Solution to 1.1.26:** The convergence of \(\int_{1}^{\infty}|f^{\prime}(x)|dx\) implies the convergence of \(\int_{1}^{\infty}f^{\prime}(x)dx\), which implies that \(\lim_{x\to\infty}f(x)\) exists. If that limit is not \(0\), then \(\sum_{n=1}^{\infty}f(n)\) and \(\int_{1}^{\infty}f(x)dx\) both diverge. We may therefore, assume that \(\lim_{x\to\infty}f(x)=0\). Then \(\int_{\lfloor r\rfloor}^{r}f(x)dx\to 0\) as \(r\to\infty\) (where \(\lfloor r\rfloor\) is the greatest integer \(\leq r\)), implying that \(\int_{1}^{\infty}f(x)dx\) converges if and only if \(\lim_{n\to\infty}\int_{1}^{n}f(x)dx\) exists (where \(n\) here tends to \(\infty\) through integer values). In other words, the convergence of \(\int_{1}^{\infty}f(x)dx\) is equivalent to the convergence of \(\sum_{n=1}^{\infty}\int_{n}^{n+1}f(x)dx\). It will therefore, suffice to prove that \(\sum_{n=1}^{\infty}|\int_{n}^{n+1}f(x)dx-f(n)|<\infty\). We have

\[\left|\int_{n}^{n+1}f(x)dx-f(n)\right| =\left|\int_{n}^{n+1}(f(x)-f(n))dx\right|\] \[=\left|\int_{n}^{n+1}\int_{n}^{x}f^{\prime}(t)dtdx\right|\leq\int _{n}^{n+1}\int_{n}^{n+1}|f^{\prime}(t)|dtdx\] \[=\int_{n}^{n+1}|f^{\prime}(t)|dt\,.\]

Hence, \(\sum_{n=1}^{\infty}\left|\int_{n}^{n+1}f(x)dx-f(n)\right|\leq\int_{1}^{\infty }|f^{\prime}(t)|dt<\infty\), as desired.

**Solution to 1.1.27:** We have

\[|u(x)|=|u(x)-u(0)|\leq|x|\]\[|u^{2}(x)-u(x)|=|u(x)||u(x)-1|\leq|x|(|x|+1)\]

so

\[|\varphi(u)|\leq\int_{0}^{1}|u(x)^{2}-u(x)|\leq\int_{0}^{1}x(x+1)dx=\frac{5}{6}.\]

Equality can be achieved if \(|u(x)|=x\) and \(|u(x)-1|=x+1\). This is the case for \(u(x)=-x\) which is in \(E\).

**Solution to 1.1.29:** Let

\[u(t)=1+2\int_{0}^{t}f(s)ds\,.\]

We have

\[u^{\prime}(t)=1+2f(t)\leq 2\sqrt{u(t)}\,,\]

so

\[\sqrt{u(t)}-1=\int_{0}^{t}\frac{u^{\prime}(s)}{2\sqrt{u(s)}}\,ds\leq\int_{0}^{ t}ds=t;\]

therefore,

\[f(t)\leq\sqrt{u(t)}\leq 1+t\,.\]

**Solution to 1.1.30:** We will show \(b\) must be zero. By subtracting and multiplying by constants, we can assume \(a=0\leq b\). Given \(\varepsilon>0\), choose \(R\geq 1\) such that

\[|\varphi(x)|\leq\varepsilon\]

and

\[\varphi^{\prime}(x)\geq b/2\geq 0\]

for all \(x\geq R\). By the Fundamental Theorem of Calculus [10, pag. 209],

\[\varphi(x)=\varphi(R)+\int_{R}^{x}\varphi^{\prime}(x)dx,\]

so

\[2\varepsilon\geq\varphi(x)-\varphi(R)\geq\int_{R}^{x}\frac{b}{2}dx=(x-R)b/2.\]

For \(x=5R\), we get

\[b\leq\varepsilon/R\leq\varepsilon.\]

Since \(\varepsilon>0\) was arbitrary, we must have \(b=0\).

**Solution to 1.1.31:** Let \(0\leq k_{1}<k_{2}<1\), then for all \(x\in(0,\pi/2)\),

\[\begin{split}\frac{-k_{1}\cos^{2}x}{\sqrt{1-k_{1}\cos^{2}x}}& >-k_{2}\cos^{2}x\\ \frac{1}{\sqrt{1-k_{1}\cos^{2}x}}&>\sqrt{1-k_{2}\cos ^{2}x}\\ \frac{1}{\sqrt{1-k_{1}\cos^{2}x}}&<\frac{1}{\sqrt{1-k _{2}\cos^{2}x}}\\ \int_{0}^{\pi/2}\frac{1}{\sqrt{1-k_{1}\cos^{2}x}}&\;dx <\int_{0}^{\pi/2}\frac{1}{\sqrt{1-k_{2}\cos^{2}x}}\;dx\,.\end{split}\]

**Solution to 1.1.32:** With the change of variables \(y=x\sqrt{t}\), we have

\[f(t)=\int_{-\infty}^{\infty}e^{-tx^{2}}\;dx=\int_{-\infty}^{\infty}e^{-y^{2}}\; \frac{dy}{\sqrt{t}}=\frac{1}{\sqrt{t}}\int_{-\infty}^{\infty}e^{-y^{2}}\;dy= \sqrt{\frac{\pi}{t}},\]

so

\[f^{\prime}(t)=-\frac{\sqrt{\pi}}{2}t^{-3/2}.\]

**Solution to 1.1.33:** Let

\[G(u,v,x)=\int_{v}^{u}e^{t^{2}+xt}dt.\]

Then \(F(x)=G(\cos x,\sin x,x)\), so

\[\begin{split} F^{\prime}(x)&=\frac{\partial G}{ \partial u}\frac{\partial u}{\partial x}+\frac{\partial G}{\partial v}\frac{ \partial v}{\partial x}+\frac{\partial G}{\partial x}\\ &=e^{u^{2}+xu}(-\sin x)-e^{(v^{2}+xv)}\cos x+\int_{v}^{u}te^{t^{2} +xt}dt\end{split}\]

and

\[F^{\prime}(0)=-1+\int_{0}^{1}te^{t^{2}}dt=\frac{1}{2}(e-3).\]

**Solution to 1.1.34:** 1. Let \(f(z)\neq 0\). Then

\[f(x)f(z)=f\left(\sqrt{x^{2}+z^{2}}\right)=f(-x)f(z),\]

so \(f(x)=f(-x)\) and \(f\) is even.

Also, \(f(0)f(z)=f(z)\), so \(f(0)=1\).

2. We will show now that \(f(\sqrt{n}x)=\left(f(x)\right)^{n}\) for real \(x\) and natural \(n\), using the Induction Principle [10, pag. 7]. The result is clear for \(n=1\)Assume it holds for \(n=k\). We have \[f\left(\sqrt{k+1}x\right) =f\left(\sqrt{\left(\sqrt{k}x\right)^{2}+x^{2}}\right)\] \[=f\left(\sqrt{k}x\right)f(x)\] \[=\left(f(x)\right)^{k}f(x)\] \[=\left(f(x)\right)^{k+1}.\] If \(p,q\in\mathbb{N}\), then \[f(p)=f\left(p^{2}\cdot 1\right)=\left(f(1)\right)^{p^{2}}\] and \[f(|p|)=f\left(\sqrt{p^{2}}\left|\frac{p}{q}\right|\right)=\left(f\left(\left| \frac{p}{q}\right|\right)\right)^{q^{2}}\] from which follows \[\left(f\left(\frac{p}{q}\right)\right)^{q^{2}}=\left(f(1)\right)^{p^{2}}.\]
* If \(f(1)>0\), we have \[f\left(\frac{p}{q}\right)=\left(f(1)\right)^{\frac{p^{2}}{q^{2}}},\] so, by continuity on \(\mathbb{R}\), \[f(x)=\left(f(1)\right)^{x^{2}}\.\]
* If \(f(1)=0\), then \(f\) vanishes on a dense set, so it vanishes everywhere, contradicting the hypothesis.
* To see that \(f(1)<0\) cannot happen, consider \(p\) even and \(q\) odd. We get \(f(p/q)>0\), so \(f\) is positive on a dcnsc set, and \(f(1)\geq 0\). Note that we used only the continuity of \(f\) and its functional equation. Differentiating, we easily check that \(f\) satisfies the differential equation. The most general function satisfying all the conditions is then \[c^{x^{2}}\] with \(0<c<1\). _Solution 2._ 1. Let \(x=y=0\). Then \(f(0)^{2}=f(0)\), so \(f(0)=0\) or \(1\). If \(f(0)=0\), then \(0=f(\sqrt{x^{2}})\) for any \(x\), so, in fact, \(f(x)=0\) for all \(x>0\). If \(f(y)\neq 0\) for any \(y\), then \(f(x)f(y)=0\) implies \(f(x)=0\) for all \(x\), so \(f(x)=0\) for all \(x\) if \(f(0)=0\). Since we assume \(f\) is nonzero, we must have \(f(0)=1\). Then evaluating at \(y=0\) gives \(f(x)=f(\sqrt{x^{2}})=f(-x)\), so \(f\) is an even function.

2. Differentiate with respect to \(y\) to get

\[f(x)f^{\prime}(y)=f^{\prime}(r)r_{y}\]

where \(r=\sqrt{x^{2}+y^{2}}\) and \(r_{y}\) denotes the partial derivative of \(r\) with respect to \(y\). Differentiate again to get

\[f(x)f^{\prime\prime}(y)=f^{\prime\prime}(r)r_{y}^{2}+f^{\prime}(r)r_{yy}\.\]

Since \(r_{y}=y/r\) and \(r_{yy}=x^{2}/r^{3}\), we get

\[f^{\prime}(x)=f^{\prime\prime}(0)xf(x)\]

for \(y=0\). The solution of this differential equation is

\[f(x)=e^{f^{\prime\prime}(0)x^{2}/2}\]

and since \(f\) vanishes at infinity, we must have \(f^{\prime\prime}(0)/2=-\gamma<0\). Thus, \(f(x)=e^{-\gamma x^{2}}\) for some positive constant \(\gamma\).

### 1.2 Limits and Continuity

**Solution to 1.2.1:** Consider \(f(x)=\sin x\). The Mean Value Theorem [13, pag. 108] implies that

\[f(x)-f(y)=f^{\prime}(\xi)(x-y)=(\cos\xi)(x-y)\quad\text{for some }\xi\in(0,1),\]

and since \(|\cos\xi|<1\), this implies

\[|f(x)-f(y)|<|x-y|\qquad\text{whenever }x\neq y.\]

However, if \(M<1\) were such that

\[|f(x)-f(y)|<M|x-y|\qquad\text{for all }x,y\in I,\]

then, putting \(x=0\) and letting \(y\to 0\), we would get \(|f^{\prime}(0)|\leq M<1\), which contradicts the fact that \(f^{\prime}(0)=1\).

**Solution to 1.2.2:** Suppose \(f\) is not continuous at \(\xi\in[0,1]\). Then, for some \(\varepsilon>0\), there is a sequence \((x_{n})\) converging to \(\xi\) with \(|f(x_{n})-f(\xi)|>\varepsilon\) for all \(n\). By the first condition, there is a sequence \((y_{n})\) such that \(y_{n}\) lies between \(\xi\) and \(x_{n}\) and \(|f(y_{n})-f(\xi)|=\varepsilon\). Then

\[y_{n}\in f^{-1}\left(f(\xi)+\varepsilon\right)\cup f^{-1}\left(f(\xi)- \varepsilon\right)\qquad\xi\notin f^{-1}\left(f(\xi)+\varepsilon\right)\cup f ^{-1}\left(f(\xi)-\varepsilon\right),\]which contradicts the second condition.

**Solution to 1.2.3:** 1. Let \(f_{1}\) be the restriction of \(f\) to \([0,2]\). The ranges of \(f\) and \(f_{1}\) are the same, by periodicity, so \(f\) attains its extrema.

2. Let \(\delta>0\). \(f_{1}\) is uniformly continuous, being a continuous function defined on a compact set, so there is \(\varepsilon>0\) such that

\[|f_{1}(a)-f_{1}(b)|<\delta\quad\text{for}\quad a,b\in[0,2],\,|a-b|<\varepsilon.\]

Let \(x,y\in\mathbb{R}\) with \(|x-y|<\varepsilon\). Then, there are \(x_{1}\), \(x_{2}=x_{1}+1\), \(y_{1}\), \(y_{2}=y_{1}+1\in[0,2]\) with \(f(x_{1})=f(x_{2})=f(x)\), \(f(y_{1})=f(y_{2})=f(y)\), and \(|x_{i}-y_{i}|<\varepsilon\) for some choice of \(i,j\in\{1,2\}\), and the conclusion follows.

3. Let \(f\) attain its maximum and minimum at \(\xi_{1}\) and \(\xi_{2}\), respectively. Then

\[f(\xi_{1}+\pi)-f(\xi_{1})\leq 0\qquad\text{and}\qquad f(\xi_{2}+\pi)-f(\xi_{2}) \geq 0;\]

as \(f\) is continuous, the conclusion follows from the Intermediate Value Theorem [Rud87, pag. 93].

**Solution to 1.2.4:** Let \((x_{n})\) be a sequence of numbers in \([0,1)\) converging to zero. As \(h\) is uniformly continuous, given \(\delta>0\) we can find \(\varepsilon>0\) such that \(|h(x)-h(y)|<\delta\) if \(|x-y|<\varepsilon\); therefore, we have

\[|h(x_{n})-h(x_{m})|<\delta\]

for \(n\) and \(m\) large enough. (\(f(x_{n})\)) is a Cauchy sequence then, so it converges, to \(\xi\), say. If \((y_{n})\) is another sequence with limit zero, a similar argument applied to \(f(x_{1}),f(y_{1}),\ldots\) shows that \(\lim f(y_{n})=\xi\). The function \(g:[0,1]\to\mathbb{R}\) given by

\[g(x)=\left\{\begin{array}{ccc}h(x)&\text{for}&x\in[0,1)\\ \xi&\text{for}&x=0\end{array}\right.\]

is clearly the unique extension of \(h\) to \([0,1]\).

**Solution to 1.2.5:** Let \(E\) be the set of discontinuities of \(f\). We have \(E=E_{1}\cup E_{2}\cup E_{3}\cup E_{4}\), where

\[E_{1}=\left\{x\in E\,|\,f(x-)=f(x+)<f(x)\right\},\quad E_{2}=\left\{x\in E\,| \,f(x-)>f(x+)\right\}\]

\[E_{3}=\left\{x\in E\,|\,f(x-)=f(x+)>f(x)\right\},\quad E_{4}=\left\{x\in E\,| \,f(x-)<f(x+)\right\}.\]

For \(x\in E_{1}\), let \(a_{x}\in\mathbb{Q}\,\) be such that \(f(x-)<a_{x}<f(x+)\). Now take \(b_{x},c_{x}\in\mathbb{Q}\,\) in such a way that \(b_{x}<x<c_{x}\) and

\[b_{x}<t<c_{x}\,,\,x\neq t\quad\text{implies}\quad f(t)<a_{x}.\]

This map \(\varphi:E_{1}\to\mathbb{Q}\,^{3}\) given by \(x\mapsto(a_{x},b_{x},c_{x})\) is injective since \((a_{x},b_{x},c_{x})=(a_{y},b_{y},c_{y})\) implies \(f(y)<a_{x}<f(y)\) for \(x\neq y\). So \(E_{1}\) is, at most, countable.

For \(x\in E_{2}\), take \(a_{x}\in\mathbb{Q}\) with \(f(x-)>a_{x}>f(x+)\) and choose \(b_{x},c_{x}\in\mathbb{Q}\) such that \(b_{x}<x<c_{x}\) and

\[b_{x}<t<x\quad\text{implies}\quad f(t)>a_{x}\]

and

\[t<c_{x}\quad\text{implies}\quad f(t)<a_{x};\]

this map is an injection \(E_{2}\to\mathbb{Q}^{3}\), so \(E_{2}\) is, at most, countable.

Similar methods lead to analogous results for \(E_{3}\) and \(E_{4}\). As the union of countable sets is countable, the result follows.

_Solution 2._ Define the function \(\sigma:\mathbb{R}\to\mathbb{R}\) by

\[\sigma(x)=\max\{\left|f(x)-f(x+)\right|,\left|f(x)-f(x-)\right|\};\]

observe that \(\sigma(x)>0\) if and only if \(x\) is a discontinuity of \(f\).

For each \(n\in\mathbb{N}\), let the set \(D_{n}\) be given by

\[D_{n}=\{x\in\mathbb{R}\left|\,\sigma(x)\geq 1/n\right.\}.\]

It is clear that the set of discontinuities of \(f\) is \(D=\bigcup_{n=1}^{\infty}D_{n}\). We shall prove that each \(D_{n}\) has no accumulation points, so, it is countable. If \(a\in D_{n}\), using the fact that \(f(a+)=\lim_{x\to a+}f(x)\), we can find \(\delta>0\) such that, for all \(x\), \(a<x<a+\delta\), we have

\[f(a+)-\frac{1}{4n}<f(x)<f(a+)+\frac{1}{4n},\]

that is, for every point in this interval, \(\sigma(x)\leq 1/2n\). In the same fashion, we can find an open set \(a-\delta<x<a\) such that no point is in \(D_{n}\), showing that \(D_{n}\) is made up of isolated points so it is countable, and so is \(D\).

**Solution to 1.2.6:** By Problem 1.2.5, it is enough to show that \(f\) has lateral limits at all points. We have, for any \(x\in\mathbb{R}\),

\[-\infty<\sup_{y<x}\{f(y)\}=f(x-)\leq f(x+)=\inf_{y<x}\{f(y)\}<\infty\]

since \(f\) is an increasing function.

**Solution to 1.2.7:** Fix \(\varepsilon>0\). For each \(x\in[0,1]\), let \(\delta_{x}\) be as in the hypothesis and \(I_{x}=(x-\delta_{x},x+\delta_{x})\). The open intervals \(\{I_{x}\}\) cover \([0,1]\) so, by compactness and the Heine-Borel Theorem [13, pag. 30], we can choose a finite subcover

\[[0,1]\subset I_{x_{1}}\cup I_{x_{2}}\cup\dots\cup I_{x_{n}}\,.\]

Let \(M=\max\{f(x_{i})+\varepsilon\}\). If \(x\in[0,1]\) then \(f(x)<M\) and \(f\) is bounded from above.

Let \(N\) be the least upper bound of \(f\) on \([0,1]\). Then there is a sequence of points \((x_{n})\) such that \((f(x_{n}))\) tends to \(N\) from below. Since \([0,1]\) is compact, by the Bolzano-Weierstrass Theorem [13, pag. 40], [14, pag. 153], \((x_{n})\) has a convergent subsequence, so (by passing to a subsequence) we may assume that \((x_{n})\) converges to some \(p\in[0,1]\). By the upper semicontinuity of \(f\) and the convergence of \((f(x_{n}))\), we have, for \(n\) sufficiently large, \(f(x_{n})<f(p)+\varepsilon\) and \(N<f(x_{n})+\varepsilon\). Combining these, we get \(f(p)\leq N<f(p)+2\varepsilon\). Since this holds for all \(\varepsilon>0\), \(f(p)=N\).

**Solution to 1.2.8:** Suppose \(f:\mathbb{R}\to\mathbb{R}\) is continuous, maps open sets to open sets but is not monotonic. Without loss of generality assume there are three real numbers \(a<b<c\) such that \(f(a)<f(b)>f(c)\). By Weierstrass Theorem [14, pag. 189], \(f\) has a maximum, \(M\), in \([a,c]\), which cannot occur at \(a\) or \(b\). Then \(f((a,c))\) cannot be open, since it contains \(M\) but does not contain \(M+\varepsilon\) for any positive \(\varepsilon\). We conclude then that \(f\) must be monotonic.

**Solution to 1.2.9:** The inequality given implies that \(f\) is one-to-one, so \(f\) is strictly monotone and maps open intervals onto open intervals, so \(f(\mathbb{R})\) is open.

Let \(z_{n}=f(x_{n})\) be a sequence in \(f(\mathbb{R})\) converging to \(z\in\mathbb{R}\). Then \(z_{n}\) is Cauchy, and, by the stated inequality, so is \(x_{n}\). Let \(x=\lim x_{n}\). By continuity we have \(f(x)=f(\lim x_{n})=\lim f(x_{n})=z\) so \(f(\mathbb{R})\) is also closed. Thus, \(f(\mathbb{R})=\mathbb{R}\).

**Solution to 1.2.10:**\(1\). For \(\varepsilon>0\) let

\[L=\max_{x\in[0,1]}(|f(x)|+1)\quad\text{and}\quad 0<\delta<\min\left\{\frac{ \varepsilon}{2L},1\right\}.\]

We have

\[\left|\int_{1-\delta}^{1}x^{n}f(x)dx\right|\leq\int_{1-\delta}^{1}x^{n}|f(x)| dx\leq L\delta\leq\frac{\varepsilon}{2}\]

and

\[\left|\int_{0}^{1-\delta}x^{n}f(x)dx\right|\leq\int_{0}^{1-\delta}(1-\delta)^{ n}|f(x)|dx\leq L\delta^{n+1},\]

so

\[\lim_{n\to\infty}\int_{0}^{1}x^{n}f(x)dx=0.\]

2. We will show that

\[\lim_{n\to\infty}n\int_{0}^{1}x^{n}(f(x)-f(1))dx=0.\]

For \(\varepsilon>0\) let \(\delta\) be such that \(|f(x)-f(1)|<\varepsilon/2\) if \(x\in[1-\delta,1]\). We have

\[\left|n\int_{1-\delta}^{n}x^{n}(f(x)-f(1))dx\right|\leq n\int_{1-\delta}^{1}x ^{n}|f(x)-f(1)|dx\leq n\int_{1-\delta}^{1}x^{n}\frac{\varepsilon}{2}dx\leq \frac{\varepsilon}{2},\]and, letting \(L=\sup_{x\in[0,1]}|f(x)-f(1)|\),

\[\left|n\int_{0}^{1-\delta}x^{n}(f(x)-f(1))dx\right|\leq n\int_{0}^{1-\delta}x^{n} Ldx=n\frac{(1-\delta)^{n+1}}{n+1}\]

and the result follows.

Now it suffices to notice that

\[n\int_{0}^{1}x^{n}f(x)dx=n\int_{0}^{1}x^{n}(f(x)-f(1))dx+n\int_{0}^{1}f(1)x^{n} dx.\]

**Solution to 1.2.11:** Suppose that \(f\) is not continuous. Then there exist \(\varepsilon>0\), \(x\in[0,1]\), and a sequence \((x_{n})\) tending to \(x\) such that \(|f(x)-f(x_{n})|\geq\varepsilon\) for all \(n\). Consider the sequence \(((x_{n},f(x_{n})))\) in \(G_{f}\). Since the unit square is compact, by Bolzano-Weierstrass Theorem [Rud87, pag. 40], [MH93, pag. 153], this sequence has a convergent subsequence; using this subsequence, we may assume that \(((x_{n},f(x_{n})))\) converges to some point \((y,z)\). Then we must have the sequence \((x_{n})\) converging to \(y\); so, by the uniqueness of limits, \(x=y\). Since \(G_{f}\) is closed, we must have \(z=f(x)\). Hence, \((f(x_{n}))\) converges to \(f(x)\), contradicting our assumption.

**Solution to 1.2.12:** For each \(y\in[0,1]\), consider the function \(g_{y}(x)=f(x,y)\). Then \(g(x)=\sup g_{y}(x)\). The family \(\{g_{y}\}\) is equicontinuous because \(f\) is uniformly continuous. It suffices then to show that the pointwise supremum of an equicontinuous family of functions is continuous. Let \(\varepsilon>0\), \(x_{0}\in[0,1]\). There is \(y_{0}\) such that

\[g_{y_{0}}(x_{0})\leq g(x_{0})<g_{y_{0}}(x_{0})+\varepsilon.\]

Let \(\delta\) be such that if \(|r-s|<\delta\), then \(|g_{y}(r)-g_{y}(s)|<\varepsilon\) for all \(y\), and \(|x_{0}-x_{1}|<\delta\). For some \(y_{1}\), we have that

\[g_{y_{1}}(x_{1})\leq g(x_{1})<g_{y_{1}}(x_{1})+\varepsilon.\]

Further, by equicontinuity of \(\{g_{y}\}\), we have the two inequalities \(|g_{y_{0}}(x_{0})-g_{y_{0}}(x_{1})|<\varepsilon\) and \(|g_{y_{1}}(x_{0})-g_{y_{1}}(x_{1})|<\varepsilon\). By combining them we get

\[g_{y_{0}}(x_{0})<g_{y_{0}}(x_{1})+\varepsilon<g(x_{1})+\varepsilon<g_{y_{1}}( x_{1})+2\varepsilon\]

and

\[g_{y_{1}}(x_{1})<g_{y_{1}}(x_{0})+\varepsilon<g(x_{0})+\varepsilon<g_{y_{0}}( x_{0})+2\varepsilon.\]

These two inequalities imply \(|g_{y_{1}}(x_{1})-g_{y_{0}}(x_{0})|<2\varepsilon\). This, combined with the first two inequalities, shows that \(|g(x_{0})-g(x_{1})|<3\varepsilon\). Since this holds for all \(\varepsilon\) and \(x_{0}\) and all \(x_{1}\) close to \(x_{0}\), \(g\) is continuous.

### 1.3 Sequences, Series, and Products

**Solution to 1.3.1:**\(A_{1}^{n}\leq A_{1}^{n}+\cdots+A_{k}^{n}\leq kA_{1}^{n}\), so we have

\[A_{1}=\lim_{n\to\infty}\left(A_{1}^{n}\right)^{1/n}\leq\lim_{n\to\infty}\left(A _{1}^{n}+\cdots+A_{k}^{n}\right)^{1/n}\leq\lim_{n\to\infty}\left(kA_{1}^{n} \right)^{1/n}=A_{1}.\]

showing that the limit equals \(A_{1}\).

**Solution to 1.3.2:** Let \(p_{1}=1\), \(p_{2}=(2/1)^{2}\), \(p_{3}=(3/2)^{3}\), \(\ldots\), \(p_{n}=(n/(n-1))^{n}\). Then

\[\frac{p_{1}p_{2}\cdots p_{n}}{n}=\frac{n^{n}}{n!},\]

and since \(p_{n}\to e\), we have \(\lim(n^{n}/n!)^{1/n}=e\) as well (using the fact that \(\lim n^{1/n}=1\)).

_Solution 2._ As the exponential is a continuous function, \(L=\exp(\lim_{n\to\infty}L_{n})\) where

\[L_{n}=\log n-\frac{1}{n}(\log 1+\log 2+\cdots+\log n).\]

Since

\[\log 1+\log 2+\cdots+\log(n-1)\leq\int_{1}^{n}\log x\,d\!x=n\log n-n+1,\]

we have

\[L_{n}\geq(1-1/n)\log n-\log n+1-1/n=1-(1+\log n)/n\to 1\quad\mbox{as}\quad n\to\infty.\]

On the other hand,

\[\log 1+\log 2+\cdots+\log n\geq\int_{1}^{n}\log xdx=n\log n-n+1,\]

so

\[L_{n}\leq\log n-(n\log n-n+1)/n=1-1/n.\]

Hence,

\[1-(1+\log n)/n\leq L_{n}\leq 1-1/n,\]

so \(L_{n}\to 1\) and \(L=\exp(1)=e\).

**Solution to 1.3.3:** Obviously, \(x_{n}\geq 1\) for all \(n\); so, if the limit exists, it is \(\geq 1\), and we can pass to the limit in the recurrence relation to get

\[x_{\infty}=\frac{3+2x_{\infty}}{3+x_{\infty}};\]

in other words, \(x_{\infty}^{2}+x_{\infty}-3=0\). So \(x_{\infty}\) is the positive solution of this quadratic equation, that is, \(x_{\infty}=\frac{1}{2}(-1+\sqrt{13}\,)\).

To prove that the limit exists, we use the recurrence relation to get

\[x_{n+1}-x_{n} = \frac{3+2x_{n}}{3+x_{n}}-\frac{3+2x_{n-1}}{3+x_{n-1}}\] \[= \frac{3(x_{n}-x_{n-1})}{(3+x_{n})(3+x_{n+1})}.\]

Hence, \(|x_{n+1}-x_{n}|\leq\frac{1}{3}|x_{n}-x_{n-1}|\). Iteration gives

\[|x_{n+1}-x_{n}|\leq 3^{-n}|x_{1}-x_{0}|=\frac{1}{3^{n}\cdot 4}.\]

The series \(\sum_{n=1}^{\infty}(x_{n+1}-x_{n})\), of positive terms, is dominated by the convergent series \(\frac{1}{4}\sum_{n=1}^{\infty}3^{-n}\) and so converges. We have \(\sum_{n=1}^{\infty}(x_{n+1}-x_{n})=\lim_{n\to\infty}x_{n}-x_{1}\) and we are done.

_Solution 2._ To prove the existence of the limit it is enough to notice that if \(g\) is defined by

\[g(x)=\frac{3+2x}{3+x}\]

we have

\[|g^{\prime}(x)|\leq\frac{3}{16}\leq 1\quad\text{for}\quad x\geq 1\]

and apply the Fixed Point Theorem [23, pag. 220].

**Solution to 1.3.5:** By the given relation \(x_{n}-x_{n-1}=(\alpha-1)(x_{n}-x_{n-1})\). Therefore, by the Induction Principle [24, pag. 7], we have \(x_{n}-x_{n-1}=(\alpha-1)^{n-1}(x_{1}-x_{0})\). Hence,

\[x_{n}-x_{0}=\sum_{k=1}^{n}(x_{k}-x_{k-1})=(x_{1}-x_{0})\sum_{k=1}^{n}(\alpha-1) ^{k-1}.\]

Taking limits, we get

\[\lim_{n\to\infty}x_{n}=\frac{(1-\alpha)x_{0}+x_{1}}{2-\alpha}\.\]

_Solution 2._ The recurrence relation can be expressed in matrix form as

\[\left(\begin{array}{c}x_{n+1}\\ x_{n}\end{array}\right)=A\left(\begin{array}{c}x_{n}\\ x_{n-1}\end{array}\right),\quad\text{where}\quad\Lambda=\left(\begin{array}{ cc}\alpha&1\!-\!\alpha\\ 1&0\end{array}\right).\]

Thus,

\[\left(\begin{array}{c}x_{n+1}\\ x_{n}\end{array}\right)=A^{n}\left(\begin{array}{c}x_{1}\\ x_{0}\end{array}\right).\]

A calculation shows that the eigenvalues of \(A\) are \(1\) and \(\alpha-1\), with corresponding eigenvectors \(v_{1}=(1,1)^{t}\) and \(v_{2}=(\alpha-1,1)^{t}\). A further calculation shows that

\[\left(\begin{array}{c}x_{1}\\ x_{0}\end{array}\right)=\left(\frac{(1-\alpha)x_{0}+x_{1}}{2-\alpha}\right)v_{1 }+\left(\frac{x_{0}-x_{1}}{2-\alpha}\right)v_{2}\.\]Hence,

\[\left(\begin{array}{c}x_{n+1}\\ x_{n}\end{array}\right)=A^{n}\left(\begin{array}{c}x_{1}\\ x_{0}\end{array}\right)=\frac{(1-\alpha)x_{0}+x_{1}}{2-\alpha}v_{1}+(\alpha-1)^ {n}\frac{x_{0}-x_{1}}{2-\alpha}v_{2}\.\]

Since \(|\alpha-1|<1\) we have \(\lim_{n\to\infty}(\alpha-1)^{n}=0\), and we can conclude that

\[\lim_{n\to\infty}x_{n}=\frac{(1-\alpha)x_{0}+x_{1}}{2-\alpha}\.\]

**Solution to 1.3.6:** The given relation can be written in matrix form as \(\left(\begin{smallmatrix}x_{n+1}\\ x_{n}\end{smallmatrix}\right)=A\binom{x_{n-1}}{x_{n}}\), where \(A=\left(\begin{smallmatrix}2c&-1\\ 1&0\end{smallmatrix}\right)\). The required periodicity holds if and only if \(A^{k}=\left(\begin{smallmatrix}1&0\\ 0&1\end{smallmatrix}\right)\). The characteristic polynomial of \(A\) is \(\lambda^{2}-2\lambda+1\), so the eigenvalues of \(A\) are \(c\pm\sqrt{c^{2}-1}\). A necessary condition for \(A^{k}=\left(\begin{smallmatrix}1&0\\ 0&1\end{smallmatrix}\right)\) is that the eigenvalues of \(A\) be \(k^{th}\) roots of unity, which implies that \(c=\cos\left(\frac{2\pi j}{k}\right)\), \(j=0,1,\ldots,\left[\frac{k}{k}\right]\). If \(c\) has the preceding form and \(0<j<\frac{k}{2}\) (i.e., \(-1<c<1\)), then the eigenvalues of \(A\) are distinct (i.e., \(A\) is diagonalizable), and the equality \(A^{k}=\left(\begin{smallmatrix}1&0\\ 0&1\end{smallmatrix}\right)\) holds. If \(c=1\) or \(-1\), then the eigenvalues of \(A\) are not distinct, and \(A\) has the Jordan Canonical Form [14, pag. 247]\(\left(\begin{smallmatrix}1&1\\ 0&1\end{smallmatrix}\right)\) or \(\left(\begin{smallmatrix}-1&1\\ 0&-1\end{smallmatrix}\right)\), respectively, in which case \(A^{k}\neq\left(\begin{smallmatrix}1&0\\ 0&1\end{smallmatrix}\right)\). Hence, the desired periodicity holds if and only if \(c=\cos\left(\frac{2\pi j}{k}\right)\), where \(j\) is an integer, and \(0<j<k/2\).

**Solution to 1.3.7:** If \(\lim x_{n}=x\in\mathbb{R}\), we have \(x=a+x^{2}\); so

\[x=\frac{1\pm\sqrt{1-4a}}{2}\]

and we must have \(a\leq 1/4\).

Conversely, assume \(0<a\leq 1/4\). As \(x_{n+1}-x_{n}=x_{n}^{2}-x_{n-1}^{2}\), we conclude, by the Induction Principle [13, pag. 7], that the given sequence is nondecreasing. Also,

\[x_{n+1}=a+x_{n}^{2}<\frac{1}{4}+\frac{1}{4}=\frac{1}{2}\]

if \(x_{n}<1/2\), which shows that the sequence is bounded. It follows that the sequence converges when \(0<a\leq 1/4\).

**Solution to 1.3.8:** Clearly, \(0\leq x_{n+1}=x_{n}(1\ \mbox{--}\ x_{n}^{n})\leq x_{n}\leq\cdots\leq x_{1}\) for all \(n\). Thus,

\[x_{n+1}=x_{n}(1-x_{n}^{n})\geq x_{n}(1-x_{1}^{n})\,\]

and therefore

\[x_{n}\geq x_{1}\prod_{1}^{n}(1-x_{1}^{k})=x_{1}\exp\left(\sum_{k=1}^{n}\log(1- x_{1}^{k})\right)\.\]Since \(\log(1-x_{1}^{k})=O(x_{1}^{k})\) as \(k\to\infty\), the sum converges to a finite value \(L\) as \(n\to\infty\) and we get

\[\liminf_{n\to\infty}x_{n}\geq x_{1}\exp(L)>0\.\]

**Solution to 1.3.9:** 1. We have

\[f(x)=\frac{1}{2}-\left(x-\frac{1}{2}\right)^{2}\]

so \(x_{n}\) is bounded by \(1/2\) and, by the Induction Principle [13, pag. 7], nondecreasing. Let \(\lambda\) be its limit. Then

\[\lambda=\frac{1}{2}-\left(\lambda-\frac{1}{2}\right)^{2}\]

and, as the sequence takes only positive values,

\[\lambda=\frac{1}{2}.\]

2. It is clear, from the expression for \(f\) above, that

\[f(x)\leq x\quad\text{for}\quad x\leq-\frac{1}{2}\]

and

\[f(x)\leq-\frac{1}{2}\quad\text{for}\quad x\geq\frac{3}{2}\]

therefore, the sequence diverges for such initial values.

On the other hand, if \(|x-1/2|<1\), we get

\[\left|f(x)-\frac{1}{2}\right|<\left|x-\frac{1}{2}\right|\]

so, for these initial values, we get

\[\left|x_{n+1}-\frac{1}{2}\right|<\left|x-\frac{1}{2}\right|^{n}=o(1).\]

**Solution to 1.3.10:** Suppose that \(\lim f_{n+1}/f_{n}=a<\infty\). \(a\geq 1\) since the the sequence \(f_{n}\) is increasing. We have

\[\frac{f_{n+1}}{f_{n}}=1+\frac{f_{n-1}}{f_{n}}.\]

Taking the limit as \(n\) tends to infinity, we get (since \(a\neq 0\))\[a=1+\frac{1}{a}\]

or

\[a^{2}-a-1=0.\]

This quadratic equation has one positive root,

\[\varphi=\frac{1+\sqrt{5}}{2}.\]

We show now that the sequence \((f_{n+1}/f_{n})\) is a Cauchy sequence. Applying the definition of the \(f_{n}\)'s, we get

\[\left|\frac{f_{n+1}}{f_{n}}-\frac{f_{n}}{f_{n-1}}\right|=\left|\frac{f_{n-1}^{ 2}-f_{n}f_{n-2}}{f_{n-1}^{2}+f_{n-1}f_{n-2}}\right|.\]

Since \(f_{n}\) is an increasing sequence,

\[f_{n-1}(f_{n-1}-f_{n-2})\geq 0\]

or

\[f_{n-1}^{2}+f_{n-1}f_{n-2}\geq 2f_{n-1}f_{n-2}.\]

By substituting this in and simplifying, we get

\[\left|\frac{f_{n+1}}{f_{n}}-\frac{f_{n}}{f_{n-1}}\right|\leq\frac{1}{2}\left| \frac{f_{n}}{f_{n-1}}-\frac{f_{n-1}}{f_{n-2}}\right|.\]

By the Induction Principle [13, pag. 7], we get

\[\left|\frac{f_{n+1}}{f_{n}}-\frac{f_{n}}{f_{n-1}}\right|\leq\frac{1}{2^{n-2}} \left|\frac{f_{3}}{f_{2}}-\frac{f_{2}}{f_{1}}\right|.\]

Therefore, by the Triangle Inequality [13, pag. 20], for all \(m>n\),

\[\left|\frac{f_{m+1}}{f_{m}}-\frac{f_{n+1}}{f_{n}}\right|\leq\left|\frac{f_{3}}{ f_{2}}-\frac{f_{2}}{f_{1}}\right|\sum_{k=n}^{m-1}\frac{1}{2^{k-2}}.\]

Since the series \(\sum 2^{-n}\) converges, the right-hand side tends to \(0\) as \(m\) and \(n\) tend to infinity. Hence, the sequence \((f_{n+1}/f_{n})\) is a Cauchy sequence, and we are done.

**Solution to 1.3.11:** We have

\[\frac{1}{n+1}+\cdots+\frac{1}{2n}=\sum_{k=1}^{n}\frac{1}{1+\frac{k}{n}}\cdot \frac{1}{n}\]which is a Riemann sum for \(\int_{0}^{1}(1+x)^{-1}dx\) corresponding to the partition of the interval \([0,1]\) in \(n\) subintervals of equal length. Therefore, we get

\[\lim_{n\to\infty}\left(\frac{1}{n+1}+\cdots+\frac{1}{2n}\right)=\int_{0}^{1} \frac{1}{1+x}dx=\log 2.\]

_Solution 2._ Using the inequalities

\[\left(1+\frac{1}{k}\right)^{k}<e<\left(1+\frac{1}{k-1}\right)^{k}\qquad(k\geq 2),\]

we get

\[\log 2 =\log\left(\prod_{k=n+1}^{2n}\frac{k}{k-1}\right)=\sum_{k=n+1}^{2 n}\frac{1}{k}\log\left(\frac{k}{k-1}\right)^{k}\] \[>\sum_{k=n+1}^{2n}\frac{1}{k}>\sum_{k=n+1}^{2n}\frac{1}{k}\log \left(\frac{k+1}{k}\right)^{k}=\log\left(\prod_{k=n+1}^{2n}\frac{k+1}{k}\right)\] \[=\log\left(\frac{2n+1}{n+1}\right);\]

therefore, we have

\[\log 2\geq\lim_{n\to\infty}\sum_{k=n+1}^{2n}\frac{1}{k}\geq\log 2\]

and the result follows.

_Solution 3._ We have

\[\frac{1}{n+1}+\cdots+\frac{1}{2n} =1+\frac{1}{2}+\cdots+\frac{1}{2n}-\left(1+\frac{1}{2}+\cdots+ \frac{1}{n}\right)\] \[=1+\frac{1}{2}+\cdots+\frac{1}{2n}-2\left(\frac{1}{2}+\cdots+ \frac{1}{2n}\right)\] \[=1-\frac{1}{2}+\cdots+\frac{1}{2n-1}-\frac{1}{2n}\]

and the result now follows from the Maclaurin expansion [13, pag. 127] of \(\log(1+x)\).

**Solution to 1.3.12:** Let \(n>0\). For \(m\geq n\), we have

\[x_{m}\leq x_{n}+\sum_{k=n}^{m-1}\frac{1}{k^{2}}\leq x_{n}+\xi_{n}\]where

\[\xi_{n}=\sum_{k=n}^{\infty}\frac{1}{k^{2}}.\]

Taking the \(\limsup\), with respect to \(m\), we have

\[x_{n}\geq\limsup_{m\to\infty}x_{m}-\xi_{n}.\]

The series \(\sum k^{-2}\) converges, so \(\lim_{n\to\infty}\xi_{n}=0\). Considering the \(\liminf\) with respect to \(n\), we get

\[\liminf_{n\to\infty}x_{n}\geq\limsup_{m\to\infty}x_{m}-\liminf_{n\to\infty}\xi_ {n}\geq\limsup_{m\to\infty}x_{m}.\]

The reverse inequality also holds, so \(\lim x_{n}\) exists.

**Solution to 1.3.13:** Fix \(\delta>0\), and choose \(n_{0}\) such that \(\varepsilon_{n}<\delta\) for all \(n\geq n_{0}\). Then

\[a_{n_{0}+1} \leq ka_{n_{0}}+\varepsilon_{n_{0}}<ka_{n_{0}}+\delta\] \[a_{n_{0}+2} <k^{2}a_{n_{0}}+k\delta+\varepsilon_{n_{0}+1}<k^{2}a_{n_{0}}+(1+ k)\delta\] \[a_{n_{0}+3} <k^{3}a_{n_{0}}+(k+k^{2})\delta+\varepsilon_{n_{0}+2}<k^{3}a_{n_ {0}}+(1+k+k^{2})\delta\]

and, by the Induction Principle [10, pag. 7],

\[a_{n_{0}+m}<k^{m}a_{n_{0}}+(1+k+\cdots+k^{m-1})\delta<k^{m}a_{n_{0}}+\frac{ \delta}{1-k}.\]

Letting \(m\to\infty\), we find that

\[\limsup_{n\to\infty}a_{n}\leq\frac{\delta}{1-k}.\]

Since \(\delta\) is arbitrary, we have \(\limsup_{n\to\infty}a_{n}\leq 0\), and thus (since \(a_{n}>0\) for all \(n\)) \(\lim_{n\to\infty}a_{n}=0\).

**Solution to 1.3.14:** If \((x_{n})\) is unbounded, then, without loss of generality, it has no finite upper bound. Take \(x_{n_{1}}=x_{1}\) and, for each \(k\in\mathbb{N}\), \(x_{n_{k}}\) such that \(x_{n_{k}}>\max\{k,x_{n_{k-1}}\}\). This is clearly an increasing subsequence of \(x_{n}\).

If \(x_{n}\) is bounded, it has a convergent subsequence: \(\lim y_{n}=\xi\), say. \(y_{n}\) contains a subsequence converging to \(\xi+\) or one converging to \(\xi-\). Suppose \((z_{n})\) is a subsequence of \((y_{n})\) converging to \(\xi+\). Let \(z_{n_{1}}=z_{1}\) and, for \(k\geq 1\), let \(\xi\leq z_{n_{k}}<z_{n_{k-1}}\). This is a monotone subsequence of \((x_{n})\).

**Solution to 1.3.15:** Suppose that there are \(x>1\), \(\varepsilon>0\) such that \(|b_{m}/b_{n}-x|\geq\varepsilon\) for all \(1\leq n<m\). Since \(\lim(b_{n}/b_{n+1})=1\), for all \(k\) sufficiently large there exists an integer \(n_{k}>k\) such that \(b_{m}/b_{k}<x\) if \(m<n_{k}\) and \(b_{m}/b_{k}>x\) if \(m>n_{k}\). In particular, for each \(k\),\[\frac{b_{n_{k}+1}}{b_{k}}-\frac{b_{n_{k}}}{b_{k}}\geq 2\varepsilon\]

or

\[\frac{b_{n_{k}+1}}{b_{n_{k}}}-1\geq 2\varepsilon\frac{b_{k}}{b_{n_{k}}}>\frac{2 \varepsilon}{x}>0.\]

As \(n_{k}\) tends to infinity as \(k\) does, the left hand side should tend to \(0\) as \(k\) tends to infinity, a contradiction.

**Solution to 1.3.16:** 1. Using the Ratio Test [13, pag. 66], we have

\[\frac{\frac{(2n)!(3n)!}{n!(4n)!}}{\frac{(2n+2)!(3n+3)!}{(n+1)!(4n+4)!}} = \frac{n!(4n)!(2n+2)(2n+1)(2n)!(3n+3)(3n+2)(3n+1)(3n)!}{(2n)!(3n)!( 4n+4)(4n+3)(4n+2)(4n+1)(4n)!}\] \[= \frac{(2n+2)(2n+1)(3n+3)(3n+2)(3n+1)}{(n+1)(4n+4)(4n+3)(4n+2)(4n+1)}\] \[\to \frac{27}{64}<1\]

so the series converges.

2. Comparing with the series \(\sum 1/(n\log n)\), which can be seen to diverge using the Integral Test [13, pag. 139],

\[\lim\frac{1/n^{1+1/n}}{1/n\log n}=\lim\frac{\log n}{n^{1/n}}=\infty\]

we conclude that the given series diverges.

**Solution to 1.3.17:** 1. Assume that \(\sum a_{n}<\infty\). As \(\left(\sqrt{a_{n+1}}-\sqrt{a_{n}}\right)^{2}=a_{n+1}+a_{n}-2\sqrt{a_{n}a_{n+1}}\), we have

\[\sum_{n=1}^{\infty}\sqrt{a_{n}a_{n+1}}\leq\frac{1}{2}\sum_{n=1}^{\infty}\left( a_{n}+a_{n+1}\right)=\frac{1}{2}a_{1}+\sum_{n=2}^{\infty}a_{n}<\infty.\]

2. Since \(\sum\left(a_{n}+a_{n+1}\right)=2\sum\sqrt{a_{n}a_{n+1}}+\sum\left(\sqrt{a_{n+1 }}-\sqrt{a_{n}}\right)^{2}\), we require a sequence \(a_{n}=b_{n}^{2},\ b_{n}>0\), such that \(\sum b_{n}b_{n+1}<\infty\) but \(\sum\left(b_{n+1}-b_{n}\right)^{2}=\infty\). One such example is

\[b_{n}=\left\{\begin{array}{ccc}\frac{1}{\sqrt{n}}&\mbox{if}&n&\mbox{is odd} \\ \frac{1}{n}&\mbox{if}&n&\mbox{is even}.\end{array}\right.\]

**Solution to 1.3.18:** As

\[\lim\left|\frac{a^{n+1}}{(n+1)^{b}(\log n+1)^{c}}\frac{n^{b}(\log n)^{c}}{a^{ n}}\right|=|a|\]

the series converges absolutely for \(|a|<1\) and diverges for \(|a|>1\).

* \(b>1\). Let \(b=1+2\varepsilon\); we have \[\frac{1}{n^{1+2\varepsilon}(\log n)^{c}}=o\left(\frac{1}{n^{1+\varepsilon}} \right)\quad(n\to\infty)\] and, as the series \(\sum n^{-(1+\varepsilon)}\) converges, the given series converges absolutely for \(b>1\).
* \(b=1\). The series converges (absolutely) only if \(c>1\) and diverges if \(c\leq 1\), by the Integral Test [13, pag. 139].
* \(b<1\). Comparing with the harmonic series, we conclude that the series diverges.
* \(a=-1\). By Leibniz Criterion [13, pag. 71], the series converges exactly when \[\lim\frac{1}{n^{b}(\log n)^{c}}=0\] which is equivalent to \(b>0\) or \(b=0\), \(c>0\).

**Solution to 1.3.19:** Note that

\[\frac{\sqrt{n+1}-\sqrt{n}}{n^{x}}\sim\frac{1}{n^{x+1/2}}\quad(n\to\infty)\]

that is,

\[\lim_{n\to\infty}\frac{\sqrt{n+1}-\sqrt{n}/n^{x}}{1/n^{x+1/2}}=1\]

so the given series and

\[\sum_{n=1}^{\infty}\frac{1}{n^{x+1/2}}\]

converge or diverge together. They converge when \(x>1/2\).

**Solution to 1.3.20:** If \(a\leq 0\), the general term does not go to zero, so the series diverges. If \(a>0\), we have, using the Maclaurin series [14, pag. 127] for \(\sin x\),

\[\frac{1}{n}-\sin\frac{1}{n}=\frac{1}{6n^{3}}+o(n^{-3})\qquad(n\to\infty)\]

and, therefore,

\[\left(\frac{1}{n}-\sin\frac{1}{n}\right)^{a}=\frac{1}{6^{a}n^{3a}}+o(n^{-3a}) \qquad(n\to\infty).\]

Thus, the series converges if and only if \(3a>1\), that is, \(a>1/3\).

**Solution to 1.3.21:** For \(n=1,2,\ldots\) the number of terms in \(A\) that are less than \(10^{n}\) is \(9^{n}-1\), so we have

\[\sum_{a\in A}\frac{1}{a} =\sum_{n\geq 1}\sum_{\begin{subarray}{c}10^{n-1}\leq a<10^{n} \\ a\in A\end{subarray}}\frac{1}{a}\] \[\leq\sum_{n\geq 1}\frac{9^{n}}{10^{n-1}}\] \[=10\sum_{n\geq 1}\left(\frac{9}{10}\right)^{n}\] \[<\infty.\]

**Solution to 1.3.22:** Let \(S\) be the sum of the given series. Let \(N_{0}=0\). By convergence, for each \(k>0\) there exists an \(N_{k}>N_{k-1}\) such that

\[\sum_{N_{k}+1}^{\infty}a_{n}\leq\frac{S}{4^{k}}.\]

For \(N_{k}+1\leq n\leq N_{k+1}\) let \(c_{n}=2^{k}\). We have \(\lim c_{n}=\infty\). As the terms are all positive, we may rearrange the sum and get

\[\sum_{n=1}^{\infty}c_{n}a_{n} =\sum_{k=0}^{\infty}\sum_{N_{k}+1}^{N_{k+1}}c_{n}a_{n}\] \[\leq\sum_{k=0}^{\infty}2^{k}\sum_{N_{k}+1}^{\infty}a_{n}\] \[=\sum_{k=0}^{\infty}2^{-k}S\] \[=2S.\]

_Solution 2._ The convergence of the given series shows that there is an increasing sequence of positive integers \((N_{k})\) with \(\sum_{n=N_{k}}^{\infty}a_{n}<1/k^{-3}\) for each \(k\). Let

\[c_{n}=\left\{\begin{array}{ll}1&\text{if}\quad n<N_{1}\\ k&\text{if}\quad N_{k}\leq n<N_{k+1}.\end{array}\right.\]

Then \(c_{n}\to\infty\), and

\[\sum_{n=1}^{\infty}c_{n}a_{n}\leq\sum_{n=1}^{N_{1}-1}a_{n}+\sum_{k=1}^{\infty} k\sum_{n=N_{k}}^{\infty}a_{k}\]

**Solution to 1.3.23:** Using the formula \(\sin 2x=2\sin x\cos x\) and the Induction Principle [MH93, pag. 7], starting with \(\sin\frac{\pi}{2}=1\), we see that

\[\cos\frac{\pi}{2^{2}}\cos\frac{\pi}{2^{3}}\cdots\cos\frac{\pi}{2^{n}}=\frac{1}{2 ^{n-1}\sin\frac{\pi}{2^{n}}}.\]

So we have

\[\frac{1}{2^{n-1}\sin\frac{\pi}{2^{n}}}=\frac{2}{\pi}\frac{\frac{\pi}{2^{n}}}{ \sin\frac{\pi}{2^{n}}}\sim\frac{2}{\pi}\qquad(n\to\infty)\]

since \(\sin x\sim x\;(x\to 0)\).

### 1.4 Differential Calculus

**Solution to 1.4.1: Lemma 1:**_If \((x_{n})\) is an infinite sequence in the finite interval \([a,b]\), then it has a convergent subsequence._

Consider the sequence \(y_{k}=\sup\{x_{n}\,|\,n\geq k\}\). By the least upper bound property, we know that \(y_{k}\) exists and is in \([a,b]\) for all \(k\). By the definition of supremum, it is clear that the \(y_{k}\)'s form a nonincreasing sequence. Let \(y\) be the infimum of this sequence. From the definition of infimum, we know that the \(y_{k}\)'s converge to \(y\). Again, by the definition of supremum, we know that we can find \(x_{n}\)'s arbitrarily close to each \(y_{k}\), so we can choose a subsequence of the original sequence which converges to \(y\).

**Lemma 2:**_A continuous function \(f\) on \([a,b]\) is bounded._

Suppose \(f\) is not bounded. Then, for each \(n\), there is a point \(x_{n}\in[a,b]\) such that \(|f(x_{n})|>n\). By passing to a subsequence, we may assume that the \(x_{n}\)'s converge to a point \(x\in[a,b]\). (This is possible by Lemma 1.) Then, by the continuity of \(f\) at \(x\), we must have that \(|f(x)-f(x_{n})|<1\) for \(n\) sufficiently large, or \(|f(x_{n})|<|f(x)|+1\), contradicting our choice of the \(x_{n}\)'s.

**Lemma 3:**_A continuous function \(f\) on \([a,b]\) achieves its extrema._

It will suffice to show that \(f\) attains its maximum, the other case is proved in exactly the same way. Let \(M=\sup f\) and suppose \(f\) never attains this value. Define \(g(x)=M-f(x)\). Then \(g(x)>0\) on \([a,b]\), so \(1/g\) is continuous. Therefore, by Lemma 2, \(1/g\) is bounded by, say, \(N\). Hence, \(M-f(x)>1/N\), or \(f(x)<M-1/N\), contradicting the definition of \(M\).

**Lemma 4:**_If a differentiable function \(f\) on \((a,b)\) has a relative extremum at a point \(c\in(a,b)\), then \(f^{\prime}(c)=0\)._

Define the function \(g\) by

\[g(x)=\left\{\begin{array}{cl}\frac{f(x)-f(c)}{x-c}&\mbox{for}\quad x\neq c\\ 0&\mbox{for}\quad x=c\end{array}\right.\]

and suppose \(g(c)>0\). By continuity, we can find an interval \(J\) around \(c\) such that \(g(x)>0\) if \(x\in J\). Therefore, \(f(x)-f(c)\) and \(x-c\) always have the same sign in \(J\), so \(f(x)<c\) if \(x<c\) and \(f(x)>f(c)\) if \(x>c\). This contradicts the fact that \(f\) has a relative extremum at \(c\). A similar argument shows that the assumption that \(g(c)<0\) yields a contradiction, so we must have that \(g(c)=0\).

**Lemma 5 (Rolle's Theorem [13, pag. 200]):**_Let \(f\) be continuous on \([a,b]\) and differentiable on \((a,b)\) with \(f(a)=f(b)\). There is a point \(c\in(a,b)\) such that \(f^{\prime}(c)=0\)._

Suppose \(f^{\prime}(c)\neq 0\) for all \(c\in(a,b)\). By Lemma 3, \(f\) attains its extrema on \([a,b]\), but by Lemma 4 it cannot do so in the interior since otherwise the derivative at that point would be zero. Hence, it attains its maximum and minimum at the endpoints. Since \(f(a)=f(b)\), it follows that \(f\) is constant, and so \(f^{\prime}(c)=0\) for all \(c\in(a,b)\), a contradiction.

**Lemma 6 (Mean Value Theorem [13, pag. 108]):**_If \(f\) is a continuous function on \([a,b]\), differentiable on \((a,b)\), then there is \(c\in(a,b)\) such that \(f(b)-f(a)=f^{\prime}(c)(b-a)\)._

Define the function \(h(x)=f(x)(b-a)-x(f(b)-f(a))\). \(h\) is continuous on \([a,b]\), differentiable on \((a,b)\), and \(h(a)=h(b)\). By Lemma 5, there is \(c\in(a,b)\) such that \(h^{\prime}(c)=0\). Differentiating the expression for \(h\) yields the desired result.

There is a point \(c\) such that \(f(b)-f(a)=f^{\prime}(c)(b-a)\), but, by assumption, the right-hand side is \(0\) for all \(c\). Hence, \(f(b)=f(a)\).

**Solution to 1.4.2:**\(1\). We have \(\exp(f(x))=(1+1/x)^{x}\), which is an increasing function. As the exponential is also increasing, so is \(f\).

\(2\). We have

\[\lim_{x\to 0}f(x)=\lim_{x\to 0}\frac{\log(x+1)-\log x}{1/x}=\lim_{x\to 0} \frac{1/(x+1)-1/x}{-1/x^{2}}=0.\]

On the other hand,

\[\lim_{x\to\infty}\left(1+\frac{1}{x}\right)^{x}=e\]

so \(\lim_{x\to\infty}f(x)=1\).

**Solution to 1.4.4:** Suppose \(y\) assumes a positive maximum at \(\xi\). Then \(y(\xi)>0\), \(y^{\prime}(\xi)=0\), and \(y^{\prime\prime}(\xi)\leq 0\), contradicting the differential equation. Hence, the maximum of \(y\) is \(0\). Similarly, \(y\) cannot assume a negative minimum, so \(y\) is identically \(0\).

**Solution to 1.4.5:**: 1. Suppose \(u\) has a local maximum at \(x_{0}\) with \(u(x_{0})>0\). Then \(u^{\prime\prime}(x_{0})\leq 0\), but \(u^{\prime\prime}(x_{0})=e^{x_{0}}u(x_{0})>0\) and we have a contradiction. So \(u\) cannot have a positive local maximum. Similarly, if \(u\) has a local minimum at \(x_{0}\), then \(u^{\prime\prime}(x_{0})\geq 0\), so we must have \(u(x_{0})\geq 0\) and \(u\) cannot have a negative local minimum.

2. Suppose \(u(0)=u(1)=0\). If \(u(x_{0})\neq 0\) for some \(x_{0}\in(0,1)\), then, as \(u\) is continuous, \(u\) attains a positive local maximum or a negative local minimum, which contradicts Part 1.
**Solution to 1.4.7:**: By Rolle's Theorem [13, pag. 200], \(f^{\prime}(x_{1})=0\) for some \(x_{1}\in(0,1)\). Then, since \(f^{\prime}(0)=0\), \(f^{\prime\prime}(x_{2})=0\) for some \(x_{2}\in(0,x_{1})\). Repeated applications of Rolle's Theorem give \(f^{(n)}(x_{n})=0\) for some \(x_{n}\in(0,x_{n-1})\), and therefore, \(f^{(n+1)}(x)=0\) for some \(x\in(0,x_{n})\subset(0,1)\).
**Solution to 1.4.9:**: Let \(x>0\) and \(\delta>0\). Since \(f\) is positive and log is continuous,

\[\log\lim_{\delta\to 0}\left(\frac{f(x+\delta x)}{f(x)}\right)^{1/\delta} =\lim_{\delta\to 0}\log\left(\frac{f(x+\delta x)}{f(x)} \right)^{1/\delta}\] \[=\lim_{\delta\to 0}\frac{\log f(x+\delta x)-\log f(x)}{\delta}\] \[=\lim_{\delta\to 0}\frac{x\left(\log f(x+\delta x)-\log f(x) \right)}{\delta x}\] \[=x\left(\log f(x)\right)^{\prime}\] \[=\frac{xf^{\prime}(x)}{f(x)}\]

and the result follows, by exponentiating both sides.
**Solution to 1.4.10:**: It is enough to show that

\[\lim_{h\to 0^{+}}\frac{f(h)-f(0)}{h}\quad\text{and}\quad\lim_{h\to 0^{-}} \frac{f(h)-f(0)}{h}\]

both exist and are equal. By L'Hopital's Rule [12, pag. 109]

\[\lim_{h\to 0^{+}}\frac{f(h)-f(0)}{h}=\lim_{h\to 0^{+}}\frac{f^{\prime}(h)}{1}= \lim_{h\to 0}f^{\prime}(h).\]

The other lateral limit can be treated similarly.
**Solution to 1.4.11:**: We have

\[\begin{array}{rcl}p_{t}(x)&=&(1+t^{2})x^{3}-3t^{3}x+t^{4}\\ p^{\prime}_{t}(x)&=&3(1+t^{2})x^{2}-3t^{3}\\ p^{\prime\prime}_{t}(x)&=&6(1+t^{2})x\end{array}\]* \(t<0\). In this case, \(p_{t}^{\prime}>0\) and \(p_{t}(x)<0\) for \(x\) sufficiently negative, and \(p_{t}(x)>0\) for \(x\) sufficiently positive. Hence, by the Intermediate Value Theorem [13, pag. 93], \(p_{t}\) has exactly one root, of multiplicity 1, since the derivative is positive.
* \(t=0\). Now \(p_{t}(x)=x^{3}\), which has a single zero of multiplicity 3.
* \(t>0\). We have \[p_{t}^{\prime}\left(\pm\sqrt{\frac{t^{3}}{1+t^{2}}}\right)=0\] and \(p_{t}^{\prime\prime}(x)<0\) for negative \(x\); \(p_{t}^{\prime\prime}(x)>0\) for positive \(x\). So \[p_{t}\left(\sqrt{\frac{t^{3}}{1+t^{2}}}\right)\] is a local minimum, and \[p_{t}\left(-\sqrt{\frac{t^{3}}{1+t^{2}}}\right)\] is a local maximum of \(p_{t}\). We will study the values of \(p_{t}\) at thcse critical points. As \(p_{t}(0)>0\) and \(p_{t}^{\prime}(0)<0\), the relative maximum must be positive. We have \[p_{t}\left(\sqrt{\frac{t^{3}}{1+t^{2}}}\right)=t^{4}\left(1-\sqrt{\frac{t}{1+t ^{2}}}\right)=A_{t}\] say. We get 1. \(0<t<2-\sqrt{3}\). In this case, we have \(A_{t}>0\), so \(p_{t}\) has one single root. 2. \(2-\sqrt{3}<t<2+\sqrt{3}\). Now \(A_{t}<0\) and \(p_{t}\) has three roots. 3. \(t>2+\sqrt{3}\). We have \(A_{t}>0\) and \(p_{t}\) has one root.

**Solution to 1.4.12:** Let

\[h(x)=\frac{f(x)-f(a)}{x-a}-f^{\prime}(a)\]

so that \(\lim_{x\to a}h(x)=0\) and \(f(x)=f(a)+\left(f^{\prime}(a)+h(x)\right)(x-a)\). Then

\[\frac{f(y_{n})-f(x_{n})}{y_{n}-x_{n}}=\frac{f^{\prime}(a)(y_{n}-x_{n})+h(x)(y_ {n}-a)-h(x_{n})(x_{n}-a)}{y_{n}-x_{n}}\]so that \[\left|\frac{f(y_{n})-f(x_{n})}{y_{n}-x_{n}}-f^{\prime}(a)\right| \leq|h(y_{n})|\left(\frac{y_{n}-a}{y_{n}-x_{n}}\right)+|h(x_{n})| \left(\frac{a-x_{n}}{y_{n}-x_{n}}\right)\] \[\leq|h(y_{n})|+|h(x_{n})|\] \[=o(1)\qquad(n\to\infty).\]

**Solution to 1.4.13:** By changing variables, it is enough to show that \(f(1)\geq f(0)\). Without loss of generality assume \(f(0)=0\). Consider the function \(g\) defined by

\[g(x)=f(x)-f(1)x.\]

As \(g\) is continuous, it attains a maximum at some point \(\xi\in[0,1]\). We can assume \(\xi<1\), because \(g(1)=g(0)=0\). As \(g(\xi)\geq g(x)\) for \(\xi<x<1\), we have

\[0\geq\limsup_{x\to\xi+}\frac{g(x)-g(\xi)}{x-\xi}=-f(1)+\frac{f(x)-f(\xi)}{x-\xi}.\]

As the rightmost term is nonnegative, we have \(f(1)\geq 0\), as desired.

**Solution to 1.4.15:** We have

\[1=f(z)\left(\frac{e^{z}-1}{z}\right)=\left(\xi_{0}+\xi_{1}z+\xi_{2}z^{2}+ \cdots\right)\left(1+\frac{z}{2!}+\frac{z^{2}}{3!}+\cdots\right).\]

Multiplying this out, we get \(\xi_{0}=1\) and

\[\sum_{k=0}^{n}\frac{\xi_{n-k}}{(k+1)!}=0.\]

From this, it can easily be seen by the Induction Principle [10, pag. 7] that all the \(\xi_{i}\)'s are rational.

**Solution to 1.4.16:** The function \(f\) given by

\[f(x)=\left\{\begin{array}{ll}(-1/3)e^{3-1/x+2/(2x-3)}&\mbox{for}\quad 0<x<3/2\\ 0&\mbox{for}\quad x\leq 0\,\mbox{or}\,x\geq 3/2\end{array}\right.\]

is such a function.

This is based on the example of a nonconstant function having derivatives of all orders, vanishing for negative :

**Solution to 1.4.18:** Let and. Then we have

As and, we have

and the right-hand side has no limit when goes to zero.

**Solution to 1.4.19:** Without loss of generality assume. As is continuous and, we have in some interval. Suppose that is not positive for all positive values of. Let. Since is continuous and positive in a neighborhood of the origin, we have and. By Rolle's Theorem, [13, pag. 200] there is a point with, however, by the definition of, we have, a contradiction.

_Solution 2._ Let. Then. As is an increasing function, we have, and the conclusion follows.

**Solution to 1.4.20:** Let be defined by. We have

so has at least one real root, say. We have

therefore, by Problem 1.4.19, has no other root.

**Solution to 1.4.21:** As and satisfy the given differential equations, we have, since, it follows from our hypotheses that. Hence, there exists a point such that for. Suppose there existed a point such that. Let be the infimum of all such points. By continuity, we must have that. Hence,repeating the above argument, we see that there must be a point \(s_{1}>t_{1}\) such that \(\varphi_{1}(t)\leq\varphi_{2}(t)\) if \(t_{1}<t<s_{1}\), contradicting our definition of \(t_{1}\).

**Solution to 1.4.22:** Let \(g:[0,1]\to\mathbb{R}\) be defined by \(g(x)=e^{-Mx}f(x)\). We have

\[g^{\prime}(x)=e^{-Mx}(f^{\prime}(x)-Mf(x))\leq 0\]

so \(g\) is a decreasing function. As \(g(0)=0\) and \(g\) is nonnegative, we get \(g\equiv 0\), so the same is true for \(f\).

**Solution to 1.4.23:** 1. The function \(f(x)\) given by

\[f(x)=x^{2}\sin\frac{1}{x}\]

has a derivative that is not continuous at zero:

\[f^{\prime}(x)=\left\{\begin{array}{ll}2x\sin\frac{1}{x}-\cos\frac{1}{x}& \mbox{for}\quad x\neq 0\\ 0&\mbox{for}\quad x=0\end{array}\right.\]

2. Consider the function \(g\) given by \(g(x)=f(x)-2x\). We then have \(g^{\prime}(0)<0<g^{\prime}(1)\). Therefore, \(g(x)<g(0)\) for \(x\) close to \(0\), and \(g(x)<g(1)\) for \(x\) close to \(1\). Then the minimum of \(g\) in \([0,1]\) occurs at an interior point \(c\in(0,1)\), at which we must have \(g^{\prime}(c)=0\), which gives \(f^{\prime}(c)=2\).

**Solution to 1.4.24:** We claim there is an \(\varepsilon>0\) such that \(f(t)\neq 0\) for all \(t\in(0,\varepsilon)\). Suppose, on the contrary, that there is a sequence \(x_{n}\to 0\) such that \(f(x_{n})=0\). Considering the real function \(\Re f(x)\), to each subinterval \([x_{n+1},x_{n}]\), we find a sequence \(t_{n}\to 0\), \(t_{n}\in[x_{n+1},x_{n}]\), such that \(\Re f^{\prime}(t_{n})=0\) for all \(n\), but since \(\lim_{t\to 0+}f^{\prime}(t)=C\), this would imply \(\Re\ C=0\). In the same fashion, using the imaginary part of \(f(x)\), we see that \(\Im\ C=0\), which is a contradiction.

Since \(f(t)\) is non-zero on a small interval starting at \(0\), the composition with the \(C^{\infty}\)-function absolute value

\[|\quad|:\mathbb{C}\setminus\{0\}\to\mathbb{R}_{+}\]

will give a \(C^{1}\)-function \(g(t)=|f(t)|\), on a small neighborhood of zero.

**Solution to 1.4.25:** Consider the function \(g\) defined on \([0,1]\) by \(g(x)=e^{x}f(x)\). We have

\[g^{\prime\prime}(x)=e^{x}\left(f^{\prime\prime}(x)+2f^{\prime}(x)+f(x)\right)\geq 0\]

so \(g\) is concave upward; that is, the point \((x,g(x))\) must lie below the chord joining \((0,g(0))\) and \((1,g(1))=(1,0)\) for \(x\in(0,1)\). Then \(g(x)\leq 0\) and the conclusion follows.

**Solution to 1.4.26:** By Taylor's Theorem [12, pag. 110], there is a constant \(C\) such that

\[|f(x)-f(0)-f^{\prime}(0)x|\leq Cx^{2}\]when \(|x|<1\). Since \(f^{\prime}(0)=0\), we actually have \(|f(x)-f(0)-f^{\prime}(0)|\leq Cx^{2}\) and, consequently, by the triangle inequality, \(f(x)\leq f(0)+Cx^{2}\) when \(|x|<1\). We conclude:

If \((x,y)\) lies on or below the graph of \(f\) and \(|x|<1\), then \(y\leq f(0)+Cx^{2}\).

Now consider the disc \(D\) centered at \((0,f(0)+b)\) with radius \(b\), where \(0<b<1\) will be chosen at the end. Clearly, \((0,f(0))\) is on the boundary of \(D\). On the other hand, if \((x,y)\in D\), then \(|x|<b<1\) and

\[x^{2}+(y-f(0)-b)^{2}<b^{2}\]

\[|y-f(0)-b|<\sqrt{b^{2}-x^{2}}\]

\[y>f(0)+b-\sqrt{b^{2}-x^{2}}=f(0)+b-b\sqrt{1-x^{2}/b^{2}}\geq f(0)+b-b(1-x^{2}/ 2b^{2})\]

since \(\sqrt{1-x}\leq 1-x/2\) when \(0\leq x\leq 1\). Thus,

\[y>f(0)+x^{2}/2b.\]

If \(1/2b\gtrsim c\), then it follows that \((x,y)\) must be above the graph of \(f\). So we are done if we take \(b=\min\{1/2,1/2c\}\).

### 1.5 Integral Calculus

**Solution to 1.5.2:** Since \(f\) is continuous, it attains its minimum and maximum at \(x_{0}\) and \(y_{0}\), respectively, in \([0,1]\). So we have

\[f(x_{0})\int_{0}^{1}x^{2}\,dx\leq\int_{0}^{1}x^{2}f(x)\,dx\leq f(y_{0})\int_{0} ^{1}x^{2}\,dx\,,\]

or

\[f(x_{0})\leq 3\int_{0}^{1}x^{2}f(x)\,dx\leq f(y_{0}).\]

Therefore, by the Intermediate Value Theorem [13, pag. 93], there is a point \(\xi\in[0,1]\) with

\[f(\xi)=3\int_{0}^{1}x^{2}f(x)\,dx\,.\]

**Solution to 1.5.3:** Since the discontinuities are only of the first type (the limit exists), they do not have any accumulation point (for a detailed proof of this, see the Solution to Problem 1.2.5), and form a finite set. Let \(d_{1}<d_{2}<\cdots<d_{n}\) be the set of discontinuities of \(f\). Then \(f\) is continuous in every interval \([x,y]\) with \(d_{n}<x<y<d_{n+1}\); using the Solution to Problem 1.5.4 (on both endpoints of the interval), \(f\) is integrable on each interval of the type \([d_{n},d_{n+1}]\), so \(f\) is integrable on \([a,b]\).

**Solution to 1.5.4:** 1. Let \(|f(x)|\leq M\) for \(x\in[0,1]\). If \((b_{n})\) is a decreasing vanishing sequence, then \(\int_{b_{n}}^{1}|f|\leq M\) is a bounded, increasing sequence, so it must converge. We conclude that \(|f|\) is Riemann integrable over \([0,1]\), and so is \(f\).

2. The function \(f(x)=1/x\) is integrable over any interval \([b,1]\) for positive \(b\), but is not integrable over \([0,1]\).

**Solution to 1.5.6:** 1. Letting \(t=x+s\), we get

\[f(x)=e^{x^{2}/2}\int_{0}^{\infty}e^{-(x+s)^{2}/2}\,ds=\int_{0}^{\infty}e^{-sx- s^{2}/2}\,ds.\]

Since \(s>0\), \(e^{-s^{2}/2}<1\), so \(e^{-sx-s^{2}/2}<e^{-sx}\) for all positive \(x\); then

\[0<f(x)<\int_{0}^{\infty}e^{-sx}\,ds=1/x.\]

2. Let \(0<x_{1}<x_{2}\). For \(s>0\), \(e^{-sx_{1}-s^{2}/2}>e^{-sx_{2}-s^{2}/2}\), so

\[\int_{0}^{\infty}e^{-sx_{1}-s^{2}/2}\,ds>\int_{0}^{\infty}e^{-sx_{2}-s^{2}/2}\,ds,\]

and \(f(x_{1})>f(x_{2})\).

**Solution to 1.5.7:** Integrating by parts and noting that \(\varphi\) vanishes at 1 and 2, we get

\[\int_{1}^{2}e^{i\lambda x}\varphi(x)\,dx=\left.\frac{e^{i\lambda x}}{i\lambda} \varphi(x)\right|_{1}^{2}-\frac{1}{i\lambda}\int_{1}^{2}e^{i\lambda x}\varphi^ {\prime}(x)\,dx=-\frac{1}{i\lambda}\int_{1}^{2}e^{i\lambda x}\varphi^{\prime} (x)\,dx,\]

applying integration by parts a second time and using the fact that \(\varphi^{\prime}\) also vanishes at the endpoints, we get

\[\int_{1}^{2}e^{i\lambda x}\varphi(x)\,dx=-\frac{1}{\lambda^{2}}\int_{1}^{2}e^ {i\lambda x}\varphi^{\prime\prime}(x)\,dx.\]

Taking absolute values gives

\[\left|\int_{1}^{2}e^{i\lambda x}\varphi(x)\,dx\right|\leq\frac{1}{\lambda^{2} }\int_{1}^{2}\left|\varphi^{\prime\prime}(x)\right|\,dx.\]

Since \(\varphi\in\ C^{2}\), the integral on the right-hand side is finite, and we are done.

**Solution to 1.5.8:** Suppose that \(f\) is such a function. Cauchy-Schwarz Inequality [13, pag. 69] gives

\[a =\int_{0}^{1}xf(x)\,dx\] \[\leq\left(\int_{0}^{1}x^{2}f(x)\,dx\int_{0}^{1}f(x)\,dx\right)^{1/2}\] \[\leq a.\]

So we must have a chain of equalities. For equality to hold in the Cauchy-Schwarz Inequality [13, pag. 69], we must have \(x\sqrt{f(x)}=k\sqrt{f(x)}\) for some constant \(k\) so \(\sqrt{f(x)}\equiv 0\), which contradicts

\[\int_{0}^{1}f(x)\,dx=1.\]

Thus, no such function \(f\) can exist.

_Solution 2._ Multiplying the given identities by \(\alpha^{2}\), \(-2\alpha\), and \(1\), respectively, we get

\[\int_{0}^{1}f(x)(\alpha-x)^{2}dx=0\]

but the integral above is clearly positive for every positive continuous function, so no such function can exist.

**Solution to 1.5.9:** Dividing the integral in \(n\) pieces, we have

\[\left|\sum_{j=0}^{n-1}\frac{f(j/n)}{n}-\int_{0}^{1}f(x)\,dx\right| =\left|\sum_{j=0}^{n-1}\left(\frac{f(j/n)}{n}-\int_{j/n}^{(j+1)/n }f(x)\,dx\right)\right|\] \[\leq\sum_{j=0}^{n-1}\int_{j/n}^{(j+1)/n}\left|f(j/n)-f(x)\right| \,dx.\]

For every \(x\in(j/n,(j+1)/n)\), applying the Mean Value Theorem [12, pag. 108], there is \(c\in(j/n,x)\) with

\[f^{\prime}(c)=\frac{f(x)-f(j/n)}{x-j/n}.\]

As the derivative of \(f\) is uniformly bounded by \(M\), this gives us the inequality

\[\left|f(x)-f(j/n)\right|\leq M(x-j/n).\]Therefore, \[\left|\sum_{j=0}^{n-1}\frac{f(j/n)}{n}-\int_{0}^{1}f(x)\,dx\right| \leq\sum_{j=0}^{n-1}\int_{j/n}^{(j+1)/n}M(x-j/n)\,dx\] \[=M\sum_{j=0}^{n-1}\left(\frac{(j+1)^{2}}{2n^{2}}-\frac{j^{2}}{2n^{ 2}}\right)-\frac{j}{n^{2}}\] \[=M\sum_{j=0}^{n-1}\frac{1}{2n^{2}}\] \[=\frac{M}{2n}.\] Solution to 1.5.10:Suppose not. Then, for some \(\delta>0\), there is a sequence of real numbers, \((x_{n})\), such that \(x_{n}\to\infty\) and \(|f(x_{n})|\geq\delta\). Without loss of generality, we can assume \(f(x_{n})\geq\delta\).

Let \(\varepsilon>0\) verify

\[|f(x)-f(y)|<\frac{\delta}{2}\quad\text{for}\quad|x-y|<\varepsilon\,,\]

then

\[\sum_{n\geq 1}\int_{x_{n}-\varepsilon}^{x_{n}+\varepsilon}f(x)dx\geq\sum_{n \geq 1}2\varepsilon\frac{\delta}{2}=\infty\]

contradicting the convergence of \(\int_{0}^{\infty}f(x)dx\). Solution to 1.5.11:Let

\[g(x)=f(x)+\int_{0}^{x}f(t)dt.\]

The result follows from the following claims.

Claim 1: \(\liminf_{x\to\infty}f(x)\leq 0\).

If not, there are \(\varepsilon,x_{0}>0\) such that \(f(x)>\varepsilon\) for \(x>x_{0}\). Then, we have

\[g(x) =f(x)+\int_{0}^{x_{0}}f(t)dt+\int_{x_{0}}^{x}f(t)dt\] \[\geq\varepsilon+\int_{0}^{x_{0}}f(t)dt+\varepsilon(x-x_{0}).\]

This is a contradiction since the right side tends to \(\infty\) with \(x\).

Claim 2: \(\limsup_{x\to\infty}f(x)\geq 0\).

This follows from Claim 1 applied to \(-f\).

Claim 3: \(\limsup_{x\to\infty}f(x)\leq 0\).

Assume not. Then, for some \(\varepsilon>0\) there is a sequence \(x_{1},x_{2},\ldots\) tending to \(\infty\) such that \(f(x_{n})>\varepsilon\) for all \(n\). By Claim 1, the function \(f\) assumes values \(\leq\varepsilon/2\) for arbitrarily large values of its argument. Thus, after possibly deleting finitely many of the \(x_{n}\)'s, we can find another sequence \(y_{1},y_{2},\ldots\) tending to \(\infty\) such that \(y_{n}<x_{n}\) for all \(n\) and \(f(y_{n})\leq\varepsilon/2\) for all \(n\). Let \(z_{n}\) be the largest number in \([y_{n},x_{n}]\) where \(f\) takes the value \(\varepsilon/2\) (it exists by the Intermediate Value Theorem [13, pag. 93]). Then

\[g(x_{n})-g(z_{n}) =f(x_{n})-f(z_{n})+\int_{z_{n}}^{x_{n}}f(t)dt\] \[>\varepsilon-\frac{\varepsilon}{2}+\int_{z_{n}}^{x_{n}}\frac{ \varepsilon}{2}dt\] \[\geq\frac{\varepsilon}{2}\]

which contradicts the existence of \(\lim_{x\to\infty}g(x)\).

Claim 4: \(\liminf_{x\to\infty}f(x)\geq 0\).

Apply Claim 3 to \(-f\).

**Solution to 1.5.12:** Suppose that for some \(\varepsilon>0\), there is a sequence \(x_{n}\to\infty\) with \(x_{n}f(x_{n})\geq\varepsilon\). Then, as \(f\) is monotone decreasing, we have \(f(x)\geq\varepsilon/x\) for \(x\) large enough, which contradicts the convergence of \(\int_{0}^{\infty}f(x)dx\), and the result follows.

**Solution to 1.5.13:** Let \(0<\varepsilon<1\). As

\[\int_{0}^{\infty}f(x)\,dx<\infty,\]

there is an \(N>0\) such that for \(n>N\),

\[\int_{n}^{\infty}f(x)\,dx<\varepsilon.\]

Therefore, for \(n\) large enough, that is, such that \(n\varepsilon>N\), we have

\[\int_{0}^{n}(x/n)f(x)\,dx =\int_{0}^{n\varepsilon}(x/n)f(x)\,dx+\int_{n\varepsilon}^{n}(x/ n)f(x)\,dx\] \[<\varepsilon\int_{0}^{n\varepsilon}f(x)\,dx+\int_{n\varepsilon} ^{n}f(x)\,dx\] \[<\varepsilon\int_{0}^{n\varepsilon}f(x)\,dx+\varepsilon\] \[<\varepsilon\left(\int_{0}^{\infty}f(x)\,dx+1\right).\]

Since this inequality holds for all \(\varepsilon>0\) and for all \(n\) sufficiently large, it follows that

\[\lim_{n\to\infty}\frac{1}{n}\int_{0}^{n}xf(x)\,dx=0.\]

**Solution to 1.5.14:** Using the Maclaurin expansion [PMJ85, pag. 127] of \(\sin x\), we get

\[\frac{\sin x}{x}=\sum_{0}^{\infty}(-1)^{n}\frac{x^{2n}}{(2n+1)!}.\]

The series above is alternating for every value of \(x\), so we have

\[\left|\frac{\sin x}{x}-\sum_{0}^{k}(-1)^{n}\frac{x^{2n+1}}{(2n+1)!}\right|\leq \frac{x^{2k+2}}{(2k+3)!}.\]

Taking \(k=2\), we have

\[\left|I-\int_{0}^{1/2}\left(1-\frac{x^{2}}{3!}\right)dx\right|\leq\int_{0}^{1/ 2}\frac{x^{4}}{5!}dx\]

which gives an approximate value of \(71/144\) with an error bounded by \(0.00013\).

**Solution to 1.5.15:** Let

\[I(t)=\int_{0}^{1}\frac{dx}{\left(x^{4}+t^{4}\right)^{1/4}}+\log t.\]

It suffices to show that for \(t>0\), the function \(I(t)\) is bounded below and monotonically increasing. For \(x,t\geq 0\), we have \((x+t)^{4}\geq x^{4}+t^{4}\), so

\[I(t)\geq\int_{0}^{1}\frac{dx}{x+t}+\log t=\int_{t}^{1+t}\frac{du}{u}+\log t= \log(1+t)\geq 0.\]

We now show that \(I^{\prime}(t)\geq 0\) for \(t>0\). We have

\[I(t)=\int_{0}^{t}\frac{dx}{t\left((x/t)^{4}+1\right)^{1/4}}+\int_{t}^{1}\frac{ dx}{t\left((x/t)^{4}+1\right)^{1/4}}+\log t\,,\]

letting \(y=x/t\), we get

\[I(t)=\int_{0}^{1}\frac{dy}{\left(y^{4}+1\right)^{1/4}}+\int_{1}^{1/t}\frac{dy} {\left(y^{4}+1\right)^{1/4}}+\log t\,,\]

so

\[I^{\prime}(t)=\frac{-1}{t^{2}\left(1/t^{4}+1\right)^{1/4}}+\frac{1}{t}\geq 0.\]

**Solution to 1.5.16:** Integrate by parts to get

\[\int_{0}^{\infty}f(x)^{2}dx=\int_{0}^{\infty}\left(\frac{d}{dx}\ x\right)f(x) ^{2}dx=-\int_{0}^{\infty}x\cdot 2f(x)f^{\prime}(x)dx\.\]The boundary terms vanish because \(xf(x)^{2}=0\) at \(x=0\) and \(\infty\). By the Cauchy-Schwarz Inequality [13, pag. 69],

\[\left|\int_{0}^{\infty}xf(x)f^{\prime}(x)dx\right|\leq\sqrt{\int_{0}^{\infty}x^{2 }f(x)^{2}dx}\ \sqrt{\int_{0}^{\infty}f^{\prime}(x)^{2}dx}\.\]

**Solution to 1.5.17:** Consider the figure

The left side of the desired inequality is the sum of the areas of the two shaded regions. Those regions together contain a rectangle of sides \(a\), and \(b\), from which the inequality follows. The condition for equality is \(b=f(a)\), the condition that the two regions fill the rectangle.

_Solution 2._ Without loss of generality, assume \(f(a)\leq b\). We have

\[ab=\int_{0}^{a}f(x)\,dx+\int_{0}^{a}\left(b-f(x)\right)\,dx.\]

The second integral is

\[\lim_{n\to\infty}\frac{a}{n}\sum_{k=0}^{n-1}\left(b-f\left(\frac{(k+1)a}{n} \right)\right).\]

For \(0\leq k\leq n-1\),

\[\frac{a}{n}=\frac{(k+1)a}{n}-\frac{ka}{n}=g\circ f\left(\frac{(k+1)a}{n} \right)-g\circ f\left(\frac{ka}{n}\right).\]Substituting in the limit above,

\[\lim_{n\to\infty}\sum_{k=0}^{n-1}\left(b-f\left(\frac{(k+1)a}{n}\right)\right) \left(g\circ f\left(\frac{(k+1)a}{n}\right)-g\circ f\left(\frac{ka}{n}\right) \right).\]

Multiplying out each term in the sum and rearranging them, and noting that \(f(0)=g(0)=0\), we get

\[\lim_{n\to\infty}\sum_{k=0}^{n-1}g\circ f\left(\frac{ka}{n}\right)\left(f \left(\frac{(k+1)a}{n}\right)-f\left(\frac{ka}{n}\right)\right)+ab-af(a).\]

Since \(g\) is continuous, this equals

\[\int_{0}^{f(a)}g(y)\,dy+a\left(b-f(a)\right).\]

As \(g(y)\geq a\) for \(y\in(f(a),b)\), we have

\[a\left(b-f(a)\right)\leq\int_{f(a)}^{b}g(y)\,dy.\]

This gives the desired inequality. Also, we see that equality holds iff \(f(a)\ =\ b\).

**Solution to 1.5.18:** Given \(\varepsilon>0\), choose \(R\) so that \(\int_{|x|\geq R}|f(x)|dx<\varepsilon/4\). Then \(\int_{|x|\geq R}|f(x)\cos(xy)|dx<\varepsilon/4\) for all \(y\). So

\[|g(z)-g(y)| =\int_{|x|\geq R}f(x)\left(\cos(xz)-\cos(xy)\right)dx\] \[\quad+\int_{|x|\geq R}f(x)\left(\cos(xz)-\cos(xy)\right)dx\] \[\leq\varepsilon/2+\int_{|x|\geq R}|f(x)||\cos(xz)-\cos(xy)|dx\.\]

The latter integral approaches \(0\) as \(z\to y\) by uniform convergence of \(\cos(xz)\) to \(\cos(xy)\) on the compact interval \(-R\leq x\leq R\). Hence, for \(|z-y|\) sufficiently small,

\[|g(z)-g(y)|<\varepsilon/2+\varepsilon/2=\varepsilon\]

and \(g\) is continuous.

**Solution to 1.5.19:** We will do the proof of the sine integral only. For \(n\geq 0\), let

\[S_{n}=\int_{\sqrt{n\pi}}^{\sqrt{(n+1)\pi}}\sin(x^{2})\,dx.\]We show that the series \(\sum S_{n}\) converges and use this to show that the integral converges.

By the choice of the domains of integration, the \(S_{n}\)'s alternate in sign. Also, setting \(u=x^{2}\), we get

\[2|S_{n}| =\left|\int_{n\pi}^{(n+1)\pi}\frac{\sin u}{\sqrt{u}}\,du\right|\] \[>\left|\int_{n\pi}^{(n+1)\pi}\frac{\sin u}{\sqrt{u+\pi}}\,du\right|\] \[=\left|\int_{(n+1)\pi}^{(n+2)\pi}\frac{\sin u}{\sqrt{u}}\,du\right|\] \[=2|S_{n+1}|.\]

Finally, the \(S_{n}\)'s tend to \(0\):

\[2|S_{n}|=\left|\int_{n\pi}^{(n+1)\pi}\frac{\sin u}{\sqrt{u}}\,du\right|<\frac{1 }{\sqrt{n\pi}}\]

and the right-hand side gets arbitrarily small as \(n\) tends to infinity. Therefore, by Leibniz Criterion [20, p. 71], the series \(\sum S_{n}\) converges. Let \(a>0\) and \(n\) be such that \(\sqrt{n\pi}\leq a<\sqrt{(n+1)\pi}\). Then

\[\int_{0}^{a}\sin(x^{2})\,dx-\sum_{k=0}^{\infty}S_{k}=\int_{a}^{\sqrt{(n+1)\pi} }\sin(x^{2})\,dx-\sum_{k=n+1}^{\infty}S_{k}.\]

The second term tends to zero as \(n\) tends to infinity. By estimates almost identical to those above,

\[\left|\int_{a}^{\sqrt{(n+1)\pi}}\sin(x^{2})\,dx\right|\leq\frac{|(n+1)\pi-a^{2 }|}{2a}\leq\frac{\pi}{2\sqrt{n\pi}},\]

so the first term does as well. Therefore, we have

\[\int_{0}^{\infty}\sin(x^{2})\,dx=\sum_{n=0}^{\infty}S_{n}<\infty.\]

**Solution to 1.5.20:** Let \(p(x)=\sum_{0}^{k}a_{j}x^{j}\) be a polynomial. We have

\[\lim_{n\to\infty}(n+1)\int_{0}^{1}x^{n}p(x)\,dx=\lim_{n\to\infty}\sum_{j=0}^{k }\frac{n+1}{n+j+1}a_{j}=p(1).\]

[MISSING_PAGE_FAIL:186]

\[\frac{\pi\log a}{2a}.\]

**Solution to 1.5.22:** As \(\sin x\leq 1\), to show that \(I\) converges, it is enough to show that \(I>-\infty\). By the symmetry of \(\sin x\) around \(\pi/2\), we have

\[I =\int_{0}^{\pi/2}\log(\sin x)\,dx+\int_{\pi/2}^{\pi}\log(\sin x)\,dx\] \[=2\int_{0}^{\pi/2}\log(\sin x)\,dx\] \[\geq 2\int_{0}^{\pi/2}\log(2x/\pi)\,dx\] \[>-\infty.\]

The first inequality holds since on \([0,\pi/2],\sin x\geq 2x/\pi\); see Problem 1.1.23. Letting \(x=2u\), we get

\[I =2\int_{0}^{\pi/2}\log(\sin 2u)\,du\] \[=2\left(\int_{0}^{\pi/2}\log 2\,du+\int_{0}^{\pi/2}\log(\sin u)\, du+\int_{0}^{\pi/2}\log(\cos u)\,du\right).\]

The first integral equals \((\pi/2)\log 2\). As \(\cos u=\sin(\pi/2-u)\), the last integral is

\[\int_{0}^{\pi/2}\log\left(\sin(\pi/2-u)\right)\,du=\int_{0}^{\pi/2}\log(\sin u )\,du=\int_{\pi/2}^{\pi}\log(\sin u)\,du.\]

The above equation becomes \(I=\pi\log 2+2I\), so \(I=-\pi\log 2\).

### 1.6 Sequences of Functions

**Solution to 1.6.1:** Let \(B\) be the set of function that are the pointwise limit of continuous functions defined on \([0,1]\). The characteristic functions of intervals, \(\chi_{I}\), are in \(B\). Notice also that as \(f\) is monotone, the inverse image of an interval is an interval, and that linear combinations of elements of \(B\) are in \(B\). Without loss of generality, assume \(f(0)=0\) and \(f(1)=1\). For \(n\in\mathbb{N}\), let the functions \(g_{n}\) be defined by

\[g_{n}(x)=\sum_{k=0}^{n-2}\frac{k}{n}\chi_{f^{-1}\left([\frac{n}{n},\frac{k+1}{ n})\right)}(x)+\frac{n-1}{n}\chi_{f^{-1}\left([\frac{n-1}{n},1)\right)}(x).\]We have \[\max_{x\in[0,1]}|g_{n}(x)-f(x)|\leq\frac{1}{n}.\] We now use the following result: **Lemma:** Let \(\{h_{n}\}\subset B\) with \(\max_{x\in[0,1]}|h_{n}(x)|\leq A_{n}\) and \(\sum_{n=1}^{\infty}A_{n}<\infty\). Then \(\sum_{n=1}^{\infty}h_{n}\in B\). As \[|g_{2^{k+1}}-g_{2^{k}}|\leq|g_{2^{k+1}}-f|+|g_{2^{k}}-f|\leq\frac{1}{2^{k-1}}\] and \(\sum 2^{-k-1}<\infty\), we get \[\sum_{k=1}^{\infty}(g_{2^{k+1}}-g_{2^{k}})=f-g_{2}\in B\] so \(f-g_{2}+g_{2}=f\in B\). _Proof of the Lemma:_ For each \(n\) let \(h_{n}\) be the pointwise limit of \(\{\varphi_{k}^{n}\}\subset B\) such that \(|h_{n}(x)|\leq A_{n}\) on \([0,1]\). Consider the functions \(\Phi_{k}=\sum_{n=1}^{k}\varphi_{k}^{n}\). Given \(\varepsilon>0\), take \(m\) such that \(\sum_{n=m+1}^{\infty}A_{n}<\varepsilon/3\). Then the sum \(\sum_{n=m+1}^{\infty}|h_{n}(x)|<\varepsilon/3\) and \(\sum_{n=m+1}^{\infty}|\varphi_{k}^{n}(x)|<\varepsilon/3\). For \(x\in[0,1]\), take \(K\) so that \[|h_{n}(x)-\varphi_{K}^{n}(x)|<\frac{\varepsilon}{3m}\quad\text{for}\quad n=1, \ldots,m.\] For \(k>K\) we then have \[\left|\sum_{n=1}^{\infty}h_{n}(x)\text{ -- }\Phi_{k}(x)\right|\leq\sum_{k=1}^{m}|h_{n}(x)- \varphi_{k}^{n}(x)|+\sum_{n=m+1}^{\infty}|h_{n}(x)|+\sum_{n=m+1}^{k}|\varphi_{ k}^{n}(x)|<\varepsilon\] so \(\sum_{n=1}^{\infty}h_{n}\in B\). **Solution to 1.6.2:** Let \(a<b\) be real numbers and \(\varepsilon>0\). Take \(n\) large enough so \[|f_{n}(a)-g(a)|<\varepsilon\quad\text{and}\quad|f_{n}(b)-g(b)|<\varepsilon.\] Then, using the Mean Value Theorem [13, pag. 108], \[|g(a)-g(b)|\leq|g(a)-f_{n}(a)|+|f_{n}(a)-f_{n}(b)|+|f_{n}(b)-g(b)|<2\varepsilon +|f_{n}^{\prime}(\xi)||b-a|\] where \(a<\xi<b\). As the inequality holds for any \(\varepsilon>0\), \[|g(a)-g(b)|\leq|b-a|\] and the continuity of \(g\) follows. _Solution 2._ Let \(N>0\). We will show that \(g\) is continuous in \([-N,N]\). We have, for any \(n\in\mathbb{N}\), by the Mean Value Theorem, \[|f_{n}(x)-f_{n}(y)|=|f_{n}^{\prime}(\xi)(x-y)|\leq 2N\quad\text{for }x,y\in[-N,N].\]So the sequence \(\{f_{n}\}\) is bounded. The relation

\[|f_{n}(x)-f_{n}(y)|=|f_{n}^{\prime}(\xi)(x-y)|\leq|x-y|\]

shows that it is also equicontinuous. By the Arzela-Ascoli Theorem [10, pag. 273] we may assume that \(\{f_{n}\}\) converges uniformly on \([-N,N]\). The function \(g\), being the uniform limit of continuous functions, is continuous as well. As \(N\) is arbitrary, we are done.

**Solution to 1.6.3:**\(1\). For \(k\in\mathbb{N}\), consider the continuous functions \(g_{k}\) given by

\[g_{k}(x)=\left\{\begin{array}{lll}4k-16k^{2}|x-\frac{3}{4}k|&\mbox{if}&x\in[ \frac{1}{2k},\frac{1}{k}]\\ \\ 0&\mbox{if}&x\not\in[\frac{1}{2k},\frac{1}{k}]\end{array}\right.\]

Define \(f_{0}\equiv 0\), and, for \(k>0\), \(f_{k}(x)=\int_{0}^{x}g_{k}(t)dt\). We have \(f_{k}\in C^{1}(\mathbb{R}_{+})\), \(f_{k}(0)=0\), and \(f_{k}^{\prime}(x)=g_{k}(x)\to 0=f_{0}^{\prime}(x)\) for all \(x\in\mathbb{R}_{+}\). However,

\[\mathop{\underline{\rm lim}}_{n\to\infty}f_{k}(x)=\lim_{n\to\infty}\int_{0}^{x }g_{k}(t)dt=\int_{0}^{\infty}g_{k}(t)dt=1\neq f_{0}(x)\cdot\]

\(2\). \(f_{k}^{\prime}(x)\to f_{0}^{\prime}(x)\) uniformly on \(\mathbb{R}\).

**Solution to 1.6.4:** Let \(a_{0},\ldots,a_{D}\) be \(D+1\) distinct points in \([0,1]\). The polynomials \(f_{m}\), defined by

\[f_{m}(x)=\prod_{\stackrel{{ i=0}}{{i\neq m}}}^{D}\frac{x-a_{i}}{a _{m}-a_{i}}\quad\mbox{for}\quad m=0,\ldots,D\]

satisfy \(f_{m}(a_{i})=0\) for \(i\neq m\), \(f_{m}(a_{m})=1\). Any polynomial of degree, at most, \(D\) can be written

\[P(x)=\sum_{m=0}^{D}P(a_{m})f_{m}(x)\]

since the right-hand side is a polynomial of degree, at most, \(D\) which agrees with \(P\) in \(D+1\) points.

Let \(M\) be an upper bound of \(|f_{m}(x)|\) for \(x\in[0,1]\), \(m=0,\ldots,D\). Given \(\varepsilon>0\) let \(N\in\mathbb{N}\) be such that \(|P_{n}(a_{m})|\leq\frac{\varepsilon}{(D+1)M}\) for \(n\geq N\). Then we have

\[|P_{n}(x)|\leq\sum_{m=0}^{D}|P_{n}(a_{m})|\,|f_{m}(x)|<\varepsilon\]

therefore the convergence is uniform.

**Solution to 1.6.5:** As \(f\) is a homeomorphism of [0,1] onto itself, we may assume without loss of generality (by replacing \(f\) by \(1-f\)) that \(f\) is strictly increasing, with \(f(0)=0\) and \(f(1)=1\). We first treat the case where \(f^{\prime}\) is a continuous function. By the Stone-Weierstrass Approximation Theorem [13, pag. 284], there is a sequence of polynomials \(\{P_{n}\}\) which converge to \(f\) uniformly. Since \(f^{\prime}>0\), we may assume (by adding a small constant) that each of the \(P_{n}\) is positive. Further, since the \(P_{n}\)'s converge uniformly,

\[\int_{0}^{1}P_{n}(t)\,dt\to\int_{0}^{1}f^{\prime}(t)\,dt=f(1)=1.\]

Defining \(a_{n}\) by

\[a_{n}^{-1}=\int_{0}^{1}P_{n}(t)\,dt\]

we can replace each \(P_{n}\) by \(a_{n}P_{n}\), so we may assume that

\[\int_{0}^{1}P_{n}(t)\,dt=1.\]

Now consider the polynomials

\[Q_{n}(x)=\int_{0}^{x}P_{n}(t)\,dt.\]

\(Q_{n}(0)=0\), \(Q_{n}(1)=1\), and \(Q^{\prime}_{n}(x)=P_{n}(x)>0\) for all \(x\) and \(n\). Hence, each \(Q_{n}\) is a homeomorphism of the unit interval onto itself, and by their definition, the \(Q_{n}\)'s converge to \(f\) uniformly.

It is enough now to show that any increasing homeomorphism of the unit interval onto itself can be uniformly approximated by \(C^{1}\) homeomorphisms. Let \(r>0\) and

\[f_{r}(x)=\left\{\begin{array}{ll}e^{1-x^{-r}}&\mbox{for}\quad 0<x\leq 1\\ 0&\mbox{for}\quad\ x=0\end{array}\right.\]

A calculation shows that \(f_{r}\) is \(C^{1}\) on \([0,1]\), \(f_{r}(1)=1\), \(f^{\prime}_{r}(0)=0\), and \(f^{\prime}_{r}(1)=r\). For \(r,s>0\), let

\[g_{r\,s}(x)=\left\{\begin{array}{ll}f_{r}(x)&\mbox{for}\quad\ x\in[0,1]\\ -f_{s}(-x)&\mbox{for}\quad x\in[-1,0].\end{array}\right.\]

Each \(g_{r\,s}\) is a \(C^{1}\)-function such that \(g_{r\,s}(0)=0\), \(g_{r\,s}(1)=1\), \(g_{r\,s}(-1)=-1\), \(g^{\prime}_{r\,s}(-1)=s\), and \(g^{\prime}_{r\,s}(1)=r\). By scaling and translating, we can find a \(C^{1}\) function on any interval such that its values and the values of its derivative at both endpoints are any given positive values desired.

We can now approximate any continuous homeomorphism \(f\) as follows: Given \(\varepsilon>0\), choose \(n>0\) such that if \(|x-y|<1/n\), for these values \(|f(x)-f(y)|<\varepsilon\). (This is possible since \([0,1]\) is compact, so \(f\) is uniformly continuous there.) Partition \([0,1]\) into \(2n\) intervals of equal length. On the intervals \([2k/2n,(2k+1)/2n]\), \(0\leq k\leq n-1\), approximate \(f\) by the line segment joining \(f(2k/2n)\) and \(f((2k+1)/2n)\). On the other intervals, join the line segments by suitable functions as defined above to make the approximating function \(C^{1}\). Since \(f\) is an increasing function, this approximating function will always lie within \(\varepsilon\) of it.

**Solution to 1.6.6:** 1. For \(\varepsilon>0\), let \(S_{\varepsilon}=\{x\in[0,1]\,|\,f(x)\geq M-\varepsilon\}\). \(f(x)\geq M-\varepsilon\) if and only if for each \(n\), \(f_{n}(x)\geq M-\varepsilon\), so \(S_{\varepsilon}=\bigcap_{n\geq 1}f_{n}^{-1}([M-\varepsilon,\infty))\). So each \(S_{\varepsilon}\) is closed. By definition of supremum, each set \(S_{\varepsilon}\) is nonempty. Also, if \(\varepsilon_{i}\) are finitely many positive numbers, \(\bigcap_{i}S_{\varepsilon_{i}}=S_{\min\varepsilon_{i}}\neq\emptyset\). As \([0,1]\) is compact, the intersection of all sets \(S_{\varepsilon}\) is nonempty. Let \(t\) belong to this intersection. Then \(M\geq f(t)\geq M-\varepsilon\) for arbitrary \(\varepsilon>0\), so \(f(t)=M\).

2. Take \(f_{n}(x)=\min\{nx,1-x\}\).

**Solution to 1.6.9:** Let \(\varepsilon>0\). By uniform continuity, for some \(\delta>0\) we have \(|f(x)-f(y)|<\varepsilon\) for \(|x-y|<\delta\). Take \(N\) satisfying \(1/N<\delta\). For \(0\leq k\leq N\), lct \(\xi_{k}=k/N\), and divide \([0,1]\) into the intervals \([\xi_{k-1},\xi_{k}]\), \(1\leq k\leq N\). Since \(f_{n}\) tends to \(f\) pointwise, by taking the maximum over the finite set \(\{\xi_{k}\}\) we know that there exists \(M>0\) such that if \(n\geq M\), then \(|f_{n}(\xi_{k})-f(\xi_{k})|<\varepsilon\) for \(0\leq k\leq N\). Each of the \(f_{n}\)'s is nondecreasing, so we have, for \(x\in[\xi_{k-1},\xi_{k}]\),

\[f(\xi_{k-1})-\varepsilon<f_{n}(x)<f(\xi_{k-1})+2\varepsilon,\]

or

\[|f_{n}(x)-f(\xi_{k-1})|<2\varepsilon.\]

Therefore,

\[|f_{n}(x)-f(x)|\leq|f_{n}(x)-f(\xi_{k-1})|+|f(\xi_{k-1})-f(x)|<3\varepsilon.\]

Since this bound does not depend on \(x\), the convergence is uniform.

**Solution to 1.6.13:** Suppose that \(f_{n_{j}}\to f\) uniformly. Then \(f\) is continuous, and \(f(0)=\lim_{j\to\infty}\cos 0=1\). So there is \(\varepsilon>0\) with \(f(x)>\frac{1}{2}\) for \(|x|<\varepsilon\). If \(j\) is large enough, we have, by uniform convergence,

\[|f(x)-f_{n_{j}}(x)|<\frac{1}{2}\quad\text{forall}x,\qquad\frac{\pi}{2n_{j}}<\varepsilon.\]

For one such \(j\), and \(x=\frac{\pi}{2n_{j}}\), we get

\[\frac{1}{2}<f(x)\leq|f(x)-f_{n_{j}}(x)|+|f_{n_{j}}(x)|<\frac{1}{2}+f_{n_{j}}(x )=\frac{1}{2}+|\cos(\pi/2)|=\frac{1}{2}\]

a contradiction.

**Solution to 1.6.14:** Let \(f_{n}:[0,1]\to\mathbb{R}\) be defined by \(f_{n}(x)=x^{n}\). \([0,1]\) is compact, \(||f_{n}||=1\), but the sequence \(f_{n}\) is not equicontinuous.

Let \(\Omega=[0,1]\), and \(f_{n}(x)=n\). This sequence is clearly equicontinuous, \(\Omega\) is compact, but no subsequence of \(f_{n}\) can converge.

Consider now \(f_{n}:(0,\frac{1}{2})\to\mathbb{R}\), \(f_{n}(x)=x^{n}\). We have \(||f_{n}||\leq\frac{1}{2}\) and \(f_{n}\to 0\) uniformly. However, \((0,\frac{1}{2})\) is not compact.

**Solution to 1.6.15:** By the Arzela-Ascoli Theorem [13, pag. 273], it will suffice to prove that the sequence \(\{f_{n}\}\) is equicontinuous and uniformly bounded.

_Equicontinuity._ For \(0\leq x<y\leq 1\) and any \(n\),

\[|f_{n}(y)-f_{n}(x)|=\left|\int_{x}^{y}f_{n}^{\prime}(t)dt\right|\leq\int_{x}^{ y}t^{-\frac{1}{2}}dt=2\sqrt{y}-2\sqrt{x}\.\]

The function \(F(x)=2\sqrt{x}\) is continuous on \([0,1]\), hence uniformly continuous. Therefore, given \(\varepsilon>0\), there is a \(\delta>0\) such that \(|F(y)-F(x)|<\varepsilon\) whenever \(x\) and \(y\) are in \([0,1]\) and \(|y-x|<\delta\). By the inequality above, we then have \(|f_{n}(y)-f_{n}(x)|<\varepsilon\) for all \(n\) when \(|y-x|<\delta\), establishing the equicontinuity of the sequence.

_Uniform boundedness._ Since \(\int_{0}^{1}f_{n}(x)dx=0\), the function \(f_{n}\) cannot be always positive or always negative, so there is a point \(x_{n}\) on \([0,1]\) such that \(f_{n}(x_{n})=0\). Then, by the estimate found above,

\[|f_{n}(x)|\leq 2\left|\sqrt{x}-\sqrt{x_{n}}\right|\leq 2\]

for all \(x\).

**Solution to 1.6.16:** We claim that a subset \(A\) of \(M\) is compact iff \(A\) is closed, bounded and \(\{f^{\prime}\mid f\in A\}\) is equicontinuous. If \(A\) satisfies all conditions and \(\{f_{n}\}\) is a subsequence in \(A\) then \(\{f_{n}\}\) and \(\{f_{n}^{\prime}\}\) are bounded and equicontinuous and by the Theorem of Arzela-Ascoli [13, pag. 273],there is a subsequence \(\left\{f_{n_{j}}\right\}\) such that \(\left\{f_{n_{j}}\right\}\) and \(\left\{f^{\prime}_{n_{j}}\right\}\) are uniformly convergent and therefore, sequences of Cauchy. Since \(M\) is complete and \(A\) is closed, \(\left\{f_{n_{j}}\right\}\) converges to \(f\in A\) in \(M\), and \(A\) is compact.

On the other hand, if \(A\) is compact, consider the spaces:

\[\widetilde{M}=\left\{(f,f^{\prime})\,|\,f\in M\right\}\quad\widetilde{A}=\left\{ (f,f^{\prime})\,|\,f\in A\right\}\]

\(\widetilde{A}\) is compact in \(\widetilde{M}\), and so are each of the projections, and, by Arzela-Ascoli Theorem, \(\left\{f^{\prime}\,|\,f\in A\right\}\) is equicontinuous.

**Solution to 1.6.18:** We have

\[g_{n}(x)=g_{n}(0)+g^{\prime}_{n}(0)x+\frac{g^{\prime\prime}_{n}(\xi)}{2}x^{2}= \frac{g^{\prime\prime}_{n}(\xi)}{2}x^{2}\quad\text{for somc}\quad\xi\in(0,1)\]

so

\[|g_{n}(x)|\leq\frac{1}{2}\quad\text{for}\quad x\in[0,1].\]

Also,

\[|g^{\prime}_{n}(x)|=|g^{\prime}_{n}(x)-g^{\prime}_{n}(0)|\leq|g^{\prime\prime} _{n}(\xi)(x-0)|\leq 1\quad\text{for}\quad x\in[0,1].\]

Therefore,

\[|g_{n}(x)-g_{n}(y)|\leq|x-y|\quad\text{for}\;\;x,y\in[0,1].\]

The sequence \(\left\{g_{n}\right\}\) is then equicontinuous and uniformly bounded; so, by the Arzela-Ascoli's Theorem [19, pag. 273], it has a uniformly convergent subsequence.

**Solution to 1.6.19:** The answer is no. Consider the sequence of functions \(f_{n}:[0,1]\to\mathbb{R}\) whose graphs are given by the straight lines through the points \((0,0)\), \((1/2n,n)\), \((1/n,0)\) to \((1,0)\).

The sequence approximates the zero-function pointwise, but \(\int_{0}^{1}f_{n}(x)dx=1/2\) for all \(n\).

**Solution to 1.6.20:** Fix \(\varepsilon>0\). Since \(K\) is continuous on the unit square, a compact set, it is uniformly continuous there. Hence, there is a \(\delta>0\) such that \(|K(x_{1},y_{1})-K(x_{2},y_{2})|<\varepsilon\) whenever \(\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}<\delta\). Let \(f\) and \(g\) be as above, and suppose \(x_{1}\) and \(x_{2}\) are in [0,1] and satisfy \(|x_{1}-x_{2}|<\delta\). Then

\[|f(x_{1})-f(x_{2})| =\left|\int_{0}^{1}g(y)\left(K(x_{1},y)-K(x_{2},y)\right)\,dy\right|\] \[\leq\int_{0}^{1}|g(y)|\,\,|K(x_{1},y)-K(x_{2},y)|\,dy\] \[\leq\int_{0}^{1}1\cdot\varepsilon\,dy=\varepsilon\,.\]

As the estimate holds for all \(f\) in \(F\), the family \(F\) is equicontinuous.

**Solution to 1.6.23:** We will first show that \(\{g_{n}\}\) is a Cauchy sequence in sup-norm. Using the Cauchy-Schwarz Inequality [14, pag. 69], we have

\[|g_{n}(x)-g_{m}(x)|\leq\int_{0}^{1}|K(x,y)|(f_{n}(y)-f_{m}(y))dy\]1. Real Analysis \[\leq\left(\int_{0}^{1}|K(x,y)|^{2}dy\right)^{1/2}\left(\int_{0}^{1}|f_{n}(y)-f_{m} (y)|^{2}dy\right)^{1/2}\] hence, \[\sup_{x\in[0,1]}|g_{n}(x)-g_{n}(x)|\leq\sup_{x\in[0,1]}\left(\int_{0}^{1}|K(x, y)|^{2}dy\right)^{1/2}\!\!\!\left(\int_{0}^{1}\!\!\!|f_{n}(y)-f_{m}(y)|^{2}dy \right)^{1/2}\] Since \(K\) is continuous, it is integrable, and taking \(M=\sup_{x,y\in[0,1]}|K(x,y)|\), we have \[\|g_{n}(x)-g_{m}(y)\|\leq M\left(\int_{0}^{1}|f_{n}(y)-f_{m}(y)|^{2}dy\right)^ {1/2}\to 0\] showing that the sequence \(\{g_{n}\}\) is a Cauchy sequence in the sup-norm; as \(C[0,1]\) is complete on this norm, the sequence converges uniformly.

**Solution to 1.6.25:** As

\[\left|\frac{e^{i\lambda_{n}x}}{n^{2}}\right|\leq\frac{1}{n^{2}}\quad\text{and }\quad\sum_{n=1}^{\infty}\frac{1}{n^{2}}<\infty\]

by Weierstrass _M-test_[13, pag. 148], the given series converges uniformly on \(\mathbb{R}\) to a continuous function \(f\). We have, since the convergence is uniform,

\[\frac{1}{2T}\int_{-T}^{T}\sum_{n=1}^{\infty}\frac{e^{i\lambda_{n}x}}{n^{2}}dx= \frac{1}{2T}\sum_{n=1}^{\infty}\int_{-T}^{T}\frac{e^{i\lambda_{n}x}}{n^{2}}dx= \sum_{n=1}^{\infty}\frac{\sin\lambda_{n}T}{n^{2}\lambda_{n}T}.\]

As

\[\left|\frac{\sin\lambda_{n}T}{n^{2}\lambda_{n}T}\right|\leq\frac{1}{n^{2}}\]

we have, again by Weierstrass _M-test_, that

\[\sum_{n=1}^{\infty}\frac{\sin\lambda_{n}T}{n^{2}\lambda_{n}T}\]

converges uniformly in \(T\). Therefore, we get

\[\lim_{T\to\infty}\frac{1}{2T}\int_{-T}^{T}f(x)dx=\lim_{T\to\infty}\sum_{n=1}^{ \infty}\frac{\sin\lambda_{n}T}{n^{2}\lambda_{n}T}=\sum_{n=1}^{\infty}\lim_{T \to\infty}\frac{\sin\lambda_{n}T}{n^{2}\lambda_{n}T}=\sum_{\lambda_{n}=0} \frac{1}{n^{2}}.\]

**Solution to 1.6.26:** Let \(\sigma>1\). It suffices to show that \(\zeta(x)\) is defined and has continuous derivatives for \(x\geq\sigma\). The series \(\sum n^{-x}\) converges for such \(x\). As \(n^{-x}\leq n^{-\sigma}\), it follows from the Weierstrass _M-test_[13, pag. 148] that the series converges uniformly, so \(\zeta\) is a continuous function. To see that it has continuous derivatives of all orders, we formally differentiate the series \(k\) times, getting

\[\sum_{n=2}^{\infty}\frac{(-\log n)^{k}}{n^{x}}.\]

It is enough to show that this series converges uniformly on \(k\). Since

\[\left|\frac{(-\log n)^{k}}{n^{x}}\right|\leq\frac{(\log n)^{k}}{n^{\sigma}},\]

by the Weierstrass _M-test_, it will suffice to show that the series

\[\sum_{n=2}^{\infty}\frac{(\log n)^{k}}{n^{\sigma}}\]

converges. But

\[\frac{(\log n)^{k}}{n^{\sigma}}=o\left(\frac{1}{n^{\sigma-\varepsilon}}\right) \quad(n\to\infty),\]

for any positive \(\varepsilon\). As

\[\sum_{1}^{\infty}\left(\frac{1}{n^{\sigma-\varepsilon}}\right)\]

converges for \(\sigma-\varepsilon>1\), we are done.

**Solution to 1.6.27:** Fix an interval \([a,b]\) and \(\varepsilon>0\). Since \(f\) is continuous, it is uniformly continuous on the interval \([a,b+1]\), then there exists an \(N>0\) such that if \(n\geq N\) and \(|x-y|<1/n\) we have \(|f(x)-f(y)|<\varepsilon\). We will show that \(f_{n}(x)\) converges uniformly to

\[\int_{x}^{x+1}f(y)\,dy\]

for all \(x\) in the given interval. Fix \(x\) and \(n\geq N\). We have

\[\left|\int_{x}^{x+1}f(y)\,dy-f_{n}(x)\right|=\left|\sum_{k=0}^{n-1}\int_{x+k/n} ^{x+(k+1)/n}f(y)\,dy-f_{n}(x)\right|.\]

By the Mean Value Theorem for Integrals [12, pag. 457], for each \(k\) there is \(a_{k}\in(x+k/n,x+(k+1)/n)\) such that

\[\int_{x+k/n}^{x+(k+1)/n}f(y)\,dy=f(a_{k})/n.\]Substituting this in the above, expanding using the definition of \(f_{n}\), and using uniform continuity, we get

\[\left|\int_{x}^{x+1}f(y)\,dy-f_{n}(x)\right|<\frac{1}{n}\sum_{k=0}^{n-1}|f(a_{k}) -f(x+k/n)|<\varepsilon.\]

Since this holds for any \(x\), we are done.

**Solution to 1.6.28:** Let \(\alpha>0\). For \(|n|>4\alpha\), the bound on \(f\) gives, for \(x\in[-\alpha,\alpha]\),

\[|f(x+n)|\leq\frac{C}{1+n^{2}/2}=M_{n}.\]

As the series

\[\sum_{-\infty}^{\infty}M_{n}\]

converges, by the Weierstrass _M-test_[13, pag. 148], the series

\[\sum_{|n|>4\alpha}f(x+n)\]

converges uniformly. So the series for \(F(x)\) converges uniformly on \([-\alpha,\alpha]\) and \(F\) is continuous there. As \(\alpha\) is arbitrary, \(F\) is continuous on \(\mathbb{R}\).

We have

\[F(x+1)-F(x) =\lim_{\alpha\to\infty}\sum_{-\alpha}^{\alpha}\left(f(x+1+n)-f(x +n)\right)\] \[=\lim_{\alpha\to\infty}\left(f(x+1+\alpha)-f(x-\alpha)\right)\] \[=0\]

the last equality holding by our assumption on \(f\).

If \(G\) is continuous and periodic with period \(1\), then, since the series for \(F\) converges uniformly,

\[\int_{0}^{1}F(x)G(x)\,dx=\sum_{-\infty}^{\infty}\int_{0}^{1}f(x+n)G(x)\,dx.\]

In each integral on the right-hand side, let \(y=x+n\), and get, since \(G(y-n)=G(y)\),

\[\sum_{-\infty}^{\infty}\int_{n}^{n+1}f(y)G(y)\,dy=\int_{-\infty}^{\infty}f(y)G( y)\,dy.\]

**Solution to 1.6.29:** Given \(f\) and \(\varepsilon\), let \(h:[0,1]\to\mathbb{R}\) be defined by \(h(x)=f\left(\sqrt[4]{x}\right)\). By the Stone-Weierstrass Approximation Theorem [13, pag. 284], there is a polynomial \(P\) such that \(\left|P(x)-h(x)\right|<\varepsilon/2\) for \(x\in[0,1]\), from which it follows that

\[\left|P\left(x^{4}\right)-f(x)\right|=\left|P\left(x^{4}\right)-h\left(x^{4} \right)\right|<\varepsilon/2\quad\text{for}\quad x\in[0,1].\]

If \(P=\sum_{k=0}^{n}a_{k}x^{k}\), take \(C_{0},\ldots,C_{n}\in\mathbb{Q}\) such that \(\sum_{k=0}^{n}\left|a_{k}-C_{k}\right|<\varepsilon/2\). Then we have

\[\left|\sum_{k=0}^{n}C_{k}x^{4k}-f(x)\right|\leq\left|\sum_{k=0}^{n}C_{k}x^{4k} -\sum_{k=0}^{n}a_{k}x^{4k}\right|+\left|\sum_{k=0}^{n}a_{k}x^{4k}-f(x)\right|<\varepsilon.\]

### 1.7 Fourier Series

**Solution to 1.7.1:** 1. We have, for \(n\in\mathbb{N}\),

\[\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)\cos nx\ dx=0\]

because the integrand is an odd function. Also

\[\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)\sin nx\ dx =\frac{2}{\pi}\int_{0}^{\pi}f(x)\sin nx\ dx\] \[=\frac{2}{\pi}\left(-\frac{x\cos nx}{n}\Big{|}_{0}^{\pi}+\int_{0}^ {\pi}\frac{\cos nx}{n}\right)\] \[=\frac{2}{\pi}\frac{(-1)^{n+1}}{n},\]

so the Fourier series of \(f\) is

\[\sum_{n=1}^{\infty}\frac{(-1)^{n+1}2}{n}\sin nx.\]

2. If the series converged uniformly the function \(f\) would be continuous, which is not the case.

3. As \(f\) and \(f^{\prime}\) are sectionally continuous, we have

\[\sum_{n=1}^{\infty}\frac{(-1)^{n+1}2\sin nx}{n}=\frac{f(x-)+f(x+)}{2}=\left\{ \begin{array}{ll}f(x)&\text{if}\quad x\neq(2n+1)\pi\\ 0&\text{if}\quad x=(2n+1)\pi\end{array}\right.\]

where \(n\in\mathbb{Z}\).

**Solution to 1.7.2:** 1. Since \(f(x)\) is an odd function, the integrals

\[\frac{1}{\pi}\int_{-\pi}^{\pi}f(x)\cos nx\ dx\]vanish for \(n\in\mathbb{N}\). The Fourier series has only terms in \(\sin nx\) given by

\[b_{n}=\frac{1}{\pi}\int_{-\pi}^{\pi}x^{3}\sin nx\;dx.\]

2. As \(f\) and \(f^{\prime}\) are sectionally continuous, we have

\[\sum_{n=1}^{\infty}b_{n}\sin nx=\frac{f(x-)+f(x+)}{2}=\left\{\begin{array}{ ll}f(x)&\mbox{if}\quad x\neq(2n+1)\pi\\ 0&\mbox{if}\quad x=(2n+1)\pi\end{array}\right.\]

where \(n\in\mathbb{Z}\).

3. Using Parseval's Identity [11, pag. 577]

\[\frac{1}{2}a_{0}^{2}+\sum_{n=1}^{\infty}(a_{n}^{2}+b_{n}^{2})=\frac{1}{\pi} \int_{-\pi}^{\pi}f^{2}(x)\;dx\]

and the fact that all \(a_{n}=0\),

\[\sum_{n=1}^{\infty}b^{2}=\frac{1}{\pi}\int_{-\pi}^{\pi}x^{6}\;dx=\frac{2}{7} \pi^{6}.\]

**Solution to 1.7.3:** The answer is no; \(f(x)=1\) satisfies the above equation and is not identically zero.

**Solution to 1.7.4:** As \(f\) is \(\sqrt{2}\)-periodic, we have

\[\hat{f}(n)=\int_{0}^{1}f(x)e^{-2n\pi ix}\,dx=\int_{0}^{1}f(x+\sqrt{2}\,)e^{-2n \pi ix}\,dx.\]

Letting \(y=x+\sqrt{2}\), we get

\[\hat{f}(n)=e^{2n\pi i\sqrt{2}}\int_{\sqrt{2}}^{1+\sqrt{2}}f(y)e^{-2n\pi iy}\;dy.\]

Since \(f\) is also \(1\)-periodic, we have

\[\hat{f}(n)=e^{2n\pi i\sqrt{2}}\int_{0}^{1}f(y)e^{-2n\pi iy}\;dy=e^{2n\pi i\sqrt {2}}\hat{f}(n).\]

\(e^{2n\pi i\sqrt{2}}\neq 1\) for \(n\neq 0\), so \(\hat{f}(n)=0\) for \(n\neq 0\) and \(f\) is constant.

**Solution to 1.7.5:** Suppose that such an \(f\) exists. As the power series for \(\epsilon^{x}\) converges uniformly, we have, for \(n>0\),

\[\hat{f}(n)=\int_{0}^{1}f(x)e^{-2\pi inx}\,dx=\sum_{k=0}^{\infty}\frac{(-2\pi ni )^{k}}{k!}\int_{0}^{1}f(x)x^{k}\,dx=-2\pi ni.\]This equality contradicts the Riemann-Lebesgue Lemma [19, pag. 628], which says that \(\lim_{n\to\infty}\hat{f}(n)=0\), so no such a function can exist.

**Solution to 1.7.6:** The Fourier series of \(f\) converges to \(f\) because \(f^{\prime\prime}\) exists. Let the Fourier series of \(f\) be

\[\frac{\alpha_{0}}{2}+\sum_{n=1}^{\infty}(\alpha_{n}\cos nx+\beta_{n}\sin nx).\]

As \(f^{\prime\prime}=g-kf\) is continuous, we obtain its Fourier series by termwise differentiating the series for \(f\), and get

\[\frac{k\alpha_{0}}{2}+\sum_{n=1}^{\infty}\left(\left(k-n^{2}\right)\alpha_{n} \cos nx+\left(k-n^{2}\right)\beta_{n}\sin nx\right)=\]

\[\frac{a_{0}}{2}+\sum_{n=1}^{\infty}(a_{n}\cos nx+b_{n}\sin nx).\]

So we have

\[\alpha_{0}=\frac{a_{0}}{k}\;,\quad\alpha_{n}=\frac{a_{n}}{k-n^{2}}\;,\quad \beta_{n}=\frac{b_{n}}{k-n^{2}}\quad\text{for}\quad n\geq 1\cdot\]

**Solution to 1.7.7:** Consider the Fourier series of \(f\),

\[f(x)=\frac{a_{0}}{2}+\sum_{n=1}^{\infty}(a_{n}\cos nx+b_{n}\sin nx).\]

We have \(a_{0}=0\), and, by Parseval's Identity [19, pag. 577],

\[\int_{0}^{2\pi}f^{2}(x)dx=\pi\sum_{n=1}^{\infty}\left(a_{n}^{2}+b_{n}^{2} \right)\leq\pi\sum_{n=1}^{\infty}\left(n^{2}a_{n}^{2}+n^{2}b_{n}^{2}\right)= \int_{0}^{2\pi}(f^{\prime}(x))^{2}dx.\]

**Solution to 1.7.8:** The Riemman-Lebesgue Lemma [19, pag. 628] states that the result is valid for all functions \(g(x)\) of the type

\[\cos(k\pi x)\quad\text{and}\quad\sin(k\pi x)\]

using linearity of the integral; the result extends to all finite trigonometric polynomials

\[p(x)=\sum_{k=0}^{n}a_{k}\cos(k\pi x)+b_{n}\sin(k\pi x)\;.\]

We will now use the fact that the set of trigonometric polynomials is dense in the space of continuous functions with the _sup_ norm (Stone-WeierstrassApproximation Theorem [13, pag. 284]) to extend it to all continuous functions. Given any \(\varepsilon>0,\) there exists a \(p_{\varepsilon}(x)\) as above such that

\[\left|g(x)-p_{\varepsilon}(x)\right|<\varepsilon\]

then

\[\left|\lim_{n\to\infty}\int_{0}^{1}f(x)g(nx)dx-\int_{0}^{1}f(x) dx\int_{0}^{1}g(x)dx\right.\\ -\left(\lim_{n\to\infty}\int_{0}^{1}f(x)p_{\varepsilon}(nx)dx- \int_{0}^{1}f(x)dx\int_{0}^{1}p_{\varepsilon}(x)dx\right)\right|\leq\\ \leq\left|\lim_{n\to\infty}\int_{0}^{1}f(x)(g(nx)-p_{\varepsilon} (nx))dx\right|+\left|\int_{0}^{1}f(x)dx\int_{0}^{1}(g(x)-p_{\varepsilon}(x))dx\right|\] \[\leq\lim_{n\to\infty}\int_{0}^{1}\left|f(x)\right|\left|g(nx)-p_{ \varepsilon}(nx)\right|dx+\int_{0}^{1}\left|f(x)\right|dx\int_{0}^{1}\left|g( x)-p_{\varepsilon}(x)\right|dx\] \[\leq 2\varepsilon\int_{0}^{1}\left|f(x)\right|dx\]

and the result follows.

### 1.8 Convex Functions

**Solution to 1.8.1:** Let \(M=\max_{x\in[0,1]}|f(x)|.\) Consider a sequence \((x_{n})\) such that \(x_{0}=1,\) and \(0<x_{n}<3^{-1}x_{n-1}\) satisfies \(|f(x)|<M/2^{n}\) for \(0<x<x_{n}.\) Define \(g:[0,1]\to[0,1]\) by \(g(0)=0\) and, using the fact that \(x_{n}\to 0,\)

\[g(x)=t\frac{M}{2^{n}}+(1-t)\frac{M}{2^{n-1}}\]

for \(0<x=tx_{n+1}+(1-t)x_{n},\)\(t\in[0,1]\,,\)\(n=0,1,\ldots.\) We have \(g\geq f\) and

\[\frac{g(x_{n})-g(x_{n+1})}{x_{n}-x_{n+1}}=\frac{M/2^{n}}{x_{n}-x_{n+1}}>\frac{M /2^{n-1}}{x_{n}-x_{n+1}}=\frac{g(x_{n-1})-g(x_{n})}{x_{n-1}-x_{n}}\]

so \(g\) is concave.

**Solution to 1.8.2:** For \(x\neq y\) and \(t\in[0,1],\) let

\[c=(\log f(y)-\log f(x))/(x\ -\ y)\,.\]

By hypothesis, we have

\[e^{c(tx+(1-t)y)}f(tx+(1-t)y)\leq te^{cx}f(x)+(1-t)e^{cy}f(y)\]\[f(tx+(1-t)y) \leq te^{c(x-y)(1-t)}f(x)+(1-t)e^{-c(x-y)t}f(y)\] \[=te^{(\log f(y)-\log f(x))(1-t)}f(x)+(1-t)e^{(\log f(x)-\log f(y))t} f(y)\] \[=t\left(\frac{f(x)}{f(y)}\right)^{t-1}f(x)+(1-t)\left(\frac{f(x)} {f(y)}\right)^{t}f(y)\] \[=f(x)^{t}f(y)^{1-t}\]

taking logarithms, we get that \(\log f\) is convex.

**Solution to 1.8.3:** Consider an interval \([a,b]\) and suppose that the maximum of \(f\) does not occur at one of its endpoints. Then, by Weierstrass Theorem [19, pag. 189], there is \(c\in(a,b)\) maximizing \(f\). By the continuity of \(f\), there are intervals \(A=[a,a_{0}]\) and \(B=[b_{0},b]\) in \([a,b]\) with \(f(x)<f(c)\) if \(x\) lies in \(A\) or \(B\). By the Mean Value Inequality for Integrals [19, pag. 457], we have

\[f(c) \leq\frac{1}{2h}\int_{A}f(y)\,dy+\frac{1}{2h}\int_{[a_{0},b_{0}]}f (y)\,dy+\frac{1}{2h}\int_{B}f(y)\,dy\] \[<\frac{a_{0}-a}{2h}f(c)+\frac{b_{0}-a_{0}}{2h}f(c)+\frac{b-b_{0}} {2h}f(c)\] \[=f(c).\]

This contradiction shows that \(f\) must attain its maximum at \(a\) or \(b\).

If \(L(x)\) is any linear function, a straightforward calculation shows that \(L\) is convex and satisfies the _mean value inequality_ above, and that both of these inequalities are, in fact, equalities. Now let \(L\) be given by

\[L(x)=\frac{(x-a)f(b)-(x-b)f(a)}{b-a}\]

and consider \(G(x)=f(x)-L(x)\). By the linearity of the integral, since \(f\) and \(L\) satisfy the Mean Value Inequality, \(G\) does as well. Therefore, \(G\) takes its maximum value at \(a\) or \(b\). A calculation shows that \(G(a)=G(b)=0\). Therefore, we must have that \(f(x)\leq L(x)\) for all \(x\in[a,b]\). For any \(t\in[0,1]\), \((1-t)a+tb\in[a,b]\). Substituting this into the inequality gives that \(f\) is convex.

## 2 Multivariable Calculus

### 2.1 Limits and Continuity

**Solution to 2.1.1:** Let \(x\in\mathbb{R}^{n}\), \(\varepsilon>0\), and let \(B\) denote the open ball with center \(f(x)\) and radius \(\varepsilon\). For \(n=1,2,\ldots\), let \(K_{n}\) be the closed ball with center \(x\) and radius \(1/n\). By (ii) we have \(\cap_{1}^{\infty}f(K_{n})=\{f(x)\}\). By (i) the sets \((\mathbb{R}^{n}-B)\cap f(K_{n})\) are compact for \(n=1,2,\ldots\). They form a decreasing sequence, and their intersection is empty, by the preceding equality. Hence, there is an \(n_{0}\) such that \((\mathbb{R}^{n}-B)\cap f(K_{n_{0}})=\emptyset\), which means that \(|f(y)-f(x)|<\varepsilon\) whenever \(|y-x|<1/n_{0}\). So \(f\) is continuous at \(x\).

**Solution to 2.1.4:** We show that \(f\) is continuous at \((0,0)\); for the general case, use a change of variables. By adding a constant, if necessary, we may assume \(f(0,0)=0\). Suppose \(f\) is not continuous at the origin. Then, for any \(\varepsilon>0\), there is a sequence \(((x_{n},y_{n}))\) tending to the origin with \(|f(x_{n},y_{n})|\geq\varepsilon\) for each \(n\). Since \(f\) is continuous in the first variable, there exists a \(\delta>0\) such that if \(|x|<\delta\), then \(|f(x,0)|<\varepsilon/2\). Applying this to our sequence, we see that there is an \(N>0\), such that if \(n\geq N\) then \(|x_{n}|<\delta\), so \(|f(x_{n},0)|<\varepsilon/2\). However, for each such \(n\), \(f(x_{n},y)\) is continuous in the second variable, so by the Intermediate Value Theorem [13, pag. 93], there exists \(y_{n}^{\prime}\), \(0<y_{n}^{\prime}<y_{n}\), such that \(|f(x_{n},y_{n}^{\prime})|=n\varepsilon/(n+1)\). Since the \(y_{n}\)'s tend to \(0\) as \(n\) tends to infinity; the \(y_{n}^{\prime}\)'s do so as well. Hence, the set \(E=\{(x_{n},y_{n}^{\prime})\,|\,n\geq N\}\cup\{(0,0)\}\) is compact. Then by our hypothesis, the set \(f(E)\) is compact. But \(f(E)=\{n\varepsilon/(n+1)\,|\,n\geq N\}\cup\{0\}\), and \(\varepsilon\) is alimit point of this set which is not contained in it, a contradiction. Hence, \(f\) is continuous at the origin and we are done.

**Solution to 2.1.5:** Continuity implies \(f(0)=0\), so if any \(x_{k}\) is 0, then so are all subsequent ones, and the desired conclusion holds. Assume therefore, that \(x_{k}\neq 0\) for all \(k\). The sequence \((\|x_{k}\|)\) is then a decreasing sequence of positive numbers, so it has a nonnegative limit, say \(c\). Suppose \(c>0\). The sequence \((x_{k})\), being bounded, has a convergent subsequence, say \(\big{(}x_{k_{j}}\big{)}\), with limit \(\alpha\). Then \(\|\alpha\|=\lim_{j\to\infty}\|x_{k_{j}}\|=c\). Hence, \(\|f(\alpha)\|<c\). But, by the continuity of \(f\),

\[f(\alpha)=\lim_{j\to\infty}f\left(x_{k_{j}}\right)=\lim_{j\to\infty}x_{k_{j}+1},\]

and \(\|x_{k_{j}+1}\|\geq c\) for all \(j\), so we have a contradiction, and the desired conclusion follows.

### 2.2 Differential Calculus

**Solution to 2.2.1:** We maximize the function \(f(x,y)=(x^{2}+y^{2})e^{-x-y}\) in the first quadrant, \(x\geq 0\) and \(y\geq 0\). The function attains a maximum there because it is nonnegative and tends to 0 as either variable tends to \(\infty\). We have

\[\frac{\partial f}{\partial x}=(2x-x^{2}-y^{2})e^{-x-y}\,\qquad\frac{\partial f }{\partial y}=(2y-x^{2}-y^{2})e^{-x-y}\.\]

The critical points of \(f\) are thus the points \((x,y)\) that satisfy

\[2x-x^{2}-y^{2}=0=2y-x^{2}-y^{2}\.\]

These equalities imply \(x=y\) and

\[2x^{2}-2x=0\,\qquad 2y^{2}-2y=0\.\]

Hence, the critical points are (1,1) and (0,0). Obviously, \(f\) does not attain its maximum at the latter point. The only candidate in the open quadrant for a point at which \(f\) attains its maximum is (1,1).

On the \(x\)-axis, we have \(f(x,0)=x^{2}e^{-x}\) and \(\frac{df(0,x)}{dx}=(x^{2}-2x)e^{-x}\), so \(\frac{df(0,x)}{dx}=0\) only for \(x=0\) and \(x=2\). The point (2,0) is thus another candidate for the point at which \(f\) attains its maximum. By the same reasoning, the point (0,2) is another such candidate. The points (2,0) and (0,2) are the only candidates on the boundary of the quadrant.

We have

\[f(1,1)=2e^{-2}\,\qquad f(2,0)=4e^{-2}=f(0,2)\.\]Hence, the maximum value of \(f\) in the quadrant is \(4e^{-2}\), that is, \[(x^{2}+y^{2})e^{-x-y} \leq 4e^{-2}\] \[\frac{x^{2}+y^{2}}{4} \leq e^{x+y-2}\] for \(x\geq 0\), \(y\geq 0\). Solution to 2.2.2:The function \(f\) is differentiable at the point \(z=(x_{0},y_{0})\in\ U\) if there is a linear transformation \(f^{\prime}(z)\in L\left(\mathbb{R}^{2},\mathbb{R}^{1}\right)\) such that \[\lim_{h\to 0}\frac{|f(z+h)-f(z)-f^{\prime}(z)h|}{\|h\|}=0.\] Continuity of the partial derivatives is a sufficient condition for differentiability. A calculation gives \[\frac{\partial f}{\partial x}(x,y)=\left\{\begin{array}{ll}(4/3)x^{1/3}\sin(y /x)-yx^{-2/3}\cos(y/x)&\mbox{if}\quad x\neq 0\\ 0&\mbox{if}\quad x=0\end{array}\right.\] \[\frac{\partial f}{\partial y}(x,y)=\left\{\begin{array}{ll}x^{1/3}\cos(y/x) &\mbox{if}\quad x\neq 0\\ 0&\mbox{if}\quad x=0\end{array}\right.\] which are continuous on \(\mathbb{R}^{2}\setminus\{(0,y)\,|\,y\in\mathbb{R}\}\). Thus, \(f\) is differentiable there. At any point \((0,y)\), we have \[\frac{f(h,k)-f(0,y)}{\|(h,k)\|}=O(|h|^{1/3})=o(1)\quad(h\to 0)\] so \(f\) is differentiable at these points also. Solution to 2.2.3:Since \(f\) is continuous and \(\mathbb{R}^{n}\) is connected, \(f(\mathbb{R}^{n})\) is connected. We will prove that \(f(\mathbb{R}^{n})\) is both open and closed in \(\mathbb{R}^{n}\). This will imply that \(f(\mathbb{R}^{n})=\mathbb{R}^{n}\), because \(f(\mathbb{R}^{n})\neq\emptyset\).

Let \(y=f(x)\in f(\mathbb{R}^{n})\). As the rank of \((\partial f_{i}/\partial x_{j})\) is \(n\), by the Inverse Function Theorem [Rud87, pag. 221], there are open neighborhoods \(V_{x}\) and \(V_{y}\) of \(x\) and \(y\) such that \(f|_{V_{x}}:V_{x}\to V_{y}\) is a diffeomorphism; therefore, \(V_{y}\) is an open neighborhood of \(y\), and \(f(\mathbb{R}^{n})\) is open.

Let \((y_{n})\) be a sequence in \(f(\mathbb{R}^{n})\) converging to \(y\in\mathbb{R}^{n}\), \(f(x_{n})=y_{n}\), say. The set \(K=\{y_{n}\,|\,n\in\mathbb{N}\}\cup\{y\}\) is compact; therefore, \(f^{-1}(K)\) is also compact. But \(\{x_{n}\,|\,n\in\mathbb{N}\}\subset f^{-1}(K)\); therefore, it contains a convergent subsequence, say \((x_{n_{j}})\) with \(x_{n_{j}}\to x\in\mathbb{R}^{n}\). Since \(f\) is continuous, \(f(x_{n_{j}})\to f(x)\). But \(\lim_{j\to\infty}y_{n_{j}}=y\); therefore, \(f(x)=y\), and \(f(\mathbb{R}^{n})\) is closed. Solution to 2.2.4:We have \(\mathbb{R}^{2}=f(S)\cup\left(\mathbb{R}^{2}\setminus f(S)\right)\) where \(S\) is the set of singularities of \(f\). It suffices to show that \(f\) maps \(R=\mathbb{R}^{2}\setminus f^{-1}\left(f(S)\right)\) onto \(\mathbb{R}^{2}\setminus f(S)\). \(f(S)\) is finite, so \(\mathbb{R}^{2}\setminus f(S)\) is connected. As \(f(S)\) is closed, \(R\) is open. It suffices to show that \(f(R)\) is open and closed in \(\mathbb{R}^{2}\setminus f(S)\).

[MISSING_PAGE_FAIL:206]

Therefore, \(g\) has a local maximum at some \(t_{0}\in(0,1)\). We have \(g^{\prime\prime}(t_{0})\leq 0\), but

\[g^{\prime\prime}(t_{0})=f^{\prime\prime}(tp_{1}+(1-t_{0})p_{2})(p_{1}-p_{2})^{2} =\langle p_{1}-p_{2},H(p_{1}-p_{2})\rangle\]

and our assumptions on \(H\) imply \(\langle p_{1}-p_{2},H(p_{1}-p_{2})\rangle>0\), a contradiction.

**Solution to 2.2.7:** As the Laplacian of \(f\) is positive, the Hessian of \(f\) has positive trace everywhere. However, since \(f\in C^{3}\), for \(f\) to have a relative maximum its Hessian must have negative eigenvalues and so its trace must be negative.

**Solution to 2.2.9:** The derivative of \(T\) is given by

\[DT=\left(\begin{array}{cc}1&2u\\ 1&2v\end{array}\right)\]

which is always nonsingular since \(\det(DT)=2v-2u\) is never \(0\). By the Inverse Function Theorem [13, pag. 221], this means that \(T\) is locally one-to-one.

2. Considering the function \(f(u,v)=u+v\) restricted to \(u^{2}+v^{2}=y\), we conclude that \(-\sqrt{2y}\leq u+v\leq\sqrt{2y}\); therefore, the range of \(T\) is

\[\left\{(x,y)\,|\,y>0\,,\,-\sqrt{2y}\leq x\leq\sqrt{2y}\right\}.\]

Let \((x,y)\in\mbox{range}(T)\). \(u+v=x\) is the equation of a straight line with slope \(-1\) in the \(u,v\)-plane which intersects the circle \(u^{2}+v^{2}=y\) centered at the origin with radius \(\sqrt{y}\). These two lines intersect exactly at one point in \(U\), so \(T\) is globally injective.

**Solution to 2.2.10:** Letting \(f_{1}\) and \(f_{2}\) be the components of \(f\), we have

\[\frac{d}{dt}\|f(t)\|^{2}=2f_{1}f_{1}^{\prime}(t)+2f_{2}f_{2}^{\prime}(t).\]

Assume \(t>0\) and use the Mean Value Theorem [13, pag. 108] to rewrite the right side as

\[2t\,(f_{1}^{\prime}(\xi_{1})f_{1}^{\prime}(t)+f_{2}^{\prime}(\xi_{2})f_{2}^{ \prime}(t))\]

where \(0<\xi_{1}=\xi_{1}(t)<t\) and \(0<\xi_{2}=\xi_{2}(t)<t\). As \(t\searrow 0\), the continuity of \(f^{\prime}\) gives

\[f_{1}^{\prime}(\xi_{1})f_{1}^{\prime}(t)+f_{2}^{\prime}(\xi_{2})f_{2}^{\prime} (t)\longrightarrow\|f^{\prime}(0)\|^{2}>0.\]

Hence, there is an \(\varepsilon>0\) such that \(\frac{d}{dt}\|f^{\prime}(t)\|^{2}>0\) for \(0<t<\varepsilon\), and the dcsired conclusion follows.

**Solution to 2.2.11:** For \(X\in\Sigma\), we have

\[\|A-X\|^{2} =(1-x)^{2}+y^{2}+z^{2}+(2-t)^{2}\] \[=y^{2}+z^{2}+1-2x+x^{2}+(2-t)^{2}\] \[\geq\pm 2yz+1-2x+2|x|(2-t)\] \[=4|x|-2x+2(\pm yz-|x|t)+1\]

We can choose the sign, so \(\pm yz-|x|t=0\) because \(\det X=0\). As \(4|x|-2x\geq 0\), we have \(\|A-X\|\geq 1\) with equality when \(4|x|-2x=0\), \(|x|=2-t\), \(y=\pm z\), and \(\det X=xt-yz=0\), which give \(S=\left(\begin{smallmatrix}0&0\\ 0&2\end{smallmatrix}\right)\).

**Solution to 2.2.13:** Each element of \(P_{2}\) has the form \(ax^{2}+bx+c\) for \((a,b,c)\in\mathbb{R}^{3}\), so we can identify \(P_{2}\) with \(\mathbb{R}^{3}\) and \(J\) becomes a scalar field on \(\mathbb{R}^{3}\):

\[J(a,b,c)=\int_{0}^{1}(ax^{2}+bx+c)^{2}\,dx=\frac{a^{2}}{5}+\frac{ab}{2}+\frac{ 2ac}{3}+\frac{b^{2}}{3}+bc+c^{2}.\]

To \(Q\) corresponds the set \(\{(a,b,c)\,|\,a+b+c=1\}\). If \(J\) achieves a minimum value on \(Q\), then, by the Method of Lagrange Multipliers [13, pag. 414], we know that there is a constant \(\lambda\) with \(\nabla J=\lambda\nabla g\), where \(g(a,b,c)=a+b+c-1\). We have

\[\nabla J=\left(\frac{2a}{5}+\frac{b}{2}+\frac{2c}{3},\;\frac{a}{2}+\frac{2b}{3 }+c,\;\frac{2a}{3}+b+2c\right)\]

and \(\nabla g=(1,1,1)\). These and the constraint equation \(g(a,b,c)=0\) form the system

\[\left(\begin{array}{cccc}2/5&1/2&2/3&-1\\ 1/2&2/3&1&-1\\ 2/3&1&2&-1\\ 1&1&1&0\end{array}\right)\left(\begin{array}{c}a\\ b\\ c\\ \lambda\end{array}\right)=\left(\begin{array}{c}0\\ 0\\ 0\\ 1\end{array}\right)\]which has the unique solution \(\lambda=2/9\), \((a,b,c)=(10/3,-8/3,1/3)\). Therefore, if \(J\) attains a minimum, it must do so at this point. To see that \(J\) does attain a minimum, parameterize the plane \(Q\) with the \(xy\) coordinates and consider the quadratic surface with a linear \(z\) term defined by \(z=J(x,y,1-x-y)\) in \(\mathbb{R}^{3}\). The surface is the graph of the map \(J:P_{2}\to\mathbb{R}\). Rotating around the \(z\)-axis will eliminate the \(xy\) cross-terms in the equation, reducing it to the standard equation of either an elliptic paraboloid or a hyperbolic paraboloid. However, \(J\) is always nonnegative, so the surface must be an elliptic paraboloid and, as such, has a minimum.

**Solution to 2.2.17:** Let \((x,t)\in\mathbb{R}^{2}\). By the Mean Value Theorem, [10, pag. 108] and the hypothesis, we have, for some \((\xi,\eta)\) in the segment connecting \((x,y)\) to \((x+y,0)\),

\[f(x,t)-f(x+t,0) =Df(\xi,\eta)\cdot((x,t)-(x+t,0))\] \[=\left(\frac{\partial f}{\partial x}(\xi,\eta),\frac{\partial f} {\partial t}(\xi,\eta)\right)\cdot(-t,t)\] \[=t\left(\frac{\partial f}{\partial x}(\xi,\eta)-\frac{\partial f} {\partial t}(\xi,\eta)\right)\] \[=0\] so \(f(x,t)=f(x+t,0)>0\).

**Solution to 2.2.18:** Given two points \(x\) and \(y\in\mathbb{R}^{n}\) one can build a polygonal path from \(x\) to \(y\) with \(n\) segments all parallel to the axis (adjusting one coordinate at a time). Applying the Mean Value Theorem [10, pag. 108] to each of the segments of the path, we have \(|f(x_{1},\ldots,x_{i-1},x_{i},y_{i+1},\ldots,y_{n})-f(x_{1},\ldots,x_{i-1},y_{i},y_ {i+1},\ldots,y_{n})|\leq K|x_{i}-y_{i}|\)

and then

\[|f(x)-f(y)| \leq\sum_{i=1}^{n}|f(x_{1},\ldots,x_{i-1},x_{i},y_{i+1},\ldots,y_{ n})\] \[\quad-f(x_{1},\ldots,x_{i-1},y_{i},y_{i+1},\ldots,y_{n})|\] \[\leq K\sum_{i=1}^{n}|x_{i}-y_{i}|.\]

Now applying the Cauchy-Schwarz Inequality [13, pag. 69] to the vectors \((1,1,\ldots,1)\) and \(x-y\), we get

\[|f(x)-f(y)| \leq K\sqrt{\sum_{i=1}^{n}1}\ \sqrt{\sum_{i=1}^{n}|x_{i}-y_{i}|^{2}}\] \[=\sqrt{n}\ K\left\|x-y\right\|.\]

**Solution to 2.2.19:** Let \(((x_{1},\ldots,x_{n}))_{k}\) be a sequence in \(\mathbb{R}^{n}\) converging to \((0,\ldots,0)\). This sequence is Cauchy, so there is an \(N>0\) such that if \(k,l>N\), then for each of the coordinates we have \(|x_{ik}-x_{il}|<\varepsilon/2nM\). Then we draw a polygonal path, as in the Solution to Problem 2.2.18, from \((x_{1k},\ldots,x_{nk})\) to \((x_{1l},\ldots,x_{nl})\), parallel to the axes.

If this path does not goes through the origin, then as before

\[|f(x_{1k},\ldots,x_{nk})-f(x_{1l},\ldots,x_{nl})|<M\sum_{i=1}^{n}|x_{ik}-x_{il} |<\varepsilon\]

and if the origin is in one of the segments of the polygonal path, we can perturb it a bit, by traversing in the same direction but \(\varepsilon/4M\) away from the origin. On this altered path

\[|f(x_{1k},\ldots,x_{nk})-f(x_{1l},\ldots,x_{nl})|<M\sum_{i=1}^{n}|x_{ik}-x_{il }|+2M\frac{\varepsilon}{4M}\leq\varepsilon\]

in both case the sequence \((f(x_{1},\ldots,x_{n}))_{k}\) is Cauchy and, thus, it converges. Given any other sequence \(\big{(}(x_{1},\ldots,x_{n})\big{)}_{k}^{{}^{\prime}}\), an identical argument shows that \(|f(x_{in},\ldots,x_{in})-f(x_{in}^{{}^{\prime}},\ldots,x_{in}^{{}^{\prime}})|\) tends to \(0\), so all sequences must converge to the same value, which can be defined as the continuous extension of \(f\) to the origin. For \(n=1\), consider the function \(f(x)=1\) if \(x<0\) and \(f(x)=0\) if \(x>0\).

**Solution to 2.2.20:**: 1. The answer is no, and a counterexample is the function

\[f(x,y)=\frac{xy}{x^{2}+y^{2}},\qquad\text{for}\,(x,y)\neq(0,0)\]

\(f\) is differentiable everywhere, but cannot be extended continuously to the origin, because it is constant equal to \(k/(1+k^{2})\) on each line \(y=kx\) passing through the origin.

2. The answer is again no, with the counterexample a variant of the previous one, the function

\[g(x,y)=\frac{xy^{2}}{x^{2}+y^{2}}\qquad\text{and}\qquad g(0,0)=0\]

\(g\) is now continuous everywhere, but not differentiable because the directional derivative does not depend linearly on the vector. Let \((u,v)\neq(0,0)\). We have

\[\lim_{t\to 0}\frac{g((0,0)+t(u,v))-g(0,0)}{t}=\lim_{t\to 0}t\frac{uv^{2}}{u^{2}+v^{2}}=0.\]

So the directional derivatives at the origin exist in all directions. If \(g\) were differentiable at \((0,0)\), as all the directional derivatives vanish there, we would have \(Dg(0,0)=0\) (the zero linear map). Then, by definition of differentiability, we would have

\[g(x,y)=o(\left\|(x,y)\right\|)\qquad((x,y)\to(0,0))\]which is absurd, since

\[\lim_{(x,y)\underset{x=y}{\rightarrow}(0,0)}\frac{g(x,y)}{\|(x,y)\|}=\lim_{x \to 0}\frac{x^{3}}{2x^{2}\sqrt{2x^{2}}}\neq 0.\]

Both examples are from [Lim82].

**Solution to 2.2.21:** A simple counterexample is

\[f(x,y)=\left\{\begin{array}{ll}x&\text{if}\quad y=0\\ 0&\text{if}\quad y\neq 0\end{array}\right.\]

and not even continuity at the origin and \(C^{1}\) on the rest of the plane is enough to guarantee differentiability, as shown in the counterexample of Problem 2.2.20, Part 2.

**Solution to 2.2.22:** Let \(\varepsilon>0.\) By the hypothesis, there is \(\delta\) such that \(\|Df(w)\|<\varepsilon\) if \(\|w\|<\delta.\) For \(\|x\|<\delta,\) by the Mean Value Theorem [Rud87, pag. 108], applied to the line segment joining \(0\) and \(x,\) we have

\[\|f(x)-f(0)\|\leq\|Df(\xi x)\|\|x-0\|<\varepsilon\|x\|\quad\text{for some} \quad 0<\xi<1,\]

which implies differentiability at the origin.

**Solution to 2.2.25:** The answer is no; to see it, consider \(f(x_{1},x_{2},x_{3})=1-x_{1}^{2}-x_{2}^{2}-x_{3}^{2}.\)

**Solution to 2.2.26:** Fix a point \(x\in\mathbb{R}^{n}.\) By the Chain Rule [Rud87, pag. 214],

\[D(g\circ f)(x)=\left(\left(Dg\right)\left(f(x)\right)\right)\left(\left(Df \right)(x)\right)=0.\]The transformation \((Dg)\left(f(x)\right):\mathbb{R}^{n}\to\mathbb{R}\) is nonzero because \(g\) has no critical points. The preceding equality therefore implies that the transformation \((Df)(x):\mathbb{R}^{n}\to\mathbb{R}^{n}\) is noninvertible, so its determinant vanishes. That determinant is the Jacobian determinant of \(f\) at \(x\).

**Solution to 2.2.27:** 1. Let \(F:\mathbb{R}^{2}\to\mathbb{R}\) be defined by \(F(x,t)=f(x)-tg(x)\). Then \(F\) is a smooth scalar field with \(F(0,0)=0\) and

\[\frac{\partial F}{\partial x}(0,0)=f^{\prime}(0)-0g^{\prime}(0)\neq 0.\]

Therefore, by the Implicit Function Theorem [13, pag. 224], there exists a positive \(\delta\) such that, for \(|t|<\delta\), \(x\) is a smooth function of \(t\), with \(x(0)=0\).

2. Differentiating both sides of \(f(x(t))=tg(x(t))\) with respect to \(t\), we have, for \(|t|<\delta\),

\[x^{\prime}(t)=\frac{g(t)}{f^{\prime}(t)}.\]

As \(x(0)=0\), the desired expansion of \(x(t)\) is

\[\frac{g(0)}{f^{\prime}(0)}t.\]

**Solution to 2.2.30:** Consider the function \(G:\mathbb{R}^{2}\to\mathbb{R}^{2}\) given by

\[G(x,y)=\left(\begin{array}{c}u(x,y)\\ v(x,y)\end{array}\right).\]

Since \(\nabla u\) and \(\nabla v\) are linearly dependent and \(\nabla u\) is never \(0\), \(G^{\prime}\) has rank \(1\) everywhere. Therefore, by the Rank Theorem [1, pag. 391], given a point \(p_{0}\in\mathbb{R}^{2}\), there is a neighborhood \(V\) of \(p_{0}\), an open set \(W\subset\mathbb{R}^{2}\), a diffeomorphism \(h:W\to V\), and a \(C^{1}\)-function \(g=(g_{1},g_{2}):\mathbb{R}\to\mathbb{R}^{2}\) such that \(G\left(h(x,y)\right)=g(x)\) on \(W\). So \(g_{1}^{\prime}(x)\) is never \(0\). Therefore, by the Inverse Function Theorem [13, pag. 221], \(g_{1}\) is locally invertible. By shrinking the set \(W\) (and so the set \(V\)), we may assume that it is invertible. Therefore, \(g_{1}^{-1}\left(u\left(h(x,y)\right)\right)=x\) or \(g_{2}\circ g_{1}^{-1}\left(u\left(h(x,y)\right)\right)=v\left(h(x,y)\right)\) for all \((x,y)\in W\). Since \(h\) is a diffeomorphism of \(W\) onto \(V\), it follows that \(g_{2}\circ g_{1}^{-1}\left(u(x,y)\right)=v(x,y)\) for all \((x,y)\in V\). \(F=g_{2}\circ g_{1}^{-1}\) satisfies the required condition.

**Solution to 2.2.31:** The conclusion is trivial if \(f\) is constant, so we assume \(f\) is not a constant. There is \((x_{0},y_{0})\in\mathbb{R}^{2}\) such that \(Df(x_{0},y_{0})\neq 0\). After performing a rotation of the coordinates, if necessary, we assume \(f_{x}(x_{0},y_{0})\neq 0\). Let \(a=f(x_{0},y_{0})\), and consider the function \(F:\mathbb{R}^{2}\to\mathbb{R}^{2}\) given by

\[F(x,y)=\left(f(x,y),y\right).\]The Jacobian of \(F\) is nonzero at \((x_{0},y_{0})\), so, by the Inverse Function Theorem [Rud87, pag. 221], the function \(F\) has a local inverse, \(G\), defined in a neighborhood of \((a,y_{0})\). Thus, \(F\left(G(a,y_{0})\right)=(a,y)\) for all \(y\) in some closed interval \(I\) containing \(y_{0}\). Let \(\gamma\) be any one-to-one map of \([0,1]\) onto \(I\). The function

\[g(t)=G\left(a,\gamma(t)\right)\ \ (t\in[0,1])\]

has the desired properties.

**Solution to 2.2.32:** Consider \(F:\mathbb{R}^{2}\rightarrow\mathbb{R}^{2}\) given by

\[F(x,y)=\left(f(x),-y+xf(x)\right).\]

A calculation gives that the Jacobian of \(F\) at \((x_{0},y_{0})\) is \(-f^{\prime}(x_{0})\neq 0\). So, by the Inverse Function Theorem [Rud87, pag. 221], \(F\) is invertible in a neighborhood of \((x_{0},y_{0})\). Similarly, \(f\) has a local inverse, \(g\), close to \(x_{0}\). In a sufficiently small neighborhood of \((x_{0},y_{0})\) we can then solve for each component of \(F^{-1}\) explicitly and get

\[g(u)=g\left(f(x)\right)=x\]

and

\[y=-v+xf(x)=-v+g(u)f(g(u))=-v+ug(u).\]

**Solution to 2.2.35:** 1. Let \(F:\mathbb{R}^{4}\rightarrow\mathbb{R}^{4}\) be defined by

\[F(x,y,z,w)=\left(x^{2}+yz,y(x+w),z(x+w),zy+w^{2}\right).\]

This map is associated with the given map because

\[\left(\begin{array}{cc}x&y\\ z&w\end{array}\right)^{2}=\left(\begin{array}{cc}x^{2}+yz&y(x+w)\\ z(x+w)&zy+w^{2}\end{array}\right).\]

The Jacobian of \(F\) at \((1,0,0,1)\) is \(2^{4}\); therefore, \(F\) is locally invertible near that point.

2. We have \(F(1,\varepsilon,\varepsilon,-1)=(1,0,0,1)\) for any \(\varepsilon\), so \(F\) is not invertible near \((1,0,0,-1)\).

**Solution to 2.2.36:** Identify the matrix \(X=\left(\begin{smallmatrix}x&y\\ z&w\end{smallmatrix}\right)\) with the element of \((x,y,z,w)\in\mathbb{R}^{4}\) in the usual way. Let \(F\) be defined by \(F(X)=X^{2}+X^{t}\). We have

\[DF(X)(x,y,z,w)=\left(\begin{array}{cccc}2x+1&z&y&0\\ y&x+w&1&y\\ z&1&x+w&z\\ 0&z&y&2w+1\end{array}\right)\]\[DF(X)(0,0,0,0)=\left(\begin{array}{cccc}1&0&0&0\\ 0&0&1&0\\ 0&1&0&0\\ 0&0&0&1\end{array}\right)\]

is invertible; therefore, by the Inverse Function Theorem [Rud87, pag. 221], there is such an \(\varepsilon\).

Global unicity fails for \(X=\left(\begin{smallmatrix}-1&0\\ 0&0\end{smallmatrix}\right)\) since \(X^{2}+X^{t}=0=0^{2}+0^{t}\).

**Solution to 2.2.37:** Since \(F(0)=0\) and \(F\) is clearly a \(C^{\infty}\)-function, the Inverse Function Theorem [Rud87, pag. 221] will yield the result if we can prove that \(DF(0)\) is invertible. We have

\[F(X+hY)-F(X)=X+hY+(X+hY)^{2}-X-X^{2}=hY+hXY+hYX+h^{2}Y^{2}\]

therefore,

\[DF(X)Y=Y+XY+YX.\]

In particular, \(DF(0)\) is the identity operator which is invertible.

**Solution to 2.2.39:**

1. Using the method of Laplace Expansions [HK61, pag. 179] we can see that finding the determinant involves only sums and multiplications of the entries of a matrix, therefore, it is a \(C^{\infty}\)-function.
2. For \(i,j=1,\ldots,n\), let \(x_{ij}\) denote the \((i,j)^{th}\) entry of \(X\), and let \(X_{ij}\) denote the cofactor of \(x_{ij}\), so that \[F(X)=\sum_{j=1}^{n}x_{ij}X_{ij}\qquad(i=1,\ldots,n)\.\] Since \(\dfrac{\partial X_{ik}}{\partial x_{ij}}=0\) for each \(i,j,k\), it follows from the preceding expression that \[\dfrac{\partial F}{\partial x_{ij}}=X_{ij}\.\] Thus, \(X\) is a critical point of \(F\) if and only if \(X_{ij}=0\) for every \(i\) and \(j\) or, what is equivalent, if and only if the rank of \(X\) does not exceed \(n-2\).

**Solution to 2.2.40:** Let \(A_{j}\) be the \(1\)-column matrix

\[A_{j}=\left(\begin{array}{c}a_{1j}\\ \vdots\\ a_{nj}\end{array}\right)\]so \(A\) is the matrix whose column \(j\) is \(A_{j}\), that is, \(A=(A_{1},\ldots,A_{n})\). Since \(\det\) is an \(n\)-linear function of \((\mathbb{R}^{n})^{n}\) into \(\mathbb{R}\), the derivative is given by

\[\frac{d}{dt}\det(A)=\sum_{j=1}^{n}\det\left(A_{1},\ldots,\frac{d}{dt}A_{j}, \ldots,A_{n}\right).\]

Let \(A(i,j)\) denote the cofactor of \(a_{ij}\), that is,

\[A(i,j)=(-1)^{i+j}\left|\begin{array}{cccccc}a_{11}&\ldots&a_{1j-1}&a_{1j+1}& \ldots&a_{1n}\\ \vdots&&\vdots&\vdots&&\vdots\\ a_{i-11}&\ldots&a_{i-1j-1}&a_{i-1j+1}&\ldots&a_{i-1n}\\ a_{i+11}&\ldots&a_{i+1j-1}&a_{i+1j+1}&\ldots&a_{i+1n}\\ \vdots&&\vdots&\vdots&&\vdots\\ a_{n1}&\ldots&a_{nj-1}&a_{nj+1}&\ldots&a_{nn}\end{array}\right|.\]

Using Laplace's Expansion Method to evaluate the determinant [10, pag. 179]

\[\det\left(A_{1},\ldots,\frac{d}{dt}A_{j},\ldots,A_{n}\right)\]

of each component of the derivative, by developing the \(j^{th}\) column we get

\[\det\left(A_{1},\ldots,\frac{d}{dt}A_{j},\ldots,A_{n}\right)=\sum_{i=1}^{n} \frac{d}{dt}a_{ij}A(i,j)\]

and

\[\frac{d}{dt}\det(A)=\sum_{j=1}^{n}\sum_{i=1}^{n}\frac{d}{dt}a_{ij}A(i,j)=\sum_ {j=1}^{n}\sum_{i=1}^{n}\frac{d}{dt}a_{ij}\det(A)b_{ji}\]

where the last equality follows from the fact that the inverse matrix is given by \(b_{ij}=\frac{1}{\det(A)}\cdot A(j,i)\). Therefore, we have

\[\frac{d}{dt}\log(\det(A)) =\frac{1}{\det(A)}\cdot\frac{d}{dt}\det(A)\] \[=\frac{1}{\det(A)}\cdot\sum_{j=1}^{n}\sum_{i=1}^{n}\frac{d}{dt}a_ {ij}\cdot\det(A)\cdot b_{ji}\] \[=\sum_{j=1}^{n}\sum_{i=1}^{n}\frac{d}{dt}a_{ij}b_{ji}.\]

### 2.3 Integral Calculus

**Solution to 2.3.1:** Let \(f:\mathbb{R}^{3}\to\mathbb{R}\), \(f(x,y,z)=(ax,by,cz)\). The volume given is the image, under \(f\), of the unit ball of \(\mathbb{R}^{3}\), \(\mathcal{B}\). As the Jacobian of \(f\) is _abc_ everywhere, we have

\[\operatorname{vol}\left(f(\mathcal{B})\right)=\int_{f(\mathcal{B})}dxdydz=\int _{\mathcal{B}}abc\,dxdydz=\frac{4}{3}\pi abc.\]

**Solution to 2.3.2:** Using polar coordinates, we have

\[\int_{\mathcal{A}}e^{-x^{2}-y^{2}}\,dxdy =\int_{0}^{2\pi}\int_{0}^{1}\rho e^{-\rho^{2}}d\rho d\theta\] \[=-\frac{1}{2}\int_{0}^{2\pi}\int_{0}^{1}-2\rho e^{-\rho^{2}}d \rho d\theta\] \[=-\frac{1}{2}\int_{0}^{2\pi}(e^{-1}-1)\] \[=\pi(e^{-1}-1).\]

**Solution to 2.3.4:** Using the parameterization

\[\left\{\begin{array}{ll}x=\sin\varphi\cos\theta&0<\theta<2\pi\\ y=\sin\varphi\sin\theta&0<\varphi<\pi\\ z=\cos\varphi&\end{array}\right.\]

we have

\[dA=\sin\varphi\ d\theta\ d\varphi\]

and

\[\int_{\mathcal{S}}(x^{2}+y+z)dA=\int_{0}^{\pi}\!\!\int_{0}^{2\pi}(\sin^{2} \varphi\cos^{2}\theta+\sin\varphi\sin\theta+\cos\varphi)\sin\varphi\ d\theta \,d\varphi.\]

Breaking the integral in three terms, we get

\[\int_{0}^{\pi}\!\!\int_{0}^{2\pi}\sin\varphi\cos\varphi\ d\theta\ d\varphi=2 \pi\cdot\frac{1}{2}\int_{0}^{\pi}\sin 2\varphi\ d\varphi=0\]

\[\int_{0}^{\pi}\!\!\int_{0}^{2\pi}\sin^{2}\varphi\sin\theta\ d\theta\ d\varphi= \left(\int_{0}^{\pi}\sin^{2}\varphi\ d\varphi\right)\int_{0}^{2\pi}\sin\theta \ d\theta=0\]

\[\int_{0}^{\pi}\!\!\int_{0}^{2\pi}\sin^{3}\varphi\cos^{2}\theta\ d\theta\ d \varphi=\left(\int_{0}^{\pi}\sin^{3}\varphi\ d\varphi\right)\left(\int_{0}^{2 \pi}\cos^{2}\theta\ d\theta\right)\]

[MISSING_PAGE_FAIL:218]

calculation shows that the integral over \(\mathcal{B}_{2}\) is \(\pi\), so the integral of \(f\) over \(\mathcal{R}\) is \(-10\pi\).

**Solution to 2.3.7:** Let \(C\) be a smooth closed path in \(\mathbb{R}^{3}\) which does not contain the origin, and let \(L\) be any polygonal line from the origin to infinity that does not intersect \(C\). \(V=\mathbb{R}^{3}\setminus L\) is simply connected; so to show that

\[\int_{C}F\cdot\mathit{ds}=0\]

it suffices to show that \(\nabla\times F=0\). Let \(r=(x,y,z)\) and \(F=(P,Q,R)\). We have

\[F(r)=\left(g\left(\left\|r\right\|\right)x,g\left(\left\|r\right\|\right)y,g \left(\left\|r\right\|\right)z\right).\]

By the Chain Rule [14, pag. 214],

\[\frac{\partial R}{\partial y}-\frac{\partial Q}{\partial z} =g^{\prime}\left(\left\|r\right\|\right)\frac{\partial\left\|r \right\|}{\partial y}z+g^{\prime}\left(\left\|r\right\|\right)\frac{\partial z }{\partial y}\] \[\quad-g^{\prime}\left(\left\|r\right\|\right)\frac{\partial \left\|r\right\|}{\partial z}y-g\left(\left\|r\right\|\right)\frac{\partial y }{\partial z}\] \[=g^{\prime}\left(\left\|r\right\|\right)\frac{yz}{\left\|r \right\|}-g^{\prime}\left(\left\|r\right\|\right)\frac{yz}{\left\|r\right\|}\] \[=0.\]

Similarly,

\[\frac{\partial P}{\partial z}-\frac{\partial R}{\partial z}=\frac{\partial Q} {\partial x}-\frac{\partial P}{\partial y}=0\]

and we are done.

**Solution to 2.3.8:** 1. From the identity

\[\vec{\nabla}\cdot\left(f\vec{J}\right)=\left(\vec{\nabla}f\right)\cdot\vec{J} +f\vec{\nabla}\cdot\vec{J}=\vec{\nabla}f\cdot\vec{J}\]

and Gauss Theorem [14, pag. 272], we obtain

\[\int_{\mathcal{B}}\left(\vec{\nabla}f\right)\cdot\vec{J}\,\mathit{ dx}\,\mathit{dy}\,\mathit{dz} =\int_{\mathcal{B}}\vec{\nabla}\cdot\left(f\vec{J}\right)\,\mathit{ dx}\,\mathit{dy}\,\mathit{dz}\] \[=\int_{\partial\mathcal{B}}f\vec{J}\cdot\vec{n}\,\mathit{dA}\] \[=0.\]

2. Apply Part 1 with \(f(x,y,z)=x\).

**Solution to 2.3.9:** By Gauss Theorem [14, pag. 272],

\[\iint_{\mathcal{D}}\operatorname{div}\left(u\operatorname{grad}u\right)\mathit{ dx}\mathit{dy}=\int_{\partial\mathcal{D}}(u\operatorname{grad}u)\cdot\vec{n}\, \mathit{ds}\,,\]where \(\vec{n}\) is the unit outward normal, and \(ds\) is the differential of arc length. The right-hand side vanishes because \(u=0\) on \(\partial\mathcal{D}.\) The left side equals the left side of \((*)\) because

\[\operatorname{div}\left(u\operatorname{grad}u\right) =\frac{\partial}{\partial x}\left(u\frac{\partial u}{\partial x} \right)+\frac{\partial}{\partial y}\left(u\frac{\partial u}{\partial y}\right)\] \[=\left(\frac{\partial u}{\partial x}\right)^{2}+\left(\frac{ \partial u}{\partial y}\right)^{2}+u\left(\frac{\partial^{2}u}{\partial x^{2}}+ \frac{\partial^{2}u}{\partial y^{2}}\right)\] \[=|\operatorname{grad}u|^{2}+\lambda u^{2}.\]

**Solution to 2.3.10:** By the Change of Variable Formula for multiple integrals [10, pag. 505],

\[\operatorname{vol}f\left(Q_{r}(x_{0})\right)=\int_{Q_{r}(x_{0})}|J(x)|\,dx.\]

Hence, if \(M_{r}\) is the maximum and \(m_{r}\) the minimum of \(|J(x)|\) for \(x\in Q_{r}(x_{0}),\) we have

\[m_{r}\leq r^{-3}\operatorname{vol}f\left(Q_{r}(x_{0})\right)\leq M_{r}.\]

By the continuity of \(J\), we have \(m_{r}\to|J(x_{0})|\) and \(M_{r}\to|J(x_{0})|\) as \(r\to 0,\) from which the desired equality follows.

To establish the inequality, we note that the same reasoning gives

\[(*)\qquad|J(x_{0})|=\lim_{r\to 0}\frac{\operatorname{vol}f\left(B_{r}(x_{0}) \right)}{\frac{4}{3}\pi r^{3}}\]

where \(B_{r}(x_{0})\) denotes the ball of radius \(r\) and center \(x_{0}.\) Let

\[K=\limsup_{x\to x_{0}}\frac{\|f(x)-f(x_{0})\|}{\|x-x_{0}\|}.\]

Then, given \(\varepsilon>0,\) there is an \(r_{\varepsilon}>0\) such that \(\|f(x)-f(x_{0})\|\leq(K+\varepsilon)\|x-x_{0}\|\) for \(\|x-x_{0}\|\leq r_{\varepsilon}.\) The latter means that, for \(r\leq r_{\varepsilon},\)

\[f\left(B_{r}(x_{0})\right)\subset B_{(K+\varepsilon)r}\left(f(x_{0})\right)\]

so that

\[\frac{\operatorname{vol}f\left(B_{r}(x_{0})\right)}{\frac{4}{3}\pi r^{3}}\leq \frac{\frac{4}{3}(K+\varepsilon)^{3}r^{3}}{\frac{4}{3}\pi r^{3}}=(K+ \varepsilon)^{3}.\]

In view of \((*),\) this gives \(|J(x_{0})|\leq(K+\varepsilon)^{3}.\) Since \(\varepsilon\) is arbitrary, we get \(|J(x_{0})|\leq K^{3},\) the desired inequality.

## 3 Differential Equations

### First Order Equations

**Solution to 3.1.1:** Suppose \(y\) is such a function. Then

\[y^{\prime}(x)=y(x)^{n}\,\]

or

\[\frac{dy}{y^{n}} =dx\] \[d\left(\frac{y^{-n+1}}{1-n}\right) =dx\] \[y^{-n+1} =(1-n)x+c\.\]

Moreover, \(c=1/y(0)^{n-1}>0\). We thus have

\[y(x)=\frac{1}{\left(c-(n-1)x\right)^{1/(n-1)}}.\]

This function solves the initial value problem \(y^{\prime}=y^{n}\), \(y(0)=c^{-1/(n-1)}\) in the interval \([0,\frac{c}{n-1})\), and, by the Picard's Theorem [29, pag. 8], it is the only solution. Since the function tends to \(\infty\) as \(x\rightarrow\frac{c}{n-1}\), there is no function meeting the original requirements.

**Solution to 3.1.5:** We have \(g^{\prime}(x)/g(x)=2\), so \(g(x)=Ke^{2x}\) where \(K\) is a constant. The initial condition \(g(0)=a\) gives \(K=a\); therefore, \(g(x)=ae^{2x}\).

**Solution to 3.1.7:** Suppose \(y(t)>0\) for \(t\in(t_{0},t_{1}),\ y(t_{0})=0\). Integrating the equation

\[\frac{y^{\prime}}{\sqrt{y}}=1\]

we get the solution \(y(t)=(t+c)^{2}/4\) where \(c\) is a constant. Each such solution can be extended to a differentiable function on \(\mathbb{R}\):

\[y(t)=\left\{\begin{array}{ll}0&\mbox{if}\quad t\leq t_{0}\\ \left(t-t_{0}\right)^{2}/4&\mbox{if}\quad t\geq t_{0}\end{array}\right.\]

We must have \(t_{0}\geq 0\) for \(y\) to satisfy the given initial condition. \(y\equiv 0\) is also a solution.

**Solution to 3.1.8:** From the equation, we get \(x^{\prime}=0\) iff \(x^{3}-x=0\), so the constant solutions are \(x=-1\), \(x=0\), and \(x=1\).

2. Considering the sign of \(x^{\prime}\), we get the phase portrait

So \(0\) is a stable singularity, and \(1\) a unstable one. There are no other singularities in \([0,1]\), so the limit of the orbit of the solution \(x(t)\) that verifies \(x(0)=1/2\) is \(0\).

**Solution to 3.1.9:** The given equation satisfies the hypotheses of Picard's Theorem [San79, pag. 8], so a solution \(x(t)\) exists in a neighborhood of the origin. Since \(\ x^{\prime}(0)=231+85\cos 85\neq 0\), by the Inverse Function Theorem [Rud87, pag. 221], \(x\) is locally invertible. Its inverse satisfies the initial value problem:

\[\frac{dt}{dx}=\frac{1}{3x+85\cos x},\quad t(77)=0.\]

So

\[t(x)=\int_{77}^{x}\frac{1}{3\xi+85\cos\xi}d\xi\]

in some neighborhood of \(77\). There are numbers \(\alpha_{1}\) and \(\alpha_{2}\) such that \(\alpha_{1}<77<\alpha_{2}\), \(3\alpha_{i}+85\cos\alpha_{i}=0\), and \(3\alpha_{i}+85\cos\alpha_{i}>0\) in \((\alpha_{1},\alpha_{2})\). So \(t(x)\) is increasing. The function \(3\xi+85\cos\xi\) behaves like \(|\xi-\alpha_{i}|\) as \(\xi\rightarrow\alpha_{i}\), so

\[\lim_{x\rightarrow\alpha_{1}}t(x)=-\infty\quad\mbox{and}\quad\lim_{x \rightarrow\alpha_{2}}t(x)=\infty.\]

We may take the inverse of \(t:(\alpha_{1},\alpha_{2})\rightarrow\mathbb{R}\) and get a function \(x(t)\) that solves our initial value problem and is defined in all of \(\mathbb{R}\).

**Solution to 3.1.16:**: 1. Let \(u\) be defined by \(u(x)=\exp(-3x^{2}/2)y(x)\). The given equation becomes

\[\frac{du}{dx} =-3xe^{-\frac{3}{2}x^{2}}y(x)+e^{-\frac{3}{2}x^{2}}\left(3xy(x)+ \frac{y(x)}{1+y^{2}}\right)\] \[=\frac{u(x)}{1+e^{3x^{2}}u(x)^{2}}\] \[=f(x,u).\]

\(f\) is clearly \(C^{1}\), so it satisfies the Lipschitz condition on any compact convex domain. The initial value problem

\[\frac{du}{dx}=\frac{u}{1+e^{3x^{2}}u},\qquad u(0)=\frac{1}{n}\]

then has a unique solution for any \(n\in\mathbb{N}\).

2. \(f\equiv 0\) is the unique solution of the initial value problem associated with the condition \(u(0)=0\). Therefore, \(f_{n}\) cannot have any zero, so \(f_{n}(x)>0\) for \(x\in[0,1]\). For \(u(x)=\exp(-3x^{2}/2)f_{n}(x)\), we have

\[0\leq\frac{u^{\prime}}{u}\leq\frac{1}{1+e^{3x^{2}}u^{2}}\leq 1\]

so

\[u(0)=\frac{1}{n}\leq u(x)\leq\frac{1}{n}e^{x}\]

therefore,

\[\frac{1}{n}e^{\frac{3}{2}}\leq f_{n}(0)\leq\frac{1}{n}e^{\frac{5}{2}}\]

and \(f_{n}(0)\to 0\) when \(n\to\infty\).
**Solution to 3.1.17:**: If \(y(t)\leq 0\) for some \(t\), then \(y^{\prime}(t)\geq 1\), so \(y(t)\) is growing faster than \(z(t)=t\) for all \(t\) where \(y(t)\leq 0\). Hence, there is a \(t_{0}\) with \(y(t_{0})>0\). For \(y>0\), \(y^{\prime}>0\), so for \(t\geq t_{0}\), \(y\) is positive. Further, for \(y>0\), \(e^{-y}>e^{-3y}\), so \(y^{\prime}>e^{-5y}\). Now consider the equation \(z^{\prime}=e^{-5z}\). Solving this by separation of variables, we get \(z(t)=\log(t/5+C)/5\), and for some choice of \(C\), we have \(z(t_{0})=y(t_{0})\). For all \(t\geq t_{0}\), \(y^{\prime}>z^{\prime}\), so \(z(t)\leq y(t)\) for \(t>t_{0}\). Since \(z(t)\) tends to infinity as \(t\) does, so does \(y\).
**Solution to 3.1.18:**: Multiplying the first equation by the integrating factor \(\exp\left(\int_{0}^{x}q(t)dt\right)\), we get

\[\frac{d}{dx}\left(f(x)\exp\left(\int_{0}^{x}q(t)dt\right)\right)=0.\]

The general solution is therefore,

\[f(x)=C\exp\left(-\int_{0}^{x}q(t)dt\right)\]where \(C\) is a constant. The hypothesis is that \(\lim_{x\to\infty}\int_{0}^{x}q(t)dt=+\infty\). Even if \(|p|\geq|q|\), the corresponding property may fail for \(p\). For example, for \(p\equiv-1\) and \(q\equiv 1\), the general solutions are respectively \(f(x)=C\exp(-x)\) and \(f(x)=C\exp(x)\).

**Solution to 3.1.19:** Consider the equation

\[0=F(x,y,z)=(e^{x}\sin y)z^{3}+(e^{x}\cos y)z+e^{y}\tan x.\]

\(F(0,0,0)\simeq 0\), and all the partial derivatives of \(F\) are continuous, with

\[\frac{\partial F}{\partial z}\Big{|}_{(0,0,0)}=\left.\left(3z^{2}(e^{x}\sin y) +e^{x}\cos y\right)\right|_{(0,0,0)}=1.\]

By the Implicit Function Theorem [13, pag. 224], there is a real valued function \(f\) with continuous partial derivatives, such that, \(F\left(x,y,f(x,y)\right)=0\) in a neighborhood of \((0,0,0)\). Locally, then, the given differential equation is equivalent to \(y^{\prime}=f(x,y)\). Since \(f\) satisfies the hypotheses of Picard's Theorem [10, pag. 8], there is a unique solution \(y\) in a neighborhood of \(0\) with \(y(0)=0\).

**Solution to 3.1.20:** Since \(f\) and \(g\) are positive, the solutions of both problems are monotonically increasing. The first differential equation can be rewritten as \(d{x}/f(x)=dt\), so its solution is given by \(x=h^{-1}(t)\), where the function \(h\) is defined by

\[h(x)=\int_{0}^{x}\frac{d\xi}{f(\xi)}\.\]

Because the solution is defined for all \(t\), we must have

\[\int_{0}^{\infty}\frac{d\xi}{f(\xi)}=\infty\,\qquad\int_{0}^{-\infty}\frac{d \xi}{f(\xi)}=-\infty.\]

Since \(g\leq f\), it follows that

\[\int_{0}^{\infty}\frac{d\xi}{g(\xi)}=\infty\,\qquad\int_{0}^{-\infty}\frac{d \xi}{g(\xi)}=-\infty.\]

Using a similar reasoning we can see that the solution of the second equation is given by \(x=H^{-1}(t)\), where

\[H(x)=\int_{0}^{x}\frac{d\xi}{g(\xi)}\.\]

The conditions \(\int_{0}^{\infty}\frac{d\xi}{g(\xi)}=\infty\), and \(\int_{0}^{-\infty}\frac{d\xi}{g(\xi)}=-\infty\) guarantee that \(H\) maps \(\mathbb{R}\) onto \(\mathbb{R}\), hence that \(H^{-1}\) is defined on all of \(\mathbb{R}\). Thus, the solution of the second equation is defined on \(\mathbb{R}\).

**Solution to 3.1.21:** Picard's Theorem [San79, pag. 8] applies because the function \(x^{2}-x^{6}\) is Lipschitzian on finite subintervals of the \(x\)-axis. Thus, two distinct solution curves are non intersecting. The constant functions \(x(t)\equiv 0\) and \(x(t)\equiv 1\) are solutions. Hence, if the solution \(x(t)\) satisfies \(x(0)>1\), then \(x(t)>1\) for all \(t\), and if it satisfies \(0<x(0)<1\), then \(0<x(t)<1\) for all \(t\).

Since

\[x^{2}-x^{6}=x^{2}(1-x^{4})=(1-x)x^{2}(1+x+x^{2}+x^{3})\,\]

we have

\[(*)\qquad\frac{d}{dt}(x-1)=-(x-1)x^{2}(1+x+x^{2}+x^{3})\.\]

We see from this (or directly from the original equation) that if \(x(0)>1\), then \(x-1\) decreases as \(t\) increases, and if \(0<x(0)<1\), then \(1-x\) decreases as \(x\) increases.

Case 1: \(x(0)>1\). In this case, \((*)\) implies

\[\frac{d}{dt}(x-1)\leq-(x-1)\]

(since \(x(t)>1\) for all \(t\)), so that

\[\frac{d}{dt}(e^{t}(x-1))\leq 0\.\]

Hence, \(e^{t}(x(t)-1)\leq x(0)-1\), that is, \(x(t)-1\leq e^{-t}(x(0)-1)\), from which the desired conclusion follows.

Case 2: \(0<x(0)<1\). In this case, \((*)\) implies

\[\frac{d}{dt}(1-x)\leq-x(0)^{2}(1-x)\]

(since \(x(t)\geq x(0)\) for all \(t\)), so that

\[\frac{d}{dt}(e^{x(0)^{2}t}(1-x))\leq 0\.\]

Therefore, \(e^{x(0)^{2}t}(1-x(t))\leq 1-x(0)\), that is, \(1-x(t)\leq e^{-x(0)^{2}t}(1-x(0))\), and the desired conclusion follows.

**Solution to 3.1.22:** Let \(y\) be a solution of the given differential equation. If \(y^{\prime}\) never vanishes, then \(y^{\prime}\) has constant sign, so \(y\) is monotone.

Suppose that \(y^{\prime}(x_{1})=0\) for some \(x_{1}\). Then the constant function \(y_{1}(x)=y(x_{1})\) is a solution of \(f(y_{1})=0\). Consider the function \(z\), \(z(x)=y_{1}\) for all \(x\). Then the differential equation \(y^{\prime}=f(y)\) with initial condition \(y(x_{1})=y_{1}\)is satisfied by \(y\) and by \(z\). \(f\) is continuously differentiable and by Picard's Theorem [San79, pag. 8], \(y=z\), so \(y\) is constant.

**Solution to 3.1.23:** For \((x_{0},y_{0})\) to be the midpoint of \(L(x_{0},y_{0})\), the \(y\) intercept of \(L\) must be \(2y_{0}\) and the \(x\) intercept must be \(2x_{0}\). Hence, the slope of the tangent line is \(-y_{0}/x_{0}\). Let the curve have the equation \(y=f(x)\). We get the differential equation

\[f^{\prime}(x)=-\frac{f(x)}{x},\]

or

\[-\frac{1}{x}=\frac{f^{\prime}(x)}{f(x)}=\frac{1}{y}\frac{dy}{dx}.\]

By separation of variables, we get

\[\log y=-\log x+C.\]

Hence,

\[f(x)=y=\frac{D}{x}\]

for some constant \(D\). Solving for the initial condition \(f(3)=2\), we get \(f(x)=6/x\).

### 3.2 Second Order Equations

**Solution to 3.2.1:** By Picard's Theorem [San79, pag. 8] there is, at most, one real valued function \(f\) on \([0,\infty)\) such that \(f(0)=1\), \(f^{\prime}(0)=0\) and \(f^{\prime\prime}(x)=(x^{2}-1)f(x)\). Since the function \(e^{-x^{2}/2}\) satisfies these conditions, we must have \(f(x)=e^{-x^{2}/2}\). We then have

\[\lim_{x\to\infty}f(x)=\lim_{x\to\infty}e^{-x^{2}/2}=0\,.\]

**Solution to 3.2.2:** The characteristic polynomial of the given differential equation is \((r-1)^{2}\) so the general solution is

\[\alpha e^{t}+\beta te^{t}.\]

The initial conditions give \(\alpha=1\), and \(\beta=0\), so the solution is \(y(t)=e^{t}\).

**Solution to 3.2.3:** The characteristic polynomial of the associated homogeneous equation is

\[r^{2}-2r+1=(r-1)^{2}\]so the general solution of the homogeneous equation

\[\frac{d^{2}x}{dt^{2}}-2\frac{dx}{dt}+x=0\]

is

\[Ae^{t}+Bte^{t}\qquad(A,B\in\mathbb{R}).\]

\((\cos t)/2\) is easily found to be a particular solution of the original equation, so the general solution is

\[Ae^{t}+Bte^{t}+\frac{\cos t}{2}.\]

The initial conditions give \(A=-\frac{1}{2}\) and \(B=\frac{1}{2}\), so the solution is

\[\frac{1}{2}(e^{t}-te^{t}+\cos t).\]

**Solution to 3.2.4:** The characteristic polynomial of the given equation is

\[5r^{2}+10r+6\]

which has roots \(-1\pm i/\sqrt{5}\), so the general solution is given by

\[x(t)=c_{1}e^{-t}\cos\left(\frac{t}{\sqrt{5}}\right)+c_{2}e^{-t}\sin\left(\frac {t}{\sqrt{5}}\right)\]

where \(c_{1}\) and \(c_{2}\) are constants. We can assume \(c_{1}\neq 0\) or \(c_{2}\neq 0\). Using calculus, we can sec that \(u^{2}(1+u^{4})^{-1}\leq 1/2\) with equality when \(u=\pm 1\). Then \(f\) attains a maximum of \(1/2\) iff \(x\) attains one of the values \(\pm 1\). We have \(\lim_{t\to\infty}x(t)=0\). Suppose \(c_{1}\neq 0\). Then, if \(k\) is a large enough integer, we have

\[\left|x\left(-\sqrt{5}k\pi\right)\right|=|c_{1}|e^{\sqrt{5}k\pi}>1\]

so, by the Intermediate Value Theorem [Rud87, pag. 93], \(x\) attains one of the values \(\pm 1\). If \(c_{2}\neq 0\), a similar argument gives the same conclusion.

**Solution to 3.2.5:** We first solve the homogeneous equation \(x^{\prime\prime}+8x^{\prime}+25=0\). The general solution is \(x_{0}(t)=c_{1}e^{ir_{1}t}+c_{2}e^{ir_{2}t}\), where \(c_{1}\) and \(c_{2}\) are constants and \(r_{k}=-4\pm 3i,\,k=1,2\), are the roots of the characteristic equation \(r^{2}+8r+25=0\).

All the solutions of the differential equation \(x^{\prime\prime}+8x^{\prime}+25x=2\cos t\) are of the form \(x(t)=x_{0}(t)+s(t)\), where \(s(t)\) is any particular solution. We solve for an \(s(t)\) by the Method of Undetermined Coefficients [BD65, pag. 115]. Consider \(s(t)=A\cos t+B\sin t\). Differentiating this expression twice, we get

\[2\cos t=s^{\prime\prime}+8s^{\prime}+25s=(24A+8B)\cos t+(24B-8A)\sin t.\]Solving the two linear equations gives \(A=3/40\) and \(B=1/40\). Therefore, the desired solution \(x(t)\) is given by \(x_{0}(t)+s(t)\), where \(c_{1}\) and \(c_{2}\) are chosen to give the correct initial conditions. \(x_{0}(t)\) tends to \(0\) as \(t\) tends to infinity; therefore, to finish the problem, we need to find constants \(\alpha\) and \(\delta\) with \(\alpha\cos(t-\delta)=A\cos t+B\sin t\). We have \(\alpha\cos(t-\delta)=\alpha\cos t\cos\delta+\alpha\sin t\sin\delta\), so the problem reduces to solving \(\alpha\cos\delta=3/40\) and \(\alpha\sin\delta=1/40\). These equations imply \(\tan\delta=1/3\) or \(\delta=\arctan(1/3)\). Hence, by elementary trigonometry, \(\cos\delta=3/\sqrt{10}\), so \(\alpha=\sqrt{10}/40\).

**Solution to 3.2.6:** 1. The differential equation is equivalent to \(y^{\prime}=z\) and \(z^{\prime}=-|y|\). We have

\[\|(z_{1},|y_{1}|)-(z_{2},|y_{2}|)\| =\sqrt{(z_{1}-z_{2})^{2}+(|y_{2}|-|y_{1}|)^{2}}\] \[\leq\sqrt{(z_{1}-z_{2})^{2}+(y_{2}-y_{1})^{2}}\] \[=\|(z_{1},y_{1})-(z_{2},y_{2})\|\]

so the Lipschitz condition is verified and our initial value problem has, by Picard's Theorem [19, pag. 8], a unique solution. If \(y\) is such a solution, define the function \(z\) by \(z(x)=y(-x)\). We have \(z^{\prime\prime}(x)=y^{\prime\prime}(-x)=-|y(-x)|=-|z(x)|\), \(z(0)=y(0)=1\) and \(z^{\prime}(0)=-y^{\prime}(0)=0\), so \(z=y\) and \(y\) is even.

2. We have

\[y^{\prime}(x)=\int_{0}^{x}y^{\prime\prime}(t)dt=-\int_{0}^{x}|y(t)|dt<0\]

so \(y\) is a decreasing function; therefore, it has, at most, one positive zero. If \(y\) is positive on \(\mathbb{R}_{+}\), by continuity, \(y\) is positive in some interval of the form \((-\varepsilon,\infty)\) for some \(\varepsilon>0\). Together with \(y(0)=1\), \(y^{\prime}(0)=0\) gives \(y(x)=\cos x\), which is absurd. We conclude then that \(y\) has exactly one positive zero.

**Solution to 3.2.7:** 1. Let the function \(g\) be defined by \(g(t)=f(x(t),x^{\prime}(t))\). We have

\[(*)\qquad g^{\prime}(t)=-2(x^{\prime}(t)^{2}+x(t)^{4})\]

so \(g\) is a decreasing function.

2. It is enough to show that \(\lim_{t\to\infty}g(t)=0\).

Since \(g\) is a positive decreasing function, the limit exists and satisfies \(\lim_{t\to\infty}g(t)=c\geq 0\). If \(c>0\), then, for some \(\varepsilon>0\), \(T\in\mathbb{R}\) we have \(x^{\prime}(t)^{2}+x^{4}(t)>\varepsilon\) for \(t\geq T\). Then, by \((*)\), we have

\[\frac{g(T)-c}{2}=\int_{T}^{\infty}(x^{\prime}(t)^{2}+x(t)^{4})dt>\int_{T}^{ \infty}\varepsilon dt=\infty\]

which is absurd. We must then have \(c=0\), as desired.

**Solution to 3.2.8:** Substituting \(y(x)=x^{a}\) gives the quadratic equation \(a(a-1)+1=0\). The two roots are

\[\frac{1}{2}\pm\frac{\sqrt{3}i}{2}\,\]

so the general solution is

\[y(x)=A\sqrt{x}\cos\left(\frac{\sqrt{3}}{2}\log x\right)+B\sqrt{x}\cos\left( \frac{\sqrt{3}}{2}\log x\right)\.\]

The boundary condition \(y(1)=0\) implies \(A=0\) and then the boundary condition \(y(L)=0\) can be satisfied for nonzero \(B\) only if

\[\sin\left(\frac{\sqrt{3}}{2}\log L\right)=0\.\]

Equivalently,

\[L=e^{2n\pi/\sqrt{3}}\]

where \(n\) is any positive integer.

**Solution to 3.2.10:** Multiplying the first equation by \(a(t)/p(t)\) where \(a\) is a differentiable function, we get

\[a(t)x^{\prime\prime}(t)+\frac{a(t)q(t)}{p(t)}x^{\prime}(t)+\frac{a(t)r(t)}{p(t )}x(t)=0.\]

Expanding the second given equation, we get

\[a(t)x^{\prime\prime}(t)+a^{\prime}(t)x^{\prime}(t)+b(t)x(t)=0.\]

For the two equations to be equivalent, we must have \(a^{\prime}(t)=a(t)q(t)/p(t)\). Solving this by separation of variables, we get

\[a(t)=\exp\left(\int_{0}^{t}\frac{q(x)}{p(x)}\,dx\right).\]

Letting \(b(t)=a(t)r(t)/p(t)\), we are done.

**Solution to 3.2.11:** The function \(x^{\prime}(1)x(t)\) - \(x^{\prime}(0)x(t+1)\) satisfies the differential equation and vanishes along with its first derivative at \(t=0\). By Picard's Theorem [10, pag. 8] this function vanishes identically. Assuming \(x\) is not the zero function, we have \(x^{\prime}(0)\neq 0\) (again, by Picard's Theorem), so \(x(t+1)=cx(t)\), where \(c=x^{\prime}(1)/x^{\prime}(0)\). It follows that the zero set of \(x\) is invariant under translation by one unit, which implies the desired conclusion.

**Solution to 3.2.12:** The characteristic polynomial of the equation is \(l^{2}-2cl+1=0\), which has the roots \(c\pm\sqrt{c^{2}-1}\).

Case 1: \(|c|>1\). Let \(\omega=\sqrt{c^{2}-1}\). Then the general solution is

\[x(t)=e^{ct}(A\cosh\omega t+B\sinh\omega t)\.\]

The condition \(x(0)=0\) implies \(A=0\), and then the condition \(x(2\pi k)=0\) implies \(B=0\), that is, \(x(t)\equiv 0\). There are no nontrivial solutions in this case.

Case 2: \(c=1\). The general solution is

\[x(t)=Ae^{t}+Bte^{t}\.\]

The condition \(x(0)=0\) implies \(A=0\), and then the condition \(x(2\pi k)=0\) implies \(B=0\). There are no nontrivial solutions in this case.

Case 3: \(c=-1\). Similar reasoning shows that there are no nontrivial solutions in this case.

Case 4: \(-1<c<1\). Let \(\omega=\sqrt{1-c^{2}}\). The general solution is then

\[x(t)=e^{ct}(A\cos\omega t+B\sin\omega t)\.\]

The condition \(x(0)=0\) implies \(A=0\). If \(B\neq 0\), the condition \(x(2\pi k)=0\) then implies \(2\pi k\omega=\pi n\) (\(n\in\mathbb{Z}\)), that is, \(\omega=n/2k\), and

\[c^{2}=1-\omega^{2}=1-\frac{n^{2}}{4k^{2}}\.\]

The right side is nonnegative and less than \(1\) only for \(0<|n|\leq 2k\). The required values of \(c\) are thus

\[c=\pm\sqrt{1-\frac{n^{2}}{4k^{2}}}\,\qquad n=1,2,\ldots,2k\.\]

### 3.3 Higher Order Equations

**Solution to 3.3.3:**

1. The characteristic polynomial of the equation is \[x^{7}+\cdots+x+1=\frac{x^{8}-1}{x-1}\] which has roots \(-1\), \(\pm i\), and \(\frac{\pm 1\pm i}{\sqrt{2}}\). For each such root \(z_{k}=u_{k}+iv_{k}\) (\(k=1,\ldots,7\)), we have the corresponding solution \[e^{z_{k}t}=e^{u_{k}t}(\cos v_{k}t+i\sin v_{k}t)\]and these form a basis for the space of complex solutions. To get a basis for the real solutions, we take the real and imaginary parts, getting the basis \[x_{1}(t)=e^{-t},\quad x_{2}(t)=\cos t,\quad x_{3}(t)=\sin t,\quad x_{4}(t)=e^{ \frac{1}{\sqrt{2}}t}\cos\frac{1}{\sqrt{2}}t,\] \[x_{5}(t)=e^{\frac{1}{\sqrt{2}}t}\sin\frac{1}{\sqrt{2}}t,\quad x_{6}(t)=e^{ \frac{-1}{\sqrt{2}}t}\cos\frac{1}{\sqrt{2}}t,\quad x_{7}(t)=e^{\frac{-1}{\sqrt {2}}t}\sin\frac{1}{\sqrt{2}}t.\]
2. A solution tends to \(0\) at \(\infty\) iff it is a linear combination of solutions in the basis with the same property. Hence, the functions \(x_{1}\), \(x_{6}\), and \(x_{7}\) form a basis for the space of solutions tending to \(0\) at \(\infty\).

**Solution to 3.3.4:** The set of complex solutions of the equation forms a complex vector space which is invariant under differentiation. Hence, the functions \(\cos\ t\) and \(\cos\ 2t\) are also solutions, and, therefore, so are \(e^{\pm it}=\cos t\pm i\sin t\) and \(e^{\pm 2it}=\cos 2t\pm i\sin 2t\). It follows that the characteristic polynomial of the equation has at least the four roots \(\pm i,\pm 2i\), so it is divisible by the polynomial \((\lambda^{2}+1)(\lambda^{2}+4)\). The differential equation is therefore, at least of order \(4\). The smallest possible order is, in fact, \(4\), because the given functions are both solutions of the equation

\[\left(\frac{d^{2}}{dt^{2}}+1\right)\left(\frac{d^{2}}{dt^{2}}+4\right)=0,\]

that is,

\[\frac{d^{4}x}{dt^{4}}+5\ \frac{d^{2}x}{dt^{2}}+4x=0.\]

The preceding reasoning applies for both real and complex coefficients.

**Solution to 3.3.5:** Solving the characteristic equation \(r^{3}-1=0\), we find that the general solution to \(y^{\prime\prime\prime}-y=0\) is given by

\[(*)\qquad y(x)=c_{1}e^{x}+c_{2}e^{-x/2}\cos(x\sqrt{3}/2)+c_{3}e^{-x/2}\sin(x \sqrt{3}/2),\]

with \(c_{1}\), \(c_{2}\), and \(c_{3}\in\mathbb{R}\). \(\lim_{x\to\infty}y(x)=0\) when \(c_{1}=0\). But \((*)\), with \(c_{1}=0\), is the general solution of the differential equation with characteristic polynomial \((r^{3}-1)/(r-1)=r^{2}+r+1\), that is,

\[y^{\prime\prime}+y^{\prime}+y=0.\]

So \(y^{\prime\prime}(0)+y^{\prime}(0)+y(0)=0\), and we can take \(a=b=c=1\) and \(d=0\).

### 3.4 Systems of Differential Equations

**Solution to 3.4.3:** Solving the first equation for \(y\) and differentiating gives

\[y =\frac{1}{10}x^{\prime}+\frac{3}{10}x\] \[y^{\prime} =\frac{1}{10}x^{\prime\prime}+\frac{3}{10}x^{\prime}.\]

Substituting this into the second equation and simplifying yields

\[x^{\prime\prime}-5x^{\prime}+6x=0.\]

Factoring the characteristic polynomial, we get

\[r^{2}-5r+6=(r-2)(r-3),\]

so the general solution to this differential equation is given by

\[x(t)=C_{1}e^{2t}+C_{2}e^{3t},\]

where \(C_{1}\) and \(C_{2}\) are constants. Substituting this in the above, we get

\[y(t)=\frac{C_{1}}{2}e^{2t}+\frac{3C_{2}}{5}e^{3t}.\]

**Solution to 3.4.4:** We have

\[\frac{d}{dt}\left(x^{2}+y^{2}\right) =2x\frac{dx}{dt}+2y\frac{dy}{dt}\] \[=2x(-x+y)+2y(\log(20+x))\] \[=-2x^{2}+2xy-2y^{2}+2y\log(20+x).\]

As, for any positive \(\varepsilon\),

\[\log(20+x)=o(x^{\varepsilon})\quad(x\to+\infty)\]

and

\[-2x^{2}+2xy-2y^{2} \leq-2(x^{2}+y^{2}-|xy|)\] \[\leq-2(x-y)^{2}\] \[\leq 0\]

we conclude that

\[\frac{d}{dt}\left(x^{2}+y^{2}\right)\leq 0\]for \(\|(x,y)\|\) large enough so the distance of \((x,y)\) to the origin is bounded.

**Solution to 3.4.5:**\(1\). Using polar coordinates, \(x=r\cos\theta\) and \(y=r\sin\theta\), we get

\[\frac{dr}{dt}=\frac{x}{r}\frac{dx}{dt}+\frac{y}{r}\frac{dy}{dt}=r(1-r^{2})\]

\[\frac{d\theta}{dt}=\frac{x}{r^{2}}\frac{dy}{dt}-\frac{y}{r^{2}}\frac{dx}{dt}=-1\]

solving these, we get

\[r=\frac{c_{1}e^{t}}{\sqrt{1+c_{1}^{2}e^{2t}}}\quad\text{and}\quad\theta=-t+c_{2}\]

where \(c_{1},c_{2}\) are constants.

For \((x_{0},y_{0})=(0,0)\), we have \(\frac{dx}{dt}=\frac{dy}{dt}=0\); therefore, \(x=y\equiv 0\). For \((x_{0},y_{0})\neq(0,0)\) let \(x_{0}=r_{0}\cos\theta_{0}\) and \(y_{0}=r_{0}\sin\theta_{0}\). We have

\[c_{1}=\frac{r_{0}}{\sqrt{1-r_{0}^{2}}}\quad\text{and}\quad c_{2}=\theta_{0}\]

so

\[x(t)=\frac{c_{1}e^{t}}{\sqrt{1+c_{1}e^{2t}}}\cos(\theta_{0}-t)\,,\qquad y(t)= \frac{c_{1}e^{t}}{\sqrt{1+c_{1}e^{2t}}}\sin(\theta_{0}-t).\]

2. We have

\[\lim_{t\to\infty}r=\lim_{t\to\infty}\frac{c_{1}e^{t}}{\sqrt{1+c_{1}e^{2t}}}=1.\]

**Solution to 3.4.9:** We have

\[\frac{d}{dt}\|x(t)\|^{2} =\frac{d}{dt}\langle x(t),x(t)\rangle\] \[=\langle x^{\prime}(t),x(t)\rangle+\langle x(t),x(t)^{\prime}\rangle\] \[=\langle Ax(t),x(t)\rangle+\langle x(t),Ax(t)\rangle\] \[=\langle(A+A^{*})\,x(t),x(t)\rangle\] so it suffices to prove that \(A+A^{*}\) is positive definite. We have

\[A+A^{*}=\left(\begin{array}{rrr}2&2&-2\\ 2&8&2\\ -2&2&16\end{array}\right)\]

and it is enough to check that the determinant of the principal minors are positive, which is a simple calculation.

[MISSING_PAGE_FAIL:234]

where the \(\xi_{j}\)'s are constants depending on \(k\). From this, it follows that each \(f_{k}(t)\) approaches \(0\) as \(t\) tends to infinity.

Solving the second equation, we get

\[f_{n+1}(t)=\xi_{n+1}e^{-(n+1)t}\]

for some \(\xi_{n+1}\in\mathbb{R}\), which has the desired form. Assume that, for some \(k\), the formula holds for \(f_{k+1}\). Differentiating it and substituting it into the first equation gives

\[f_{k}^{\prime}=\sum_{j=k+1}^{n+1}(k+1+j)\xi_{j}e^{-jt}-kf_{k}.\]

This is a first order linear differential equation which we can solve. Letting \(\mu_{j}=(k+1+j)\xi_{j}\), we get

\[f_{k}=\left(\int_{0}^{t}e^{ks}\left(\sum_{j=k+1}^{n+1}\mu_{j}e^{-js}\right)\, ds+C\right)e^{-kt}\]

where \(C\) is a constant. Changing the order of summation and evaluating, we get

\[f_{k}=\left(\sum_{j=k+1}^{n+1}\frac{\mu_{j}}{k-j}e^{(k-j)x}\right|_{x=0}^{t}+C \right)e^{-kt}=\sum_{j=k}^{n+1}\xi_{j}e^{-jt}\]

where the \(\xi_{j}\)'s are some real constants, and we are done.

**Solution to 3.4.15:** We solve the case \(n=1\) in two different ways. _First method_. Let \(B\) be the indefinite integral of \(A\) vanishing at \(0\). One can then integrate the equation \(\frac{dx}{dt}=Ax\) with the help of the integrating factor \(e^{-B}\), namely

\[0=e^{-B}\frac{dx}{dt}-e^{-B}A\frac{dx}{dt}=\frac{d}{dt}\left(e^{-B}x\right),\]

giving \(x(t)=e^{B(t)}x(0)\). Since \(A(t)\leq\beta\), we have \(B(t)\leq\beta t\) for \(t>0\), so

\[|x(t)|=|x(0)|e^{B(t)}\leq|x(0)|e^{-\beta t},\]

as desired.

\(n=1\), _Second method_. Consider the derivative of \(e^{-\beta t}x\):

\[\frac{d}{dt}\left(e^{-\beta t}x\right)=e^{-\beta t}\left(\frac{dx}{dt}-\beta x \right)=e^{-\beta t}\left(A-\beta\right)x.\]

By Picard's Theorem [San79, pag. 8], \(x\) either has a constant sign or is identically \(0\). Hence, \(e^{-\beta t}x\) is nonincreasing when \(x\) is positive and nondecreasing when \(x\) is negative, which gives the desired conclusion.

\(n>1\). We have for a solution \(x(t)\),

\[\frac{d}{dt}\|x\|^{2} =2\langle\frac{dx}{dt},x\rangle\] \[=2\langle Ax,x\rangle\] \[\leq 2\beta\|x\|^{2}\]

which reduces the case \(n>1\) to the case \(n=1\).

**Solution to 3.4.16:** 1. We have

\[\frac{d}{dt}\ \|X(t)\|^{2} =\frac{d}{dt}(X(t)\cdot X(t))=2X(t)\cdot\frac{dX(t)}{dt}\] \[=2X(t)\cdot WX(t)=2W^{t}X(t)\cdot X(t)\] \[=-2WX(t)\cdot X(t)=-2X(t)\cdot WX(t)\] \[=-\frac{d}{dt}\ \|X(t)\|^{2}\,\]

from which it follows that \(\frac{d}{dt}\ \|X(t)\|^{2}=0\), hence that \(\|X(t)\|\) is constant.

2. We have

\[\frac{d}{dt}(X(t)\cdot v) =\frac{dX(t)}{dt}\cdot v=WX(t)\cdot v\] \[=X(t)\cdot W^{t}v=-X(t)\cdot Wv=0.\]

3. It will suffice to show that the null space of \(W\) is nontrivial. For if \(v\) is a nonzero vector in that null space, then

\[\|X(t)-v\|^{2}=\|X(t)\|^{2}+\|v\|^{2}-2X(t)\cdot v\,\]

which is constant by Part 1 and Part 2, implying that \(X(t)\) lies on the intersection of two spheres, one with center \(0\) and one with center \(v\).

The nontriviality of the null space of \(W\) follows from the antisymmetry of \(W\):

\[\det W =\det W^{t}=\det(-W)\] \[=(-1)^{3}\det W=-\det W\.\]

Hence, \(\det W=0\), so \(W\) is singular.

**Solution to 3.4.17:** Consider the function \(u\) defined by \(u(t)=\|x(t)\|^{2}\).

We have, using Rayleigh's Theorem [19, pag. 418],

\[u^{\prime}(t) =2\langle x(t),x^{\prime}(t)\rangle\] \[=2\langle x(t),P(t)x(t)\rangle\] \[\leq-2\langle x(t),x(t)\rangle\] \[=-2u(t)\]which implies that \(u(t)\leq u(0)\exp(-2t)\) for \(t>0\), so \(\lim_{t\to\infty}u(t)=0\), and the result follows. Solution to 3.4.18:Expanding the matrix differential equation, we get the family of differential equations \[\frac{df_{ij}}{dt}=f_{i-1\,j-1},\hskip 28.452756pt1\leq i,j\leq n,\] where \(f_{ij}\equiv 0\) if \(i\) or \(j\) equals \(0\). Solving these, we get \[\text{X}(t)\hskip-2.845276pt=\hskip-2.845276pt\left(\begin{array}{cccc}\xi_ {11}&\xi_{12}&\xi_{13}&\xi_{14}\\ \xi_{21}&\xi_{11}t+\xi_{22}&\xi_{12}t+\xi_{23}&\xi_{13}t+\xi_{24}\\ \xi_{31}&\xi_{21}t+\xi_{32}&\frac{1}{2}\xi_{11}t^{2}+\xi_{22}t+\xi_{33}&\frac{ 1}{2}\xi_{12}t^{2}+\xi_{23}t+\xi_{34}\\ \xi_{41}&\xi_{31}t+\xi_{42}&\frac{1}{2}\xi_{21}t^{2}+\xi_{32}t+\xi_{43}&\frac{ 1}{6}\xi_{11}t^{3}+\frac{1}{2}\xi_{22}t^{2}+\xi_{33}t+\xi_{44}\end{array}\right)\] where the \(\xi_{ij}\)'s are constants. Solution 2.We will use a power series. Assume \(X(t)=\sum_{n=0}^{\infty}t^{n}C_{n}\). The given equation gives \[\sum_{n=1}^{\infty}nt^{n-1}C_{n}=\sum_{n=0}^{\infty}At^{n}C_{n}B\] which can be written as \[\sum_{n=0}^{\infty}t^{n}\left((n+1)C_{n+1}-AC_{n}B\right)\rightleftharpoons 0\] giving the recurrence relation \[C_{n+1}=\frac{1}{n+1}AC_{n}B,\] so we have \[C_{n}=\frac{1}{n!}A^{n}C_{0}B^{n}.\] Since \(A^{4}=B^{4}=0\), the solution reduces to a polynomial of degree at most \(3\): \[X(t)=C_{0}+tAC_{0}B+\frac{t^{2}}{2}A^{2}C_{0}B^{2}+\frac{t^{3}}{6}A^{3}C_{0}B^ {3}\] where \(C_{0}=X(0)\) is the initial value of \(X\).

## 4 Metric Spaces

### 4.1 Topology of \(\mathbb{R}^{n}\)

**Solution to 4.1.1:** Suppose there is no such \(\varepsilon\). Then there exists a sequence \((x_{n})\) in \(K\) such that none of the balls \(B_{1/n}(x_{n})\) is contained in any of the balls \(B_{j}\). Since \(K\) is compact, this sequence has a limit point, by the Bolzano-Weierstrass Theorem [12, pag. 40], [13, pag. 153], \(x\in K\). Then, since the \(B_{j}\)'s are an open cover of \(K\), there is a \(j\) and an \(\varepsilon>0\) such that \(B_{\varepsilon}(x)\subset B_{j}\). Let \(1/N<\varepsilon/2\), and choose \(n>N\) such that \(|x-x_{n}|<\varepsilon/2\). Then \(B_{1/n}(x_{n})\subset B_{\varepsilon}(x)\subset B_{j}\), contradicting our choice of \(x_{n}\)'s. Hence, the desired \(\varepsilon\) must exist.

_Solution 2._ Suppose the conclusion is false. Then, for each positive integer \(n\), there are two points \(x_{n}\) and \(y_{n}\) in \(K\) such that \(|x_{n}-y_{n}|<1/n\), yet no \(B_{j}\) contains both \(x_{n}\) and \(y_{n}\). Since \(K\) is compact, the sequence \((x_{n})\) has a convergent subsequence, \((x_{n_{k}})\) say, with limit \(\rho\in K\). Then, obviously, \(y_{n_{k}}\to\rho\). There is a \(B_{j}\) that contains \(\rho\). Since \(B_{j}\) is open and \(\rho=\lim x_{n_{k}}=\lim y_{n_{k}}\), both \(x_{n_{k}}\) and \(y_{n_{k}}\) must be in \(B_{j}\) for \(k\) sufficiently large, in contradiction to the way the points \(x_{n}\) and \(y_{n}\) were chosen.

_Solution 3._ By compactness, we can choose a finite subcover \(\{B_{j}\}_{j=1}^{N}\) of \(K\), [12, pag. 30]. For \(x\in K\), define

\[f(x)=\max\{\operatorname{dist}(x,\mathbb{R}^{n}\setminus B_{j})\,|\,x\in B_{j}\}.\]

Then \(f(x)>0\) for each \(x\in K\), because each \(B_{j}\) is open and there are only finitely many of them. Since \(K\) is compact and \(f\) is continuous and strictlypositive on \(K\), \(f\) has a positive minimum \(\varepsilon>0\). By definition of \(f\), every \(\varepsilon\)-ball centered at a point of \(K\) is contained in some \(B_{j}\).

**Solution to 4.1.2:** Suppose \(U_{n}\) is an open set of real numbers for \(n\in\mathbb{N}\), such that \(\mathbb{Q}\,=\cap U_{n}\). Then each set \(\mathbb{R}\setminus U_{n}\) is nowhere dense, since it is a closed set which contains only irrational numbers. We then have

\[\mathbb{R}=\bigcup_{n\in\mathbb{N}}U_{n}\bigcup_{q\in\mathbb{Q}}\{q\}\]

but \(\mathbb{R}\) is not a countable union of nowhere dense sets, by Baire's Category Theorem [13, pag. 175]. So \(\mathbb{Q}\,\) cannot be a countable intersection of open sets.

**Solution to 4.1.3:** Suppose \(x,y\in X\). Without loss of generality, assume \(x<y\). Let \(z\) be such that \(x<z<y\) (for instance, \(z\) irrational verifying the double inequality). Then

\[(-\infty,z)\cap X\,,\,\,\,(z,\infty)\cap X\]

is a disconnection of \(X\). We conclude then that \(X\) can have only one element.

**Solution to 4.1.4:** The Cantor set [12, pag. 41] is an example of a closed set having uncountably many connected components.

Let \(A\) be an open set and suppose \(C_{\alpha}\,,\,\alpha\in\Gamma\) are its connected components. Each \(C_{\alpha}\) is an open set, so it contains a rational number. As the components are disjoint, we have an injection of \(\Gamma\) in \(\mathbb{Q}\,,\) so \(\Gamma\) is, at most, countable.

**Solution to 4.1.5:** Suppose we have

\[[0,1]=\bigcup_{i\in\mathbb{N}}[a_{i},b_{i}]\]

where the \([a_{i},b_{i}]\)'s are non empty pairwise disjoint intervals. Let \(X\) be the set of the corresponding endpoints:

\[X=\{a_{1},a_{2},\ldots\}\cup\{b_{1},b_{2},\ldots\}.\]

We will show that \(X\) is a perfect set, so it cannot be countable.

The complement of \(X\) in \([0,1]\) is a union of open intervals, so it is open, and \(X\) is closed. By the assumption, there must be elements of \(X\) in \((a_{i}\rightharpoonup\varepsilon,a_{i})\) for each \(\varepsilon>0\), and each \(i\in\mathbb{N}\), and similarly for the \(b_{i}\)'s. Each element of \(X\) is then an accumulation point, and \(X\) is perfect.

**Solution to 4.1.6:** 1. Let \(X=\{x\}\) and \((y_{n})\) be a sequence in \(Y\) such that \(|x-y_{n}|<d(X,Y)+1/n\). As \((y_{n})\) is bounded, passing to a subsequence,we may assume that it converges, to \(y\), say. As \(Y\) is closed, \(y\in Y\) and, by the continuity of the norm, \(|x-y|=d(X,Y)\).

2. Let \((x_{n})\) be a sequence in \(X\) such that \(d((x_{n}),Y)<d(X,Y)+1/n\). As \(X\) is compact, by the Bolzano-Weierstrass Theorem [13, pag. 40], [14, pag. 153], we may assume, passing to a subsequence, that \((x_{n})\) converges, to \(x\), say. We then have \(d(X,Y)=d(\{x\},Y)\) and the result follows from Part 1.

3. Take \(X=\{(x,1/x)\,|\,x>0\}\) and \(Y=\{(x,0)\,|\,x>0\}\) in \(\mathbb{R}^{2}\).

**Solution to 4.1.7:** Suppose that \(S\) contains no limit points. Then, for each \(x\in S\), there is a \(\delta_{x}>0\) such that \(B_{\delta_{x}}\cap S=\{x\}\). Let \(\varepsilon_{x}=\delta_{x}/2\). The balls \(B_{\varepsilon_{x}}(x)\) are disjoint, so we can choose a distinct point from each one with rational coordinates. Since the collection of points in \(\mathbb{R}^{n}\) with rational coordinates is countable, the set \(S\) must be countable, a contradiction. Hence, \(S\) must contain one of its limit points.

**Solution to 4.1.8:** Let \(y\) be a limit point of \(Y\) and \((y_{n})\) a sequence in \(Y\) converging to \(y\). Without loss of generality, we may suppose that \(|y_{n}-y|<r\). By the definition of \(Y\), there is a sequence \((x_{n})\) in \(X\) with \(|x_{n}-y_{n}|=r\). Therefore, \(|x_{n}-y|\leq|x_{n}-y_{n}|+|y_{n}-y|<2r\), so the sequence \((x_{n})\) is bounded. Hence, it has a limit point \(x\in X\). By passing to subsequences of \((x_{n})\) and \((y_{n})\), if necessary, we may assume that \(\lim x_{n}=x\). Let \(\varepsilon>0\). For \(n\) large, we have

\[|x-y|\leq|x-x_{n}|+|x_{n}-y_{n}|+|y_{n}-y|\leq r+2\varepsilon\]

and

\[r=|x_{n}-y_{n}|\leq|x_{n}-x|+|x-y|+|y-y_{n}|\leq|x-y|+2\varepsilon.\]

Since \(\varepsilon\) is arbitrary, \(|x-y|=r\). Hence, \(y\in Y\) and \(Y\) is closed.

**Solution to 4.1.9:** For \(k=1,\ldots\), let \(B_{k}\) be the family of open balls in \(\mathbb{R}^{n}\) whose centers have rational coordinates and whose radii are \(1/k\). Each family \(B_{k}\) is countable. For each ball \(B\in B_{k}\) such that \(B\cap A\neq\emptyset\), choose a point in \(B\cap A\), and let \(A_{k}\) be the set of chosen points. Each \(A_{k}\) is a countable subset of \(A\), so the set \(A_{\infty}=\cup A_{k}\) is a countable subset of \(A\). Since \(A\) is closed, the inclusion \(\overline{A_{\infty}}\subset A\) is obvious. Suppose \(a\in A\) and fix a positive integer \(k\). Then \(a\) lies in some ball that \(B_{k}\) is covered by \(U_{1},\ldots,U_{j_{k}}\). Define \(V_{j}\) by setting \(V_{j}=U_{j}\setminus B_{k}\) for \(j_{k}+1\leq j\leq j_{k+1}\) (if the indices \(j_{k}\) are all equal from some point on, set \(V_{j}=\emptyset\) for \(j\) larger than their ultimate value.) The sets \(V_{1},V_{2},\ldots\) have the required property.

**Solution to 4.1.11:** If \(K\) is not bounded, then the function \(x\mapsto\|x\|\) is not bounded on \(K\). If \(K\) is bounded but not compact, then it is not closed, by the Heine-Borel Theorem, [20, pag. 40], [21, pag. 155]; therefore, there exists \(\xi\in\overline{K}\setminus K\). In this case, the function \(x\mapsto\|x-\xi\|^{-1}\) is not bounded on \(K\).

**Solution to 4.1.12:** 1. Suppose not. Then there is a positive number \(\delta\) and a subsequence of \((x_{i})\), \((y_{n})\), such that

\[|y_{n}-x|\geq\delta.\]

As \(A\) is compact, by the Bolzano-Weierstrass Theorem [20, pag. 40], [21, pag. 153], \((y_{n})\) has a convergent subsequence, which, by hypothesis, converges to \(x\), contradicting the inequality.

2. Let \(A=\mathbb{R}\) and consider

\[x_{i}=\left\{\begin{array}{ccc}i&\mbox{if}&i&\mbox{is odd}\\ \frac{1}{i}&\mbox{if}&i&\mbox{is even.}\end{array}\right.\]

All the convergent subsequences converge to zero, but \((x_{i})\) diverges.

**Solution to 4.1.13:** Let \(\varepsilon>0\). As \(f\) is uniformly continuous on \(X\), there is a \(\delta>0\) such that

\[|f(x)-f(y)|<\varepsilon\leq\varepsilon+M_{1}|x-y|\]

for \(|x-y|<\delta\) and any \(M_{1}\geq 0\).

Assume \(|x-y|\geq\delta\). As \(f\) is bounded, there is an \(M_{2}>0\) with \(|f(x)-f(y)|\leq M_{2}\) for all \(x\) and \(y\). Let \(M_{1}=M_{2}/\delta\). We have

\[|f(x)-f(y)|\leq\delta M_{1}\leq M_{1}|x-y|\leq M_{1}|x-y|+\varepsilon\]

for all \(x,y\in X\).

**Solution to 4.1.14:** Let

\[S=\bigcup_{\alpha}S_{\alpha}=A\cup B\]

where \(A\) and \(B\) are open. The origin belongs to \(A\) or to \(B\). Without loss of generality, assume \(O\in A\). For every \(\alpha\), we have

\[S_{\alpha}=(S_{\alpha}\cap A)\cup(S_{\alpha}\cap B)\]so, as \(S_{\alpha}\) is connected and \(O\in S_{\alpha}\cap A\), we get \(S_{\alpha}\cap B=\emptyset\). Therefore, \[S\cap B=\bigcup_{\alpha}(S_{\alpha}\cap B)=\emptyset\] and \(S\) is connected.

**Solution to 4.1.16:** The assertion is true. Let \(S\) be such a set and \(a\) a point in \(S\). Define the set \(S_{a}=\{b\in S\,|\,a\text{ and }b\text{ are connected by a path in }S\}\). \(S_{a}\) is open (because \(S\) is locally path connected) as well as its complement in \(S\), so these two sets make up a partition of \(S\), which is connected, therefore, the partition is trivial and \(S_{a}\) is the whole \(S\).

**Solution to 4.1.19:**\(1\). \(P^{2}\) is the quotient of the sphere \(S^{2}\) by the equivalence relation that identifies two antipode points \(x\) and \(-x\). If \(\pi:S^{2}\to P^{2}\) is the natural projection which associates each point \(x\in S^{2}\) to its equivalence class \(\pi(x)=\{x,-x\}\in P^{2}\), the natural topology is the quotient topology; that is, \(A\subset P^{2}\) is open if and only if \(\pi^{-1}(A)\subset S^{2}\) is open. With this topology, the projection \(\pi\) is a continuous function and \(P^{2}=\pi(S^{2})\) is compact, being the image of a compact by a continuous function.

Another topology frequently referred to as the _usual_ topology of \(P^{2}\) is the one defined by the metric

\[d(x,y)=\min\{|x-y|,|x+y|\}.\]

It is a straightforward verification that the function \(d\) above satisfies all axioms of a metric. We will show now that it defines the same topology as the one above, on the space that we will call \((P^{2},d)\).

The application \(\pi:S^{2}\to P^{2}\) with the metric as above satisfies the inequality

\[d(\pi(x),\pi(y))\leq|x-y|\]

so \(d\) is continuous. This defines a function \(\bar{\pi}\) on the quotient which is

the identity and then continuous. Since \(P^{2}\) is compact and \((P^{2},d)\) Hausdorff, \(\bar{\pi}\) is a homeomorphism and the two topologies in \(P^{2}\) are equivalent.

Now \(\mathcal{S}\mathcal{O}(3)\) is the group of orthogonal transformations of \(\mathbb{R}^{3}\) with determinant \(1\), so every matrix in this set of satisfies

\[X\cdot X^{t}=\left(\begin{array}{ccc}1&0&0\\ 0&1&0\\ 0&0&1\end{array}\right)\]therefore, \(\sum_{k=1}^{3}X_{ik}^{2}=1\), for \(i=1,2,3\), implying that \(S\mathbb{O}(3)\) is bounded. Consider now the transformation

\[\begin{array}{rcl}f:M_{3\times 3}\approx\mathbb{R}^{9}&\to&M_{3\times 3}\times \mathbb{R}\\ X&\to&(X^{t}X,\det X).\end{array}\]

\(f\) is continuous and \(S\mathbb{O}(3)=f^{-1}(I,1)\), that is, the inverse image of a closed set, then itself a closed set, showing that \(S\mathbb{O}(3)\) is compact. Another way to see this is to observe that the function

\[X\to\sqrt{\operatorname{tr}\,(X^{t}X)}\]

is a norm on the space of matrices \(M_{n\times n}\equiv\mathbb{R}^{n^{2}}\) and that for matrices in the orthogonal group \(\operatorname{tr}\,(X^{t}X)=n\), so \(\mathbb{O}(n)\) and, consequentially, \(S\mathbb{O}(n)\) are compact.

2. To see the homeomorphism between \(P^{2}\) and \(Q\), first define the application \(\varphi:P^{2}\to Q\) given by the following construction: For each line \(\widetilde{x}\) through the origin, take \(\varphi_{x}:\mathbb{R}^{3}\to\mathbb{R}^{3}\) as the rotation of \(180^{\circ}\) around the axis \(\widetilde{x}\). This is well defined and continuous. To see that it is surjective, notice that every orthogonal matrix in \(\dim 3\) is equivalent to one of the form

\[\left(\begin{array}{ccc}1&0&0\\ 0&\cos\theta&\sin\theta\\ 0&-\sin\theta&\cos\theta\end{array}\right)\]

and with the additional condition of symmetry \(\theta=\pi\), which is a rotation of \(180^{\circ}\) around an axis. For more details see the Solution to Problem 7.4.18. Since \(\varphi\) is continuous and injective on a compact, it is an homeomorphism.

**Solution to 4.1.21:** Convergence in \(M_{n\times n}\) is entrywise convergence. In other words, the sequence \((A_{k})\) in \(M_{n\times n}\) converges to the matrix \(A\) if and only if, for each \(i\) and \(j\), the \((i,j)^{th}\) entry of \(A_{k}\) converges to the \((i,j)^{th}\) entry of \(A\). It follows that the operator of multiplication in \(M_{n\times n}\) is continuous; in other words, if \(A_{k}\to A\) and \(B_{k}\to B\), then \(A_{k}B_{k}\to AB\). Now suppose \((A_{k})\) is a sequence of nilpotent matrices in \(M_{n\times n}\) and assume \(A_{k}\to A\). Then \(A_{k}^{n}\to A^{n}\) by the continuity of multiplication. But \(A_{k}^{n}=0\) for each \(k\) since \(A_{k}\) is nilpotent. Hence, \(A^{n}=0\), that is, \(A\) is nilpotent. As a subset of a metric space is closed exactly when it contains all its limit points, the conclusion follows.

### 4.2 General Theory

**Solution to 4.2.1:** Let \(\mathcal{U}\) be an open cover of \(C\). Then there is a set \(U_{0}\) in \(\mathcal{U}\) that contains \(x_{0}\). Since \(\lim_{n\to\infty}x_{n}=x_{0}\), there is an \(n_{0}\) such that \(x_{n}\) is in \(U_{0}\) for all \(n>n_{0}\). For each \(n\leq n_{0}\) there is a set \(U_{n}\) in \(\mathcal{U}\) that contains \(x_{n}\). The subfamily \(\{U_{0},U_{1},\ldots,U_{n_{0}}\}\) is then a finite subcover of \(C\), proving, by the Heine-Borel Theorem [12, pag. 30], that \(C\) is compact.

**Solution to 4.2.2:** Let \(X\) be a compact metric space. For each \(n\in\mathbb{N}\), consider a cover of \(X\) by balls with radius \(1/n\), \(\mathcal{B}(1/n)=\{B_{\alpha}(x_{\alpha},1/n)\,|\,x_{\alpha}\in X\}\). As \(X\) is compact, a finite subcollection of \(\mathcal{B}(1/n)\), \(\mathcal{B}^{\prime}(1/n)\), covers \(X\), by the Heine-Borel Theorem [12, pag. 30]. Let \(A\) be the set consisting of the centers of the balls in \(\mathcal{B}^{\prime}(1/n)\), \(n\in\mathbb{N}\). \(A\) is a countable union of finite sets, so it is countable. It is also clearly dense in \(X\).

**Solution to 4.2.3:** Suppose \(x\not\in f(X)\). As \(f(X)\) is closed, there exists a positive number \(\xi\) such that \(d(x,f(X))\geq\xi\).

As \(X\) is compact, using the Bolzano-Weierstrass Theorem [12, pag. 40], [13, pag. 153], the sequence of iterates \((f^{n}(x))\) has a convergent subsequence, \((f^{n_{i}}(x))\), say. For \(i<j\), we have

\[d\left(f^{n_{i}}(x),f^{n_{j}}(x)\right)=d\left(x,f^{n_{j}-n_{i}}(x)\right)\geq\xi\]

which contradicts the fact that every convergent sequence in \(X\) is a Cauchy sequence, and the conclusion follows.

**Solution to 4.2.4:** For \(x\in C\) we clearly have \(f(x)=0\). Conversely, if \(f(x)=0\), then there is a sequence \((y_{n})\) in \(C\) with \(d(x,y_{n})\to 0\). As \(C\) is closed, we have \(x\in C\).

Given \(x\), \(z\in M\) and \(y\in C\), we have, by the Triangle Inequality [13, pag. 20],

\[d(x,y)\leq d(x,z)+d(z,y).\]

Taking the infimum of both sides over \(y\in C\), we get

\[f(x)\leq d(x,z)+f(z)\]

or

\[f(x)-f(z)\leq d(x,z),\]

and, by symmetry,

\[f(z)-f(x)\leq d(x,z).\]

Therefore,

\[|f(x)-f(z)|\leq d(x,z)\]

and \(f\) is continuous.

**Solution to 4.2.5:**\(\|f\|\geq 0\) for all \(f\) in \(C^{1/3}\) is clear. If \(f\equiv 0\), it is obvious that \(\|f\|=0\). Conversely, suppose that \(\|f\|=0\). Then, for all \(x\neq 0\), we have

\[0\leq\frac{|f(x)-f(0)|}{|x-0|}\leq\|f\|=0.\]Since \(f(0)=0\), this implies \(f(x)=0\) for all \(x\). Let \(f,g\in C^{1/3}\) and \(\varepsilon>0\). There exists \(x\neq y\) such that

\[\|f+g\| \leq\frac{|(f+g)(x)-(f+g)(y)|}{|x-y|^{1/3}}+\varepsilon\] \[\leq\frac{|f(x)-f(y)|}{|x-y|^{1/3}}+\frac{|g(x)-g(y)|}{|x-y|^{1/3} }+\varepsilon\] \[\leq\|f\|+\|g\|+\varepsilon.\]

Since \(\varepsilon\) was arbitrary, the Triangle Inequality holds.

The property \(\|cf\|=|c\|\|f\|\) for \(f\in C^{1/3}\) and \(c\in\mathbb{R}\) is clear.

Let \(\{f_{n}\}\) be a Cauchy sequence in \(C^{1/3}\). By the definition of the norm, for all \(x\in[0,1]\) and any \(\varepsilon>0\) there is an \(N>0\) such that if \(n,m>N\), we have

\[|(f_{n}-f_{m})(x)-(f_{n}-f_{m})(0)|\leq|x-0|^{1/3}\varepsilon\]

or

\[|f_{n}(x)-f_{m}(x)|\leq\varepsilon.\]

Hence, the sequence \(\{f_{n}\}\) is uniformly Cauchy. A similar calculation shows that functions in \(C^{1/3}\) are continuous. Since the space of continuous functions on \([0,1]\) is complete with respect to uniform convergence, there exists a continuous function \(f\) such that the \(f_{n}\)'s converge to \(f\) uniformly. Suppose \(f\notin C^{1/3}\). Then, for any \(M>0\), there exist \(x\neq y\) such that

\[\frac{|f(x)-f(y)|}{|x-y|^{1/3}}>M.\]

So

\[\frac{|f(x)-f_{n}(x)|}{|x-y|^{1/3}}+\frac{|f_{n}(x)-f_{n}(y)|}{|x-y|^{1/3}}+ \frac{|f(y)-f_{n}(y)|}{|x-y|^{1/3}}>M.\]

Since the \(f_{n}\)'s converge to \(f\) uniformly, for fixed \(x\) and \(y\) we can make the first and third terms as small as desired. Hence, \(\|f_{n}\|>M\) for all \(M\) and \(n\) sufficiently large, contradicting the fact that \(f_{n}\in C^{1/3}\) and that, since the \(f_{n}\)'s are Cauchy, their norms are uniformly bounded.

Suppose now that the sequence \(\{f_{n}\}\) does not converge to \(f\) in \(C^{1/3}\). Then there is an \(\varepsilon>0\) such that \(\|f_{n}-f\|>\varepsilon\) for infinitely many \(n\)'s. But then there exist \(x\neq y\) with

\[\frac{|f_{n}(x)-f(x)|}{|x-y|^{1/3}}+\frac{|f_{n}(y)-f(y)|}{|x-y|^{1/3}}>\varepsilon\]

for those \(n\)'s. But, as we have uniform convergence, we can make the left hand side as small as desired for fixed \(x\) and \(y\), a contradiction.

**Solution to 4.2.7:** Since \(f(K)\subset f(K_{n})\) for all \(n\), the inclusion \(f(K)\subset\cap_{1}^{\infty}f(K_{n})\) is clear. Let \(y\) be a point in \(\cap_{1}^{\infty}f(K_{n})\). Then, for each \(n\), the set \(f^{-1}(\{y\})\cap K_{n}\) is nonempty and compact (the latter because it is a closed subset of the compact set \(K_{n}\)). Also, \(f^{-1}(\{y\})\cap K_{n+1}\subset f^{-1}(\{y\})\cap K_{n}\). Hence, by the Nested Set Property [13, pag. 157], the set \[\bigcap_{1}^{\infty}\left(f^{-1}\left(\{y\}\right)\cap K_{n}\right)=f^{-1} \left(\{y\}\right)\cap K\] is nonempty; that is, \(y\in f(K)\). Solution to 4.2.8: 1. The completeness of \(X_{1}\) implies the completeness of \(X_{2}\). In fact, assume \(X_{1}\) is complete, and let \((y_{n})\) be a Cauchy sequence in \(X_{2}\). The conditions on \(f\) imply that it is one-to-one, so each \(y_{n}\) can be written uniquely as \(f(x_{n})\) with \(x_{n}\) in \(X_{1}\). Then \(d_{1}(x_{m},x_{n})\leq d_{2}(y_{m},y_{n})\), implying that \((x_{n})\) is a Cauchy sequence, hence convergent, say to \(x\). Since \(f\) is continuous, we then have \(\lim y_{n}=f(x)\), proving that \(X_{2}\) is complete. 2. The completeness of \(X_{2}\) does not imply the completeness of \(X_{1}\). For an example, take \(X_{1}=(-\frac{\pi}{2},\frac{\pi}{2})\), \(X_{2}=\mathbb{R}\), and \(f(x)=\tan x\). Since \(f^{\prime}(x)=\sec^{2}x\geq 1\) on \(X_{1}\), the condition \(|x-y|\leq|f(x)-f(y)|\) holds.

### 4.3 Fixed Point Theorem

**Solution to 4.3.1:** The map is the image, by a contraction, of a complete metric space (California!). The result is a consequence of the Fixed Point Theorem [12, pag. 220]. Solution to 4.3.2: Let \(g(x)=(1+x)^{-1}\). We have

\[g^{\prime}(x)=\frac{-1}{(1+x)^{2}}\]

therefore,

\[|g^{\prime}(x)|\leq\frac{1}{(1+x_{0}/2)^{2}}<1\quad\text{for}\quad x>x_{0}.\]

Then, by the Fixed Point Theorem [12, pag. 220], the sequence given by

\[x_{0}>0\,,\qquad x_{n+1}=g(x_{n})\]

converges to the unique fixed point of \(g\) in \([x_{0},\infty)\). Solving \(g(x)=x\) in that domain gives us the limit

\[\frac{-1+\sqrt{5}}{2}.\]

[MISSING_PAGE_EMPTY:247]

By the Contraction Mapping Principle [10, pag. 275], \(T\) has a unique fixed point, \(h\in C([0,1])\). We have \[h(x)+\int_{0}^{1}K(x,y)h(y)dy=e^{x^{2}}.\] Any such a solution is a fixed point of \(T\), so it must equal \(h\).

**Solution to 4.3.6:** Consider the map \(T:C\left([0,1]\right)\to C\left([0,1]\right)\) defined by

\[T(f)=g(x)+\int_{0}^{x}f(x-t)e^{-t^{2}}\,dt.\]

Given \(f,h\in C\left([0,1]\right)\), we have

\[\|T(f)-T(h)\|_{\infty} \leq\sup_{x\in[0,1]}\int_{0}^{x}|f(x-t)-h(x-t)|e^{-t^{2}}\,dt\] \[\leq\|f-h\|_{\infty}\sup_{x\in[0,1]}\int_{0}^{x}e^{-t^{2}}\,dt\] \[=\|f-h\|_{\infty}\int_{0}^{1}e^{-t^{2}}\,dt<\|f-h\|_{\infty}\] so \(T\) is a contraction. Since \(C\left([0,1]\right)\) is a complete metric space, by the Contraction Mapping Principle [10, pag. 275] there is \(f\in C\left([0,1]\right)\) such that \(T(f)=f\), as desired.

**Solution to 4.3.7:** Define the operator \(T\) on \(C\left([0,1]\right)\) by

\[T(f)(x)=\sin x+\int_{0}^{1}\frac{f(y)}{e^{x+y+1}}\,dy.\]

Let \(f,g\in C\left([0,1]\right)\). We have

\[\|T(f)-T(g)\| \leq\sup_{x}\left\{\int_{0}^{1}\frac{|f(y)-g(y)|}{e^{x+y+1}}\,dy\right\}\] \[\leq\sup_{x}\{|f(x)-g(x)|e^{-x}\}\int_{0}^{1}\frac{dy}{e^{y+1}}\] \[\leq\|f-g\|\left(\frac{1}{e}-\frac{1}{e^{2}}\right)\] \[\leq\lambda\|f-g\|,\]

where \(0<\lambda<1\) is a constant. Hence, \(T\) is a strict contraction. Therefore, by the Contraction Mapping Principle [10, pag. 275], there is a unique \(f\in C\left([0,1]\right)\) with \(\mathrm{T}(f)=f\).

**Solution to 4.3.8:** Since \(M\) is a complete metric space and \(S^{2}\) is a strict contraction, by the Contraction Mapping Principle [10, pag. 275] there is a unique point \(x\in M\) such that \(S^{2}(x)=x.\) Let \(S(x)=y.\) Then \(S^{2}(y)=S^{3}(x)=S(x)=y.\) Hence, \(y\) is a fixed point of \(S^{2},\) so \(x=y.\) Any fixed point of \(S\) is a fixed point \(S^{2},\) so \(S\) has a unique fixed point.

### 5.1 Complex Numbers

**Solution to 5.1.1:** We have

\[1=e^{2k\pi i}\quad\text{for}\quad k\in\mathbb{Z};\]

therefore,

\[1^{\frac{1}{3}+i} =e^{\left(\frac{1}{3}+i\right)\log 1}=e^{\left(\frac{1}{3}+i \right)2k\pi i}\] \[=e^{-2k\pi+i\frac{2k\pi}{3}}\] \[=e^{-2k\pi}\left(\cos\frac{2k\pi}{3}+i\sin\frac{2k\pi}{3}\right) \quad(k\in\mathbb{Z}).\]

**Solution to 5.1.2:** We have \(i^{i}=e^{i\log i}\) and \(\log i=\log|i|+i\arg i=i(\pi/2+2k\pi)\), \(k\in\mathbb{Z}\). So the values of \(i^{i}\) are \(\{e^{-(\pi/2+2k\pi)}\,|\,k\in\mathbb{Z}\}\).

**Solution to 5.1.4:** Multiplying by a unimodular constant, if necessary, we can assume \(c=1\). Then \(\Im a+\Im b=0\). So \(a=\bar{b}\). Their real part must be negative, since otherwise the real parts of \(a\), \(b\), and \(c\) would sum to a positive number. Therefore, there is \(\theta\) such that \(a=\cos\theta+i\sin\theta\) and \(b=\cos\theta-i\sin\theta\), \(\cos\theta=-1/2\). Then \(\theta=2\pi/3\) and we are done.

**Solution to 5.1.5:** 1. We have

\[P_{n-1}(x)=\frac{x^{n}-1}{x-1}\]\[=x^{n-1}+\cdots+1\]

for \(x\neq 1\), so \(P_{n-1}(1)=n\).

2. Let

\[p_{k}=e^{\frac{2\pi i(k-1)}{n}}\qquad\text{for }k=1,\ldots,n\]

be the \(n^{th}\) roots of \(1\). As \(p_{1}=1\), we have

\[\prod_{i=2}^{n}(z-p_{k})=P_{n-1}(z).\]

Letting \(z=1\), and using Part 1, we get the desired result.

**Solution to 5.1.6:** Consider the complex plane divided into four quadrants by the lines \(\Re z=\pm\Im z\), and let \(\Delta_{i}\) be the set of indices \(j\) such that \(z_{j}\) lies in the \(i^{th}\) quadrant. The union of the four sets \(\Delta_{i}\) is \(\{1,2,\ldots,n\}\), so there is an \(i\) such that \(\Delta=\Delta_{i}\) satisfies

\[\sum_{j\in\Delta}|z_{j}|\geq\frac{1}{4}\sum_{j=1}^{n}|z_{j}|.\]

Since multiplying all of the \(z_{j}\) by a unimodular constant will not affect this sum, we may assume that \(\Delta\) is the quadrant in the right half-plane, where \(\Re z_{j}>0\) and \(|z_{j}|\leq\sqrt{2}\Re z_{j}\). So we have

\[\left|\sum_{j\in\Delta}z_{j}\right|\geq\sum_{j\in\Delta}\Re z_{j}\geq\frac{1} {\sqrt{2}}\sum_{j\in\Delta}|z_{j}|.\]

Combining this with the previous inequality, we get the desired result.

**Solution to 5.1.7:** The functions \(1,\ e^{2\pi ix},\ldots,e^{2\pi inx}\) are orthonormal on [0,1]. Hence,

\[\int_{0}^{1}\left|1-\sum_{k=1}^{n}a_{k}\ e^{2\pi ikx}\right|^{2}dx=1+\sum_{k=1 }^{n}|a_{s}|^{2}\geq 1\.\]

Since the integrand is continuous and nonnegative, it must be \(\geq 1\) at some point.

_Solution 2._ Since \(\int_{0}^{1}e^{2\pi ikx}dx=0\) for \(k\neq 0\), we have

\[1=\int_{0}^{1}\left(1-\sum_{k=1}^{n}a_{k}e^{ikx}\right)dx\leq\int_{0}^{1} \left|1-\sum_{k=1}^{n}a_{k}\ e^{ikx}\right|dx\.\]

Now argue as above.

**Solution to 5.1.8:** We have

\[e^{b}-e^{a}=\int_{a}^{b}e^{z}\,dz\]

for all complex numbers \(a\) and \(b\), where the integral is taken over any path connecting them. Suppose that \(a\) and \(b\) lie in the left half-plane. Then we can take a path also in the same half-plane, and for any \(z\) on this line, \(|e^{z}|\leq 1\). Therefore, integrating along this line, we get

\[|e^{b}-e^{a}|\leq\int_{a}^{b}|e^{z}|\,|dz|\leq|b-a|.\]

**Solution to 5.1.9:** The boundary of \(N(A,r)\) consists of a finite set of circular arcs \(C_{i}\), each centered at a point \(a_{i}\) in \(A\). The sectors \(S_{i}\) with base \(C_{i}\) and vertex \(a_{i}\) are disjoint, and their total area is \(Lr/2\), where \(L\) is the length of the boundary. Since everything lies in a disc of radius \(2\), the total area is at most \(4\pi\), so \(L\leq 8\pi/r\).

**Solution to 5.1.10:** Without loss of generality, suppose that

\[|\alpha_{1}|\leq|\alpha_{2}|\leq\cdots\leq|\alpha_{l}|<|\alpha_{l+1}|=\cdots=| \alpha_{k}|\]

that is, exactly \(k-l\) of the \(\alpha\)'s with maximum modulus (\(l\) may be zero.)

We will first show that \(|\alpha_{k}|=\sup_{j}|\alpha_{j}|\) is an upper bound for the expression, and then prove that a subsequence gets arbitrarily close to this value. We have

\[\left|\sum_{j=1}^{k}\alpha_{j}^{n}\right|^{1/n}\leq\left(\sum_{j=1}^{k}|\alpha _{j}|^{n}\right)^{1/n}\leq\left(k\,|\alpha_{k}|^{n}\right)^{1/n}=k^{1/n}\,| \alpha_{k}|\]

the limit on the right exists and is \(|\alpha_{k}|=\sup_{j}|\alpha_{j}|\), so

\[\limsup_{n}\left|\sum_{j=1}^{k}\alpha_{j}^{n}\right|^{1/n}\leq\sup_{j}|\alpha_ {j}|\.\]

Now dividing the whole expression by \(\alpha_{k}^{n}\) we get

\[\sum_{j=1}^{k}\alpha_{j}^{n}=\alpha_{k}^{n}\sum_{j=1}^{k}\left(\frac{\alpha_{j }}{\alpha_{k}}\right)^{n}=\alpha_{k}^{n}\left(\sum_{j=1}^{l}\left(\frac{\alpha _{j}}{\alpha_{k}}\right)^{n}+\sum_{j=l+1}^{k}e^{in\theta_{j}}\right)\]

since the last \(k-l\) terms all have absolute value \(1\).

I suffices to show that

[MISSING_PAGE_FAIL:253]

### 5.2 Series and Sequences of Functions

**Solution to 5.2.1:** Multiplying the first \(N+1\) factors we get

\[\frac{1-z^{10}}{1-z}\ \frac{1-z^{100}}{1-z^{10}}\ \frac{1-z^{1000}}{1-z^{100}} \cdots\frac{1-z^{10N}}{1-z^{10N-1}}=\frac{1-z^{10N}}{1-z}\]

so the product converges to \(1/(1-z)\) as \(N\to\infty\).

**Solution to 5.2.2:** From the recurrence relation, we see that the coefficients \(a_{n}\) grow, at most, at an exponential rate, so the series has a positive radius of convergence. Let \(f\) be the function it represents in its disc of convergence, and consider the polynomial \(p(z)=3+4z-z^{2}\). We have

\[p(z)f(z) =(3+4z-z^{2})\sum_{n=0}^{\infty}a_{n}z^{n}\] \[=3a_{0}+(3a_{1}+4a_{0})z+\sum_{n=0}^{\infty}(3a_{n}+4a_{n-1}-a_{ n-2})z^{n}\] \[=3+z.\]

So

\[f(z)=\frac{3+z}{3+4z-z^{2}}.\]

The radius of convergence of the series is the distance from \(0\) to the closest singularity of \(f\), which is the closest root of \(p\). The roots of \(p\) are \(2\pm\sqrt{7}\). Hence, the radius of convergence is \(\sqrt{7}-2\).

**Solution to 5.2.3:** Let \(f(z)=\exp\left(\frac{z}{z-2}\right)\). The series can then be rewritten as \(\sum_{n=1}^{\infty}\frac{1}{n^{2}}\left(f(z)\right)^{n}\), so, by the standard theory of power series, it converges if and only if \(\left|f(z)\right|\leq 1\). The preceding inequality holds when \(\Re\frac{z}{z-2}\leq 0\), so the problem reduces to that of finding the region sent into the closed left half-plane by the linear fractional map \(z\mapsto\frac{z}{z-2}\). The inverse of the preceding map is the map \(g\) defined by \(g(z)=\frac{2z}{z-1}\). Since \(g(0)=0\) and \(g(\infty)=2\), the image of the imaginary axis under \(g\) is a circle passing through the points \(0\) and \(2\). As \(g\) sends the real axis onto itself, that circle must be orthogonal to the real axis, so it is the circle \(\left|z-1\right|=1\). Thus, \(g\) sends the open left half-plane either to the interior or to the exterior of that circle. Since \(g(-1)=1\), the first possibility occurs. We can conclude that \(\left|f(z)\right|\leq 1\) if and only if \(\left|z-1\right|\leq 1\) and \(z\neq 2\), which is the region of convergence of the original series.

**Solution to 5.2.4:** The radius of convergence, \(R\), of this power series is given by

\[\frac{1}{R}=\limsup_{n\to\infty}|a_{n}|^{1/n}.\]

For \(|z|<1\), we have

\[\sum_{n=1}^{\infty}nz^{n-1}=\left(\sum_{n=0}^{\infty}z^{n}\right)^{\prime}= \left(\frac{1}{1-z}\right)^{\prime}=\frac{1}{(1-z)^{2}}.\]

By the Identity Theorem [13, pag. 397],

\[f(z)=\frac{1}{(1-z)^{2}}\]

where the right-hand side is analytic. Since this happens everywhere except at \(z=1\), the power series expansion of \(f\) centered at \(-2\) will have a radius of convergence equal to the distance between \(-2\) and \(1\). Hence, \(R=3\).

**Solution to 5.2.5:** As

\[1-x^{2}+x^{4}-x^{6}+\cdots=\frac{1}{1+x^{2}}\]

which has singularities at \(\pm i\), the radius of convergence of

\[\sum_{n=0}^{\infty}a_{n}(x-3)^{n}\]

is the distance from \(3\) to \(\pm i\), \(|3\mp i|=\sqrt{10}\). We then have

\[\limsup_{n\to\infty}\left(|a_{n}|^{\frac{1}{n}}\right)=\frac{1}{\sqrt{10}}.\]

**Solution to 5.2.6:** As \(\lim_{n\to\infty}\sqrt[n]{n^{2}}=1\), we have

\[\frac{1}{R}=\limsup_{n\to\infty}\sqrt[n]{|a_{n}|}=\limsup_{n\to\infty}\sqrt[n]{ n^{2}|a_{n}|}\]so \(\sum a_{n}z^{n}\) and \(\sum n^{2}a_{n}z^{n}\) have the same radius of convergence, and the conclusion follows.

**Solution to 5.2.9:** Let \(R\) denote the radius of convergence of this power series.

\[R=\limsup_{n}|n^{\log n}|^{1/n}=\limsup_{n}e^{(\log n)^{2}/n}=e^{0}=1.\]

The series and all term by term derivatives converge absolutely on \(|z|<1\) and diverge for \(|z|>1\). Let \(|z|=1\). For \(k\geq 0\) the \(k^{th}\) derivative of the power series is

\[\sum_{n=k}^{\infty}n(n-1)\cdots(n-k+1)\frac{z^{n-k}}{n^{\log n}}.\]

To see that this converges absolutely, note that

\[\sum_{n=k}^{\infty}n(n-1)\cdots(n-k+1)\frac{1}{n^{\log n}}\leq\sum_{n=k}^{ \infty}\frac{1}{n^{\log n-k}}.\]

Since, for \(n\) sufficiently large, \(\log n-k>2\), and \(\sum 1/n^{2}\) converges, by the Comparison Test [14, pag. 60] it follows that the power series converges absolutely on the circle \(|z|=1\).

**Solution to 5.2.10:** We have

\[\limsup\Big{|}\frac{a_{n}}{n!}\Big{|}^{1/n} =\limsup|a_{n}|^{1/n}\limsup\bigg{|}\frac{1}{n!}\bigg{|}^{1/n}\] \[=\frac{1}{R}\limsup\bigg{|}\frac{1}{n!}\bigg{|}^{1/n}\] \[=\frac{1}{R}\cdot 0\] \[=0\]

so \(h\) is entire.

Let \(0<r<R\). Then \(1/R<1/r\), so there is an \(N>0\) such that \(|a_{n}|\leq 2/r^{n}\) for \(n>N\). Further, there exists a constant \(M>2\) such that \(|a_{n}|\leq M/r^{n}\) for \(1\leq n\leq N\). Therefore, for all \(z\),

\[|h(z)|\leq\sum_{n=1}^{\infty}|a_{n}|\frac{|z|^{n}}{n!}\leq M\sum_{n=1}^{\infty }\frac{|z|^{n}}{r^{n}n!}=Me^{|z|/r}.\]

**Solution to 5.2.11:** Let the residue of \(f\) at \(1\) be \(K\). We have

\[\sum_{n=0}^{\infty}a_{n}z^{n}=\frac{K}{1-z}+\sum_{n=0}^{\infty}b_{n}z^{n}\quad \text{with}\quad\limsup_{n\to\infty}|b_{n}|^{1/n}>1.\]Therefore,

\[\sum_{n=0}^{\infty}a_{n}z^{n}=\sum_{n=0}^{\infty}(K+b_{n})z^{n}\]

and \(a_{n}=K+b_{n}\). As \(\sum b_{n}<\infty\), we have \(\lim b_{n}=0\) and \(\lim a_{n}=K\).

**Solution to 5.2.12:** The rational function

\[f(z)=\frac{1-z^{2}}{1-z^{12}}\]

has poles at all nonreal twelfth roots of unity (the singularities at \(z^{2}=1\) are removable). Thus, the radius of convergence is the distance from \(1\) to the nearest singularity:

\[R=|\exp(\pi i/6)-1|=\sqrt{(\cos(\pi/6)-1)^{2}+\sin^{2}(\pi/6)}=\sqrt{2-\sqrt{3}}\.\]

**Solution to 5.2.14:** By the Hurwitz Theorem [13, pag. 423], each zero of \(g\) is the limit of a sequence of zeros of the \(g_{n}\)'s, which are all real, so the limit will be real as well.

**Solution to 5.2.15:** Let \(\varepsilon_{k}=\lim_{n\to\infty}g_{n}^{(k)}(0)\). Then, clearly, \(|\varepsilon_{k}|\leq|f^{(k)}(0)|\) for all \(k\). Since \(f\) is an entire function, its Maclaurin series [13, pag. 234] converges absolutely for all \(z\). Therefore, by the Comparison Test [13, pag. 60], the series

\[\sum_{k=0}^{\infty}\varepsilon_{k}z^{k}\]

converges for all \(z\) and defines an entire function \(g(z)\). Let \(R>0\) and \(\varepsilon>0\). For \(|z|\leq R\), we have

\[|g_{n}(z)-g(z)| \leq\sum_{k=0}^{N}|g_{n}^{(k)}(0)-\varepsilon_{k}|R^{k}\] \[\leq\sum_{k=0}^{N}|g_{n}^{(k)}(0)-\varepsilon_{k}|R^{k}+\sum_{k=N +1}^{\infty}2|f^{(k)}(0)|R^{k}\]

taking \(N\) sufficiently large, the second term is less than \(\varepsilon/2\) (since the power series for \(f\) converges absolutely and uniformly on the disc \(|z|\leq R\)). Let \(n\) be so large that \(|g_{n}^{(k)}(0)-\varepsilon_{k}|<\varepsilon/2M\) for \(1\leq k\leq N\), where

\[M=\sum_{k=0}^{N}R^{k}.\]

Thus, for such \(n\), we have \(|g_{n}(z)-g(z)|<\varepsilon\). Since this bound is independent of \(z\), the convergence is uniform.

### 5.3 Conformal Mappings

**Solution to 5.3.1:** We will show that the given transformations also map straight lines into circles or straight lines.

\(z\mapsto z+b\) and \(z\mapsto kz\) clearly map circles and straight lines into circles and straight lines.

Let \(S=\{z\,|\,|z-\alpha|=r\}\), \(\alpha=x_{0}+iy_{0}\), and \(f(z)=1/z=w=u+iv\). The equation for \(S\) is

\[(z-\alpha)(\overline{z}-\overline{\alpha})=r^{2}\]

or

\[\frac{1}{w\overline{w}}-\frac{\alpha}{\overline{w}}-\frac{\overline{\alpha}}{ w}=r^{2}-|\alpha|^{2}.\]

* If \(r=|\alpha|\), that is, when \(S\) contains the origin, we get \[1-\alpha w-\overline{\alpha}\overline{w}=0\] or \[\Re(\alpha w)=\frac{1}{2}.\] This is equivalent to \[ux_{0}-vy_{0}=\frac{1}{2}\] which represcnts a straight line.
* If \(r\neq|\alpha|\), we obtain \[w\overline{w}-\left(\frac{\overline{\alpha}}{|\alpha|^{2}-r^{2}}\right) \overline{w}-\left(\frac{\alpha}{|\alpha|^{2}-r^{2}}\right)w=\frac{-1}{| \alpha|^{2}-r^{2}}.\] Letting \[\beta=\frac{\overline{\alpha}}{|\alpha|^{2}-r^{2}}\] we get \[w\overline{w}-\beta\overline{w}-\overline{\beta}w+|\beta|^{2}=\frac{r^{2}}{ \left(|\alpha|^{2}-r^{2}\right)^{2}}\] and \[|w-\beta|^{2}=\left(\frac{r}{|\alpha|^{2}-r^{2}}\right)^{2}\] which represents the circle centered at \(\beta\) with radius \(r/(|\alpha|^{2}-r^{2})\).

If \(S\) is a straight line, then, for some real constants \(a\), \(b\), and \(c\), we have, for \(z=x+iy\in S\),

\[ax+by=c.\]Letting \(\alpha=a-ib\), we get

\[\Re(\alpha z)=c\]

or

\[\alpha z+\overline{\alpha z}=2c\]

and it follows, as above, that \(f(S)\) is a straight line or a circle.

Finally, let

\[f(z)=\frac{az+b}{cz+d}.\]

If \(c=0\)\(f\) is linear, so it is the sum of two functions that map circles and lines into circles and lines, so \(f\) itself has that mapping property. If \(c\neq 0\), we have

\[\frac{az+b}{cz+d}=\frac{1}{c}\left(a-\frac{ad-bc}{cz+d}\right)\]

so \(f(z)=f_{3}\left(f_{2}\left(f_{1}(z)\right)\right)\) where

\[f_{1}(z)=cz+d,\qquad f_{2}(z)=\frac{1}{z},\qquad f_{3}(z)=\frac{a}{c}-\frac{ ad-bc}{c}z,\]

each of which has the desired property, and so does \(f\).

**Solution to 5.3.3:** Let \(A=\{z\,|\,|z|<1\,,\,|z-1/4|>1/4\}\) and \(B=\{z\,|\,r<|z|<1\}\). Let \(f(z)=(z-\alpha)/(\alpha z-1)\) be a linear fractional transformation mapping \(A\) onto \(B\), where \(-1<\alpha<1\). We have

\[f\left(\{z\,|\,|z-1/4|=1/4\}\right)=\{z\,|\,|z|=r\}\]

so

\[\{f(0),f(1/2)\}=\{-r,r\}\]

and

\[0=r-r=f(0)+f(1/2)=\alpha+\frac{1/2-\alpha}{\alpha/2-1}\]

which implies \(\alpha=2-\sqrt{3}\). Therefore, \(r=|f(0)|=2-\sqrt{3}\).

Suppose now that \(g\) is a linear fractional transformation mapping \(C=\{z\,|\,s<|z|<1\}\) onto \(A\). Then \(g^{-1}(\mathbb{R})\) is a straight line through the origin, bccause the real line is orthogonal to the circles \(\{z\,|\,|z-1/4|=1/4\}\) and \(\{z\,|\,|z|=1\}\). Multiplying by a unimodular constant, we may assume \(g^{-1}(\mathbb{R})=\mathbb{R}\). Then \(f\circ g(C)=A\) and \(f\circ g(\mathbb{R})=\mathbb{R}\). Replacing, if necessary, \(g(z)\) by \(g(s/z)\), we may suppose \(f\circ g(\{z\,|\,|z|\leq 1\})=\{z\,|\,|z|\leq 1\}\), so

\[f\circ g(z)=\beta\frac{z-\alpha}{\overline{\alpha}z-1}\quad\text{with}\quad| \alpha|<|\beta|=1.\]

Using the relation \(0=f(s)+f(-s)\), we get \(\alpha=0\), so \(f\circ g(z)=\beta z\) and \(s=r=2-\sqrt{3}\).

**Solution to 5.3.4:** Suppose \(f\) is such a function. Let \(g:A\to B\) be defined by \(g(z)=f(z)^{2}/z\). Then, as on \(C_{1}\cup C_{4}\), the absolute value of \(g\) is \(1\), then \(g\) is a constant, \(c\), say. Therefore, \(f(z)=\sqrt{cz}\) which is not continuous on \(A\). We conclude that no such function can exist.

**Solution to 5.3.5:** The map \(z\mapsto iz\) maps the given region conformally onto \(A=\mathbb{D}\cap\{z\,|\,\Im z>0\}\). The map

\[w\mapsto\frac{1+w}{1-w}\]

maps \(A\) onto the first quadrant, \(Q\). The square function takes \(Q\) onto \(\{z\,|\,\Im z>0\}\). Finally,

\[\xi\mapsto\frac{\xi-i}{\xi+i}\]

takes \(\{\xi\,|\,\Im\xi>0\}\) onto \(\mathbb{D}\). Combining these, we get for the requested map:

\[z\mapsto\frac{(1+iz)^{2}-i(1-iz)^{2}}{(1+iz)^{2}+i(1-iz)^{2}}.\]

**Solution to 5.3.6:** The map \(\varphi_{1}(z)=2z-1\) maps conformally the semidisc

\[\{z\,|\,\Im z>0,|z-1/2|<1/2\}\]

onto the upper half of the unit disc. The map

\[\varphi_{2}(z)=\frac{1+z}{1-z}\]

maps the unit disc conformally onto the right half-plane. Letting \(z=re^{i\theta}\), it becomes

\[\frac{1+re^{i\theta}}{1-re^{i\theta}}=\frac{1-r^{2}+2ir\sin\theta}{|1+re^{i \theta}|^{2}}.\]

Since \(\sin\theta>0\) for \(0<\theta<\pi\), \(\varphi_{2}\) maps the upper half of \(\mathbb{D}\) onto the upper-right quadrant. The map \(\varphi_{3}(z)=z^{2}\) maps the upper-right quadrant conformally onto the upper half-plane. The composition of \(\varphi_{1}\), \(\varphi_{2}\), and \(\varphi_{3}\) is the desired map, namely the function \(z\mapsto\frac{z^{2}}{(1-z)^{2}}\).

**Solution to 5.3.8:** Suppose \(f\) is such a map. \(f\) is bounded, so the singularity at the origin is removable, \(p=\lim_{z\to 0}f(z)\). Since \(f\) is continuous, \(p\) is in the closure of \(A\).

Suppose that \(p\) is on the boundary of \(A\). Then \(f\left(G\right)=A\cup\{p\}\), which is not an opcn sct, contradicting the Open Mapping Theorem, [13, pag. 436].

Let \(p\in A\) and \(a\in G\) be such that \(f(a)=p\). Take disjoint open neighborhoods \(U\) of \(0\) and \(V\) of \(a\). By the Open Mapping Theorem, \(f(U)\) and\(f(V)\) are open sets containing \(p\). Then \(f(U)\cap f(V)\) is a nonempty open set. Take \(x\in f(U)\cap f(V)\), \(x\neq p\). Then \(x=f(z)\) for some nonzero \(z\in U\) and \(x=f(w)\) for some \(w\in V\). Then \(z\) and \(w\) are distinct elements of \(G\) with \(f(z)=f(w)\), contradicting the injectivity of \(f\).

### 5.4 Integral Representation of Analytic Functions

**Solution to 5.4.1:** By the Cauchy-Riemann equations [11, pag. 72],

\[u_{x}=v_{y}\qquad\text{and}\qquad u_{y}=-v_{x}.\]

Thus, \(au+bw=c\) implies

\[au_{x}+bv_{x}=0=au_{y}+bv_{y}\]

and, therefore,

\[au_{x}-bu_{y}=0=au_{y}+bu_{x}.\]

In matrix form, this reads

\[\left(\begin{array}{cc}a&-b\\ b&a\end{array}\right)\left(\begin{array}{c}u_{x}\\ u_{y}\end{array}\right)=\left(\begin{array}{c}0\\ 0\end{array}\right).\]

Since the matrix has nonzero determinant \(a^{2}+b^{2}\), the homogeneous system has only the zero solution. Hence, \(u_{x}=u_{y}=0\). By the Cauchy-Riemann equations, \(v_{x}=v_{y}=0\). Since \(D\) is connected, \(f\) is constant.

**Solution to 5.4.2:** 1. The Maclaurin series for \(\cos z\) is \(\sum_{0}^{\infty}\frac{(-1)^{n}z^{2n}}{(2n)!}\), and it converges uniformly on compact sets. Hence, for fixed \(z\),

\[f(t)\cos(zt)=\sum_{0}^{\infty}\frac{(-1)^{n}f(t)t^{2n}z^{2n}}{(2n)!}\]

with the series converging uniformly on [0,1]. We can therefore, interchange the order of integration and summation to get

\[h(z)=\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n)!}\left(\int_{0}^{1}t^{2n}f(t)dt \right)z^{n}\]

in other words, \(h\) has the power series representation

\[h(z)=\sum_{0}^{\infty}c_{2n}z^{2n}\qquad\text{with}\qquad c_{2n}=\frac{(-1)^{ n}}{(2n)!}\int_{0}^{1}t^{2n}f(t)dt\,.\]

Since \(h\) is given by a convergent power series, it is analytic.

2. Suppose \(h\) is the zero function. Then, by Part 1, \(\int_{0}^{1}t^{2n}f(t)dt=0\) for \(n=0,1,2,\ldots\). Hence, if \(p\) is any polynomial, then \(\int_{0}^{1}p(t^{2})f(t)dt=0\). By the Stone-Weierstrass Approximation Theorem [MH93, pag. 284], there is a sequence \(\{p_{k}\}\) of polynomials such that \(p_{k}(t)\to f\left(\sqrt{t}\,\right)\) uniformly on [0,1]. Then \(p_{k}(t^{2})\to f(t)\) uniformly on [0,1], so \[\int_{0}^{1}f(t^{2})dt=\lim_{k\rightarrow\infty}\int_{0}^{1}p_{k}(t^{2})f(t)dt=0\] implying that \(f\equiv 0\).

**Solution to 5.4.3:** Let \(z\in\mathbb{C}\,\). We have

\[g(z)=\int_{0}^{1}\sum_{n=0}^{\infty}f(t)\frac{t^{n}z^{n}}{n!}\,dt.\]

Since \(f\) is bounded, this series converges uniformly in \(t\), so we can change the order of summation and get

\[g(z)=\sum_{n=0}^{\infty}z^{n}\left(\frac{1}{n!}\int_{0}^{1}f(t)t^{n}\,dt \right)=\sum_{n=0}^{\infty}\xi_{n}z^{n}\]

where

\[\xi_{n}=\frac{1}{n!}\int_{0}^{1}f(t)t^{n}\,dt\,.\]

We have

\[|\xi_{n}|\leq\frac{1}{n!}\int_{0}^{1}|f(t)|\,dt\]

so the radius of convergence of the series of \(g\) is \(\infty\).

_Solution 2._ Let \(z_{0}\in\mathbb{C}\). We have

\[\frac{g(z)-g(z_{0})}{z-z_{0}}=\int_{0}^{1}f(t)\frac{e^{tz}-e^{tz_{0}}}{z-z_{0}} \,dt.\]

From the power series expansion \(e^{t(z-z_{0})}=\sum_{n=0}^{\infty}\frac{t^{n}(z-z_{0})^{n}}{n!}\), one gets

\[\frac{e^{tz}-e^{tz_{0}}}{z-z_{0}}=te^{tz_{0}}+O(z-z_{0})\]

uniformly on \(0\leq t\leq 1\), when \(z\to z_{0}\). Thus, as \(z\to z_{0}\), the integrand in the integral above converges uniformly on \([0,1]\) to \(tf(t)e^{tz_{0}}\), and one can pass to the limit under the integral sign to get

\[\lim_{z\to z_{0}}\frac{g(z)-g(z_{0})}{z-z_{0}}=\int_{0}^{1}tf(t)e^{tz_{0}}dt,\]

[MISSING_PAGE_FAIL:263]

circle onto the ellipse of axes \(|a|(1+r)\) and \(|a(1-r)|\), rotated from the standard position \(\arg a+\beta/2\).

**Solution to 5.5.2:** We have

\[L =\int_{0}^{2\pi}\big{|}f^{\prime}(e^{i\theta})\big{|}\,\big{|}ie^{ i\theta}\big{|}\,d\theta=\int_{0}^{2\pi}\big{|}f^{\prime}(e^{i\theta})\big{|}\,d\theta\] \[\geq\left|\int_{0}^{2\pi}f^{\prime}(e^{i\theta})d\theta\right|\] \[=2\pi\,|f^{\prime}(0)|\]

by the Mean Value Property [12, pag. 185].

**Solution to 5.5.3:** As the Jacobian of the transformation is \(|f^{\prime}(z)|^{2}\), we have

\[A=\int_{\mathbb{D}}|f^{\prime}(z)|^{2}\,dx\,dy.\]

\(f^{\prime}(z)\) can be found by term by term differentiation:

\[f^{\prime}(z)=\sum_{n=1}^{\infty}nc_{n}z^{n-1}\]

so

\[|f^{\prime}(z)|^{2}=\sum_{j,k=1}^{\infty}jkc_{j}\bar{c}_{k}z^{j-1}\bar{z}^{k- 1}.\]

We then have

\[A=\int\int_{\mathbb{D}}\sum_{j,k=1}^{\infty}jkc_{j}\bar{c}_{k}z^{j-1}\bar{z}^{ k-1}\,dxdy.\]

Letting \(z=re^{i\theta}\), we get

\[A=\sum_{j,k=1}^{\infty}jkc_{j}\bar{c}_{k}\int_{0}^{1}\int_{0}^{2\pi}r^{j+k-1}e ^{i(j-k)\theta}\,d\theta dr.\]

Since

\[\int_{0}^{2\pi}e^{in\theta}\,d\theta=0\]

for \(n\neq 0\), we have

\[A=2\pi\sum_{n=1}^{\infty}n^{2}|c_{n}|^{2}\int_{0}^{1}r^{2n-1}\,dr=\pi\sum_{n=1 }^{\infty}n|c_{n}|^{2}.\]

**Solution to 5.5.4:** We have, for \(z,w\in\mathbb{D}\),

\[f(w)=f(z)\quad\text{iff}\quad(w-z)\left(1+\frac{w+z}{2}\right)=0\]

so \(f\) in injective. Then the area of its image is given by

\[\int_{\mathbb{D}}\left|f^{\prime}(z)\right|^{2}dxdy =\int_{\mathbb{D}}\left(1+2\Re z+|z|^{2}\right)dz\] \[=\int_{\mathbb{D}}\left(1+2x+x^{2}+y^{2}\right)dxdy\] \[=\int_{0}^{2\pi}\int_{0}^{1}\left(1+2r\cos\theta+r^{2}\right)drd\theta\] \[=\frac{3\pi}{2}.\]

**Solution to 5.5.5:** Assume \(f\) is not constant. Fix \(z_{0}\in\mathbb{D}\) and let \(h\) be defined by \(h(z)=f(z)-f(z_{0})\). As \(h\) has only isolated zeros in \(\mathbb{D}\), we can find an increasing sequence \(\rho_{i}\to 1\) with \(h(z)\neq 0\) for \(|z|=\rho_{i}\), \(i=1,\ldots\). Let \(g\) be the function given by \(g(z)=a_{1}(z-z_{0})\). For \(|z|=\rho_{i}\), we have

\[|g(z)-h(z)| =\left|\sum_{n\geq 2}a_{n}z^{n}-\sum_{n\geq 2}a_{n}z_{0}^{n} \right|\] \[\leq\max\left|\frac{d}{dz}\sum_{n\geq 2}a_{n}z^{n}\right|_{z=w} \left|\left|z-z_{0}\right|\quad(w\,\text{in the segment}\left[z,z_{0}\right])\right.\] \[\leq\sum_{n\geq 2}na_{n}\rho_{i}^{n-1}|z-z_{0}|\] \[\leq|a_{1}||z-z_{0}|\] \[=|g(z)|.\]

By Rouche's Theorem [14, pag. 421], \(h\) has a unique zero in the disc \(\{z\,|\,|z|<\rho_{i}\}\), so \(f\) assumes the value \(f(z_{0})\) only once there. Letting \(\rho_{i}\to 1\), we get that \(f\) is injective in \(\mathbb{D}\).

**Solution to 5.5.6:** Let \(f\in X_{k}\), \(z\in\mathbb{D}\), and \(\gamma\) be the circle around \(z\) with radius \(r=(1-|z|)/2\). \(\gamma\) lies inside the unit disc, so, by Cauchy's Integral Formula for derivatives [14, pag. 169], we have

\[|f^{\prime}(z)|\leq\frac{1}{2\pi}\int_{\gamma}\frac{|f(w)|}{|z-w|^{2}}|dw|\leq \frac{C}{r(1-|z|)^{k}}=\frac{2C}{(1-|z|)^{k+1}},\]

where \(C\) is a constant, so \(f^{\prime}\in X_{k+1}\).

Let \(f^{\prime}\in X_{k+1}\) with \(f(0)=0\) (the general case follows easily from this). Letting \(z=re^{i\theta}\), we have

\[|f(z)| \leq\int_{0}^{z}|f^{\prime}(w)|\,|dw|\] \[=\int_{0}^{r}\big{|}f^{\prime}(te^{i\theta})\big{|}\;dt\] \[\leq\int_{0}^{r}\frac{C}{(1-r)^{k+1}}\,dt\] \[=\frac{kC}{(1-r)^{k}}\cdot\]

Hence, \(f\in X_{k}\).

**Solution to 5.5.7:** Let \(f(z)=\sum_{n\geq 0}a_{n}z^{n}\) for \(z\in\mathbb{D}=\{z\,|\,|z|<1\}\).

As \(f(z)\) is analytic, so is \(g:\mathbb{D}\to\mathbb{C}\) defined by \(g(z)=f(z)-\overline{f(\overline{z})}\). We have, for real \(z\in\mathbb{D}\),

\[\begin{array}{rcl}g(z)&=&\sum(a_{n}-\bar{a}_{n})z^{m}\\ &=&f(z)-\overline{f(\overline{z})}\\ &=&f(z)-f(z)\\ &=&0\end{array}\]

therefore, \(g(z)\equiv 0\) on \(\mathbb{D}\), so the coefficients \(a_{n}\) are all real.

Put \(z_{0}=e^{i\pi\sqrt{2}}\), and let \(a_{k}\) be the nonzero coefficient of smallest index. We have

\[\frac{f(tz_{0})-a_{0}}{a_{k}t^{k}}=z_{0}^{k}+\frac{t}{a_{k}}\sum_{n\geq k+1}a_ {n}z_{0}^{n}t^{n-k+1}\;.\]

\(tz_{0}\in\mathbb{D}\) for \(t\in[0,1)\) and the left hand side expression is a real number for all \(t\), so

\[\lim_{t\to 0}\frac{f(tz_{0})-a_{0}}{a_{k}t^{k}}=z_{0}^{k}\in\mathbb{R}\]

which implies \(k=0\), by the irrationality of \(\sqrt{2}\), thus \(f\) is a constant.

**Solution to 5.5.8:** Let \(\sum_{0}^{\infty}c_{n}z^{n}\) be the Maclaurin series for \(f\). Then \(f^{\prime}(z)=\sum_{1}^{\infty}nc_{n}z^{n-1}\). The Cauchy Inequalities [13, pag. 170] give

\[|c_{n}| =\left|\frac{1}{2\pi i}\int_{|z|=r}\frac{f^{\prime}(z)}{z^{n}}dz\right|\] \[=\left|\frac{1}{2\pi r^{n-1}}\int_{0}^{2\pi}f^{\prime}(re^{i \theta})e^{-i(n-1)\theta}d\theta\right|\] \[\leq\frac{M}{r^{n-1}}\,,\qquad 0<r<1\cdot\]Letting \(r\to 1\), we get \(|c_{n}|\leq M/n\) (\(n=1,2,\ldots\)). Hence,

\[\int_{[0,1)}|f(x)|dx \leq\int_{0}^{1}\left(\sum_{0}^{\infty}|c_{n}|x^{n}\right)dx\] \[\leq|c_{0}|+M\int_{0}^{1}\left(\sum_{0}^{\infty}\frac{x^{n}}{n} \right)dx\] \[=|c_{0}|+M\int_{0}^{1}\log\frac{1}{1-x}dx\] \[=|c_{0}|+M\lim_{r\to 1}\left(-(1-x)\log\frac{1}{1-x}+x\right) \biggr{|}_{0}^{r}\] \[=|c_{0}|+M.\]

**Solution to 5.5.9:** As \(|h(0)|=5\), by the Maximum Modulus Principle [13, pag. 185], \(h\) is constant in the unit disc. Therefore, \(h^{\prime}(0)=0\).

**Solution to 5.5.10:**

\[\varphi(z)=i\left(\frac{1+z}{1-z}\right)\]

maps the unit disc to the upper half-plane with \(\varphi(0)=i\). Thus, \(f\circ\varphi\) maps the unit disc into itself fixing \(0\). By the Schwarz Lemma [13, pag. 190], \(|f\circ\varphi(z)|\leq|z|\). Solving \(\varphi(z)=2i\), we get \(z=1/3\). Hence, \(|f(2i)|\leq 1/3\). Letting \(f=\varphi^{-1}\), we see that this bound is sharp.

**Solution to 5.5.11:** The function

\[\varphi(z)=\frac{1+z}{1-z}\]

maps the unit disc, \(\mathbb{D}\), onto the right half-plane, with \(\varphi(0)=1\). Therefore, the function \(f\circ\varphi\) maps \(\mathbb{D}\) into itself, with \(f\circ\varphi(0)=0\). By the Schwarz Lemma [13, pag. 190], we have \(\left|\left(f\circ\varphi\right)^{\prime}(0)\right|\leq 1\), which gives \(|f^{\prime}(\varphi(0))\varphi^{\prime}(0)|\leq 1\) and \(|f^{\prime}(1)|\leq 1/2\). A calculation shows that equality happens for \(f=\varphi^{-1}\).

**Solution to 5.5.12:** Suppose \(f\) has infinitely many zeros in \(\mathbb{D}\). If they have a cluster point in \(\mathbb{D}\), then \(f\equiv 0\) and the result is trivial. Otherwise, since \(\{z\in\mathbb{C}\mid|z|\leq 1\}\) is compact, there is a sequence of zeros converging to a point in the boundary of \(\mathbb{D}\), and the conclusion follows.

Assume now that \(f\) has only finitely many zeros in \(\mathbb{D}\), \(w_{1},\ldots,w_{m}\). Then \(f\) can be written as

\[f(z)=(z-w_{1})^{\alpha_{1}}\cdots(z-w_{m})^{\alpha_{m}}g(z)\]where \(g\) is analytic and never zero on \(\mathbb{D}\). Applying the Maximum Modulus Principle [13, pag. 185], we get that \(1/g\) attains a maximum in the disc \(|z|\leq(1-1/n)\) at a point \(z_{n}\) with \(|z_{n}|=1-1/n\) (\(n\geq 2\)). Then \(|g(z_{2})|\geq|g(z_{3})|\geq\cdots\). The product \((z-w_{1})^{\alpha_{1}}\cdots(z-w_{m})^{\alpha_{m}}\) is clearly bounded, and so is \(f(z_{n})\).

**Solution to 5.5.13:** 1. We can assume \(f\) has only finitely many zeros. (Otherwise, assuming \(f\not\equiv 0\), its zero sequence has the required property, since the zeros of a nonconstant analytic function in an open connected set can cluster only on the boundary of the set.) That done, we can, after replacing \(f\) by its quotient with a suitable polynomial, assume \(f\) has no zeros. Then \(1/f\) is analytic in the disc. For \(n=1,2,\ldots\), let \(M_{n}\) be the maximum of \(|1/f(z)|\) for \(|z|=1-\frac{1}{n}\). By the Maximum Modulus Principle [13, pag. 185], \(M_{n}\geq M_{1}\) for all \(n\). Hence, for each \(n\), there is a point \(a_{n}\) such that \(|a_{n}|=1-\frac{1}{n}\) and \(|f(a_{n})|=1/M_{n}\leq 1/M_{1}=|f(0)|\). Then \((f(a_{n}))\) is a bounded sequence of complex numbers and so has a convergent subsequence, which gives the desired conclusion.

2. Let \((z_{n})\) be a sequence with the properties given in Part 1. Subtracting a constant from \(f\), if needed, we can assume \(\lim f(z_{n})=0\). We can suppose also that \(|z_{n+1}|>|z_{n}|>0\) for all \(n\). For each \(n\), let \(M_{n}\) be the maximum of \(|f(z)|\) for \(|z|=|z_{n}|\). The numbers \(M_{n}\) are positive (since \(f\) is nonconstant) and increase with \(n\) (by the Maximum Modulus Principle [13, pag. 185]). Since \(f(z_{n})\to 0\), there is an \(n_{0}\) such that \(|f(z_{n})|<M_{1}\) for \(n\geq n_{0}\). For such \(n\), the restriction of \(|f|\) to the circle \(|z|=|z_{n}|\) is a continuous function that takes values both larger than \(M_{1}\) and smaller than \(M_{1}\). By the Intermediate Value Theorem [13, pag. 93], there is for each \(n\geq n_{0}\), a point \(b_{n}\) such that \(|b_{n}|=|z_{n}|\) and \(|f(b_{n})|=M_{1}\). Then, for the desired sequence \((w_{n})\), we can take any subsequence of \((b_{n})\) along which \(f\) converges. (There will be such a subsequence by the boundedness of the sequence \((f(b_{n}))\).)

**Solution to 5.5.14:** Suppose \(f(a)=a\in\mathbb{D}\), \(f(b)=b\in\mathbb{D}\), and \(a\not=b\). Let \(\varphi:\mathbb{D}\rightarrow\mathbb{D}\) be the automorphism of the unit disc that maps \(0\) to \(a\) (\(\varphi(z)=(a-z)/(1-\bar{a}z)\)). Then the function \(g=\varphi^{-1}\circ f\circ\varphi\) maps \(\mathbb{D}\) into itself with \(g(0)=0\) and \(g(\varphi^{-1}(b))=\varphi^{-1}(b)\). Since \(\varphi\) is one-to-one and \(a\not=b\), \(\varphi^{-1}(b)\not=0\). Hence, by the Schwarz Lemma [13, pag. 190], there exists a unimodular constant \(\lambda\) such that \(g(z)=\lambda z\), and letting \(z=\varphi^{-1}(b)\), we see that \(\lambda=1\); that is, \(g\) is the identity map and so is \(f\).

**Solution to 5.5.15:** Let \(\varphi_{z_{0}}\) be the automorphism of the unit disc given by

\[\varphi_{z_{0}}(z)=\frac{z-z_{0}}{1-\bar{z}_{0}z}\,,\]

we have

\[\varphi^{\prime}_{z_{0}}(z)=\frac{1-|z_{0}|^{2}}{(1-\bar{z}_{0}z)^{2}}\,.\]Now consider the composition

\[g(z)=\varphi_{f\circ\varphi_{z_{0}}(0)}\circ f\circ\varphi_{z_{0}}(z)=\varphi_{f(-z _{0})}\circ f\circ\varphi_{z_{0}}(z)\]

then \(g(0)=0\) and as composition of maps of the unit disc into itself, we can apply the Schwarz Lemma [13, pag. 190] to obtain \(\left|g^{\prime}(0)\right|\leq 1\). Computing \(g^{\prime}(0)\) using the chain rule, we have

\[\left|g^{\prime}(0)\right|=\left|\frac{1}{1-\left|f(-z_{0})\right|^{2}}\cdot f ^{\prime}(-z_{0})\cdot(1-\left|z_{0}\right|^{2})\right|\leq 1\]

so we can conclude that

\[\left|f^{\prime}(z)\right|\leq\frac{1-\left|f(z)\right|^{2}}{1-\left|z\right|^ {2}}\leq\frac{1}{1-\left|z\right|^{2}}\,.\]

The first inequality is known as Picks' Lemma and is the main ingredient in the proof that an analytic map of the disc into itself that preserves the hyperbolic distance between any two points, preserves all distances, for more detail see [1, Vol. 2, SS290] or [17, pag. 16].

_Solution 2._ Using the same notation as above,

\[\left|(f\circ\varphi_{z_{0}})^{\prime}(0)\right|\leq\frac{1}{2\pi}\int_{\left| \omega\right|=r}\frac{\left|f\circ\varphi_{z_{0}}(w)\right|}{\left|\omega \right|^{2}}\left|d\omega\right|\]

that is

\[\left|f^{\prime}(-z_{0})\right|\left|1-\left|z_{0}\right|^{2}\right|\leq\frac{ 1}{2\pi}\int_{0}^{2\pi}\frac{d\theta}{r}=\frac{1}{r}\]

which holds for any \(\left|z_{0}\right|<r=\left|w\right|<1\), so the conclusion follows.

**Solution to 5.5.16:** Let \(\xi\in\mathbb{D}\) and \(\varphi:\mathbb{D}\to\mathbb{D}\) be the automorphism of \(\mathbb{D}\) that maps \(\xi\) to \(0\),

\[\varphi(z)=\frac{z-\xi}{1-\xi z}.\]

Cauchy's Integral Formula for derivatives [13, pag. 169] gives, for \(\left|\xi\right|<r<1\),

\[\left|\left(f\circ\varphi\right)^{\prime}(0)\right| \leq\left|\frac{1}{2\pi i}\int_{\left|w\right|=r}\frac{\left(f \circ\varphi\right)(w)}{w^{2}}\,dw\right|\] \[\leq\frac{1}{2\pi}\int_{\left|w\right|=r}\frac{C}{(1-\left|\varphi \right|)\left|w\right|^{2}}\left|dw\right|\] \[\leq\frac{1}{2\pi}\int_{\left|w\right|=r}\frac{C}{(1-\left|w \right|)\left|w\right|^{2}}\left|dw\right|\] \[=\frac{C}{r(1-r)}.\]In the last inequality, we used the Schwarz Lemma, [13, pag. 190], \(|\varphi(w)|\leq|w|\). Elementary calculus shows that

\[\frac{C}{r(1-r))}\leq 4C\]

so we have

\[\left|\left\langle f\circ\varphi\right\rangle^{\prime}(0)\right|\leq 4C\]

and since \(\varphi^{\prime}(0)=1/(1-|\xi|^{2})\),

\[|f^{\prime}(\xi)|\leq\frac{4C}{1-|\xi|^{2}}.\]

**Solution to 5.5.17:** Using Cauchy's Integral Formula [13, pag. 169], for \(0<r<1\), we have

\[\left|\frac{f^{(n)}(0)}{n!}\right| \leq\frac{1}{2\pi}\int_{|w|=r}\frac{|f(w)|}{|w|^{n+1}}\left|dw\right|\] \[\leq\frac{1}{2\pi}\int_{|w|=r}\frac{1}{(1-r)r^{n+1}}\left|dw \right|=\frac{1}{(1-r)r^{n}}.\]

Letting \(r=n/(n+1)\), we get \(|f^{(n)}(0)/n!|\leq(n+1)(1+1/n)^{n}<(n+1)e\).

**Solution to 5.5.18:** By the Schwarz Lemma [13, pag. 190],

\[|f(z)|\leq|z|.\]

If \(f(z)=a_{1}z+a_{2}z^{2}+\cdots\), let \(g\) be defined by

\[g(z)=\frac{f(z)+f(-z)}{2z}=a_{2}z+a_{4}z^{3}+a_{6}z^{5}+\cdots\]

\(g\) is analytic in \(\mathbb{D}\), and since

\[|g(z)|\leq\frac{|f(z)|+|f(-z)|}{2|z|}\leq 1\]

\(g\) maps \(\mathbb{D}\) into \(\mathbb{D}\). Hence, by the Schwarz Lemma,

\[|g(z)|\leq|z|\]

or

\[|f(z)+f(-z)|\leq 2|z|^{2}.\]

Now suppose equality held for \(z_{0}\in\mathbb{D}\). We would have \(|g(z_{0})|=|z_{0}|\) so, by the Schwarz Lemma,

\[g(z)=\lambda z\]for some unimodular \(\lambda\), or

\[f(z)+f(-z)=2\lambda z^{2}.\]

Plugging this back into the power series for \(g(z)\), we get \(a_{2}=\lambda\) and \(a_{4}=a_{6}=\cdots=0\). Hence,

\[f(z)=\lambda z^{2}+h(z)\]

where \(h(z)\) is odd. We have

\[1\geq|f(z)|=|\lambda z^{2}+h(z)|\]

and

\[1\geq|f(-z)|=|\lambda z^{2}+h(-z)|=|\lambda z^{2}-h(z)|.\]

Therefore,

\[\begin{array}{rcl}(\lambda z^{2}+h(z))(\overline{\lambda z^{2}}+\overline{h( z)})&\leq&1\\ (\lambda z^{2}-h(z))(\overline{\lambda z^{2}}-\overline{h(z)})&\leq&1.\end{array}\]

Expanding and adding, we get

\[\begin{array}{rcl}|z|^{4}+|h(z)|^{2}&\leq&1\\ |h(z)|^{2}&\leq&1-|z|^{4}\end{array}\]

which, by the Maximum Modulus Principle [13, pag. 185], implies \(h(z)\equiv 0\).

**Solution to 5.5.19:** Schwarz's Lemma [13, pag. 190] implies that the function \(f_{1}(z)=f(z)/z\) satisfies \(|f_{1}(z)|\leq 1\). The linear fractional map \(z\mapsto\frac{z-r}{1-rz}\) sends the unit disc onto itself. Applying Schwarz's Lemma to the function \(f_{2}(z)=f_{1}\left(\frac{z-r}{1-rz}\right)\), we conclude that the function \(f_{3}(z)=f_{1}(z)/\left(\frac{z-r}{1-rz}\right)\) satisfies \(|f_{3}(z)|\leq 1\). Similarly, the map \(z\mapsto\frac{z+r}{1+rz}\) sends the unit disc onto itself, and Schwarz's Lemma applied to the function \(f_{4}(z)=f_{3}(z)/\left(\frac{z+r}{1+rz}\right)\) implies that the function \(f_{5}(z)=f_{3}\left(\frac{z+r}{1+rz}\right)\) satisfies \(|f_{5}(z)|\leq 1\). All together, then,

\[|f(z)|\leq|z|\left|\frac{z-r}{1-rz}\right|\left|\frac{z+r}{1+rz}\right|\left|f _{5}(z)\right|\leq|z|\left|\frac{z-r}{1-rz}\right|\left|\frac{z+r}{1+rz}\right|\]

which is the desired inequality.

### 5.6 Growth Conditions

**Solution to 5.6.1:** Let \(g(z)=f(z)-f(0)\). Then \(g(0)=0\), so \(g(z)/z\) has a removable singularity at \(0\) and extends to an entire function. \(g(z)/z\) tendsto \(0\) as \(|z|\) tends to infinity since \(f(z)/z\) does. Let \(\varepsilon>0\). There is an \(R>0\) such that \(|g(z)/z|<\varepsilon\) for \(|z|\geq R\). By the Maximum Modulus Principle [13, pag. 185], \(|g(z)/z|<\varepsilon\) for all \(z\). Since \(\varepsilon\) is arbitrary, \(g(z)/z\) is identically \(0\). Hence, \(g(z)=0\) for all \(z\) and \(f\) is constant.

**Solution to 5.6.3:** If \(g\equiv 0\), the result is trivially true. Otherwise, the zeros of \(g\) are isolated points. \(|f/g|\) is bounded by \(1\) in \(\mathbb{C}\), so all the singularities of \(f/g\) are removable, and \(f/g\) can be extended to an entire function. Liouville's Theorem [13, pag. 170] now guarantees that \(f/g\) must be a constant.

**Solution to 5.6.4:** Let \(h(z)=f(z)-kg(z)\). Then \(h\) is entire and \(\Re h(z)\leq 0\). We then have

\[\left|e^{h(z)}\right|\leq 1\quad\text{for all}\quad z\in\mathbb{C}\]

therefore, by Liouville's Theorem [13, pag. 170], \(e^{h}\) is constant, and so is \(h\).

**Solution to 5.6.5:** 1. Using Cauchy's Integral Formula for derivatives [13, pag. 169], we get

\[\left|f^{(k)}(0)\right| \leq\frac{k!}{2\pi}\int_{|z|=R}\left|\frac{f(z)}{z^{k+1}}\right| \left|dz\right|\] \[\leq\frac{k!}{2\pi R^{k+1}}\int_{|z|=R}\left|a\sqrt{|z|}+b\right| \left|dz\right|\] \[=\frac{k!\left(a\sqrt{|z|}+b\right)}{R^{k}}\] \[=o(1)\quad(R\to\infty)\]

so \(f^{(k)}(0)=0\) for \(k\geq 1\), and \(f\) reduces to a constant, \(f(0)\).

2. Using the same method as above for \(k\geq 3\), we get

\[\left|f^{(k)}(0)\right| \leq\frac{k!}{2\pi}\int_{|z|=R}\left|\frac{f(z)}{z^{k+1}}\right| \left|dz\right|\] \[\leq\frac{k!}{2\pi R^{k+1}}\int_{|z|=R}\left|a\sqrt{|z|^{5}}+b \right|\left|dz\right|\] \[=\frac{k!\left(a\sqrt{|z|^{5}}+b\right)}{R^{k}}=o(1)\quad(R\to\infty)\]

so \(f^{(k)}(0)=0\) for \(k\geq 3\) and \(f\) reduces to a polynomial of degree, at most, \(2\), \(f(0)+f^{\prime}(0)z+f^{\prime\prime}(0)z^{2}/2\).

**Solution to 5.6.6:** For \(r>0\), let \(z=re^{i\theta}\) in Cauchy's Integral Formula for derivatives [12, pag. 169] to get

\[f^{(n)}(0)=\frac{n!}{2\pi i}\int_{0}^{2\pi}\frac{f(re^{i\theta})}{r^{n}e^{in \theta}}\,d\theta.\]

Combining this with the inequality given yields

\[|f^{(n)}(0)|/n!\leq r^{17/3-n}/2\pi.\]

For \(n>5\), letting \(r\) tend to infinity, we get \(f^{(n)}(0)=0\). If \(n\leq 5\), letting \(r\) tend to \(0\) gives the same result. Hence, the coefficients of the Maclaurin series [12, pag. 234] of \(f\) are all \(0\), so \(f\equiv 0\).

**Solution to 5.6.7:** If such a function \(f\) exists then \(g=1/f\) is also analytic on \(\mathbb{C}\setminus\{0\}\), and satisfies \(|g(z)|\leq\sqrt{|z|}\). Since \(g\) is bounded on \(\{z:0<|z|<1\}\), \(g\) has a removable singularity at \(0\), and extends as an analytic function over the complex plane. Fix \(z\), choose \(R>|z|\), and let \(C_{R}\) be the circle with center \(0\) and radius \(R\).

Then

\[g^{\prime}(z)=\frac{1}{2\pi i}\int_{C_{R}}\frac{g(w)}{(w-z)^{2}}dw\]

so

\[|g^{\prime}(z)|\leq\frac{1}{2\pi}\cdot 2\pi R\cdot\frac{\sqrt{R}}{(R-|z|)^{2}} \to 0\;\;\mbox{as}\;\;R\rightarrow\infty\;.\]

Thus, \(g^{\prime}=0\) everywhere, so \(g\) (and, hence, \(f\)) is constant. But this contradicts the hypothesis \(|f(z)|\geq\frac{1}{\sqrt{|z|}}\) for small \(z\), so no such function exists.

**Solution to 5.6.8:** By Liouville's Theorem [12, pag. 170], it will be enough to prove that \(f\) is bounded. For \(|\Re z|\geq 1/2\), we have \(|f(z)|\leq\sqrt{2}\). Let \(z_{0}\) be a point such that \(|\Re z_{0}|<1/2\). Let \(S\) be the square with vertices \(i\Im z_{0}\pm 1\pm i\), oriented counterclockwise.

Then \(z_{0}\) is in the interior of \(S\), so Cauchy's Integral Formula [167, pag. 167] gives

\[f(z_{0})=\frac{1}{2\pi i}\int_{S}\frac{f(z)}{z-z_{0}}\;dz.\]

The absolute value of the integrand is, at most, \(2|\Re z|^{-1/2}\). The contribution to the integral from each vertical edge is thus, at most, \(4\) in absolute value. The contribution from each horizontal edge is, at most, \(2\int_{-1}^{1}|x|^{-1/2}dx=8\) in absolute value. Hence,

\[|f(z_{0})|\leq\frac{1}{2\pi}\left(4+4+8+8\right)=12\pi\]

proving that \(f\) is bounded.

### 5.7 Analytic and Meromorphic Functions

**Solution to 5.7.1:**\(f(z)=\sqrt{z}\) is a counterexample. Define it by making a cut on the negative real axis and choosing an associated branch of the logarithm:

\[f(z)=\left\{\begin{array}{ll}e^{\frac{1}{2}\log z}&z\neq 0\\ 0&z=0.\end{array}\right.\]

\(f\) is analytic in the right half-plane and so on the disc \(|z-1|<1\). Since \(\sqrt{z}\) tends to \(0\) as \(z\) tends to \(0\), \(f\) is continuous on the disc \(|z-1|\leq 1\). However, \(f\) cannot be analytic on any open disc of radius larger than \(1\). For if it were, \(f\) would be analytic at \(0\), so

\[f^{\prime}(0)=\lim_{z\to 0}\frac{f(z)}{z}\]would exist and be finite, which is absurd.

**Solution to 5.7.2:** 1. \(f(z)=z^{2}\) is entire and satisfies

\[f(1/n)=f(-1/n)=1/n^{2}.\]

2. By the Identity Theorem [13, pag. 397], in a disc centered at the origin, \(g\) would have to be \(z^{3}\) and \(-z^{3}\), which is not possible; therefore, no such function \(g\) can exist.

**Solution to 5.7.4:** Suppose \(f(\mathbb{C}\,)\) is not dense. Then, for some \(w\in\mathbb{C}\) and \(\varepsilon>0\), we have \(|f(z)-w|\geq\varepsilon\) for all \(z\in\mathbb{C}\,.\) The function \(1/(f(z)-w)\) is then entire and bounded in modulus by \(1/\varepsilon\), so, by Liouville's Theorem [13, pag. 170], is a constant, and so is \(f\).

**Solution to 5.7.5:** Let \(f(x+iy)=u(x,y)+iv(x,y)\), where \(u(x,y)=e^{x}s(y)\) and \(v(x,y)=e^{x}t(y)\). From the Cauchy-Riemann equations [13, pag. 72], we get \(e^{x}s(y)=e^{x}t^{\prime}(y)\), so \(s(y)=t^{\prime}(y)\). Similarly, \(s^{\prime}(y)=-t(y)\). This equation has the unique solution \(s(y)=\cos y\) satisfying the initial conditions \(s(0)=1\) and \(s^{\prime}(0)=-t(0)=0\), which, in turn, implies that \(t(y)=-s^{\prime}(y)=\sin y\).

**Solution to 5.7.6:**\(f^{\prime\prime}+f\) is analytic on \(\mathbb{D}\) and vanishes on \(X=\{1/n\,|\,n\geq 0\}\), so it vanishes identically. Using the Maclaurin expansion [13, pag. 234] of \(f\), we get

\[\sum_{k\geq 0}\frac{f^{(k)}(0)}{k!}z^{k}=-\sum_{k\geq 0}\frac{f^{(k+2)}(0)}{k! }z^{k}.\]

So we have

\[f(0)=-f^{\prime\prime}(0)=\cdots=(-1)^{k}f^{(2k)}(0)=\cdots\]

and

\[f^{\prime}(0)=-f^{\prime\prime\prime}(0)=\cdots=(-1)^{k}f^{(2k+1)}(0)=\cdots.\]

Therefore,

\[f(z) =f(0)\sum_{k\geq 0}\frac{(-1)^{k}}{(2k)!}z^{2k}+f^{\prime}(0) \sum_{k\geq 0}\frac{(-1)^{k}}{(2k+1)!}z^{2k+1}\] \[=f(0)\cos z+f^{\prime}(0)\sin z.\]

Conversely, any linear combination of \(\cos z\) and \(\sin z\) satisfies the given equation, so these are all such functions.

**Solution to 5.7.7:** It is enough to show that for any \(z\in\Omega\), the derivative in the sense of \(\mathbb{R}^{2}\) has an associated matrix

\[Df(z)=\left(\begin{array}{cc}a&c\\ b&d\end{array}\right)\]

[MISSING_PAGE_FAIL:276]

\[f_{3}(x)=\left\{\begin{array}{ll}x-1/2&\mbox{for}\quad 0\leq x\leq 1/2\\ 1/2-x&\mbox{for}\quad 1/2\leq x\leq 1\end{array}\right.\quad f_{4}(x)=-f_{3}(x).\]

**Solution to 5.7.11:** The function \(g(z)=\overline{f(\overline{z})}\) is analytic in the same region as \(f\), and \(f-g=0\) on \((1,\infty)\). Since the zero set of \(f-g\) has limit points in the region \(|z|>1\), the Identity Theorem [13, pag. 397] implies that \(f-g\equiv 0\). Hence, \(f(z)\equiv\overline{f(\overline{z})}\). In particular, for \(x\) in \((-\infty,-1)\), \(f(x)=\overline{f(x)}\).

_Solution 2._ Let \(\sum_{-\infty}^{\infty}c_{n}z^{n}\) be the Laurent expansion [13, pag. 246] of \(f\) about \(\infty\). It will suffice to show that \(c_{n}\) is real for all \(n\). The series \(\sum_{-\infty}^{\infty}(\Re c_{n})z^{n}\) converges everywhere the original series does (since its terms are dominated in absolute value by those of the original series); let \(g(z)=\sum_{-\infty}^{\infty}(\Re c_{n})z^{n}\). For \(x\) in \((1,\infty)\),

\[g(x)=\Re f(x)=f(x)\.\]

As above, the Identity Theorem [13, pag. 397] implies \(g=f\), so each \(c_{n}\) is real, as desired.

**Solution to 5.7.12:** The function \(g(z)=\overline{f(\overline{z})}\) is analytic and coincides with \(f\) on the real axis; therefore, it equals \(f\). The line in question is its own reflection with respect to the real axis. Since it also passes through the origin, it must be one of the axes.

**Solution to 5.7.13:** By the Schwarz Reflection Principle for circles [1, pag. 85], we have

\[f(z)=\overline{f(1/\overline{z})}.\]

For \(x\) real, we get

\[f(x)=\overline{f(1/x)}=\overline{f(x)}\]

so \(f(x)\) is real.

**Solution to 5.7.14:** 1. Let \(z_{1},z_{2},\ldots,z_{n}\) be the zeros of \(p\), enumerated with multiplicities, so that

\[p(z)=c(z-z_{1})(z-z_{2})\cdots(z-z_{n})\]

where \(c\) is a constant. Then

\[\frac{p^{\prime}(z)}{p(z)}=\frac{1}{z-z_{1}}+\frac{1}{z-z_{2}}+\cdots+\frac{1} {z-z_{n}}\]

and, for \(x\) real,

\[\Im\frac{p^{\prime}(z)}{p(z)}=\frac{\Im z_{1}}{|x-z_{1}|^{2}}+\frac{\Im z_{2}} {|x-z_{2}|^{2}}+\cdots+\frac{\Im z_{n}}{|x-z_{n}|^{2}}.\]Part 1 is now obvious.

2. Write \(z_{j}=x_{j}+y_{j}\), so that

\[\int_{-\infty}^{\infty}\frac{\Im z_{j}}{|x-z_{j}|^{2}} =\int_{-\infty}^{\infty}\frac{y_{j}}{(x-x_{j})^{2}+y_{j}^{2}}\,dx\] \[=\int_{-\infty}^{\infty}\frac{y_{j}}{x^{2}+y_{j}^{2}}\,dx\] \[=\int_{-\infty}^{\infty}\frac{d}{dx}\left(\arctan\frac{x}{y_{j}} \right)\,dx\] \[=\pi\,.\]

Hence,

\[\int_{-\infty}^{\infty}\Im\frac{p^{\prime}(x)}{p(x)}\,dx=\pi n=\pi\deg p\,.\]

**Solution to 5.7.15:** Let \(D\) be an open disc with \(\overline{D}\subset G\). It will suffice to show that there is an \(n\) such that \(f^{(n)}\) has infinitely many zeros in \(D\). For then, the zeros of \(f^{(n)}\) will have a limit point in \(G\), forcing \(f^{(n)}\) to vanish identically in \(G\) by the Identity Theorem [13, pag. 397], and it follows that \(f\) is a polynomial of degree, at most, \(n-1\).

By hypothesis, \(D\) is the union of the sets \(Z_{n}=\{z\in D\,|\,f^{(n)}(z)=0\}\) for \(n=1,2,\ldots\). Since \(D\) is uncountable, at least one \(Z_{n}\) is, in fact, uncountable (because a countable union of finite sets is, at most, countable).

**Solution to 5.7.16:** We have

\[\log\left(\frac{z(2-z)}{1-z}\right) =\log(2-z)+\log\left(\frac{1}{\frac{1}{z}-1}\right)\] \[=\log 2+\log\left(1-\frac{z}{2}\right)+\pi i+\log\left(\frac{1}{1- \frac{1}{z}}\right).\]

In the unit disc, the principal branch of \(\log\left(\frac{1}{1-z}\right)\) is represented by the series \(\sum_{1}^{\infty}\frac{z^{n}}{n}\), which one can obtain by termwise integration of the geometric series \(\frac{1}{1-z}=\sum_{0}^{\infty}z^{n}\). Hence,

\[\log\left(1-\frac{z}{2}\right)=-\sum_{1}^{\infty}\frac{z^{n}}{2^{n}n}\qquad \left(|z|<2\right),\]

\[\log\left(\frac{1}{1-\frac{1}{z}}\right)=\sum_{1}^{\infty}\frac{z^{-n}}{n} \qquad\left(|z|>1\right),\]

and

\[\log\left(\frac{z(2-z)}{1-z}\right)=-\sum_{-\infty}^{-1}\frac{z^{n}}{n}+\log 2 +\pi i-\sum_{1}^{\infty}\frac{z^{n}}{2^{n}n}\quad\text{for}\quad 1<|z|<2.\]

**Solution to 5.7.17:** Let \(u=\Re f\) and \(v=\Im f\). For \(x\) real, we have

\[f^{\prime}(x)=\frac{\partial u}{\partial x}(x,0)=\frac{\partial v}{\partial y}(x,0),\]

where the first equality holds because \(v=0\) on the real axis and the second one follows from the Cauchy-Riemann equations [13, pag. 72]. Since \(v\) is positive in the upper half-plane, \(\frac{\partial v}{\partial y}\geq 0\) on the real axis. It remains to show that \(f^{\prime}\) does not vanish on the real axis.

It suffices to show that \(f^{\prime}(0)\neq 0\). In the contrary case, since \(f\) is non-constant, we have

\[f(z)=cz^{k}\left(1+O(z)\right)\qquad(z\to 0)\]

where \(c\neq 0\) is real and \(k\geq 2\). For small \(z\), the argument of the factor \(1+O(z)\) lies between \(-\frac{\pi}{4}\) and \(\frac{\pi}{4}\), say, whereas on any half-circle in the upper half-plane centered at \(0\), the factor \(cz^{k}\) assumes all possible arguments. On a sufficiently small such half-circle, therefore, the product will assume arguments between \(\pi\) and \(2\pi\), contrary to the assumption that \(\Im f(z)>0\) for \(\Im z>0\). This proves \(f^{\prime}(0)\neq 0\).

**Solution to 5.7.18:** Letting \(z=i\theta\), we have

\[\cos\theta=\tfrac{1}{2}(z+z^{-1})\]

and \(d\theta=dz/iz\), so that

\[\frac{1}{2\pi}\int_{0}^{2\pi}e^{2\zeta\cos\theta}d\theta=\frac{1}{2\pi}\int_{ \gamma}e^{\zeta(z+z^{-1})}\frac{dz}{z}\]

where \(\gamma\) is the unit circle. Next,

\[\frac{1}{2\pi i}\int_{\gamma}e^{\zeta(z+z^{-1})}\frac{dz}{z} =\frac{1}{2\pi i}\int_{\gamma}\sum_{n=0}^{\infty}\frac{1}{n!} \left(\frac{\zeta}{z}\right)^{n}e^{\zeta z}\ \frac{dz}{z}\] \[=\sum_{n=0}^{\infty}\frac{1}{2\pi i}\int_{\gamma}\frac{\zeta^{n}} {n!}\ \frac{e^{\zeta z}}{z^{n}}\ \frac{dz}{z}.\]

Now,

\[\frac{e^{\zeta z}}{z^{n+1}} =\frac{1}{z^{n+1}}\left(1+\zeta z+\tfrac{1}{2}(\zeta z)^{2}+ \cdots+\frac{1}{k!}(\zeta z)^{k}+\cdots\right)\] \[=\frac{1}{z^{n+1}}+\frac{\zeta}{z^{n}}+\cdots+\frac{1}{n!}\ \frac{\zeta^{n}}{z}+\frac{\zeta^{n+1}}{(n+1)!}+\cdots\ \.\]Thus, the residue at zero is \(\zeta^{n}/n!\) and

\[\frac{1}{2\pi i}\int_{\gamma}\frac{e^{\zeta z}}{z^{n+1}}\ dz=\frac{\zeta^{n}}{n!}\]

hence

\[\left(\frac{\zeta^{n}}{n!}\right)^{2}=\frac{1}{2\pi i}\int_{\gamma}\frac{\zeta^ {n}e^{\zeta z}}{n!z^{n}}\ \frac{dz}{t}\]

and the result follows.

**Solution to 5.7.19:** 1. The function \(f\) is not constant, because if \(f\) took the constant value \(c\), then \(f^{-1}(\{c\})\) would equal \(U\), a noncompact set. Since \(f\) is holomorphic and nonconstant, it is an open map, and \(f(U)\) is open. Since \(V\) is connected, it only remains to show that \(f(U)\) is closed relative to \(V\). Let \(a\in V\cap\overline{f(U)}\). There is a sequence \((w_{n})\) in \(f(U)\) such that \(a=\lim w_{n}\). For each \(n\), there is a point \(z_{n}\) in \(U\) with \(w_{n}=f(z_{n})\). The set \(K=\{a,w_{1},w_{2},\ldots\}\) is a compact subset of \(V\), so \(f^{-1}(K)\) is also compact. Since the sequence \((z_{n})\) lies in a compact subset of \(U\), it has a subsequence, \((z_{n_{k}})\), converging to a point \(b\) of \(U\). Then \(f(b)=\lim f(z_{n_{k}})=\lim w_{n_{k}}=a\), proving that \(a\) is in \(f(U)\) and hence that \(f(U)\) is closed relative to \(V\).

2. Take \(U=V=\mathbb{C}\) and \(f(z)=|z|\).

**Solution to 5.7.20:** By the Inverse Function Theorem [Rud87, pag. 221], it will suffice to prove that \(Jh(0)\neq 0\), where \(Jh\) denotes the Jacobian of \(h\):

\[Jh=\det\left(\begin{array}{cc}\frac{\partial}{\partial x}(u+p)&\frac{ \partial}{\partial x}(v-q)\\ \frac{\partial}{\partial y}(u+p)&\frac{\partial}{\partial y}(v-q)\end{array} \right)\.\]

By the Cauchy-Riemann equations [MH87, pag. 72],

\[\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y}\,\qquad\frac{ \partial u}{\partial y}=-\frac{\partial v}{\partial x}\,\qquad\frac{\partial p}{ \partial x}=\frac{\partial q}{\partial y}\,\qquad\frac{\partial p}{\partial y}=-\frac{ \partial q}{\partial x}\cdot\]

Hence,

\[Jh =\det\left(\begin{array}{cc}\frac{\partial u}{\partial x}+ \frac{\partial p}{\partial x}&\frac{\partial v}{\partial x}-\frac{\partial q} {\partial x}\\ -\frac{\partial v}{\partial x}-\frac{\partial q}{\partial x}&\frac{\partial u }{\partial x}-\frac{\partial p}{\partial x}\end{array}\right)\] \[=\left(\frac{\partial u}{\partial x}\right)^{2}-\left(\frac{ \partial p}{\partial x}\right)^{2}+\left(\frac{\partial v}{\partial x}\right) ^{2}-\left(\frac{\partial q}{\partial x}\right)^{2}\] \[=|f^{\prime}|^{2}-|g^{\prime}|^{2}\.\]

Since \(|g^{\prime}(0)|<|f^{\prime}(0)|\), it follows that \((Jh)(0)\neq 0\), as desired.

**Solution to 5.7.21:**\(f\) does not have a removable singularity at \(\infty\). If \(f\) had an essential singularity at infinity, for any \(w\in\mathbb{C}\) there would exist a sequence \(z_{n}\to\infty\) with \(\lim f(z_{n})=w\). Therefore, \(f\) has a pole at infinity and is a polynomial.

**Solution to 5.7.22:** Clearly, entire functions of the form \(f(z)=az+b\), \(a,b\in\mathbb{C}\)\(a\neq 0\), are one-to-one maps of \(\mathbb{C}\) onto \(\mathbb{C}\). We will show that these are all such maps by considering the kind of singularity such a map \(f\) has at \(\infty\). If it has a removable singularity, then it is a bounded entire function, and, by Liouville's Theorem [13, pag. 170], a constant.

If it has an essential singularity, then, by the Casorati-Weierstrass Theorem [13, pag. 256], it gets arbitrarily close to any complex number in any neighborhood of \(\infty\). But if we look at, say, \(f(0)\), we know that for some \(\varepsilon\) and \(\delta\), the disc \(|z|<\delta\) is mapped onto \(|f(0)-z|<\varepsilon\) by \(f\). Hence, \(f\) is not injective.

Therefore, \(f\) has a pole at \(\infty\), so is a polynomial. But all polynomials of degree \(2\) or more have more than one root, so are not injective.

**Solution to 5.7.23:** 1. If \(w\) is a period of \(f\), an easy induction argument shows that all integer multiples of \(w\) are periods of \(f\). It is also clear that any linear combination of periods of \(f\), with integer coefficients, is a period of \(f\).

2. If \(f\) had infinitely many periods in a bounded region, by the Identity Theorem [13, pag. 397], \(f\) would be constant.

**Solution to 5.7.24:** For \(0<r<r_{0}\), by the formula for Laurent coefficients [13, pag. 246], we have

\[|c_{n}| \leq\frac{1}{2\pi r^{n+1}}\int_{|z|=r}|f(z)|\,|dz|\] \[=\frac{1}{2\pi r^{n}}\int_{0}^{2\pi}|f(re^{i\theta})|\,d\theta\] \[\leq\sqrt{\frac{M}{2\pi}}r^{-(n+2)}.\]

If \(n<-2\), as \(r\) gets arbitrarily close to zero, this upper bound gets arbitrarily small. Hence, for \(n<-2\), \(c_{n}=0\).

### 5.8 Cauchy's Theorem

**Solution to 5.8.1:** By Cauchy's Integral Formula [13, pag. 167], we have

\[e^{0}=\frac{1}{2\pi i}\int_{|z|=1}\frac{e^{z}}{z}dz=\frac{1}{2\pi}\int_{0}^{2 \pi}e^{e^{i\theta}}d\theta\]therefore, \[\int_{0}^{2\pi}e^{e^{i\theta}}d\theta=2\pi.\] Solution to 5.8.2:By Cauchy's Integral Formula for derivatives [13, pag. 169], we have \[\frac{d}{dz}e^{z}\bigg{|}_{z=0}=\frac{1}{2\pi i}\int_{|z|=1}\frac{e^{z}}{z^{2}} dz=\frac{1}{2\pi}\int_{0}^{2\pi}e^{e^{i\theta}-i\theta}d\theta\] therefore, \[\int_{0}^{2\pi}e^{e^{i\theta}-i\theta}d\theta=2\pi.\] Solution to 5.8.4:Let \(p(z)=a_{n}z^{n}+\cdots+a_{0}\). If \(p\) has no zeros then \(1/p\) is entire. As \(\lim_{|z|\to\infty}p(z)=\infty\), \(1/p\) is bounded. By Liouville's Theorem [13, pag. 170]\(1/p\) is constant, and so is \(p\). Solution 2.Let \(p(z)=a_{n}z^{n}+\cdots+a_{0}\), \(n\geq 1\). If \(p\) has no zeros, then \(1/p\) is entire. As \(\lim_{|z|\to\infty}p(z)=\infty\), the Maximum Modulus Principle [13, pag. 185] gives \[\max_{z\in\mathbb{C}}\frac{1}{|p(z)|}=\lim_{R\to\infty}\max_{|z|\leq R}\frac{1 }{|p(z)|}=\lim_{R\to\infty}\max_{|z|=R}\frac{1}{|p(z)|}=0\] which is a contradiction. Solution 3.For \(p(z)=a_{n}z^{n}+\cdots+a_{0}\) with \(n\geq 1\) let the functions \(f\) and \(g\) be given by \(f(z)=a_{n}z^{n}\), \(g(z)=p(z)-f(z)\). For \(R>1\) consider the circle centered at the origin with radius \(R\), \(C_{R}\). For \(z\in C_{R}\) we have \[|f(z)|=|a_{n}|R^{n}\quad\text{and}\quad|g(z)|\leq\left(|a_{0}|+\cdots+|a_{n-1} |\right)R^{n-1}.\] Therefore, on \(C_{R}\), \[|g|<|f|\quad\text{if}\quad R>\frac{|a_{0}|+\cdots+|a_{n-1}|}{|a_{n}|}\] so, by Rouche's Theorem [13, pag. 421], \(f+g=p\) has \(n\) zeros in \(\{z\in\mathbb{C}\,|\,|z|<R\}\). Solution 4.Let \(P(z)\) be a nonconstant polynomial. We may assume \(P(z)\) is real for real \(z\), otherwise we consider \(P(z)\overline{P}(z)\). Suppose that \(P\) is never zero. Since \(P(z)\) does not either vanish or change sign for real \(z\), we have \[(*)\qquad\int_{0}^{2\pi}\frac{d\theta}{P(2\cos\theta)}\neq 0.\]But

\[\int_{0}^{2\pi}\frac{d\theta}{P(2\cos\theta)} =\frac{1}{i}\int_{|z|=1}\frac{dz}{zP(z+z^{-1})}\] \[=\frac{1}{i}\int_{|z|=1}\frac{z^{n-1}dz}{Q(z)}\]

where \(Q(z)=zP(z+z^{-1})\) is a polynomial. For \(z\neq 0\), \(Q(z)\neq 0\); in addition, if \(a_{n}\) is the leading coefficient of \(P\), we have \(Q(0)=a_{n}\neq 0\). Since \(Q(z)\) is never zero, the last integrand is analytic and, hence, the integral is zero, by Cauchy's Theorem [11, pag. 152], contradicting \((*)\).

This solution is an adaptation of [1].

_Solution 5._ Let \(p(z)=a_{n}z^{n}+\cdots+a_{0}\), \(n\geq 1\). We know that \(\lim_{|z|\to\infty}|p(z)|=\infty\), thus the preimage, by \(p\), of any bounded set is bounded. Let \(w\) be in the closure of \(p(\mathbb{C})\). There exists a sequence \(\{w_{n}\}\subset p(\mathbb{C})\) with \(\lim_{n}w_{n}=w\). The set \(\{w_{n}\,|\,n\in\mathbb{N}\}\) is bounded so, by the previous observation, so is its preimage, \(p^{-1}(\{w_{n}\,|\,n\in\mathbb{N}\})=X\). \(X\) contains a convergent sequence, \(z_{n}\to z_{0}\), say. By continuity we have \(p(z_{0})=w\), so \(w\in p(\mathbb{C})\). We proved then that \(p(\mathbb{C})\) is closed. As any analytic function is open we have that \(p(\mathbb{C})\) is closed and open. As only the empty set and \(\mathbb{C}\) itself are closed and open we get that \(p(\mathbb{C})=\mathbb{C}\) and \(p\) is onto. In fact, all we need here, in order to show that \(p\) is open, is that \(p:\mathbb{R}^{2}\to\mathbb{R}^{2}\) has isolated singularities, which guides us into another proof.

_Solution 6._ By the Solution to Problem 2.2.4 the map \(p:\mathbb{R}^{2}\to\mathbb{R}^{2}\) is onto guaranteeing a point where \(p(x,y)=(0,0)\).

_Solution 7._ Let \(p(z)=a_{n}z^{n}+\cdots+a_{0}\), \(n\geq 1\). Consider the polynomial \(q\) given by \(q(z)=\overline{a_{n}}z^{n}+\cdots+\overline{a_{0}}\). Assume \(p\) has no zeros. As the conjugate of any root of \(q\) is a root of \(p\), \(q\) is also zero free. Then the function \(1/pq\) is entire. By Cauchy's Theorem [11, pag. 152], we have

\[\int_{\Gamma}\frac{dz}{p(z)q(z)}=0\]

where \(\Gamma\) is the segment from \(-R\) to \(R\) in the horizontal axis together with the half circle \(C=\{z\in\mathbb{C}\,|\,|z|=R,\,\Im(z)>0\}\). But we have

\[\int_{\Gamma}\frac{dz}{p(z)q(z)} =\int_{C}\frac{dz}{p(z)q(z)}+\int_{-R}^{R}\frac{dz}{|p(z)|^{2}}\] \[=o(1)+\int_{-R}^{R}\frac{dz}{|p(z)|^{2}}\quad(R\to\infty)\]

this gives, for large \(R\),

\[\int_{-R}^{R}\frac{dz}{|p(z)|^{2}}=0\]which is absurd since the integrand is a continuous positive function.

_Solution 8._ Let \(p(z)=a_{n}z^{n}+\cdots+a_{0}\), \(n\geq 1\). For \(R\) large enough, as \(\lim_{|z|\to\infty}p(z)=\infty\), \(|p|\) has a minimum in \(\{z\in\mathbb{C}\,|\,|z|<R\}\), at \(z_{0}\), say. Suppose \(p(z_{0})\neq 0\). Expanding \(p\) around \(z_{0}\) we get

\[p(z)=p(z_{0})+\sum_{j=k}^{n}b_{j}(z-z_{0})^{j}\quad b_{k}\neq 0.\]

Let \(w\) be a k-root of \(-p(z_{0})/b_{k}\). We get, for \(\varepsilon>0\),

\[p(z_{0}+w\varepsilon) =p(z_{0})+b_{k}w^{k}\varepsilon^{k}+\sum_{j=k+1}^{n}b_{j}w^{j} \varepsilon^{j}\] \[=p(z_{0})(1-\varepsilon^{k})+\sum_{j=k+1}^{n}b_{j}w^{j} \varepsilon^{j}\]

therefore, for \(\varepsilon\) small enough, we have \(|z_{0}+w\varepsilon|<R\) and

\[|p(z_{0}+w\varepsilon)| \leq|p(z_{0})||1-\varepsilon^{k}|-\sum_{j=k+1}^{n}|b_{j}w^{j}| \varepsilon^{j}\] \[=|p(z_{0})|-\left(|p(z_{0})|-\sum_{j=k+1}^{n}|b_{j}w^{j}| \varepsilon^{j-k}\right)\varepsilon^{k}\] \[<|p(z_{0})|\]

which contradicts the definition of \(z_{0}\). We conclude then that \(p(z_{0})=0\).

_Solution 9._ Let \(p(z)=a_{n}z^{n}+\cdots+a_{0}\), \(n\geq 1\). We have

\[\operatorname{Res}\left(\frac{p^{\prime}}{p},\infty\right)=-\lim_{|z|\to\infty }z\frac{p^{\prime}(z)}{p(z)}=-n.\]

As the singularities of \(p^{\prime}/p\) occur at the zeros of its denominator, the conclusion follows.

**Solution to 5.8.5:** By Morera's Theorem [19, pag. 173], it suffices to show that

\[\int_{\gamma}f(z)\,dz=0\]

for all rectangles \(\gamma\) in \(\mathbb{C}\,\). Since \(f\) is analytic on \(\{z\,|\,\Im z\neq 0\}\), which is simply connected, it is enough to consider rectangles which contain part of the real axis in their interiors.

Let \(\gamma\) be such a rectangle and \(l\) be the segment of \(\mathbb{R}\) in its interior. For \(\varepsilon>0\) small enough, draw line segments \(l_{1}\) and \(l_{2}\) parallel to the real axis at distance \(\varepsilon\) above and below it, forming contours \(\gamma_{1}\) and \(\gamma_{2}\).

Since \(f\) is continuous, its integral depends continuously on the path. So, as \(\varepsilon\) tends to \(0\),

\[(*)\qquad\int_{\gamma_{1}}f(z)\,dz+\int_{\gamma_{2}}f(z)\,dz=\int_{\gamma_{1}+ \gamma_{2}}f(z)\,dz\longrightarrow\int_{\gamma}f(z)\,dz,\]

since the integrals along \(l_{1}\) and \(l_{2}\) have opposite orientation, in the limit, they cancel each other. By Cauchy's Theorem [13, pag. 152], the left side of \((*)\) is always \(0\), so

\[\int_{\gamma}f(z)\,dz=0.\]

**Solution to 5.8.6:** We have, using the fact that the exponential is \(2\pi\)-periodic,

\[\frac{1}{2\pi i}\int_{|z|=R}z^{n-1}|f(z)|^{2}\,dz =\frac{1}{2\pi i}\int_{|z|=R}z^{n-1}\left|\sum_{i=0}^{n}a_{i}z^{i }\right|^{2}\,dz\] \[=\frac{1}{2\pi i}\int_{|z|=R}z^{n-1}\sum_{i=0}^{n}a_{i}z^{i}\sum _{i=0}^{n}\overline{a_{i}z}^{i}\,dz\] \[=\frac{1}{2\pi}\int_{0}^{2\pi}R^{n}e^{in\theta}\sum_{i,j=0}^{n}a _{i}\overline{a_{j}}R^{i+j}e^{(i-j)\theta}\,d\theta\] \[=\frac{1}{2\pi}\int_{0}^{2\pi}\sum_{i,j=0}^{n}a_{i}\overline{a_{j }}R^{n+i+j}e^{(n+i-j)\theta}\,d\theta\]\[=\frac{1}{2\pi}\int_{0}^{2\pi}a_{0}\overline{a_{n}}R^{2n}\,d\theta\] \[=a_{0}\overline{a_{n}}R^{2n}.\]

**Solution to 5.8.7:** By Cauchy's Theorem [MH87, pag. 152],

\[\frac{1}{2\pi i}\int_{|z|=r}f(z)^{2}\ \frac{dz}{z}=f(0)^{2}\]

for \(r>1\). Parameterizing the domain of integration by \(z=re^{i\theta}\), we find

\[\frac{1}{2\pi i}\int_{0}^{2\pi}f(re^{i\theta})^{2}\tau i\mathrm{e}^{i\theta} \frac{d\theta}{re^{i\theta}}=f(0)^{2}.\]

Simplifying and taking real parts gives

\[\int_{0}^{2\pi}\left(u(re^{i\theta})^{2}-v(re^{i\theta})^{2}\right)d\theta=2 \pi\left(u(0)^{2}-v(0)^{2}\right)=0\.\]

**Solution to 5.8.8:** We have

\[\left|\frac{d^{m}f}{dz^{m}}\right|\leq M(1+|z|^{k})\]

for all \(z\). Dividing both sides by \(|z|^{k}\) and taking the limit as \(|z|\) tends to infinity, we see that \(d^{m}f/dz^{m}\) has a pole at infinity of degree at most, \(k\) so \(d^{m}f/dz^{m}\) is a polynomial of degree, at most, \(k\). Letting \(n=m+k+1\), we must have that \(d^{n}f/dz^{n}=0\) and that \(n\) is the best possible such bound.

**Solution to 5.8.9:** 1. We have

\[f(z)=(z-z_{1})^{n_{1}}\cdots(z-z_{k})^{n_{k}}g(z)\]

where \(g\) is an analytic function with no zeros in \(\Omega\). So

\[\frac{f^{\prime}(z)}{f(z)}=\frac{n_{1}}{z-z_{1}}+\cdots+\frac{n_{k}}{z-z_{k}}+ \frac{g^{\prime}(z)}{g(z)}.\]

Since \(g\) is never \(0\) in \(\Omega\), \(g^{\prime}/g\) is analytic there, and, by Cauchy's Theorem [MH87, pag. 152], its integral around \(\gamma\) is \(0\). Therefore,

\[\frac{1}{2\pi i}\int_{\gamma}\frac{f^{\prime}(z)}{f(z)}\,dz =\sum_{j=1}^{k}\frac{1}{2\pi i}\int_{\gamma}\frac{n_{j}}{z-z_{j}} \,dz\] \[=\sum_{j=1}^{k}n_{j},\]2. We have

\[\frac{zf^{\prime}(z)}{f(z)}=\frac{z}{z-z_{1}}+\frac{g^{\prime}(z)}{g(z)}\]

so

\[\frac{1}{2\pi i}\int_{\gamma}\frac{zf^{\prime}(z)}{f(z)}\,dz=z_{1}.\]

**Solution to 5.8.10:** Suppose \(f(z_{1})=f(z_{2})\) and let \(\gamma\) be the segment connecting these two points. We have \(0=\int_{\gamma}f^{\prime}(z)dz\). Hence,

\[\int_{\gamma}(f^{\prime}(z)-f^{\prime}(z_{0}))dz=-f^{\prime}(z_{0})(z_{2}-z_{1 }).\]

Taking absolute values, we get

\[|f^{\prime}(z_{0})|\,|z_{2}-z_{1}|\leq\int_{\gamma}|f^{\prime}(z)-f^{\prime}(z_ {0})|\,|dz|<\int_{\gamma}|f^{\prime}(z_{0})|\,|dz|=|f^{\prime}(z_{0})|\,|z_{2} -z_{1}|,\]

an absurd. We conclude, then, that \(f\) is injective.

**Solution to 5.8.11:** It suffices to show that there exists an integer \(n\) such that the image of \(\Omega\) under \(h(z)=f(z)/z^{n}\) contains no curves with positive winding number about \(0\); because it implies the existence of an analytic branch of the logarithm in \(h(\Omega)\). Each closed curve in \(h(\Omega)\) is the image of a closed curve in \(\Omega\), so it is enough to show that the images of simple closed curves in \(\Omega\) have winding number \(0\) about the origin.

Consider two classes of simple closed curves in \(\Omega\)

* \(\Gamma_{1}\), the curves with \(0\) in their interiors, and
* \(\Gamma_{2}\), the curves with \(0\) in their exteriors.

Since \(f\) has no zeros in \(\Omega\), it is clear that if \(\gamma\in\Gamma_{2}\), then \(\operatorname{Ind}_{f(\gamma)}(0)=0\). From the shape of \(\Omega\), it follows that all the curves in \(\Gamma_{1}\) are homotopic. Let \(n\) be the winding number about \(0\) of \(f(\gamma)\) for \(\gamma\in\Gamma_{1}\). Since \(h\) has no zeros in \(\Omega\), we must have \(\operatorname{Ind}_{h(\gamma)}(0)=0\) for \(\gamma\in\Gamma_{2}\). Fix \(\gamma\in\Gamma_{1}\); then

\[\operatorname{Ind}_{h(\gamma)}(0)=\frac{1}{2\pi i}\int_{\gamma}\!\frac{h^{ \prime}(z)}{h(z)}\,dz=\frac{1}{2\pi i}\int_{\gamma}\!\!\left(\frac{f^{\prime}( z)}{f(z)}-\frac{n}{z}\right)dz=\operatorname{Ind}_{f(\gamma)}(0)-n=0\]

and we are done.

**Solution to 5.8.12:** Let \(c>0\). It suffices to show that there is a constant \(M\) such that

\[|f(z_{1})-f(z_{2})|\leq M|z_{1}-z_{2}|\quad\text{for all}\quad z_{1},z_{2}\in \{z\,|\,\Re z>c\,,\,|z_{1}-z_{2}|<c\}.\]Fix two such points and let \(\gamma\) be the circle of radius \(c\) whose center is the midpoint of the segment joining them. \(\gamma\) lies in the right half-plane, so, by Cauchy's Integral Formula [13, pag. 167], we have

\[|f(z_{1})-f(z_{2})| \leq\frac{1}{2\pi}\int_{\gamma}\left|\frac{f(\zeta)}{z_{1}-\zeta}- \frac{f(\zeta)}{z_{2}-\zeta}\right|\,|d\zeta|\] \[\leq\frac{N|z_{1}-z_{2}|}{2\pi}\int_{\gamma}\frac{|d\zeta|}{|z_{1}- \zeta||z_{2}-\zeta|}\]

where \(N\) is the supremum of \(|f|\) in the right half-plane. On \(\gamma\), \(|z_{i}-\zeta|\geq c/2\) for \(i=1,2\), so

\[|f(z_{1})-f(z_{2})|\leq\frac{4N}{c}|z_{1}-z_{2}|.\]

### 5.9 Zeros and Singularities

**Solution to 5.9.1:**\(F\) is a map from \(\mathbb{C}\,^{3}\) to the space of monic polynomials of degree \(3\), that takes the roots of a monic cubic polynomial to its coefficients, because if \(\alpha\), \(\beta\), and \(\gamma\) are the zeros of \(z^{3}-Az^{2}+Bz-C\), we have

\[A=\alpha+\beta+\gamma,\qquad\alpha\beta+\alpha\gamma+\beta\gamma=B,\qquad\alpha \beta\gamma=C.\]

Thus, by the Fundamental Theorem of Algebra (for several different proofs see the Solution to Problem 5.8.4), it is clear that \(F\) is onto. \(F(1,1,0)=F(1,0,1)\), so \(F\) is not injective, in fact, \(F(u,v,w)=F(v,w,u)=F(w,u,v)\).

**Solution to 5.9.2:** Using Rouche's Theorem [13, pag. 421], it is easy to conclude that \(p(z)\) has two zeros inside the circle \(|z|=3/4\).

_Solution 2._ The constant term of \(p\) is \(1\), so the product of its roots is \(1\), in absolute value. They either all have absolute value \(1\), or at least one lies inside \(|z|<1\). The former is not possible, since the degree of \(p\) is odd, it has at least one real root, and a calculation shows that neither \(1\) nor \(-1\) is a root. So \(p\) has a root in the unit disc.

**Solution to 5.9.3:** For \(|z|=1\), we have

\[\left|-z^{3}\right|=1>|f(z)|\]

so, by Rouche's Theorem [13, pag. 421], \(f(z)-z^{3}\) and \(z^{3}\) have the same number of zeros in the unit disc.

**Solution to 5.9.4:** Let \(f_{1}\) and \(f_{2}\) be defined by \(f_{1}(z)=3z^{100}\) and \(f_{2}(z)=-e^{z}\). On the unit circle, we have

\[|f_{1}(z)|=3>1=|f_{2}(z)|.\]By Rouche's Theorem [12, pag. 421], we know that \(f\) and \(f_{1}\) have the same number of zeros in the unit disc, namely \(100\).

Let \(\xi\) be a zero of \(f\). Then

\[f^{\prime}(\xi)=300\xi^{99}-e^{\xi}=300\xi^{99}-3\xi^{100}=3\xi^{99}\left(100-3 \xi\right)\neq 0\]

so all the zeros of \(f\) are simple.

**Solution to 5.9.5:** 1. Let \(f(z)=4z^{2}\) and \(g(z)=2z^{5}+1\). For \(|z|=1\), we have

\[|f(z)|=4>3\geq|g(z)|\.\]

By Rouche's Theorem [12, pag. 421], \(f\) and \(p=f+g\) have the same number of roots in \(|z|<1\). Since \(f\) has two roots in \(|z|<1\), so does \(p\).

2. There is at least one real root, since \(p\) has odd degree. We have \(p^{\prime}(z)=10z^{4}+8z\), so \(p^{\prime}\) has two real zeros, namely at \(0\) and \(-(4/5)^{\frac{1}{3}}\). Moreover, on the real axis, \(p^{\prime}\) is positive on \((-\infty,-(4/5)^{\frac{1}{3}})\) and \((0,\infty)\), and negative on \((-(4/5)^{\frac{1}{3}},0)\). Thus, \(p\) is increasing on the first two intervals and decreasing on the last one. Since \(p(0)=1>0\), also \(p(-(4/5)^{\frac{1}{3}})>0\), so \(p\) has no root in \([-(4/5)^{\frac{1}{3}},\infty)\) and exactly one in \((-\infty,-(4/5)^{\frac{1}{3}})\). (The real root is actually in \((-2,-1)\), since \(p(-1)>0\) and \(p(-2)<0\).)

**Solution to 5.9.6:** Let \(p(z)=3z^{9}+8z^{6}+z^{5}+2z^{3}+1\). For \(|z|=2\), we have

\[|p(z)-3z^{9}| =|8z^{6}+z^{5}+2z^{3}+1|\] \[\leq 8|z|^{6}+|z|^{5}+2|z|^{3}+1\] \[=561<1536=|3z^{9}|\]

so, by Rouche's Theorem [12, pag. 421], \(p\) has nine roots in \(|z|<9\).

For \(|z|=1\), we have

\[|p(z)-8z^{6}| =|3z^{9}+z^{5}+2z^{3}+1|\] \[\leq 3|z|^{9}+|z|^{5}+2|z|^{3}+1\] \[=7<8=|8z^{6}|\]

and we conclude that \(p\) has six roots in \(|z|<1\). Combining these results, we get that \(p\) has three roots in \(1<|z|<2\).

**Solution to 5.9.7:** For \(z\) in the unit circle, we have

\[\left|5z^{2}\right|=5>4\geq\left|z^{5}+z^{3}+2\right|\]

so, by Rouche's Theorem [12, pag. 421], \(p(z)\) has two zeros in the unit disc. For \(|z|=2\),

\[\left|z^{5}\right|=32>30\geq\left|z^{3}+5z^{2}+2\right|\]so \(p(z)\) has five zeros in \(\{z\,|\,|z|<2\}\). We conclude then that \(p(z)\) has three zeros in \(1<|z|<2\).

**Solution to 5.9.8:** Let \(p(z)=z^{7}-4z^{3}-11\). For \(z\) in the unit circle, we have

\[|p(z)-11|=\left|z^{7}-4z^{3}\right|\leq 5<11\]

so, by Rouche's Theorem [13, pag. 421], the given polynomial has no zeros in the unit disc. For \(|z|=2\),

\[\left|p(z)-z^{7}\right|=\left|4z^{3}+11\right|\leq 43<128=\left|z^{7}\right|\]

so there are seven zeros inside the disc \(\{z\,|\,|z|<2\}\) and they are all between the two given circles.

**Solution to 5.9.9:** Rescale by setting \(z=\varepsilon^{-1/5}w\). Then we need to show that exactly five roots of the rescaled polynomial

\[p_{\varepsilon}(w)=w^{7}+w^{2}+\delta,\]

with \(\delta=\varepsilon^{2/5}\to 0\) as \(\varepsilon\to 0\), converge to the unit circle as \(\varepsilon\to 0\). We have \(p_{0}(w)=w^{2}(w^{7}+1)\). Since two roots of \(p_{0}\) are at \(w=0\) and the other five are on the unit circle, the result follows from the continuity of the roots of a polynomial as functions of the coefficients, see 5.9.27.

_Solution 2._ Let \(q(z)=z^{2}+1\), so

\[|p(z)-q(z)|=\varepsilon|z|^{7}=r^{7}\varepsilon^{-2/5}\]

on the circle \(|z|=r\varepsilon^{-1/5}\). Also,

\[|q(z)|=|z^{2}+1|>r^{2}\varepsilon^{-2/5}-1\]

on \(|z|=r\varepsilon^{-1/5}\). Since \(r<1\), \(r^{7}<r^{2}\), and \(r^{7}\varepsilon^{-2/5}<r^{2}\varepsilon^{-2/5}-1\) for \(\varepsilon\) sufficiently small. Then \(|p(z)-q(z)|<|q(z)|\) on \(|z|=r\varepsilon^{-1/5}\), and by Rouche's Theorem [13, pag. 421], \(p\) and \(q\) have the same number of zeros inside \(|z|=r\varepsilon^{-1/5}\), namely two. By the Fundamental Theorem of Algebra (for several different proofs see the Solution to Problem 5.8.4), the other five roots must lie in \(|z|>r\varepsilon^{-1/5}\).

Now take \(q(z)=\varepsilon z^{7}\), so

\[|p(z)-q(z)|=|z^{2}+1|\leq R^{2}\varepsilon^{-2/5}+1\]

on \(|z|=R\varepsilon^{-1/5}\), where

\[|q(z)|=R^{7}\varepsilon^{-2/5}.\]

Since \(R>1\), we have \(R^{7}>R^{2}\) and

\[R^{2}\varepsilon^{-2/5}+1<R^{7}\varepsilon^{-2/5}\]for \(\varepsilon\) sufficiently small. Thus, \(|p(z)-q(z)|<|q(z)|\) on \(|z|=R\varepsilon^{-1/5}\), so \(p\) and \(q\) have the same number of zeros inside \(|z|=R\varepsilon^{-1/5}\), namely seven. This leaves precisely five roots between the two circles.

**Solution to 5.9.10:** The determinant of \(A(z)\) is \(8z^{4}+6z^{2}+1\). For \(z\) in the unit circle, we have

\[\left|8z^{4}\right|=8>7\geq\left|6z^{2}+1\right|\]

so, by Rouche's Theorem [13, pag. 421], \(\det A(z)\) has four zeros in the unit disc. Also,

\[\frac{d}{dz}\left(\det A(z)\right)=z(32z^{3}+12)\]

with roots

\[0\,,\,\pm i\sqrt{\frac{3}{8}}\]

which are not zeros of \(\det A(z)\). Thus, all the four zeros are simple, so they are distinct.

**Solution to 5.9.12:** Let \(z_{1},\ldots,z_{n}\) be the zeros of \(p\), and \(z\) a zero of \(p^{\prime}\), \(z\neq z_{i}\), \(i=1,\ldots,n\). We have

\[0=\frac{p^{\prime}}{p}(z)=\sum_{i=1}^{n}\frac{1}{z-z_{i}}\]

Using the fact that \(1/\alpha=\bar{\alpha}/|\alpha|^{2}\) and conjugating we get

\[\sum_{i=1}^{n}\frac{z-z_{i}}{|z-z_{i}|^{2}}=0\]

which is clearly impossible if \(\Re z\leq 0\).

This result can be generalized to give the Gauss-Lucas Theorem [14, pag. 94]: _The zeros of \(p^{\prime}\) lie in the convex hull of the zeros of \(p\)_. If \(z_{1},\ldots,z_{n}\) are the zeros of \(p\), and \(z\) is a zero of \(p^{\prime}\), \(z\neq z_{i}\), \(i=1,\ldots,n\). We have, similar to the above,

\[\sum_{i=1}^{n}\frac{z-z_{i}}{|z-z_{i}|^{2}}=0\]

which is impossible if \(z\) is not in the convex hull of \(z_{1},\ldots,z_{n}\).

**Solution to 5.9.13:** We may assume \(r\neq 0\). Let \(n=\deg p\) and \(x_{1}<x_{2}<\cdots<x_{k}\) be the roots of \(p\), with multiplicities \(m_{1},m_{2},\ldots,m_{k}\), respectively. If any \(m_{j}\) exceeds \(1\), then \(p-rp^{\prime}\) has a root at \(x_{j}\) of multiplicity \(m_{j}-1\) (giving a total of \(n-k\) roots all together). We have

\[p(x)=c(x-x_{1})^{m_{1}}\cdots(x-x_{k})^{m_{k}}.\]The logarithmic derivative \(p^{\prime}/p\) is given by

\[\frac{p^{\prime}(x)}{p(x)}=\sum_{j=1}^{k}\frac{m_{j}}{x-x_{j}}.\]

Its range on the interval \((x_{j},x_{j+1})\) (\(j=1,\ldots,k-1\)) is all of \(\mathbb{R}\), since it is continuous there and

\[\lim_{x\to x_{j}+}\frac{p^{\prime}(x)}{p(x)}=+\infty\;,\qquad\lim_{x\to x_{j}- }\frac{p^{\prime}(x)}{p(x)}=-\infty.\]

Hence, there is a point \(x\in(x_{j},x_{j+1})\) where \(p^{\prime}(x)/p(x)=1/r\); in other words, where \(p-rp^{\prime}\) has a root. Thus, \(p-rp^{\prime}\) has at least \(k-1\) real roots other than the \(n-k\) that are roots of \(p\). Hence, \(p-rp^{\prime}\) has at least \(n-1\) real roots all together, and the nonreal ones come in conjugate pairs. Hence, it has only real roots.

**Solution to 5.9.14:** Let \(R>\lambda+1\) and consider the contour \(C_{R}=\Gamma_{R}\cup[-Ri,Ri]\), where \(\Gamma_{R}=\{z\,|\,|z|=R\,,\,\Re z\leq 0\}\) and \([-Ri,Ri]=\{z\,|\,\Re z=0\,,\,-R\leq\Im z\leq R\}\).

Let the functions \(f\) and \(g\) be defined by \(f(z)=z+\lambda\), \(g(z)=-e^{z}\). On \(\Gamma_{R}\), we have

\[|f(z)|\geq|z|-\lambda>1\geq|g(z)|\]

and on \([-Ri,Ri]\),

\[|f(z)|\geq\lambda>1=|g(z)|.\]

By Rouche's Theorem [MH87, pag. 421], \(f_{\lambda}\) and \(f\) have the same number of zeros inside the contour \(C_{R}\), so \(f_{\lambda}\) has exactly one zero there. As this conclusion is valid for every \(R>\lambda+1\), we conclude that \(f_{\lambda}\) has one zero in the left half-plane. As \(f\) is real on the real axis and \(f(x)f(0)<0\) for \(x\) small enough, we get that the zero of \(f_{\lambda}\) is real.

Solution 2.We find the number of zeros of \(f_{\lambda}\) in the left half-plane by considering a Nyquist diagram [1, pag. 106] relative to the rectangle with corners \(iy\), \(-x+iy\), \(-x-iy\), and \(-iy\), \(x,y>\lambda\). This will give the change in \((1/2\pi)\arg f_{\lambda}(z)\). Then we let \(x,y\rightarrow\infty\).

On the right side of the rectangle, as \(t\) ranges from \(-y\) to \(y\), \(f_{\lambda}(it)=it+\lambda-\cos t-i\sin t\) has a positive real part, and its imaginary part changes sign from negative to positive. On the top of the rectangle, as \(s\) ranges from \(0\) to \(-x\), \(f_{\lambda}(s+iy)=s+iy+\lambda-e^{s}\cos y-ie^{s}\sin y\) has positive imaginary part, and its real part changes sign from positive to negative.

Similar reasoning shows that on the left side of the rectangle, \(\Re f_{\lambda}<0\) and \(\Im f_{\lambda}\) changes sign from positive to negative. On the bottom of the rectangle, \(\Im f_{\lambda}<0\) and \(\Re f_{\lambda}\) changes sign from negative to positive. Hence, \(f_{\lambda}\) is never \(0\) on this rectangle and the image of the rectangle winds around the origin exactly once. By the Argument Principle [13, pag. 419], \(f_{\lambda}\) has exactly one zero in the interior of this rectangle. Letting \(x\) and \(y\) tend to infinity, we see that \(f_{\lambda}\) has exactly one zero in the left half-plane. As \(f_{\lambda}\) is real on the real axis and \(f_{\lambda}(x)f_{\lambda}(0)<0\) for \(x\) small enough, we get that the zero of \(f_{\lambda}\) is real.

Solution to 5.9.15:For \(|z|=1\), we have

\[\left|ze^{\lambda-z}\right|=e^{\Re(\lambda-z)}>e^{0}=1=|-1|\]

so, by Rouche's Theorem [13, pag. 421], the given equation has one solution in the unit disc. Let \(f(z)=ze^{\lambda-z}\). As, for \(z\) real, \(f\) increases from \(f(0)=0\) to \(f(1)=e^{\lambda-1}>1\), by the Intermediate Value Theorem [13, pag. 93], \(f(\xi)=1\) for some \(\xi\in(0,1)\).

Solution to 5.9.16:By the Gauss-Lucas Theorem [12, pag. 94] (see Solution to 5.9.12), if \(p(z)\) is a polynomial, then all of the roots of \(p^{\prime}(z)\) lie in the convex hull of the roots of \(p(z)\). Let \(z=1/w\). The given equation becomes, after multiplying by \(w^{n}\), \(w^{n}+w^{n-1}+a=0\). The derivative of the right-hand side is \(nw^{n-1}+(n-1)w^{n-2}\), which has roots \(0\) and \(-(n-1)/n\geq 1/2\). For these two roots to lie in the convex hull of the roots of \(w^{n}+w^{n-1}+a\), the latter must have at least one root in \(|w|\geq 1/2\), which implies that \(az^{n}+z+1\) has at least one root in \(|z|\leq 2\).

Solution 2.The product of the roots of \(p(z)=az^{n}+z+1\) is its constant term, namely \(1\), so all \(p\)'s roots are unimodular or at least one is in \(|z|<1\).

**Solution to 5.9.19:** Let \(p(z)\) denote the polynomial and suppose \(p(z_{0})=0\) for some \(z_{0}\in\mathbb{D}\). Then \(z_{0}\) is also a root of \((z-1)p(z)\). We then have

\[0=a_{0}z_{0}^{n+1}+(a_{1}-a_{0})z_{0}^{n}+\cdots+(a_{n}-a_{n-1})z_{0}-a_{n}.\]

Since all the \(a_{i}\)'s are positive and \(|z_{0}|<1\), we have, by the Triangle Inequality [13, pag. 20],

\[a_{n} =|a_{0}z_{0}^{n+1}+(a_{1}-a_{0})z_{0}^{n}+\cdots+(a_{n}-a_{n-1})z_{ 0}|\] \[<a_{0}+(a_{1}-a_{0})+\cdots+(a_{n}-a_{n-1})\] \[=a_{n},\]

a contradiction.

**Solution to 5.9.20:** By Descartes' Rule of Signs [12, pag. 7], [13, pag. 172], the polynomial \(p(z)\) has zero or two positive real roots. As \(p(0)=3\) and \(p(1)=-2\), by the Intermediate Value Theorem [13, pag. 93], \(p(z)\) has one and so, two, positive real roots. Replacing \(z\) by \(-z\), and again applying Descartes' Rule of Signs, we see that \(p(-z)\) has one positive real root, so \(p(z)\) has one negative real root. Applying Rouche's Theorem [13, pag. 421] to the functions \(f=p\) and \(g=6z\) on the unit circle, we see that \(p\) has exactly one zero in the unit disc, which is positive as seen above. Hence, the real roots are distinct. (The same conclusion would follow from noticing that \(p\) and \(p^{\prime}\) have no common roots.) The imaginary roots are conjugate, so they are distinct as well.

_Solution 2._ Graphing the polynomial \(y=x^{5}-6x+3\) (for real \(x\)), we can see the result easily. First, \(y^{\prime}=5x^{4}-6\) and the only two real roots are \(x=\pm\sqrt[4]{6/5}\) and none of them are multiple. Now looking at the limits when \(x\to-\infty\) and \(x\to\infty\), we can conclude that the graph looks like

\[y\]So there are three distinct real roots. There cannot be a forth, otherwise \(y^{\prime}\) would have a third root. The other two roots are then complex and not real; since they are conjugate, they are distinct, making for five distinct roots, three of them real.

**Solution to 5.9.21:** Let \(z\) be a zero of the given polynomial with \(|z|=r\). If \(r\leq 1\), then \(z\) lies in the given disc. For \(r>1\), we have

\[r^{2n}=|-z^{n}|^{2}=\left|\sum_{i=0}^{n-1}c_{i}z^{i}\right|^{2}.\]

By the Cauchy-Schwarz Inequality [13, pag. 69], we get

\[r^{2n}\leq\sum_{i=0}^{n-1}|c_{i}|^{2}\sum_{i=0}^{n-1}|z^{i}|^{2}.\]

The second sum is a finite geometric series which sums to \(\frac{r^{2n}-1}{r^{2}-1}\). Combining these, we have

\[r^{2n}<\left(\sum_{i=0}^{n-1}|c_{i}|^{2}\right)\left(\frac{r^{2n}}{r^{2}-1} \right).\]

Multiplying both sides by \(\frac{r^{2}-1}{r^{2n}}\), we get the result wanted.

**Solution to 5.9.22:** The product of all zeros of \(P(x)\) (with multiplicities) equals \(\pm 1\), so, if there are no roots inside the unit circle, then there are no roots outside the unit circle either. Hence, all roots are on the unit circle. From \(P(0)=-1<0\) and \(\lim_{x\to\infty}P(x)=+\infty\), it follows that \(P(x)\) has a real zero in the interval \((0,\infty)\). Since it lies on the unit circle, it must be \(1\), so \(P(1)=0\).

**Solution to 5.9.23:** Let \(R>0\). Consider the semicircle with diameter \([-Ri,Ri]\) containing \(R\) and its diameter. We will apply the Argument Principle [13, pag. 419] to the given function on this curve.

Suppose \(n\) is even. Then

\[(iy)^{2n}+\alpha^{2}(iy)^{2n-1}+\beta^{2}=y^{2n}+\beta^{2}-i\alpha^{2}y^{2n-1}\]

is always in the first quadrant for \(y<0\), so the change in the argument when we move from \(0\) to \(-Ri\) is close to zero, for \(R\) large. On the semicircle,

\[z^{2n}+\alpha^{2}z^{2n-1}+\beta^{2}=z^{2n}\left(1+\frac{\alpha^{2}}{z}+\frac{ \beta^{2}}{z^{2n}}\right)\]

which is close to \(z^{2n}\) for \(R\) large. So the argument changes by \(2\pi n\) when we go from \(-Ri\) to \(Ri\). From \(Ri\) to \(0\),

\[y^{2n}+\beta^{2}-i\alpha^{2}y^{2n-1}\]is always in the fourth quadrant, so the change in the argument is close to zero, for \(R\) large. The total change is then \(2\pi n\), so there are \(n\) roots with positive real part.

Now, suppose that \(n\) is odd. We have

\[(iy)^{2n}+\alpha^{2}(iy)^{2n-1}+\beta^{2}=-y^{2n}+\beta^{2}+i\alpha^{2}y^{2n-1}\]

so when we go from the origin to \(-Ri\), for \(R\) large, the argument change is close to \(-\pi\). The variation on the semicircle is again about \(2\pi n\). The change when \(y\) goes from \(R\) to \(0\) in the argument of

\[-y^{2n}+\beta^{2}+i\alpha^{2}y^{2n-1}\]

is about \(-\pi\). Therefore, the number of zeros with, positive real part is now \((-\pi+2\pi-\pi)/2\pi=n-1\).

**Solution to 5.9.24:** Let \(\rho>0\) and consider the functions

\[g_{n}(z)=f_{n}(1/z)=1+z+\frac{z^{2}}{2!}+\cdots+\frac{z^{n}}{n!}.\]

Since \(g_{n}(0)\neq 0\) for all \(n\), \(g_{n}(z)\) has a zero in \(|z|\leq\rho\) if and only if \(f_{n}(z)\) has a zero in \(|z|\geq\rho\). \(g_{n}(z)\) is a partial sum of the power series for \(e^{z}\). Since this series converges locally uniformly and \(\{z\,|\,|z|\leq\rho\}\) is compact, for any \(\varepsilon>0\) there is \(N>0\) such that if \(n\geq N\), then \(|g_{n}(z)-e^{z}|<\varepsilon\) for all \(z\) in this disc. \(e^{z}\) attains its minimum \(m>0\) in this disc. Taking \(N_{0}\) such that if \(n\geq N_{0}\), \(|g_{n}(z)-e^{z}|<m/2\) for all \(z\) in the disc, we get that \(g_{n}(z)\) is never zero for \(|z|\leq\rho\). Therefore, \(f_{n}(z)\) has no zeros outside this disc.

**Solution to 5.9.26:** The function \(\sin z\) satisfies the identity \(\sin(z+\pi)=-\sin z\), and vanishes at the points \(n\pi\), \(n\in\mathbb{Z}\), and only at those points. For \(m\) a positive integer, let \(R_{m}\) denote the closed rectangle with vertices \((m-\frac{1}{2})\pi+i\varepsilon\) and \((m+\frac{1}{2})\pi\pm i\varepsilon\). The function \(\sin z\) has no zeros on the boundary of \(R_{m}\), so its absolute value has a positive lower bound, say \(\delta\), there. (The number \(\delta\) is independent of \(m\) because of the identity \(\sin(z+\pi)=-\sin z\).) Suppose \((m-\frac{1}{2})\pi-|a|>\frac{1}{\delta}\). Then, for \(z\) in \(R_{m}\), we have

\[\frac{1}{|z-a|}\leq\frac{1}{|z|-a}\leq\frac{1}{(m-\frac{1}{2})\pi-|a|}<\delta\]

implying that \(\frac{1}{|z-a|}<|\sin z|\) on the boundary of \(R_{m}\). By Rouche's Theorem [10, pag. 421] then, the functions \(\sin z\) and \(f(z)=\sin z+\frac{1}{z-a}\) have the same number of zeros in the interior of \(R_{m}\). Since \(\sin z\) has one zero there, so does \(f(z)\). As the condition on \(m\) holds for all sufficiently large \(m\), the desired conclusion follows.

**Solution to 5.9.27:** We will prove that the simple zeros of a polynomial depend continuously on the coefficients of the polynomial, around a simple root.

Consider

\[p(z)=\hat{a}_{0}+\hat{a}_{1}z+\cdots+\hat{a}_{n}z^{n}=\hat{a}_{n}\prod_{j=1}^{s}(z- z_{j})^{m_{j}}\quad(\hat{a}_{n}\neq 0).\]

For \((\xi_{0},\ldots,\xi_{n-1})\in\mathbb{C}\,^{n}\), let \(F\) be the polynomial given by

\[F(z)=\hat{a}_{0}\xi_{0}+(\hat{a}_{1}+\xi_{1})z+\cdots+(\hat{a}_{n-1}+\xi_{n-1}) z^{n-1}+\hat{a}_{n}z^{n}\]

and, for each \(1\leq k\leq s\), let \(0<r_{k}<\min_{k\neq j}|z_{k}-z_{j}|\).

We will show that for some \(\varepsilon>0\), \(|\xi_{i}|<\varepsilon\) for \(i=0,\ldots,n-1\) implies that \(F\) has \(m_{j}\) zeros inside the circle \(C_{k}\) centered at \(z_{k}\) with radius \(r_{k}\).

Let \(\zeta\) be the polynomial given by

\[\zeta(z)=\xi_{0}+\xi_{1}z+\cdots+\xi_{n-1}z^{n-1}.\]

On \(C_{k}\), we have

\[|\zeta(z)|\leq\varepsilon M_{k},\quad M_{k}=\sum_{j=1}^{n-1}(r_{k}+|z_{k}|)^{j}\]

and

\[|p(z)|\geq|\hat{a}_{n}|r_{k}^{m_{k}}\prod_{\begin{subarray}{c}j=1\\ j\neq k\end{subarray}}^{k}\left(|z_{j}-z_{k}|-r_{k}\right)^{m_{j}}=\delta_{k}>0.\]

Taking \(\varepsilon<\delta_{k}/M_{k}\), we get \(|\zeta(z)|<|p(z)|\) on \(C_{k}\); therefore, by Rouch\(\acute{\rm e}\)'s Theorem [12, pag. 421], \(F\) has the same number of zeros in \(C_{k}\) as \(p\). As in this domain \(p\) has a single zero with multiplicity \(m_{j}\), we are done.

**Solution to 5.9.28:** From

\[f^{(k)}(z)=\sum_{n\geq k}n(n-1)\cdots(n-k+1)a_{n}z^{n-k},\]

we conclude that

\[\left|f^{(k)}(re^{i\theta})\right|\leq\left|f^{(k)}(r)\right|\]

for \(0<r<1\), and \(0<\theta\leq 2\pi\). Suppose \(f\) can be analytically continued in a neighborhood of \(z=1\); then its power series expansion around \(z=1/2\),

\[\sum_{n=0}^{\infty}\beta_{n}(z-1/2)^{n}\]

has a radius of convergence \(R>1/2\). Let \((\gamma_{n})\) be the Taylor coefficients [12, pag. 233] of the power series expansion of \(f\) around the point \((1/2)e^{i\theta}\). By the above inequality, \(|\gamma_{n}|\leq|\beta_{n}|\). Therefore, the power series around the point \((1/2)e^{i\theta}\) has a radius of convergence of at least \(R\). So \(f\) can be analytically continued in a neighborhood of every point of the unit circle. However, the Maclaurin series [MH87, pag. 234] of \(f\) has radius of convergence \(1\), which implies that at least one point on the unit circle is a singularity of \(f\), and get a contradiction.

**Solution to 5.9.29:** Without loss of generality, assume \(r=1\).

Suppose \(f\) is analytic at \(z=1\). Then \(f\) has a power expansion centered at \(1\) with positive radius of convergence. Therefore, \(f\) has a power series expansion centered at \(z=1/2\) with radius \(1/2+\varepsilon\) for some positive \(\varepsilon\).

As

\[f^{(n)}\left(\frac{1}{2}\right)=\sum_{k\geq n}\frac{k!}{(k-n)!}a_{k}\left( \frac{1}{2}\right)^{k-n}\]

we have, for \(1<x<1+\varepsilon\),

\[f(x) =\sum_{n\geq 0}\frac{f^{(n)}(1/2)}{n!}\left(x-\frac{1}{2}\right)^ {n}\] \[=\sum_{n\geq 0}\frac{1}{n!}\left(x-\frac{1}{2}\right)^{n}\sum_{k \geq n}\frac{k!}{(k-n)!}a_{k}\left(\frac{1}{2}\right)^{k-n}\] \[=\sum_{k\geq 0}a_{k}\sum_{n=0}^{k}\frac{k!}{n!(k-n)!}\left(x- \frac{1}{2}\right)^{n}\left(\frac{1}{2}\right)^{k-n}\] \[=\sum_{k\geq 0}a_{k}x^{k}\]

which is absurd because we assumed the radius of convergence of \(\sum a_{n}z^{n}\) to be \(1\). This contradiction shows that \(f\) cannot be analytic at \(z=1\).

**Solution to 5.9.30:** 1. As

\[(\tan z)^{-2}-z^{-2}=\frac{z^{2}-(\tan z)^{2}}{z^{2}(\tan z)^{2}}\]

the Maclaurin expansion [12, pag. 234] of the numerator has no terms of degree up to 3, whereas the expansion of the denominator starts with \(z^{4}\), therefore, the limit is finite.

2. As

\[\tan z=z+\frac{1}{3}z^{3}+o(z^{4})\qquad(z\to 0)\]

we have

\[(\tan z)^{-2}-z^{-2}=\frac{z^{2}-z^{2}-\frac{2}{3}z^{4}+o(z^{4})}{z^{4}+o(z^{4 })}\qquad(z\to 0)\]

so the limit at 0 is \(-2/3\).

**Solution to 5.9.31:** If \(g\) has a removable singularity at infinity, it is a bounded entire function, and so, by Liouville's Theorem [12, pag. 170], it is constant, which contradicts our hypothesis. If \(g\) has an essential singularity at infinity, by, the Casorati-Weierstrass Theorem [12, pag. 256], there is an unbounded sequence \((z_{n})\) such that \(g(z_{n})\) tends to 0. Hence, \(h(z_{n})\) tends to \(f(0)\), contradicting the fact that \(h\) is a polynomial and, thus, has a pole at infinity. Therefore, \(g\) must have a pole at infinity and be a polynomial.

Let \((\zeta_{n})\) be any unbounded sequence. Since \(g\) is a polynomial, it is surjective and maps bounded sets to bounded sets. Hence, there is an unbounded sequence \((\xi_{n})\) with \(g(\xi_{n})=\zeta_{n}\) for all \(n\). Therefore, \(f(\zeta_{n})=h(\xi_{n})\) tends to infinity as \(n\) tends to infinity, since \(h\) has a pole at infinity. Since this holds for all unbounded sequences, we see that \(f\) has a pole at infinity as well, so it is also a polynomial.

### 5.10 Harmonic Functions

**Solution to 5.10.1:** Derivating twice, we can see that

\[\frac{\partial^{2}u}{\partial x^{2}}=6x=-\frac{\partial^{2}u}{\partial y^{2}},\]

so \(\Delta u=0\). The function \(f\) is then given by (see [1, pages 126-127])

\[f(z)=2u\left(\frac{z}{2},\frac{z}{2i}\right)=2\left(\frac{z^{3}}{8}-3\frac{z}{ 2}\frac{z^{2}}{(-4)}\right)=z^{3}.\]

**Solution to 5.10.2:** Since \(u\) is the real part of an analytic function, it is harmonic in the unit disc \(\mathbb{D}\). By Green's Theorem [14, pag. 253],

\[\int_{\partial\mathbb{D}}\frac{\partial u}{\partial y}\,dx-\frac{\partial u}{ \partial x}\,dy=-\int_{\mathbb{D}}\left(\frac{\partial^{2}u}{\partial x^{2}}+ \frac{\partial^{2}u}{\partial y^{2}}\right)\,dxdy=0.\]

**Solution to 5.10.3:** 1. Let \(f=u+iv\). Then \(v\) is identically \(0\) on the unit circle. By the Maximum Modulus Principle [13, pag. 185] for harmonic functions, \(v\) is identically zero on \(\mathbb{D}\). By the Cauchy-Riemann equations [13, pag. 72], the partial derivatives of \(u\) vanish; hence, \(u\) is constant also and so is \(f\).

2. Consider

\[f(z)=i\frac{z+1}{z-1}.\]

\(f\) is analytic everywhere in \(\mathbb{C}\) except at \(1\). We have

\[f\left(e^{i\theta}\right)=i\frac{e^{i\theta}+1}{e^{i\theta}-1}=i\frac{e^{i \theta/2}+e^{-i\theta/2}}{e^{i\theta/2}-e^{-i\theta/2}}=\cot\left(\frac{ \theta}{2}\right)\in\mathbb{R}.\]

**Solution to 5.10.4:** We have \(u=\Re z^{s}\), \(z^{s}\equiv e^{s\log z}\), and \(\log z=\) principal branch of log with \(-\pi<\arg z<\pi\). \(z^{s}\) is analytic in the slit plane \(\mathbb{C}\backslash(-\infty,0]\) and \(\frac{d}{dz}e^{s\log z}=sz^{s-1}\). Hence, \(u=\Re z^{s}\) is harmonic in the same domain.

**Solution to 5.10.5:** Let \(v\) be the harmonic conjugate of \(u\). Then, \(f=u+iv\) is an entire function. Consider \(h=e^{-f}\). Since \(u\geq 0\), \(|h|\leq 1,\ h\) is a bounded entire function and, by Liouville's Theorem [13, pag. 170], a constant. Therefore, \(u\) is constant as well.

**Solution to 5.10.6:** Let \(v\) be a harmonic conjugate of \(u\), and let \(f=e^{u+iv}\). Then \(f\) is an entire function and, for \(|z|>1\), we have

\[|f(z)|=e^{u(z)}\leq e^{a\log|z|+b}=e^{b}|z|^{a}\.\]

Let \(n\) be a positive integer such that \(n\geq a\). Then the function \(z^{-n}f(z)\) has an isolated singularity at \(\infty\) and, by the preceding inequality, is bounded in a neighborhood of \(\infty\). Hence, \(\infty\) is a removable singularity of \(z^{-n}f(z)\) and, thus, is, at worst, a pole of \(f\). That means \(f\) is an entire function with, at worst, a pole at \(\infty\), and so \(f\) is a polynomial. Since nonconstant polynomials are surjective and \(f\) omits the value \(0\), \(f\) must be constant, and so is \(u\), as desired.

### 5.11 Residue Theory

**Solution to 5.11.1:** Since the \(r_{i}\)'s are distinct, \(f\) has a simple pole at each of these points. If \(A_{1},A_{2},\ldots,A_{n}\) are the residues of \(f\) at each of thesepoints, then

\[g(z)=f(z)-\frac{A_{1}}{z-r_{1}}-\frac{A_{2}}{z-r_{2}}-\cdots-\frac{A_{n}}{z-r_{n}}\]

is entire. Clearly, \(g\) tends to zero as \(z\) tends to infinity, so, by the Maximum Modulus Principle [13, pag. 185], \(g\) must be identically zero and we are done.

**Solution to 5.11.2:** We have

\[a_{-1}=\operatorname{Res}\left(\cot\pi z,-1\right)+\operatorname{Res}\left( \cot\pi z,0\right)+\operatorname{Res}\left(\cot\pi z,1\right)=\frac{3}{\pi}.\]

For \(n<-1\), the coefficients are given by

\[a_{n} =\frac{1}{2\pi}\int_{|z|=3/2}\frac{\cot\pi z}{z^{n+1}}dz\] \[=\operatorname{Res}\left(\frac{\cot\pi z}{z^{n+1}},-1\right)+ \operatorname{Res}\left(\frac{\cot\pi z}{z^{n+1}},1\right)\] \[=\lim_{z\to-1}(z+1)\frac{\cot\pi z}{z^{n+1}}+\lim_{z\to 1}(z-1) \frac{\cot\pi z}{z^{n+1}}\] \[=\left((-1)^{-n-1}+1\right)\frac{1}{\pi}.\]

**Solution to 5.11.4:** If the roots of \(f\) are not distinct, then some \(x_{0}\) satisfies \(f(x_{0})=f^{\prime}(x_{0})=0\). But \(f^{\prime}(x)=1+x+\cdots+\frac{x^{m-1}}{(m-1)!}\), so

\[0=f(x_{0})=f^{\prime}(x_{0})=\frac{x_{0}^{m}}{m!}\]

and \(x_{0}=0\). However, \(0\) is clearly not a root of \(f\). Hence, the roots of \(f\) are distinct and nonzero.

For \(0\leq k\leq n-2\), consider the integral

\[I_{k}=\int_{C_{r}}\frac{z^{k}}{f(z)}dz\]

where \(C_{r}\) is a circle of radius \(r\) centered at the origin such that all the roots of \(f\) lie inside it. By Cauchy's Theorem [13, pag. 152], \(I_{k}\) is independent of \(r\), and as \(r\to\infty\), the integral tends to \(0\). Hence, \(I_{k}=0\). By the Residue Theorem [13, pag. 280],

\[0=\sum\ \operatorname{Res}\frac{z^{k}}{f(z)}=\sum_{i=1}^{N}\frac{z_{i}^{k}}{f^{ \prime}(z_{i})}=\sum_{i=1}^{n}\frac{z_{i}^{k}}{f(z_{i})-\frac{z_{i}^{n}}{n!}}= n!\sum_{i=1}^{n}z_{i}^{k-n}.\]

Since \(2\leq m-k\leq n\), we get the desired result.

**Solution to 5.11.5:** Let the disc centered at the origin with radius \(r\) contain all the zeros of \(Q\). Let \(C_{R}\) be a circle centered at the origin with radius \(R>r\). Then, by the Deformation Theorem [16, pag. 148],

\[\int_{C}\frac{P(z)}{Q(z)}\,dz=\int_{C_{R}}\frac{P(z)}{Q(z)}\,dz\]

where \(C\) is any closed curve outside \(|z|=r\). As

\[\frac{P(z)}{Q(z)}=O\left(|z|^{-2}\right)\quad(|z|\to\infty)\]

we have

\[\int_{C_{R}}\frac{P(z)}{Q(z)}\,dz=O\left(|z|^{-2}\right)2\pi R=o(1)\quad(R\to\infty)\]

and the result follows.

**Solution to 5.11.6:** We have

\[\int_{C_{a}}\frac{z^{2}+e^{z}}{z^{2}(z-2)}dz=\int_{C_{a}}\frac{1}{(z-2)}dz+\int _{C_{a}}\frac{e^{z}}{z^{2}}\frac{1}{(z-2)}dz.\]

We will use the Residue Theorem [16, pag. 280].

\[\operatorname{Res}\left(\frac{1}{z-2},2\right)=1.\]

Let \(f(z)=e^{z}/z^{2}(z-2)\). The following expansions hold:

\[\frac{1}{z-2} =-\frac{1}{2}\left(1+\frac{z}{2}+\frac{z^{2}}{4}+\frac{z^{3}}{8}+ \cdots\right)\] \[\frac{1}{z^{2}(z-2)} =-\frac{1}{2z^{2}}-\frac{1}{4z}-\frac{1}{8}-\cdots\] \[\frac{e^{z}}{z^{2}(z-2)} =\left(1+z+\frac{z^{2}}{2}+\frac{z^{3}}{3!}+\cdots\right)\left(- \frac{1}{2z^{2}}-\frac{1}{4z}-\frac{1}{8}-\cdots\right)\] \[=-\frac{1}{2z^{2}}-\frac{3}{4z}-\frac{5}{8}-\cdots\] thus \[\operatorname{Res}\left(f(z),0\right)=-\frac{3}{4}.\] Also, \[\operatorname{Res}\left(f(z),2\right)=\left.\frac{d}{dz}\frac{e^{z}}{z^{2}} \right|_{z=2}=0.\] Therefore, we have, for \(a>2\),

\[\int_{C_{a}}\frac{z^{2}+e^{z}}{z^{2}(z-2)}\,dz=2\pi i\,\operatorname{Res} \left(\frac{1}{z-2},2\right)+\operatorname{Res}\left(f,0\right)+\operatorname {Res}\left(f,2\right)=-\frac{\pi i}{2}\]and for \(a<2\),

\[\int_{C_{a}}\frac{z^{2}+e^{z}}{z^{2}(z-2)}\,dz=2\pi i\,\operatorname{Res}\left(f(z ),0\right)=-\frac{3\pi i}{2}.\]

**Solution to 5.11.7:** Let \(f(z)=\sqrt{z^{2}-1}=\sum_{k=0}^{\infty}\left(\begin{array}{c}1/2\\ k\end{array}\right)z^{2k}\). \(f\) is analytic for \(|z|>1\); therefore,

\[\int_{C}\sqrt{z^{2}-1}\,dz=-2\pi i\,\operatorname{Res}\left(f(z),\infty\right).\]

We have

\[\frac{1}{z^{2}}f\left(\frac{1}{z}\right) =\frac{1}{z^{3}}\sqrt{1-z^{2}}\] \[=\frac{1}{z^{3}}\sum_{k\geq 0}\left(\begin{array}{c}1/2\\ k\end{array}\right)(-1)^{k}z^{2k}\] \[=\sum_{k\geq 0}\left(\begin{array}{c}1/2\\ k\end{array}\right)(-1)^{k}z^{2k-3}\]

so

\[\operatorname{Res}\left(f(z),\infty\right)=\operatorname{Res}\left(\frac{1}{z ^{2}}f\left(\frac{1}{z}\right),0\right)=\frac{1}{2}.\]

We then obtain

\[\int_{C}\sqrt{z^{2}-1}\,dz=-\pi i.\]

**Solution to 5.11.8:** Using the change of variables \(z=1/w\), we obtain

\[\frac{1}{2\pi i}\int_{C}\frac{dz}{\sin\frac{1}{z}}=\frac{1}{2\pi i}\int_{|w|=5 }\frac{-dw}{w^{2}\sin w}\]

where the contour is oriented clockwise. By the Residue Theorem [13, pag. 280], we have

\[\frac{-1}{2\pi i}\int_{|w|=5}\frac{-dw}{w^{2}\sin w} =\operatorname{Res}\left(\frac{1}{w^{2}\sin w},\pi\right)+ \operatorname{Res}\left(\frac{1}{w^{2}\sin w},-\pi\right)\] \[+\operatorname{Res}\left(\frac{1}{w^{2}\sin w},0\right).\]

We have

\[\operatorname{Res}\left(\frac{1}{w^{2}\sin w},\pm\pi\right)=\lim_{w\to\pm\pi} \frac{w\mp\pi}{w^{2}\sin w}=-\frac{1}{\pi^{2}}\]and

\[\frac{1}{w^{2}\sin w} =\frac{1}{w^{2}\left(w-w^{3}/3!+w^{5}/5!+\cdots\right)}\] \[=\frac{1}{w^{3}}\frac{1}{1-\left(w^{2}/3!-w^{4}/5!+\cdots\right)}\] \[=\frac{1}{w^{3}}\left(1+\left(w^{2}/3!-w^{4}/5!+\cdots\right)\right.\] \[\qquad+\left(w^{2}/3!-w^{4}/5!+\cdots\right)^{2}+\cdots\right)\] \[=1/3!w+\cdots\]

Then,

\[\frac{1}{2\pi i}\int_{|w|=5}\frac{dw}{w^{2}\sin w}=\frac{1}{6}-\frac{2}{\pi^{2 }}.\]

**Solution to 5.11.11:**\((e^{2\pi z}+1)^{-2}\) has a double pole at \(\pm i/2.\) By the Residue Theorem [13, pag. 280], the value of this integral is \(2\pi i\) times the sum of the residues of \((e^{2\pi z}+1)^{-2}\) at these two points. We have

\[-e^{2\pi z}=e^{-\pi i}e^{2\pi z}=e^{2\pi(z-i/2)}=1+2\pi(z-i/2)+2\pi^{2}(z-i/2) ^{2}+\cdots\]

hence,

\[e^{2\pi z}+1=-2\pi(z-i/2)-2\pi^{2}(z-i/2)^{2}-\cdots\]

and so

\[(e^{2\pi z}+1)^{2}=4\pi^{2}(z-i/2)^{2}+8\pi^{3}(z-i/2)^{3}+\cdots\]

The residue at \(i/2\) is

\[\frac{d}{dz}\left.\left(\frac{(z-i/2)^{2}}{(e^{2\pi z}+1)^{2}} \right)\right|_{z=i/2} =\frac{d}{dz}\left.\left(\frac{1}{4\pi^{2}+8\pi^{3}(z-i/2)+O((z-i /2)^{2})}\right)\right|_{z=i/2}\] \[=\frac{-8\pi^{3}+O(z-i/2)}{(4\pi^{2}+O(z-i/2))^{2}}\bigg{|}_{z=i/ 2}\] \[=-\frac{1}{2\pi}.\]

Using the fact that \(-e^{2\pi z}=e^{\pi i}e^{2\pi z}\), an identical calculation shows that the other residue is also \(-1/2\pi\), so the integral equals \(-2i\).

**Solution to 5.11.12:** A standard application of the Rouche's Theorem [13, pag. 421] shows that all the roots of the denominator lie in the open unit disc. By the Deformation Theorem [13, pag. 148], therefore, the integral will not change if we replace the given contour by the circle centered at the origin with radius \(R>1.\) Using polar coordinates on this circle, the integral becomes

\[\frac{1}{2\pi i}\int_{0}^{2\pi}\frac{Re^{11i\theta}iRe^{i\theta}d\theta}{12R^{ 12}e^{12i\theta}-9R^{9}e^{9i\theta}+2R^{6}e^{6i\theta}-4R^{3}e^{3i\theta}+1}=\]\[\frac{1}{2\pi}\int_{0}^{2\pi}\frac{d\theta}{12-9R^{-3}e^{-3i\theta}+2R^{-6}e^{-6i \theta}-4R^{-9}e^{-9i\theta}+R^{-12}}\]

which has the limit \(1/12\) as \(R\to\infty\). The value of the given integral is therefore, \(1/12\).

**Solution to 5.11.13:** We make the change of variables \(u=z-1\). The integral becomes

\[\int_{|u+1|=2}(2u+1)e^{1+1/u}\,du.\]

Using the power series for the exponential function, we get

\[(2u+1)e^{1+1/u}=e\left(2u+3+\frac{2}{u}+\cdots\right)\,.\]

The residue of this function at zero, which lies inside \(|u+1|=2\), is \(2e\), so the integral is \(4e\pi i\).

**Solution to 5.11.14:** Denote the integrand by \(f\). By the Residue Theorem [13, pag. 280], \(I\) is equal to the sum of the residues of \(f\) at \(-1/2\) and \(1/3\), which lie in the interior of \(C\). \(I\) is also the negative of the sum of the residues in the exterior of \(C\), namely at \(2\) and \(\infty\). We have

\[\operatorname{Res}\left(f,2\right)=\lim_{z\to 2}(z-2)f(z)=-1/5^{5}.\]

As \(\lim_{z\to\infty}f(z)=0\),

\[\operatorname{Res}\left(f,\infty\right)=-\lim_{z\to\infty}zf(z)=0.\]

So \(I=1/5^{5}\).

**Solution to 5.11.15:** The numerator in the integrand is \(\frac{1}{3n}\) times the derivative of the denominator. Hence, \(I\) equals \(\frac{1}{3n}\) times the number of zeros of the denominator inside \(C\); that is, \(I=\frac{1}{3}\).

_Solution 2._ For \(r>1\), let \(C_{r}\) be the circle \(|z|=r\), oriented counterclockwise. By Cauchy's Theorem [13, pag. 152], and using the parameterization \(z=re^{i\theta}\),

\[I =\frac{1}{2\pi i}\int_{C_{r}}\frac{z^{n-1}}{3z^{n}-1}\,dz\] \[=\frac{1}{2\pi}\int_{0}^{2\pi}\frac{r^{n}e^{in\theta}}{3r^{n}e^{ in\theta}-1}\,d\theta.\]

As \(r\to\infty\), the integrand converges uniformly to \(\frac{1}{3}\), giving \(I=\frac{1}{3}\).

**Solution to 5.11.16:** The integrand has two singularities inside \(C\), a pole of order \(1\) at the origin and a pole of order \(2\) at \(-1/2\). Hence,

\[\int_{C}\frac{e^{z}}{z(2z+1)^{2}}\,dz=2\pi i\left(\operatorname{Res}\left( \frac{e^{z}}{z(2z+1)^{2}},0\right)+\operatorname{Res}\left(\frac{e^{z}}{z(2z+ 1)^{2}},-\frac{1}{2}\right)\right)\,.\]The residues can be evaluated by standard methods:

\[\begin{split}\operatorname{Res}\left(\frac{e^{z}}{z(2z+1)^{2}},0 \right)&=\left.\frac{e^{z}}{z(2z+1)^{2}}\right|_{z=0}=1\\ \operatorname{Res}\left(\frac{e^{z}}{z(2z+1)^{2}},-\frac{1}{2} \right)&=\frac{1}{4}\left.\frac{d}{dz}\left(\frac{e^{z}}{z} \right)\right|_{z=-\frac{1}{2}}\\ &=\frac{1}{4}\left.\left(\frac{e^{z}}{z}-\frac{e^{z}}{z^{2}} \right)\right|_{z=-\frac{1}{2}}=-\frac{3e^{-\frac{1}{2}}}{2}\.\end{split}\]

Hence,

\[\int_{C}\frac{e^{z}}{z(2z+1)^{2}}\ dz=2\pi i\left(1-\frac{3}{2\sqrt{e}}\right).\]

**Solution to 5.11.17:** The function \(f\) has poles of order \(1\) at \(z=\pm 1\) and a pole of order \(2\) at \(z=0\). These are the only singularities of \(f\). The winding numbers of \(\gamma\) around \(-1,\,0,\,1\) are \(1,\,2,\,-1\), respectively. By the Residue Theorem [13, pag. 280],

\[\frac{1}{2\pi i}\int_{\gamma}f(z)dz=\operatorname{Res}\left(f,-1\right)+2 \operatorname{Res}\left(f,0\right)-\operatorname{Res}\left(f,1\right)\,.\]

Since \(1\) and \(-1\) are simple poles, we have

\[\begin{split}\operatorname{Res}\left(f,1\right)&= \lim_{z\to 1}(z-1)f(z)=\left.\frac{-e^{z}}{z^{2}(z+1)}\right|_{z=1}=\frac{-e}{2}\\ \operatorname{Res}\left(f,-1\right)&=\lim_{z\to-1}(z+1 )f(z)=\left.\frac{-e^{z}}{z^{2}(z-1)}\right|_{z=-1}=\frac{e^{-1}}{2}\cdot\end{split}\]

To find the residue at \(0\), we use power series:

\[\begin{split}\frac{e^{z}}{z^{2}(1-z^{2})}&=\frac{1 }{z^{2}}\left(1+z+\frac{z^{2}}{2}+\cdots\right)\left(1+z^{2}+z^{4}+\cdots \right)\\ &=\frac{1}{z^{2}}\left(1+z+\cdots\right)=\frac{1}{z^{2}}+\frac{1} {z}+\cdots\end{split}\]

It follows that \(\operatorname{Res}(f,0)=1\). Hence,

\[\frac{1}{2\pi i}\int_{\gamma}f(z)dz=\frac{e^{-1}}{2}+2+\frac{e}{2}=2+\cosh 1.\]

**Solution to 5.11.19:** The roots of \(1-2z\cos\theta+z^{2}=0\) are \(z=\cos\theta\pm i\sqrt{1-\cos^{2}\theta}=e^{\pm i\theta}\). Using the Residue Theorem, [13, pag. 280], we get

\[\frac{1}{2\pi i}\int_{|z|=2}\frac{z^{n}}{1-2z\cos\theta+z^{2}}dz =\frac{1}{2\pi i}\int_{|z|=2}\frac{z^{n}}{(z-e^{i\theta})(z-e^{-i \theta})}dz\] \[=\text{Res }\left(\frac{z^{n}}{(z-e^{i\theta})(z-e^{-i\theta})},e^{ i\theta}\right)\] \[+\text{Res }\left(\frac{z^{n}}{(z-e^{i\theta})(z-e^{-i\theta})},e^{ -i\theta}\right)\] \[=\frac{z^{n}}{z-e^{-i\theta}}\Bigg{|}_{z=e^{i\theta}}+\frac{z^{n} }{z-e^{i\theta}}\Bigg{|}_{z=e^{-i\theta}}\] \[=\frac{e^{in\theta}}{e^{i\theta}-e^{-i\theta}}+\frac{e^{-in\theta }}{e^{-i\theta}-e^{i\theta}}\] \[=\frac{e^{in\theta}-e^{-in\theta}}{e^{i\theta}-e^{-i\theta}}\] \[=\frac{\sin(n\theta)}{\sin\theta}.\]

**Solution to 5.11.20:** Substituting \(z=e^{i\theta}\), we have

\[I(a) =\int_{0}^{2\pi}\frac{d\theta}{a+\frac{e^{i\theta}+e^{-i\theta}} {2}}=2\int_{0}^{2\pi}\frac{e^{i\theta}d\theta}{2ae^{i\theta}+e^{2i\theta}+1}\] \[=\frac{2}{i}\int_{|z|=1}\frac{dz}{z^{2}+2az+1}.\]

The roots of the polynomial in the denominator are \(-a+\sqrt{a^{2}-1}\) and \(-a-\sqrt{a^{2}-1}\), of which only the former is within the unit circle. By the Residue Theorem [13, pag. 280],

\[I(a)=4\pi\text{ Res }\left(\frac{1}{z^{2}+2az+1}\,-a+\sqrt{a^{2}-1}\right).\]

Since the function in question has a single pole at \(z=-a+\sqrt{a^{2}-1}\), the residue equals

\[\frac{1}{2z+2a}\Bigg{|}_{z=-a+\sqrt{a^{2}-1}}=\frac{1}{2\sqrt{a^{2}-1}}\]

giving \(I(a)=\frac{2\pi}{\sqrt{a^{2}-1}}\).

Consider the function \(F\) defined for \(\xi\not\in[-1,1]\) by

\[F(\xi)=\int_{0}^{2\pi}\frac{d\theta}{\xi+\cos\theta}.\]As \(F^{\prime}(\xi)\) exists, \(F\) is analytic on its domain. Combining with the previous results, we have that the function \[F(\xi)-\frac{2\pi}{\sqrt{\xi^{2}-1}}\] is analytic and vanishes for \(\xi>1\); therefore, it must be identically zero. From this, we obtain that \[\int_{0}^{2\pi}\frac{d\theta}{\xi+\cos\theta}=\frac{2\pi}{\sqrt{\xi^{2}-1}}\] in the domain of \(F\).

**Solution to 5.11.21:** Let \(f\) be the function defined by

\[f(z)=\frac{i}{(z-r)(rz-1)}.\]

We have

\[\int_{|z|=1}f(z)dz=\int_{0}^{2\pi}\frac{d\theta}{1-2r\cos\theta+r^{2}}.\]

For \(|r|<1\),

\[\operatorname{Res}\left(f(z),r\right)=\frac{i}{r^{2}-1}\]

and

\[\int_{0}^{2\pi}\frac{d\theta}{1-2r\cos\theta+r^{2}}=\frac{2\pi}{1-r^{2}}.\]

For \(|r|>1\), we get

\[\operatorname{Res}\left(f(z),\frac{1}{r}\right)=\frac{i}{1-r^{2}}\]

and

\[\int_{0}^{2\pi}\frac{d\theta}{1-2r\cos\theta+r^{2}}=\frac{2\pi}{r^{2}-1}.\]

_Solution 2._ Suppose that \(r\in\mathbb{R}\) and \(0<r<1\). Let \(u_{0}\) be defined on the unit circle by \(u_{0}(z)=1\). The solution of the corresponding Dirichlet Problem [13, pag. 600], that is, the harmonic function on \(\mathbb{D}\), \(u\), that agrees with \(u_{0}\) on \(\partial\mathbb{D}\) is given by Poisson's Formula [13, pag. 195]:

\[u(r)=\frac{1-r^{2}}{2\pi}\int_{0}^{2\pi}\frac{d\theta}{1-2r\cos\theta+r^{2}}\]

but \(u\equiv 1\) is clearly a solution of the same problem. Therefore, by unicity, we get

\[\int_{0}^{2\pi}\frac{d\theta}{1-2r\cos\theta+r^{2}}=\frac{2\pi}{1-r^{2}}.\]

[MISSING_PAGE_EMPTY:309]

others, we have

\[I=\frac{1}{2}\Re\left(i2\pi i\ \frac{z^{3}+1}{2(z-2)}\bigg{|}_{z=1/2}\right)= \frac{3\pi}{8}.\]

**Solution to 5.11.24:** Consider the contour in the figure

We have

\[\int_{0}^{2\pi}\frac{1-\cos(n\theta)}{1-\cos\theta}d\theta=\lim_{\varepsilon \to 0}\int_{\varepsilon}^{2\pi-\varepsilon}\frac{1-\cos(n\theta)}{1-\cos \theta}d\theta=\lim_{\varepsilon\to 0}\int_{\varepsilon}^{2\pi-\varepsilon} \frac{1-e^{in\theta}}{1-\cos\theta}d\theta,\]

the last equality because the integral of \(f(\theta)=\frac{i\sin(n\theta)}{1-\cos\theta}\) vanishes (since \(f(2\pi-\theta)=-f(\theta)\)). Next,

\[\int_{\varepsilon}^{2\pi-\varepsilon}\frac{1-e^{in\theta}}{1-\cos\theta}d \theta=\int_{\Gamma_{\varepsilon}}\frac{1-z^{n}}{1-(z+1/z)/2}\frac{dz}{iz},\]

where \(\Gamma_{\varepsilon}\) is the almost-circle \(\{e^{i\theta}:\varepsilon\leq\theta\leq 2\pi-\varepsilon\}\), traversed counterclockwise. The latter integral equals

\[\frac{2}{i}\int_{\Gamma_{\varepsilon}}\frac{z^{n}-1}{(z-1)^{2}}dz,\]

which, when \(\varepsilon\to 0\), tends to

\[\pi i\frac{2}{i}\ \text{Res}\left(\frac{z^{n}-1}{(z-1)^{2}},1\right)=2\pi n,\]so the integral in the statement of the problem has the value \(2\pi n\).

**Solution to 5.11.25:** Let \(z=e^{i\theta}\). Then

\[\int_{-\pi}^{\pi}\frac{\sin n\theta}{\sin\theta}d\theta =\int_{|z|=1}\frac{z^{n}-z^{-n}}{z-z^{-1}}\frac{dz}{iz}\] \[=\frac{1}{i}\int_{|z|=1}\frac{z^{2n}-1}{z^{2}-1}\frac{1}{z^{n}}dz\] \[=\frac{1}{i}\int_{|z|=1}\left(1+z^{2}+\cdots+z^{2n-2}\right)\frac {1}{z^{n}}dz\] \[=\sum_{k=0}^{n-1}\int_{|z|=1}z^{2k-n}dz\,.\]

If \(n\) is even, only even powers of \(z\) occur, and each term vanishes. For odd \(n\), we have

\[\int_{-\pi}^{\pi}\frac{\sin n\theta}{\sin\theta}d\theta=\frac{1}{i}\int_{|z|=1 }\frac{dz}{z}=2\pi.\]

**Solution to 5.11.26:** We have

\[C_{n}(a)+iS_{n}(a) =\int_{-\pi}^{\pi}\frac{e^{in\theta}}{a-\cos\theta}\,d\theta\] \[=-2\int_{-\pi}^{\pi}\frac{e^{i(n+1)\theta}}{e^{2i\theta}-2ae^{i \theta}+1}\,d\theta\] \[=2i\int_{|z|=1}\frac{z^{n}}{z^{2}-2az+1}\,dz.\]

Let \(f(z)\) denote this last integrand. Its denominator has two zeros, \(a\pm\sqrt{a^{2}-1}\), of which \(a-\sqrt{a^{2}-1}\) is inside the unit circle. The residue is given by

\[\text{Res }\left(f,a-\sqrt{a^{2}-1}\right)=\frac{\left(a-\sqrt{a^{2}-1}\, \right)^{n}}{\left(a-\sqrt{a^{2}-1}-a-\sqrt{a^{2}-1}\,\right)}=\frac{\left(a- \sqrt{a^{2}-1}\,\right)^{n}}{-2\sqrt{a^{2}-1}}.\]

Therefore, by the Residue Theorem [13, pag. 280],

\[C_{n}(a)+iS_{n}(a)=\frac{2\pi\left(a-\sqrt{a^{2}-1}\,\right)^{n}}{\sqrt{a^{2} -1}}.\]

Since the right-hand side is real, this must be the value of \(C_{n}(a)\), and \(S_{n}(a)=0\).

### 5.12 Integrals Along the Real Axis

**Solution to 5.12.1:** We have

\[\int_{-\infty}^{\infty}f_{m}(x)\overline{f_{n}(x)}\,dx=\frac{1}{\pi}\int_{- \infty}^{\infty}\frac{(x-i)^{m}}{(x+i)^{m+1}}\frac{(x+i)^{n}}{(x-i)^{n+1}}\,dx.\]

If \(m=n\), we get

\[\frac{1}{\pi}\int_{-\infty}^{\infty}\frac{dx}{1+x^{2}}=\frac{1}{\pi}\arctan x \bigg{|}_{-\infty}^{\infty}=1.\]

If \(m<n\), as \(x^{2}+1=(x-i)(x+i)\), we have

\[\frac{1}{\pi}\int_{-\infty}^{\infty}\frac{1}{x^{2}+1}\frac{(x+i)^{n-m}}{(x-i) ^{n-m}}\,dx.\]

Since the numerator has degree 2 less than the denominator, the integral converges absolutely. We evaluate it using residue theory. Let \(C_{R}=[-R,R]\cup\Gamma_{R}\) be the contour

We evaluate the integral over \(C_{R}\). For \(R>0\) sufficiently large, the integrand has a pole at \(x=i\) inside the contour. Calculating the residue, we get

\[\frac{d^{n-m+1}}{dx}\,\left((x-i)^{n-m+1}\frac{(x+i)^{n-m-1}}{(x-i)^{n-m+1}} \right)\bigg{|}_{x=i}=0.\]

By the Residue Theorem [13, pag. 280], the integral over \(C_{R}\) is 0 for all such \(R\). Letting \(R\) tend to infinity, we see that the integral over the semicircle \(\Gamma_{R}\) tends to 0 since the numerator has degree 2 less than the denominator. So

\[\frac{1}{\pi}\int_{-\infty}^{\infty}\frac{1}{x^{2}+1}\frac{(x+i)^{n-m}}{(x-i)^ {n-m}}\,dx=0.\]

**Solution to 5.12.2:** Consider the following contour around the pole of the function

\[f(z)=\frac{1-e^{i|a|z}}{z^{2}}\]

On the larger arc \(z=R(\cos\theta+i\sin\theta)\), so

\[\left|\frac{1-e^{i|a|z}}{z^{2}}\right|\leq\frac{1+e^{-R|a|\sin\theta}}{R^{2}}=O \left(R^{-2}\right)\quad(R\rightarrow\infty).\]

Then

\[\int_{0}^{\infty}\frac{1-\cos\alpha x}{x^{2}}\ dx =\frac{1}{2}\Re\left(\pi i\ \mathrm{Res}\left(\frac{1-e^{i|a|z}}{z^ {2}},0\right)\right)\] \[=\frac{1}{2}\Re\left(\pi i\ 2\frac{-i|a|e^{i|a|z}}{2}\bigg{|}_{z=0 }\right)\] \[=\frac{\pi|a|}{2}.\]

**Solution to 5.12.3:** Consider the function \(f\) defined by

\[f(z)=\frac{\left(e^{iz}-1\right)^{2}}{z^{2}}.\]

\(f\) has a removable singularity at the origin, so

\[\int_{C_{R}}f(z)dz=0\]where \(C_{R}=\Gamma_{R}\cup[-R,R]\).

Therefore,

\[\int_{-R}^{R}\frac{\left(e^{ix}-1\right)^{2}}{x^{2}}dx+\int_{\Gamma_{R}}\frac{e^{ 2iz}-1}{z^{2}}dz+2i\int_{\Gamma_{R}}\frac{dz}{z}=0\cdot\]

We have

\[\int_{\Gamma_{R}}\frac{e^{2iz}-1}{z^{2}}dz=o(1)\quad(R\to\infty)\]

by Jordan's Lemma [13, pag. 301], so

\[\int_{-\infty}^{\infty}\left(\frac{\sin x}{x}\right)^{2}\,dx =-\frac{1}{2}\lim_{R\to\infty}\Re\left(\int_{-R}^{R}\frac{\left( e^{ix}-1\right)^{2}}{x^{2}}dx\right)\] \[=-\frac{1}{2}2i\lim_{R\to\infty}\int_{\Gamma_{R}}\frac{dz}{z}\] \[=\pi.\]

_Solution 2._ Assuming Dirichlet's Integral

\[\int_{0}^{\infty}\frac{\sin x}{x}\ dx=\frac{\pi}{2}\]

whose evaluation can be found in [14, page 86], we can use integration by parts:

\[\int_{0}^{\infty}\frac{\sin^{2}x}{x^{2}}\ dx =-\frac{1}{x}\sin^{2}x\bigg{|}_{0}^{\infty}-\int_{0}^{\infty}- \frac{1}{x}\frac{\sin 2x}{x}\ dx\] \[=0+\int_{0}^{\infty}\frac{\sin y}{y}\ dy\] \[=\frac{\pi}{2}.\]

**Solution to 5.12.4:** The integrand is absolutely integrable, because it is bounded in absolute value by 1 near the origin and by \(1/|x|^{3}\) away from the origin. We have

\[\sin^{3}x =-\frac{1}{8i}\left(e^{ix}-e^{-ix}\right)^{3}=-\frac{1}{8i}\left(e^ {3ix}-e^{-3ix}-3e^{ix}+3e^{-ix}\right)\] \[=\Im\left(\frac{3}{4}e^{ix}-\frac{1}{4}e^{3ix}\right).\]

For \(0<\varepsilon<R\), consider the contour \(C_{\varepsilon,R}=\Gamma_{R}\cup\gamma_{\varepsilon}\cup[-R,-\varepsilon]\cup[ \varepsilon,R]\)

by Cauchy's Theorem [13, pag. 152],

\[0=\int_{C_{\varepsilon,R}}\frac{3e^{iz}-e^{3iz}}{z^{3}}\,dz=\int_{\Gamma_{R}}+ \int_{[-R,-\varepsilon]}+\int_{\gamma_{\varepsilon}}+\int_{[\varepsilon,R]}.\]

The integral over \(\Gamma_{R}\) is bounded in absolute value by \((4R^{-3})(2\pi R)\) since \(|e^{iz}|\) and \(|e^{31z}|\) are bounded by 1 in the upper half-plane, so it tends to 0 as \(R\to\infty\). To estimate the integral over \(\gamma_{\varepsilon}\), we note that

\[\frac{3e^{iz}-e^{3iz}}{z^{3}} =\frac{1}{z^{3}}\left(2+\frac{3(iz)^{2}}{2}-\frac{(3iz)^{2}}{2}+ O(z^{3})\right)\] \[=\frac{2}{z^{3}}+\frac{3}{z}+O(1)\qquad(z\to 0).\]

Hence,

\[\int_{\gamma_{\varepsilon}}\frac{3e^{iz}-e^{3iz}}{z^{3}}\,dz =\int_{\pi}^{0}\left(\frac{2}{\varepsilon^{3}e^{3i\theta}}-\frac{ 3}{\varepsilon e^{i\theta}}+O(1)\right)i\varepsilon e^{i\theta}\,d\theta\] \[=\frac{2i}{\varepsilon^{2}}\int_{\pi}^{0}e^{-2i\theta}d\theta+3i \int_{\pi}^{0}d\theta+O(\varepsilon)\] \[=0-3\pi i+O(\varepsilon)\to-3\pi\qquad\text{as}\quad\varepsilon \to 0.\]

Thus,

\[\lim_{R\to\infty\atop\varepsilon\to 0}\left(\int_{-R}^{-\varepsilon}\frac{3e^{ ix}-e^{3ix}}{x^{3}}\,dx+\int_{\varepsilon}^{R}\frac{3e^{ix}-e^{3ix}}{x^{3}} \,dx\right)=3\pi i.\]The integral \(I\) is one-fourth the imaginary part of the preceding limit, so \(I=\frac{3\pi}{4}\).

**Solution to 5.12.5:** Let

\[f(z)=\frac{e^{iz}z^{3}}{(z^{2}+1)^{2}}=\frac{e^{iz}z^{3}}{(z+i)^{2}(z-i)^{2}}.\]

Integrate \(f\) over a closed semicircular contour \(C_{R}=[-R,R]\cup\Gamma_{R}\) with radius \(R\) in the upper half plane.

The portion \([-R,R]\) along the axis gives

\[\int_{-R}^{R}\frac{x^{3}}{(x^{2}+1)^{2}}\ (\cos x+i\sin x)dx\]

whose imaginary part is

\[\int_{-R}^{R}\frac{x^{3}\sin x}{(x^{2}+1)^{2}}\ dx.\]

This integral converges as \(R\to\infty\) to

\[\int_{-\infty}^{\infty}\frac{x^{3}\sin x}{(x^{2}+1)^{2}}\ dx.\]

To establish the convergence, note that integration by parts gives

\[\int_{-R}^{R}\frac{x^{3}\sin x}{(x^{2}+1)^{2}}\ dx=\left.\frac{(-\cos x)x^{3}} {(x^{2}+1)^{2}}\right|_{-R}^{R}+\int_{-R}^{R}\cos x\ \frac{d}{dx}\left(\frac{x^{3}}{(x^ {2}+1)^{2}}\right)dx\]

and

\[\left|\frac{(-\cos x)x^{3}}{(x^{2}+1)^{2}}\right|\leq\frac{1}{|x|}\to 0\quad\mbox{ as }\quad x\to\infty\,\]

and the second term is integrable by the Comparison Test [13, pag. 60], as it is \(\cos x\) times a rational function; that is, \(O(1/x^{2})\). The real part also converges by similar reasoning, and since the integrand is odd, it converges to zero.

The integral of \(f\) over \(\Gamma_{R}\) is treated as follows. Let \(z=Re^{i\theta}\) for \(0\leq\theta\leq\pi\). Then

\[\int_{\Gamma_{R}}\frac{e^{iz}z^{3}}{(z^{2}+1)^{2}}\ dz=\int_{0}^{\pi}\frac{e^{iR (\cos\theta+i\sin\theta)}z^{3}}{(z^{2}+1)^{2}}\ iRe^{i\theta}\ d\theta\.\]

This is bounded above in absolute value for large \(R\) by

\[A\int_{0}^{\pi}e^{-R\sin\theta}d\theta\]

for a constant \(A\) and this integral tends to zero as \(R\to\infty\) (Jordan's Lemma [13, pag. 301]). Finally,

\[\int_{C_{R}}f(z)dz=2\pi i\ \mathrm{Res}(f,i)\]

and since we have a second order pole, we have

\[\mathrm{Res}(f,i)=\frac{d}{dz}\ \left(\frac{e^{iz}z^{3}}{(z+i)^{2}}\right) \bigg{|}_{z=i}=\frac{1}{4e}.\]

Thus,

\[\int_{C_{R}}f(z)dz=\frac{\pi i}{2e}\]

and so the required integral is \(\pi/2e\).

**Solution to 5.12.6:** Using an argument similar to the one in Problem 5.12.5 with the function

\[f(z)=\frac{e^{iz}z}{(z^{2}+1)^{2}}\,\]

we get

\[\int_{-\infty}^{\infty}\frac{x\sin x}{(x^{2}+1)^{2}}\ dx =\Re\left(2\pi i\ \mathrm{Res}(f,i)\right)=\Re 2\pi i\frac{d}{dz} \ \left(\frac{e^{iz}z}{(z+i)^{2}}\right)\bigg{|}_{z=i}\] \[=\Re\left(2\pi i\frac{1}{4e}\right)=\frac{\pi}{2e}.\]

**Solution to 5.12.7:** The function

\[g(z)=\left\{\begin{array}{ll}\frac{\sin x}{z(z^{2}+a^{2})}&\mathrm{if}\quad z \neq 0\\ \frac{1}{a^{2}}&\mathrm{if}\quad z=0\end{array}\right.\]

is entire and satisfies \(g(z)=o(|z|^{2})\) (\(|z|\to\infty\)) so the given integral, \(I\) say, is absolutely convergent.

We have

\[4I=\int_{-\infty}^{\infty}\frac{e^{ix}}{x(x^{2}+a^{2})}dx+\int_{-\infty}^{\infty} \frac{e^{-ix}}{x(x^{2}+a^{2})}dx.\]

Consider the integral

\[\int_{C_{R}}\frac{e^{iz}}{z(z^{2}+a^{2})}dz\]

where the contour \(C_{R}\) is the interval and the semicircle with the same endpoints oriented counterclockwise.

By Jordan's Lemma [19, pag. 301], we have

\[\left|\int_{\Gamma_{R}}\frac{e^{iz}}{z(z^{2}+a^{2})}dz\right|\leq\frac{\pi}{R} \int_{\Gamma_{R}}\frac{1}{(z^{2}+a^{2})}dz=o(1)\quad(|z|\to\infty)\]

so the contribution from the semicircle to the integral above is zero. By the Residue Theorem [19, pag. 280], we have

\[\int_{C_{R}}\frac{e^{iz}}{z(z^{2}+a^{2})}dz=2\pi i\text{ Res }\left(\frac{e^{iz}}{z(z^{2}+a^{2})}\,,\,ia\right)=\frac{e^{-a}}{ia(2ia)}.\]

So

\[\int_{-\infty}^{\infty}\frac{e^{ix}}{x(x^{2}+a^{2})}dx=\frac{e^{-a}}{ia(2ia)}.\]

[MISSING_PAGE_FAIL:319]

As \(z^{2}+9\) has simple zeros at \(\pm 3i\), by the Residue Theorem [13, pag. 280],

\[\int_{C_{R}}\frac{ze^{iz}}{z^{2}+9}\,dz=2\pi i\,\operatorname{Res}\,(f,3i)=e^{-3 }\pi i.\]

By Jordan's Lemma [13, pag. 301], we have

\[\left|\int_{\Gamma_{R}}\frac{ze^{iz}}{z^{2}+9}\,dz\right|\leq\int_{\Gamma_{R}} \frac{|z||e^{iz}|}{|z|^{2}-9}\,|dz|\leq\frac{\pi R}{R^{2}-9}=o(1)\quad(R\to\infty)\]

so, in the limit the integral along the upper half-circle contributes nothing.

We can evaluate the second integral in the same way, getting

\[\int_{C_{R}}\frac{e^{iz}}{z^{2}+9}\,dz=\frac{e^{-3}\pi}{3}.\]

Again, in the limit, the upper half-circle contributes zero, so

\[\lim_{R\to\infty}\int_{-R}^{R}\frac{\sin x}{x-3i}\,dx=e^{-3}\pi.\]

**Solution to 5.12.9:** Consider the function \(f\) defined by

\[f(z)=\frac{e^{iz}}{z(z-\pi)}.\]

By Cauchy's Theorem [13, pag. 152],

\[\int_{C(\varepsilon,R)}f(z)dz=0\]

where \(C(\varepsilon,R)\) is the contour \(\Gamma_{R}\cup\gamma_{0}\cup[\varepsilon,\pi-\varepsilon]\cup\gamma_{\pi}\cup[ \pi+\varepsilon,R]\).

The poles of \(f\) at \(0\) and \(\pi\) are simple; therefore,

\[\lim_{\varepsilon\to 0}\int_{\gamma_{0}}f(z)dz=-\pi i\,\operatorname{Res}\,(f(z),0 )=i\]\[\lim_{\varepsilon\to 0}\int_{\gamma_{\pi}}f(z)dz=-\pi i\ \text{Res}\left(f(z),\pi \right)=i.\]

We also have, for \(|z|=R\),

\[\frac{e^{iz}}{z(z-\pi)}=O\left(R^{-2}\right)\ \ \ (R\to\infty)\]

so

\[\lim_{R\to\infty}\int_{\Gamma_{R}}f(z)dz=0.\]

Taking imaginary parts, we obtain

\[\int_{-\infty}^{\infty}\frac{\sin x}{x(x-\pi)}dx=-2.\]

**Solution to 5.12.11:** An argument similar to the one used in Problem 5.12.9 with the contour around the simple poles \(-1/2\) and \(1/2\), gives

\[\int_{-\infty}^{\infty}\frac{\cos(\pi x)}{4x^{2}-1}\ dx =\Re\left(\pi i\left(\text{Res}\left(\frac{e^{\pi iz}}{4z^{2}-1}, -\frac{1}{2}\right)+\text{Res}\left(\frac{e^{\pi iz}}{4z^{2}-1},\frac{1}{2} \right)\right)\right)\] \[=\Re\pi i\left(\frac{i}{4}+\frac{i}{4}\right)=-\frac{\pi}{2}.\]

**Solution to 5.12.12:** Consider the following contour \(C\) and the function

\[f(z)=\frac{e^{inz}}{z^{4}+1}\]

We have

\[\left|\int_{\Gamma_{R}}\frac{e^{inz}}{z^{4}+1}\ dz\right|\leq\int_{\Gamma_{R}} \frac{|e^{inz}|}{R^{4}+1}|dz|\leq\frac{\pi R}{R^{4}+1}\]which approaches \(0\) when \(R\to\infty\) (note that for \(z\in\Gamma_{R}\), \(|e^{inz}|=e^{-\Im nz}\leq 1\)). Taking the real part and using the fact that for these roots \(1/z_{0}^{3}=-z_{0}\), we have

\[\int_{-\infty}^{\infty}\frac{\cos x}{x^{4}+1}\ dz =\lim_{R\to\infty}\Re\left(\int_{C}\frac{e^{inz}}{z^{4}+1}\ dz\right)\] \[=\Re\left(2\pi i\left(\ \text{Res}\left(\frac{e^{inz}}{z^{4}+1},e^ {\pi i/4}\right)+\text{Res}\left(\frac{e^{inz}}{z^{4}+1},e^{3\pi i/4}\right) \right)\right)\] \[=-2\pi\Im\left(\frac{e^{inz}}{4z^{3}}\Big{|}_{z=e^{\pi i/4}}+\left. \frac{e^{inz}}{4z^{3}}\right|_{z=e^{3\pi i/4}}\right)\] \[=\frac{\pi e^{-\frac{n}{\sqrt{2}}}}{\sqrt{2}}\left(\cos\frac{n}{ \sqrt{2}}+\sin\frac{n}{\sqrt{2}}\right).\]

**Solution to 5.12.13:** Consider the same contour \(C\) as in Problem 5.12.12; which encircles two of the poles \((e^{\frac{\pi i}{4}}\) and \(e^{\frac{\pi i}{4}})\), and the function

\[f(z)=\frac{z^{2}+1}{z^{4}+1}.\]

We have

\[\int_{0}^{\infty}\frac{x^{2}+1}{x^{4}+1}\ dz =\frac{1}{2}\left(2\pi i\left(\ \text{Res}\left(\frac{z^{2}+1}{z^{4}+1},e^{\pi i/4}\right)+\text{Res}\left( \frac{z^{2}+1}{z^{4}+1},e^{3\pi i/4}\right)\right)\right)\] \[=\pi i\left.\left(\frac{z^{2}+1}{4z^{3}}\right|_{z=e^{\pi i/4}}+ \left.\frac{z^{2}+1}{4z^{3}}\right|_{z=e^{3\pi i/4}}\right)\] \[=-\frac{\pi i}{4}\ \big{(}(z^{2}+1)z\big{|}_{z=e^{\pi i/4}}+(z^{2}+1)z\big{|}_{z=e^{3\pi i/4}}\big{)}\] \[=\frac{\pi}{\sqrt{2}}.\]

**Solution to 5.12.14:** This integral converges, by Dirichlet's Test [11, pag. 287], since

\[\lim_{x\to\pm\infty}\frac{x}{z^{2}+4x+20}=0\]

monotonically and

\[\int_{\alpha}^{\beta}\sin x\,dx=O(1)\qquad(\alpha\to-\infty\,,\,\beta\to\infty).\]

Consider the integral

\[I=\int_{C_{R}}f(z)e^{iz}\,dz\ \ \ \text{where}\ \ \ f(z)=\frac{z}{z^{2}+4z+20}.\]The curve \(C_{R}\) is the contour

where \(\Gamma_{R}\) is the semicircle of radius \(R>0\). The integral \(I\) is equal to the sum of the residues of \(g(z)=f(z)e^{iz}\) inside of \(C_{R}\). \(f\) has poles at \(-2\pm 4i\), of which only\(-2+4i\) lies inside \(C_{R}\). Hence,

\[I=2\pi i\operatorname{Res}\left(g,-2+4i\right)=2\pi i\lim_{z\to-2+4i}\frac{ze^{ iz}}{z-(-2-4i)}=\frac{\pi}{4}(-2+4i)e^{-4-2i}.\]

We have, by Jordan's Lemma [13, pag. 301],

\[\left|\int_{\Gamma_{R}}g(z)\,dz\right|\leq\frac{R}{R^{2}-4R-20}\int_{\Gamma_{R }}|e^{iz}|\,|dz|\leq\frac{R\pi}{R^{2}-4R-20}=o(1)\quad(R\to\infty).\]

So,

\[\int_{-\infty}^{\infty}f(x)\sin x\,dx =\Im\left(\int_{-\infty}^{\infty}f(x)e^{ix}\,dx\right)\] \[=\Im\left(\lim_{R\to\infty}\int_{C_{R}}f(z)e^{iz}\,dz\right)\] \[=\Im\left(\frac{\pi}{4}(-2+4i)e^{-4-2i}\right)\] \[=\frac{\pi}{2e^{4}}(2\cos 2+\sin 2).\]

**Solution to 5.12.15:** Consider the following contour avoiding the pole of the function

\[f(z)=\frac{z+i\varepsilon^{iz}}{z^{3}}\]we have

\[\left|\int_{\Gamma_{R}}\frac{z+ie^{iz}}{z^{3}}\ dz\right|\leq\int_{\Gamma_{R}}\frac {|z|+|e^{iz}|}{R^{3}}|dz|\leq\frac{\pi(R+1)}{R^{2}}\]

which approaches \(0\) when \(R\to\infty\) (note that for \(z\in\Gamma_{R}\), \(|e^{iz}|=e^{-\Im z}\leq 1\)); and around \(0\),

\[\frac{z+ie^{iz}}{z^{3}}=\frac{1}{z^{3}}\left(z+i\left(1+iz+\frac{(iz)^{2}}{2}+ \cdots\right)\right)=\frac{i}{z^{3}}-\frac{i}{2z}+g(z),\]

where \(g\) is analytic. Then

\[\int_{\gamma_{\epsilon}}\frac{z+ie^{iz}}{z^{3}}\ dz=i\int_{\gamma_{\epsilon}} \frac{dz}{z^{3}}-\frac{i}{2}\int_{\gamma_{\epsilon}}\frac{dz}{z}+\int_{\gamma _{\epsilon}}g(z)dz=-\frac{\pi}{2}+\int_{\gamma_{\epsilon}}g(z)dz.\]

Now since

\[\left|\int_{\gamma_{\epsilon}}g(z)dz\right|\leq\max_{|z|\leq\epsilon}|g(z)|\pi \varepsilon\to 0\ \ \mbox{as}\ \ \varepsilon\to 0\]

the integral along the real axis will approach \(\frac{\pi}{2}\). Taking the real part, one gets

\[\int_{0}^{\infty}\frac{x-\sin x}{x^{3}}dx=\frac{1}{2}\frac{\pi}{2}=\frac{\pi}{ 4}.\]

**Solution to 5.12.16:** Denote the given integral by \(I\). Consider the function \(f(z)=(1+z+z^{2})^{-2}\). \(f\) has two poles of degree \(2\) at \(z=(-1\pm i\sqrt{3})/2\). We evaluate the contour integral

\[I^{\prime}=\int_{C_{R}}f(z)\,dz.\]

[MISSING_PAGE_EMPTY:325]

where the small circle, \(\gamma_{\varepsilon}\), has radius \(\varepsilon\), and the large circle, \(\Gamma_{R}\), radius \(R\). Since \(z^{2\alpha-1}\) is defined to be \(e^{(2\alpha-1)\log z}\), we choose as our branch of the logarithm that with arguments between \(-\pi/2\) and \(3\pi/2\) (that is, the one with the cut along the negative imaginary axis).

The integrand has a simple pole inside \(C_{\varepsilon\,R}\) at \(i\), so, by the Residue Theorem [13, pag. 280], the integral is equal to

\[2\pi i\;\text{Res}\,(f,i)=\frac{2\pi ie^{(2\alpha-1)\log i}}{2i}=-\pi ie^{ \alpha\pi i}.\]

As \(\varepsilon\) and \(R\) tend to \(0\) and infinity, respectively, the integral on \([\varepsilon,R]\) tends to the desired integral. On the segment \([-R,-\varepsilon]\), we make the change of variables \(y=-z\), getting

\[\int_{-R}^{-r}\frac{e^{(2\alpha-1)\log z}}{1+z^{2}}\,dz=-e^{2\alpha\pi i}\int_ {\varepsilon}^{R}\frac{e^{(2\alpha-1)\log y}}{1+y^{2}}\,dy,\]

so this integral tends to a constant multiple of the desired integral. On \(\Gamma_{R}\), a calculation shows that \(\left|z^{2\alpha-1}\right|=\left|z\right|^{2\Re\alpha-1}e^{-2\Im\alpha\arg z}\), so if we assume that \(\Im\alpha\geq 0\), we have \(\left|z^{2\alpha-1}\right|\leq\left|z\right|^{2\Re\alpha-1}\) and

\[\left|\int_{\gamma_{2}}\frac{z^{2\alpha-1}}{1+z^{2}}\,dz\right|\leq\frac{\pi R ^{2\Re\alpha}}{R^{2}-1}.\]

This tends to \(0\) whenever \(\Re\alpha<1\).

On \(\gamma_{\varepsilon}\), essentially the same estimate holds:

\[\left|\int_{\gamma_{1}}\frac{z^{2\alpha-1}}{1+z^{2}}\,dz\right|\leq\frac{\pi \varepsilon^{2\Re\alpha}}{1-\varepsilon^{2}}\]

and this tends to \(0\) whenever \(\Re\alpha>0\).

So we have

\[\left(1-e^{2\alpha\pi i}\right)\int_{0}^{\infty}\frac{t^{2\alpha-1}}{1+t^{2}} \,dt=-\pi ie^{\alpha\pi i}.\]

Dividing through, we get

\[\frac{-\pi ie^{\alpha\pi i}}{1-e^{2\alpha\pi i}}=\frac{\pi}{2\sin(\pi\alpha)}.\]

Therefore, twice this is our answer, subject to the restrictions \(0<\Re\alpha<1\) and \(\Im\alpha\geq 0\). However, if \(\Im\alpha\leq 0\), we may replace \(\alpha\) by \(\bar{\alpha}\) and obtain the above equality with \(\bar{\alpha}\). Then, by taking the complex conjugate of both sides, we see that we can eliminate the second restriction.

Solution 2.: Considering the slightly more complex contour of integration below, we can do away with the change of variables. So consider the integral

\[\int_{C}\frac{z^{\alpha-1}}{z+1}dz\]where \(C\) is

The origin is a branch point and the two straight lines are close to the \(x\)-axis. The integrand has one simple pole at \(z=-1\) inside \(C\). Thus,

\[\int_{C}\frac{z^{\alpha-1}}{z+1}dz=2\pi i\ \text{Res}\left(\frac{z^{\alpha-1}}{z+1}, -1\right)=2\pi i\lim_{z\to-1}\frac{z^{\alpha-1}}{z+1}(z+1)=2\pi ie^{(\alpha-1 )\pi i}.\]

On the other hand, the intcgral can be split in four integrals along the segments of the contour:

\[2\pi i\ e^{(\alpha-1)\pi i} =\int_{\Gamma_{R}}\frac{z^{\alpha-1}}{z+1}dz+\int_{\gamma_{e}} \frac{z^{\alpha-1}}{z+1}dz+\int_{\ell_{1}}\frac{z^{\alpha-1}}{z+1}dz+\int_{ \ell_{2}}\frac{z^{\alpha-1}}{z+1}dz\] \[=\int_{0}^{2\pi}\frac{(Re^{i\theta})^{\alpha-1}}{Re^{i\theta}+1}iR \ e^{i\theta}d\theta+\int_{2\pi}^{0}\frac{(\varepsilon e^{i\theta})^{\alpha-1 }}{\varepsilon e^{i\theta}+1}i\varepsilon e^{i\theta}\ d\theta\] \[\quad+\int_{e}^{R}\frac{x^{\alpha-1}}{x+1}dx+\int_{R}^{\varepsilon }\frac{(xe^{2\pi i})^{\alpha-1}}{xe^{2\pi i}+1}dx.\]

Taking the limits as \(\varepsilon\to 0\) and \(R\to\infty\), we get

\[\int_{0}^{\infty}\frac{x^{\alpha-1}}{x+1}dx+\int_{\infty}^{0}\frac{e^{2\pi i( \alpha-1)}x^{\alpha-1}}{x+1}dx=2\pi i\ e^{(\alpha-1)\pi i}\]

or

\[\left(1-e^{2\pi i(\alpha-1)}\right)\int_{0}^{\infty}\frac{x^{\alpha-1}}{x+1}dx =2\pi i\ e^{(\alpha-1)\pi i}.\]

Hence,

\[\int_{0}^{\infty}\frac{x^{\alpha-1}}{x+1}dx=\frac{2\pi i\ e^{(\alpha-1)\pi i}} {1-e^{(\alpha-1)2\pi i}}=\frac{\pi}{\sin\alpha\pi}.\]

**Solution to 5.12.18:** Making the substitution \(x=\sqrt{y}\) the integral becomes

\[\frac{1}{2}\int_{0}^{\infty}\frac{y^{-1/4}}{1+y}dy\]

which is equal to \(\frac{\pi}{\sqrt{2}}\) by Problem 5.12.17 with \(\alpha=\frac{3}{4}\).

**Solution to 5.12.19:** Observing that the function is even, doubling the integral from \(0\) to \(\infty\) and making the substitution \(y=x^{2n}\), we get

\[\int_{-\infty}^{\infty}\frac{dx}{1+x^{2n}}=2\int_{0}^{\infty}\frac{dx}{1+x^{2n }}=\frac{1}{n}\int_{0}^{\infty}\frac{y^{\frac{1}{2n}-1}}{y+1}\,dy=\frac{\pi}{n \sin(\pi/2n)}\]

by Problem 5.12.17.

**Solution to 5.12.20:** We have

\[I =\int_{0}^{\infty}\frac{x}{e^{x}+e^{-x}}dx\] \[=\frac{1}{2}\int_{-\infty}^{\infty}\frac{x}{e^{x}-e^{-x}}dx\] \[=\frac{1}{2}\int_{0}^{\infty}\frac{\log u}{(u-1/u)u}du\] \[=\frac{1}{4}\int_{-\infty}^{\infty}\frac{\log|u|}{u^{2}-1}du\]

where we used \(u=e^{x}\). Integrate

\[f(z)=\frac{\log z}{x^{2}-1}\]

over the contour \(\Gamma=\Gamma_{R}\cup\gamma_{-1}\cup\gamma_{0}\cup\gamma_{1}\).

By Cauchy's Theorem [12, pag. 152], we have

\[\int_{\Gamma}f(z)dz=0\]also,

\[\int_{\gamma_{-1}}f(z)dz=-i\pi\ \mbox{Res}(f,-1)=\frac{\pi^{2}}{2}\]

\[\int_{\gamma_{n}}f(z)dz=-i\pi\frac{\log 1}{2}=0\]

\[\int_{\Gamma_{R}}f(z)dz\to 0\quad\mbox{as}\quad R\to\infty\quad\mbox{since} \quad\lim_{R\to\infty}\frac{R\log R}{R^{2}-1}=0\]

\[\int_{\gamma_{0}}f(z)dz\to 0\quad\mbox{since}\quad\lim_{\varepsilon\to 0}\frac{ \varepsilon\log\varepsilon}{\varepsilon^{2}-1}=0.\]

So we get

\[\int_{-\infty}^{\infty}\frac{\log|u|}{u^{2}-1}du=\frac{\pi^{2}}{2}\]

and

\[I=\frac{\pi^{2}}{8}.\]

**Solution to 5.12.21:** The roots of the denominator are \(1\pm i\sqrt{3}\), and for large \(|x|\), the absolute value of the integrand is of the same order of magnitude as \(x^{-2}\). It follows that the integral converges. For \(R>2\), let

\[I_{R}=\int_{C_{R}}\frac{e^{-iz}}{z^{2}-2z+4}\ dz\,\]

where the contour \(C_{R}\) consists of the segment \([-R,R]\) together with the semicircle \(\Gamma_{R}\) in the lower half-plane with the same endpoints as that segment, directed clockwise.

The integrand has only one singularity inside \(C_{R}\), a simple pole at \(1-i\sqrt{3}\). By the Residue Theorem [13, pag. 280],

\[I_{R}=-2\pi i\ \mbox{Res}\ \bigg{(}\frac{e^{-iz}}{z^{2}-2z+4}\,\ z=1-i\sqrt{3} \bigg{)}\.\]The residue, since we are dealing with a simple pole, equals

\[\lim_{z\to 1-i\sqrt{3}}\left(z-1+i\sqrt{3}\right)\left(\frac{e^{-iz}}{z^{2}-2z+4}\right)=\left.\frac{e^{-iz}}{z-1-i\sqrt{3}}\right|_{z=1-i\sqrt{3}}=\frac{e^{-\sqrt{3}-i}}{-2i\sqrt{3}}.\]

Hence, \(I_{R}=\frac{\pi e^{-\sqrt{3}-i}}{\sqrt{3}}\). Since \(|e^{-iz}|\) is bounded by \(1\) in the lower half-plane, we have, for large \(R\),

\[\left|\int_{\Gamma_{R}}\frac{e^{-iz}}{z^{2}-2z+4}\ dz\right|\leq\frac{2\pi R}{R^{2}-2R-4}\longrightarrow 0\qquad(R\to\infty)\.\]

Hence,

\[\frac{\pi e^{-\sqrt{3}-i}}{\sqrt{3}}=\int_{-R}^{R}\frac{e^{-ix}}{x^{2}-2x+4}\ dx+\int_{\Gamma_{R}}\frac{e^{-iz}}{z^{2}-2z+4}\ dz\longrightarrow I\qquad(R\to\infty)\,\]

giving \(I=\frac{\pi e^{-\sqrt{3}-i}}{\sqrt{3}}\).

**Solution to 5.12.22:** The integral converges absolutely since, for each \(0<e<1\), we have \(\log x=o(x^{e})\ (x\to\ 0+)\).

Consider the function

\[f(z)=\frac{\log z}{(z^{2}+1)(z^{2}+4)}\]

and, for \(0<\varepsilon<R\), consider the contour \(C_{\varepsilon,R}=\Gamma_{R}\cup\gamma_{e}\cup[-R,-\varepsilon]\cup[\varepsilon,R]\).

On the small circle, we have

\[\lim_{\varepsilon\to 0}\left|\int_{\gamma_{e}}f(z)dz\right|\leq\frac{|\log \varepsilon|+\pi}{\frac{1}{2}}\pi\varepsilon=o(1)\quad(\varepsilon\to 0)\]

and on the larger one,

\[\lim_{R\to\infty}\left|\int_{\Gamma_{R}}f(z)dz\right|\leq\frac{|\log R|+\pi}{( R^{2}-1)(R^{2}-4)}\pi R=o(1)\quad(R\to\infty).\]Combining with the Residue Theorem [11, pag. 280] we get

\[\int_{-\infty}^{0}f(z)dz+\int_{0}^{\infty}f(z)dz=2\pi i\left(\operatorname{Res}(f,i)+\operatorname{Res}(f,2i)\right).\]

We have

\[\operatorname{Res}(f,i)=\lim_{z\to i}f(z)(z-i)=\frac{\pi}{12}\]

and

\[\operatorname{Res}(f,2i)=\lim_{z\to 2i}f(z)(z-2i)=\frac{\log 2+\frac{\pi i}{2}}{-1 2i}=\frac{i\log 2}{12}-\frac{\pi}{24}.\]

We also have

\[\int_{-\infty}^{0}f(z)dz =\int_{-\infty}^{0}\frac{\log(-x)+\pi i}{(x^{2}+1)(x^{2}+4)}dx\] \[=\int_{0}^{\infty}\frac{\log x}{(x^{2}+1)(x^{2}+4)}dx+\int_{0}^{ \infty}\frac{\pi i}{(x^{2}+1)(x^{2}+4)}dx\]

and

\[\int_{0}^{\infty}f(z)dz=\int_{0}^{\infty}\frac{\log x}{(x^{2}+1)(x^{2}+4)}dx\]

so

\[2\int_{0}^{\infty}\frac{\log x}{(x^{2}+1)(x^{2}+4)}dx+\frac{\pi^{2}i}{12}=2\pi i \left(\frac{\pi}{12}+\frac{i\log 2}{12}-\frac{\pi}{24}\right)\]

and

\[\int_{0}^{\infty}\frac{\log x}{(x^{2}+1)(x^{2}+4)}dx=-\frac{\pi\log 2}{12}.\]

Solution to 5.12.23:For \(0<\varepsilon<1<R\), let \(C_{\varepsilon,R}\) denote the contour pictured below. Let \(\log z\) denote the branch of the logarithm function in the plane slit along the negative imaginary axis.

[MISSING_PAGE_EMPTY:332]

For \(\lambda\neq 0\),

\[(\text{sech}\,x)^{2}\cos\lambda x=\Re\left(\frac{4e^{i\lambda x}}{\left(e^{x}+e^{- x}\right)^{2}}\right)\]

so we consider the function \(f\) given by

\[f(z)=\frac{e^{i\lambda z}}{\left(e^{z}+e^{-z}\right)^{2}}.\]

This function has a simple pole inside the contour

\[C=[-R,R]\cup[R,R+\pi i]\cup[R+\pi i,-R+\pi i]\cup[-R+\pi i,-R].\]

We have

\[\int_{[R+\pi i,-R+\pi i]}f(z)dz =-\int_{-R}^{R}\frac{e^{i\lambda(x+\pi i)}dz}{\left(-e^{x}-e^{-x} \right)^{2}}\] \[=-e^{-\lambda\pi}\int_{-R}^{R}\frac{e^{i\lambda x}dx}{\left(e^{x} +e^{-x}\right)^{2}}\]

and

\[\left|\int_{[R,R+\pi i]}f(z)dz\right| =\left|\int_{0}^{1}\frac{e^{i\lambda(R+\pi ix)}\pi idx}{\left(e^{ R+\pi ix}+e^{-R-\pi ix}\right)^{2}}\right|\] \[\leq\frac{\pi e^{|\lambda|\pi}}{\left(e^{R}-e^{-R}\right)^{2}}=o (1)\quad(R\to\infty)\]

similarly, we get

\[\int_{[-R+\pi i,-R]}f(z)dz=o(1)\quad(R\to\infty).\]

Therefore,

\[\left(1-e^{-\lambda\pi}\right)\int_{-\infty}^{\infty}\frac{e^{i\lambda x}dx}{ \left(e^{x}+e^{-x}\right)^{2}}=2\pi i\text{ Res}\left(f(z),\frac{\pi i}{2} \right)=\frac{\lambda\pi e^{-\lambda\pi/2}}{2}.\]Thus,

\[\int_{0}^{\infty}(\operatorname{sech}x)^{2}\cos\lambda x\,dx=\frac{\lambda\pi/2}{ \sinh(\lambda\pi/2)}.\]

**Solution to 5.12.25:** If \(b=0\), the integral is well known:

\[\int_{0}^{\infty}e^{-x^{2}}\,dx=\frac{\sqrt{\pi}}{2}\]

and we will use this result to compute the full integral (for other values of \(b\)) below. It can also be computed using the Residue Theorem applied to the function \(f(z)=e^{-x^{2}}\) and the following contour. For the details, see [13, pag. 321-322].

Now if \(b\neq 0\), consider the function \(f(z)=e^{-z^{2}}e^{i2bz}\) and the contour

Since \(f\) is entire, the integral around the contour is zero, for any \(R\) and \(\tau\). If \(b\) is less than zero, then draw the contour below the \(x\)-axis. Evaluating the integral over each one of the two sides parallel to the \(x\)-axis, we have

\[\int_{I}f(z)\,dz=\int_{-R}^{R}e^{-x^{2}}e^{i2bx}\,dx\]\[\int_{III}f(z)\,dz = \int_{R}^{-R}e^{-(x+\tau i)^{2}}e^{i2bx}\ dx\] \[= -e^{\tau^{2}-2b\tau}\int_{-R}^{R}e^{-x^{2}}e^{2i(b-\tau)x}\ dx.\]

Along the vertical segments (II and IV),

\[|f(z)| = \left|e^{-(\pm R+iy)^{2}}e^{i2b(\pm R+iy)}\right|\] \[= e^{-R^{2}+y^{2}}e^{-2by}\] \[\leq e^{-R^{2}}e^{\tau^{2}+2b\tau}.\]

Then \(\left|\int_{II}f\right|\) and \(\left|\int_{III}f\right|\) are bounded by \(\tau e^{-R^{2}}e^{\tau^{2}+2b\tau}\), and with \(\tau\) and \(b\) fixed, this goes to \(0\) as \(R\to\infty\). Letting \(R\to\infty\), the integral along the circuit becomes

\[\int_{-\infty}^{\infty}e^{-x^{2}}e^{2bix}\ dx-e^{\tau^{2}-2b\tau}\int_{- \infty}^{\infty}e^{-x^{2}}e^{2i(b-\tau)x}\ dx=0\]

Since this holds for all \(\tau\) and \(b\), let \(b=\tau\) and the integral becomes

\[\int_{-\infty}^{\infty}e^{-x^{2}}e^{2bix}\ dx = e^{-b^{2}}\int_{-\infty}^{\infty}e^{-x^{2}}\ dx\] \[= e^{-b^{2}}\sqrt{\pi}.\]

and the result follows.

Algebra

### 6.1 Examples of Groups and General Theory

**Solution to 6.1.6:** If \(a,b\in G\), then \(a>0\) and \(b\neq 1\), so \(a^{\log b}\in G\). Therefore, the operation \(*\) is well defined.

_Identity._ The constant \(e\) is the identity since \(a*e=a^{\log e}=a^{1}=a\) and \(e*a=e^{\log a}=a\).

_Associativity._ We have

\[(a*b)*c=c^{\log(e^{\log a\log b})}=e^{\log a\log b\log c}=a^{\log(e^{\log b \log c})}=a*(b*c).\]

_Invertibility._ Since \(a\neq 1\), \(e^{1/\log a}\) exists and is an element of \(G\). A calculation shows that \(a*e^{1/\log a}=e^{1/\log a}*a=e\).

_Solution 2._ The map \(\log:G\rightarrow\mathbb{R}\setminus\{0\}\) is a bijection that transforms the operation \(*\) into multiplication; that is, \(\log(a*b)=(\log a)(\log b)\). Since \(\mathbb{R}\setminus\{0\}\) forms a group with respect to multiplication, \(G\) is a group with respect to \(*\).

**Solution to 6.1.8:** Fix an element \(a\in G\) different from the identity, and consider the map \(\varphi:G\setminus\{e\}\to G\setminus\{e\}\) defined by \(\varphi(c)=c^{-1}ac\). The map is onto, so, since \(G\) is finite, it is one-to-one. As \(\varphi(a)=a\) and \(a^{-2}aa^{2}=a\), it must be that \(a^{2}=e\). Thus, all elements of \(G\), other than the identity, have order \(2\). Then, if \(a\) and \(b\) are in \(G\), we have

\[ab=a(ab)^{2}b=a^{2}(ba)b^{2}=ba\]in other words, \(G\) is commutative, and it follows that \(G\) has order 2.

_Solution 2._ Since \(G\) is finite, it has an element of prime order \(p\). Hence, every element of \(G\), other than the identity, has order \(p\). Since \(G\) is a \(p\)-group, it has a nontrivial central element. Therefore, all elements are central; in other words, \(G\) is abelian. Hence, \(G\) has order 2.

_Solution 3._ By our hypothesis, any two nonidentity elements are conjugate. Hence, there are two conjugacy classes: The class containing the identity and the class containing all the other elements of \(G\). Letting \(n\) be the order of \(G\), we see that the second conjugacy class must contain \(n-1\) elements. But, by the class equation, we know that the order of any conjugacy class divides the order of the group, so \((n-1)|n\). Solving for \(n>0\), we see that the only possible solution is \(n=2\).

**Solution to 6.1.10:** Consider the group \(G^{\prime}=\{a^{n}b^{m}\,|\,0\leq n\leq r-1,\,0\leq m\leq s-1\}\). As the order of any element of \(G^{\prime}\) divides the order of \(G^{\prime}\), we have \(|G^{\prime}|=rs\). This shows that \((ab)^{k}\) is never the identity for \(0<k<rs\). Clearly we have \((ab)^{rs}=a^{r}b^{s}=e\), so the order of \(ab\) is \(rs\).

**Solution to 6.1.12:** Let \(g,h\in H\) and let \(x\in D\setminus H\). Then

\[h^{-1}g^{-1}=xhx^{-1}xgx^{-1}=xhgx^{-1}=(hg)^{-1}=g^{-1}h^{-1}\]

and we can conclude immediately from this that \(H\) is abelian.

Let \(x\in D\setminus H\). We have [D:H]=2, so \(x^{2}\in H\). By hypothesis, \(xx^{2}x^{-1}=x^{-2}\) or \(x^{4}=1\). Therefore, \(x\) has order 1, 2, or 4. But \(n\) is odd, so 4 does not divide the order of \(D\), so, by Lagrange's Theorem [13, pag. 41], \(x\) cannot have order 4. By our choice of \(x\), \(x\neq 1\), so \(x\) cannot have order 1. Hence, \(x\) has order 2.

### 6.2 Homomorphisms and Subgroups

**Solution to 6.2.2:** Let \(n=[\mathbb{C}^{*}:H]\). By Lagrange's Theorem [13, pag. 41], the order of any element of \(\mathbb{C}^{*}/H\) divides \(n\). So \(x^{n}\in H\) for all \(x\in\mathbb{C}^{*}\). Therefore, \(\left(\mathbb{C}^{*}\right)^{n}=\mathbb{C}\subset H\).

**Solution to 6.2.3:** 1. The number of conjugates of \(H\) in \(G\) is \(|G:N(H;G)|\) where \(N(H;G)=\{g\in G\,|\,g^{-1}Hg=H\}\) is the normalizer of \(H\). As \(H\subset N(H;G)\), we have \(|G:H|\geq|G:N(H;G)|\).

2. By Problem 6.4.16, there is a normal subgroup of \(G\), \(N\), contained in \(H\), such that \(G/N\) is finite. By Part 1 we can find a coset \(Ng\in G/N\) such that \(Ng\) is not contained in any conjugate \(y^{-1}Hy/N\) of \(H/N\) in \(G/N\). Then \(g\not\in y^{-1}Hy\) for any \(y\in G\).

**Solution to 6.2.4:** We will prove a more general result. Let \(G=\langle g\rangle\), \(|G|=n\), and \(\alpha\in\operatorname{Aut}G\). As \(\alpha(g)\) also generates \(G\), we have \(\alpha(g)=g^{k}\) for some \(1\leq k<n\), \((k,n)=1\). Conversely, \(x\mapsto x^{k}\) is an automorphism of \(G\) for \((k,1)=1\). Let \(\mathbb{Z}_{n}\) be the multiplicative group of residue classes modulo \(n\) relatively prime to \(n\). If \(\overline{k}\) denotes the residue class containing \(k\), we can define \(\Phi:\operatorname{Aut}G\to\mathbb{Z}_{n}\) by

\[\Phi(\alpha)=\overline{k}\qquad\text{iff}\qquad\alpha(g)=g^{k}.\]

It is clear that \(\Phi\) is an isomorphism. As \(\mathbb{Z}_{n}\) is an abelian group of order \(\varphi(n)\) (\(\varphi\) is Euler's totient function [13, pag. 77], [10, pag. 43]), so is \(\operatorname{Aut}G\). When \(n\) is prime, these groups are also cyclic.

**Solution to 6.2.5:** 1. If \(g^{-1}\varphi(g)=h^{-1}\varphi(h)\) for some \(g,h\in G\), then \(\varphi(g)\varphi(h)^{-1}=gh^{-1}\), so, by hypothesis, \(gh^{-1}=1\) and \(g=h\). Thus, there are \(|G|\) elements of that form, so they must constitute all of \(G\).

2. Using Part 1, we have, for \(z=g^{-1}\varphi(g)\in G\),

\[\varphi(z)=\varphi(g^{-1})\varphi^{2}(g)=\varphi(g^{-1})g=z^{-1}\]

so \(g\mapsto g^{-1}\) is an automorphism of \(G\), which implies that \(G\) is abelian. For any \(z\in G\), \(z\neq 1\), we have \(z^{-1}=\varphi(z)\neq z\), so \(G\) has no element of order 2, and \(|G|\) is odd.

**Solution to 6.2.6:** Let \(G\) be the group. If \(G\) is not abelian and \(a\) is an element not in the center, then the map \(x\mapsto a^{-1}xa\) is the desired automorphism. If \(G\) is cyclic, say of order \(m\), and \(n\) is an integer larger than 1 and relatively prime to \(m\), then the map \(x\mapsto x^{n}\) is the desired automorphism. If \(G\) is any finite abelian group, then, by the Structure Theorem [10, pag. 109], it is a direct product of cyclic groups. If one of the factors has order at least 3, we get the desired automorphism by using the preceding one in that factor and the identity in the other factors. If every factor has order 2, we get the desired automorphism by permuting any two of the factors.

**Solution to 6.2.11:** The only homomorphism is the trivial one. Suppose \(\varphi\) is a nontrivial homomorphism. Then \(\varphi(a)=m\neq 1\) for some \(a,m\in\mathbb{Q}\). We have

\[a=\frac{a}{2}+\frac{a}{2}=\frac{a}{3}+\frac{a}{3}+\frac{a}{3}+\cdots\]

but \(m\) is not the \(n^{th}\) power of a rational number for every positive \(n\). For example \(3/5=1/5+1/5+1/5\) but \(\sqrt[3]{\frac{3}{5}}\notin\mathbb{Q}^{+}\).

**Solution to 6.2.12:** We show that \(f\) is an isomorphism from \(\ker i\) onto \(\ker j\). Let \(y\in\ker i\). We have

\[j(f(y))=f(y)-f(g(f(y)))=f(y-g(f(y)))=f(i(y))=f(0)=0.\]

[MISSING_PAGE_FAIL:339]

**Solution to 6.3.3:** 1. Let \(G=\langle c\rangle.\) We have \(a=c^{r}\) and \(b=c^{s}\) for some positive odd integers \(r\) and \(s,\) so \(ab=c^{r+s}\) with \(r+s\) even, and \(ab\) is a square.

2. Let \(G=\mathbb{Q}\,^{*},\) the multiplicative group of the rational numbers, \(a=2,\) and \(b=3.\) Then \(ab=6,\) and none of these is a square in \(G.\)

**Solution to 6.3.5:** Let \(e\) be the identity in \(G,\) and let \(N=\{e,a\}\) be the normal subgroup of order \(2.\) If \(x\in G,\) then \(x^{-1}ax\in N\) and certainly does not equal \(e,\) so it equals \(a.\) Thus, \(xa=ax\) for all \(x\in G.\) The quotient group \(G/N\) has order \(p\) and so is cyclic. Let \(x\) be any element not in \(N.\) Then the coset of \(x\) in \(G/N\) has order \(p,\) so, in particular, the order of \(x\) itself is not \(2.\) But the order of \(x\) divides \(2p,\) so it must be \(p\) or \(2p.\) In the latter case, \(G\) is the cyclic group generated by \(x.\) In the former case, since \(xa=ax,\) we have \((xa)^{p}=x^{p}a^{p}=a,\) so \((xa)^{2p}=a^{2}=e,\) and \(xa\) has order \(2p,\) which means \(G\) is the cyclic group generated by \(xa.\)

### 6.4 Normality, Quotients, and Homomorphisms

**Solution to 6.4.3:** The subgroup \(H\) is normal only if \(aHa^{-1}=H\) or \(aH=Ha\) for all \(a\in G.\) Since \(H\) has only one left coset different from itself, it will suffice to show that this is true for a fixed \(a\) which is a representative element of this coset. Since \(H\) has the same number of right and left cosets, there exists a \(b\) such that \(H\) and \(bH\) form a partition of \(G.\) Since cosets are either disjoint or equal and \(H\cap aH=\emptyset,\) we must have that \(aH=Hb.\) But then \(a\in Hb,\) so \(Hb=Ha.\)

**Solution to 6.4.5:** Denote by \(h_{i}H\) (and \(k_{i}K\)) a coset of \(H\) (and \(K\)) and suppose

\[G=h_{1}H\cup\cdots\cup h_{r}H\cup k_{1}K\cup\cdots\cup k_{s}K.\]

Since all of the cosets of \(K\) are equal or disjoint and since the index of \(K\) in \(G\) is infinite, there is a \(k\in K\) such that

\[kK\subset h_{1}H\cup\cdots\cup h_{r}H.\]

Therefore, for \(1\leq i\leq s,\)

\[k_{i}K\subset k_{i}k^{-1}h_{1}H\cup\cdots\cup k_{i}k^{-1}h_{r}H.\]

This implies that \(G\) can be written as the union of a finite number of cosets of \(H,\) contradicting the fact that the index of \(H\) in \(G\) is infinite. Hence, \(G\) cannot be written as the finite union of cosets of \(H\) and \(K.\)

**Solution to 6.4.6:** 1. First, note that the multiplication rule in \(G\) reads

\[\left(\begin{array}{cc}a&b\\ 0&a^{-1}\end{array}\right)\left(\begin{array}{cc}a_{1}&b_{1}\\ 0&a_{1}^{-1}\end{array}\right)=\left(\begin{array}{cc}aa_{1}&ab_{1}+ba_{1}^{ -1}\\ 0&a^{-1}a_{1}^{-1}\end{array}\right)\, \tag{6.1}\]which gives \(\left(\begin{smallmatrix}a&b\\ 0&a^{-1}\end{smallmatrix}\right)^{-1}=\left(\begin{smallmatrix}a^{-1}&-b\\ 0&a\end{smallmatrix}\right)\). This makes it clear that \(N\) is a subgroup, and if \(\left(\begin{smallmatrix}1&\beta\\ 0&1\end{smallmatrix}\right)\) is in \(N\), then

\[\left(\begin{smallmatrix}a&b\\ 0&a^{-1}\end{smallmatrix}\right)^{-1}\!\!\left(\begin{array}{cc}1&\beta\\ 0&1\end{array}\right)\left(\begin{array}{cc}a&b\\ 0&a^{-1}\end{array}\right) = \left(\begin{array}{cc}a^{-1}&\neg b\\ 0&a\end{array}\right)\!\!\left(\begin{array}{cc}a&b+\beta a^{-1}\\ 0&a^{-1}\end{array}\right)\] \[= \left(\begin{array}{cc}1&\beta a^{-2}\\ 0&1\end{array}\right)\in N\,\]

proving that \(N\) is normal.

By (6.1), the map from \(G\) onto \(\mathbb{R}_{+}\) (the group of positive reals under multiplication) given by \(\left(\begin{smallmatrix}a&b\\ 0&a^{-1}\end{smallmatrix}\right)\mapsto a\) is a homomorphism whose kernel is \(N\) (which by itself proves that \(N\) is a normal subgroup). Hence, \(G/N\) is isomorphic to \(\mathbb{R}_{+}\), which is isomorphic to the additive group \(\mathbb{R}\).

2. To obtain the desired normal subgroup majorizing \(N\), we can take the inverse image under the homomorphism above of any nontrivial proper subgroup of \(\mathbb{R}_{+}\). If we take the inverse image of \(\mathbb{Q}_{+}\), the group of positive rationals, we get the proper normal subgroup

\[N^{\prime}=\left\{\left(\begin{array}{cc}a&b\\ 0&a^{-1}\end{array}\right)\mid a\in\mathbb{Q}_{+}\right\}\]

of \(G\), which contains \(N\) properly.

**Solution to 6.4.11:** Let \(\{a_{1}H,a_{2}H,\ldots,a_{\frac{n}{m}}H\}\) be the set of distinct cosets of \(H\). \(G\) acts on on this set by left multiplication and any \(g\in G\) permutes these \(n/m\) cosets. This group action defines a map

\[\varphi:G\to S_{\frac{n}{m}}\]

from \(G\) to the permutation group on \(n/m\) objects. There are two cases to consider depending on \(\varphi\) being injective or not.

If \(\varphi\) is not injective, then \(\ker\varphi\) is a normal subgroup \(K\neq\{e\}\); and \(K\neq G\), as well, because if \(g\not\in H\), \(gH\neq H\); so g is not a trivial permutation.

If \(\varphi\) is injective, then \(|\varphi(G)|=n\), and \(\varphi(G)\) is a subgroup of \(S_{\frac{n}{m}}\). But \([S_{\frac{n}{m}}:\varphi(G)]=|S_{\frac{n}{m}}|/|\varphi(G)|=\left(\frac{n}{m} \right)!/n<2\). So \(|S_{\frac{n}{m}}:\varphi(G)|=1\), that is, \(G\) is isomorphic to \(S_{\frac{n}{m}}\), and in that case, \(A_{\frac{n}{m}}\) is a nontrivial normal subgroup.

**Solution to 6.4.12:**

Let \(H\) be a subgroup of \(G\) of index \(3\). \(G\) acts by left multiplication on the left cosets \(\{gH\}\) of the subgroup \(H\). This gives a homomorphism of \(G\) into the symmetric group of degree \(3\), the group of permutations of these cosets. The subgroup \(H\) is the stabilizer of one element of this set of cosets, namely the coset \(1H\). This homomorphism cannot map onto the entire symmetric group, since this symmetric group has a subgroup of index \(2\), which would pull back to a subgroup of \(G\) of index \(2\). Thus, it must map onto the cyclic subgroup of order \(3\), and the group \(H\) is then the kernel of this homomorphism.

**Solution to 6.4.13:** 1. The cycles of \(\lambda_{g}\) are the right cosets \(\langle g\rangle x\) of the subgroup \(\langle g\rangle\) in \(G\), so the lengths of each one is the order of \(g\), and the number of cycles is \([G:\langle g\rangle]\).

If the order of \(g\) is odd, then each cycle has odd length, so each cycle is even, and so is \(\lambda_{g}\).

If the order of \(g\) is even, then each cycle is of even length and, therefore, odd. Also,

\[[G:\langle g\rangle]\cdot|\langle g\rangle|=|G|\]

is odd. As \([G:\langle g\rangle]\) is the number of cycles, \(\lambda_{g}\) is odd.

2. Let \(\varphi:G\rightarrow\{-1,1\}\) be defined by \(g\mapsto\varphi(g)=\) sign of \(\lambda_{g}\). \(\varphi\) is a morphism and, by Part 1, its kernel is \(N\). So \(N\) is a normal subgroup of \(G\) with index 1 or 2. By Cauchy's Theorem [1, pag. 61], \(G\) has an element of order 2, which is not in \(N\), so \(N\) has order 2.

**Solution to 6.4.14:** Let \(g=xyx^{-1}y^{-1}\) be a commutator. It suffices to show that conjugation by \(g\) fixes every element of \(N\). As \(N\) is cyclic, Aut(N) is abelian, and, because \(N\) is normal, conjugation by any element of \(G\) is an automorphism of \(N\). Let \(\varphi_{x}\) be the automorphism of conjugation by \(x\). We have \(\varphi_{x}\varphi_{y}=\varphi_{y}\varphi_{x}\). Hence, for \(n\in N\), \(gng^{-1}=\varphi_{x}\circ\varphi_{y}\circ\varphi_{x}^{-1}\circ\varphi_{y}^{-1 }(n)=n\).

**Solution to 6.4.15:** We will show that if the index of \(N\) in \(G\) is not finite and equal to a prime number, then there is a subgroup \(H\) properly between \(N\) and \(G\). Since any nontrivial proper subgroup of \(G/N\) is the image of such a subgroup, we need only look at subgroups of \(G/N\).

Suppose first that the index of \(N\) in \(G\) is infinite, and let \(g\) be an element of \(G/N\). If \(g\) is a generator of \(G/N\), then \(G/N\) is isomorphic to \(\mathbb{Z}\), and the element \(g^{2}\) generates a proper nontrivial subgroup of \(G/N\). Otherwise, \(g\) generates such a subgroup.

Suppose that the index of \(N\) in \(G\) is finite but not a prime number. Let \(p\) be any prime divisor of the index. By Cauchy's Theorem [19, pag. 152], there is an element of order \(p\) in \(G/N\). This element cannot generate the whole group, so it generates a nontrivial proper subgroup of \(G/N\).

**Solution to 6.4.16:** Let the index of \(A\) in \(G\) be \(n\). \(G\) acts by left multiplication on the cosets \(gA\), and this gives a homomorphism into the group of permutations of the cosets, which has order \(n!\). The kernel, \(N\), of this homomorphism is contained in \(A\), so the index of \(N\) in \(G\) is, at most, \(n!\).

### 6.5 \(S_{n}\), \(A_{n}\), \(D_{n}\),...

**Solution to 6.5.2:** Think of \(S_{4}\) as permuting the set \(\{1,2,3,4\}\). For \(1\leq i\leq 4\), let \(G_{i}\subset S_{4}\) be the set of all permutations which fix \(i\). Clearly, \(G_{i}\) is a subgroup of \(S_{4}\); since the elements of \(G_{i}\) may freely permute the three elements of \(\{1,2,3,4\}\setminus\{i\}\), it follows that \(G_{i}\) is isomorphic to \(S_{3}\). Thus, the \(G_{i}\)'s are the desired four subgroups isomorphic to \(S_{3}\).

Similarly, for \(i,j\in\{1,2,3,4\}\), \(i\neq j\), let \(H_{ij}\) be the set of permutations which fix \(i\) and \(j\). Again \(H_{ij}\) is a subgroup of \(S_{4}\), and since its elements can freely permute the other two elements, each must be isomorphic to \(S_{2}\). Since for each pair \(i\) and \(j\) we must get a distinct subgroup, this gives us six such subgroups.

Finally, note that \(S_{2}\) is of order 2 and so is isomorphic to \(\mathbb{Z}_{2}\). Therefore, any subgroup of \(S_{4}\) which contains the identity and an element of order 2 is isomorphic to \(S_{2}\). Consider the following three subgroups: \(\{1,(1\,2)(3\,4)\}\), \(\{1,(1\,3)(2\,4)\}\), and \(\{1,(1\,4)(2\,3)\}\). None of these three groups fix any of the elements of \(\{1,2,3,4\}\), so they are not isomorphic to any of the \(H_{ij}\). Thus, we have found the final three desired subgroups.

**Solution to 6.5.3:** Let \(\sigma\) be a 5-cycle and \(\tau\) a 2-cycle. By renaming the elements of the set, we may assume \(\sigma=(1\ 2\ 3\ 4\ 5)\) and \(\tau=(a\ b)\). Letting \(\sigma\) act repeatedly on \(\tau\) as in the hint, we get the five transpositions \((a+i\ b+i)\), \(1\leq i\leq 5\), where we interpret \(a+i\) to be \(a+i-5\) if \(a+i>5\). Fixing \(i\) such that \(a+i-5=1\) and letting \(c=b+i\), we see that \(G\) contains the five transpositions \((1\ c)\), \((2\ c+1),\ldots,(5\ c+4)\). Since \(a\neq b\), \(c\neq 1\).

Let \(d=c-1\). Since \(d\) does not equal 0 or 5, these five transpositions can be written as \((c+nd\ c+(n+1)d)\), \(0\leq n\leq 4\). By the Induction Principle [13, pag. 7] the hint shows that \(G\) contains the four transpositions

\[(1\ c+nd)=(1\ c+(n-1)d)(c+(n-1)d\ c+nd)(1\ c+(n-1)d),\]

\(1\leq n\leq 4\). Since they are distinct, it follows that \(G\) contains the four transpositions \((1\ 2)\), \((1\ 3)\), \((1\ 4)\), and \((1\ 5)\). Applying the hint a third time, we see that \((i\ j)=(1\ i)(1\ j)(1\ i)\) is an element of \(G\) for all \(i\) and \(j\), \(1\leq i,j\leq 5\). Hence, \(G\) contains all of the 2-cycles. Since every element in \(S_{n}\) can be written as the product of 2-cycles, we see that \(G\) is all of \(S_{n}\).

**Solution to 6.5.7:** The order of a \(k\)-cycle is \(k\), so the smallest \(m\) which simultaneously annihilates all 9-cycles, 8-cycles, 7-cycles, and 5-cycles is \(2^{3}\cdot 3^{2}\cdot 5\cdot 7=2520\). Any \(n\)-cycle, \(n\leq 9\), raised to this power is annihilated, so \(n=2520\).

To compute \(n\) for \(A_{9}\), note that an 8-cycle is an odd permutation, so no 8-cycles are in \(A_{9}\). Therefore, \(n\) need only annihilate 4-cycles (since a 4-cycle timcs a transposition is in \(A_{9}\)), 9-cycles, 7-cycles, and 5-cycles. Thus, \(n=2520/2=1260\).

**Solution to 6.5.8:** We have \(1111=11\times 101\), the product of two primes. So \(G\) is cyclic, say \(G=\langle a\rangle\). From \(1111>999\), it follows that \(a\), when written as a product of disjoint cycles, has no cycles of length 1111. Therefore, all cycles of \(a\) have lengths 1, 11, and 101. Let there be \(x\), \(y\), and \(z\) cycles of lengths, respectively, 1, 11, and 101. If \(x>0\), then \(a\) has a fixed point, and this is then the desired fixed point for all of \(G\). So assume that \(x=0\). Then \(11x+101z=999\). It follows that \(2z\equiv 9\pmod{11}\), so \(z\equiv 10\pmod{11}\), and, therefore, \(z\geq 10\). But then \(999=11y+101z\geq 1010\), a contradiction.

**Solution to 6.5.9:** Call \(i\) and \(j\in\{1,2,\ldots,n\}\) equivalent if there exists \(\sigma\in G\) with \(\sigma(i)=j\). (This is clearly an equivalence relation.) For each \(i\), the set \(G_{i}=\{\sigma\in G\,|\,\sigma(i)=i\}\) is a subgroup of \(G\), and the map \(G\to\{1,2,\ldots,n\}\), \(\sigma\mapsto\sigma(i)\), induces a bijection from the coset space \(G/G_{i}\) to the equivalence class of \(i\). Hence, for each \(i\), the size of its equivalence class equals \([G:G_{i}]\), which is a power of \(p\). Choosing one \(i\) from each equivalence class and summing over \(i\), one finds that all these powers of \(p\) add up to \(n\), since \(p\) does not divide \(n\), one of these powers have to be \(p^{0}=1\). This corresponds to an equivalence class that contains a single element \(i\), and this \(i\) satisfies \(\sigma(i)=i\) for all \(\sigma\in G\).

**Solution to 6.5.12:** To determine the center of

\[D_{n}=\langle a,b\,|\,a^{n}=b^{2}=1,ba=a^{-1}b\rangle\]

(\(a\) is a rotation by \(2\pi/n\) and \(b\) is a flip), it suffices to find those elements which commute with the generators \(a\) and \(b\). Since \(n\geq 3\), \(a^{-1}\neq a\). Therefore,

\[a^{r+1}b=a(a^{r}b)=(a^{r}b)a=a^{r-1}b\]

so \(a^{2}=1\), a contradiction; thus, no element of the form \(a^{r}b\) is in the center. Similarly, if for \(1\leq s<n\), \(a^{s}b=ba^{s}=a^{-s}b\), then \(a^{2s}=1\), which is possible only if \(2s=n\). Hence, \(a^{s}\) commutes with \(b\) if and only if \(n=2s\). So, if \(n=2s\), the center of \(D_{n}\) is \(\{1,a^{s}\}\); if \(n\) is odd the center is \(\{1\}\).

**Solution to 6.5.13:** The number of Sylow 2-subgroups of \(D_{n}\) is odd and divides \(n\). Each Sylow 2-subgroup is cyclic of order 2, since \(2^{1}\) is the largest power of 2 dividing the order of the group. By considering the elements of \(D_{n}\) as symmetries of a regular \(n\)-gon, we see that there are \(n\) reflections through axes dividing the \(n\)-gon in half, and each of these generates a different subgroup of order 2. Thus, the answer is that there are exactly \(n\) Sylow 2-subgroups in \(D_{n}\) when \(n\) is odd.

### 6.6 Direct Products

**Solution to 6.6.2:** Suppose \(\mathbb{Q}\) was the direct sum of two nontrivial subgroups \(A\) and \(B\). Fix \(a\neq 0\) in \(A\) and \(b\neq 0\) in \(B\). We can write \(a=a_{0}/a_{1}\) and \(b=b_{0}/b_{1}\), where the \(a_{i}\)'s and \(b_{i}\)'s are nonzero integers. Since \(A\) and \(B\) are subgroups, \(na\in A\) and \(nb\in B\) for all integers \(n\). In particular,\((a_{1}b_{0})a\in A\) and \((b_{1}a_{0})b\in B\). But

\[(a_{1}b_{0})a=(a_{1}b_{0})a_{0}/a_{1}=a_{0}b_{0}=(b_{1}a_{0})b_{0}/b_{1}=(b_{1}a _{0})b.\]

Hence, \(A\) and \(B\) have a nontrivial intersection, a contradiction.

**Solution to 6.6.3:** Let \(C_{m}\) denote the cyclic group of order \(m\) for \(m\in\mathbb{N}\). By the Structure Theorem for abelian groups [10, pag. 109], if \(G\) is a finite abelian group, there exist unique nonnegative integers \(n_{p^{r}}(G)\) for each prime number \(p\) and each nonnegative integer \(r\) such that \(G\) is isomorphic to

\[\prod_{p}\prod_{r}C_{p^{r}}^{n_{p^{r}}(G)}.\]

If \(H\) is another abelian group, \(G\times H\) is isomorphic to

\[\prod_{p}\prod_{r}C_{p^{r}}^{n_{p^{r}}(G)}\times\prod_{p}\prod_{r}C_{p^{r}}^{n_ {p^{r}}(H)}\cong\prod_{p}\prod_{r}C_{p^{r}}^{n_{p^{r}}(G)+n_{p^{r}}(H)}.\]

Hence, \(n_{p^{r}}(G\times H)=n_{p^{r}}(G)+n_{p^{r}}(H)\). Now this and the fact that \(A\times B\) is isomorphic to \(A\times C\) yield the identities \(n_{p^{r}}(B)=n_{p^{r}}(C)\) for all primes \(p\) and all nonnegative integers \(r\). We conclude \(B\) and \(C\) are isomorphic.

**Solution to 6.6.4:** Let \(\pi_{3}:A\to G_{1}\times G_{2}\) be the natural projection map. We have \(\ker\pi_{3}=\{(1,1,g_{3})\in A\}\). Let \(N_{3}=\{g_{3}\,|\,(1,1,g_{3})\in\ker\pi_{3}\}\). Since \(\ker\pi_{3}\) is a normal subgroup of \(A\), \(N_{3}\) is normal in \(G_{3}\). Let \(A^{\prime}=G_{1}\times G_{2}\times G_{3}/N_{3}\). Since \(\pi_{3}\) is onto, for any \((g_{1},g_{2})\in G_{1}\times G_{2}\), there exists \(g_{3}\in G_{3}\) such that \((g_{1},g_{2},g_{3})\in A\), and, thus, \((g_{1},g_{2},\overline{g_{3}})\in A^{\prime}\).

Define the map \(\varphi:G_{1}\times G_{2}\to G_{3}/N_{3}\) by \(\varphi(g_{1},g_{2})=\overline{g_{3}}\), where \(g_{3}\) is such that \((g_{1},g_{2},g_{3})\in A\). This is well defined, for if \((g_{1},g_{2},g_{3})\) and \((g_{1},g_{2},h_{3})\) are both in \(A\), then \((1,1,g_{3}h_{3}^{-1})\in A\), so \(g_{3}h_{3}^{-1}\in N_{3}\), which, in turn, implies that \(\overline{g_{3}}=\overline{h_{3}}\). The map \(\varphi\) is clearly a homomorphism. Furthermore, since \(\pi_{1}:A\to G_{2}\times G_{3}\) is onto, if \(g_{3}\in G_{3}\), there exist \(g_{1}\in G_{1}\) and \(g_{2}\in G_{2}\) such that \((g_{1},g_{2},g_{3})\in A\). Thus, \(\varphi(g_{1},g_{2})=\overline{g_{3}}\) so \(\varphi\) is onto.

Therefore, \(\varphi(G_{1}\times\{1\})\) and \(\varphi(\{1\}\times G_{2})\) are subgroups of \(G_{3}/N_{3}\) which commute with each other. If these two subgroups were equal to one another and to \(G_{3}/N_{3}\), then \(G_{3}/N_{3}\) would be abelian. As \(G_{3}\) is generated by its commutator subgroup, this would imply \(G_{3}/N_{3}\) to be trivial or, equivalently, \(G_{3}=N_{3}\), which we assumed not to be the case. So we may assume that \(\varphi(\{1\}\times G_{2})\neq G_{3}/N_{3}\). Pick \(\overline{g_{3}}\in G_{3}/N_{3}\setminus\varphi(\{1\}\times G_{2})\). Since \(\pi_{2}:A\to G_{1}\times G_{3}\) is onto, there exists a \(g_{2}\in G_{2}\) such that \((1,g_{2},g_{3})\in A\). Hence, \(\varphi(1,g_{2})=\overline{g_{3}}\), contradicting our choice of \(\overline{g_{3}}\).

Therefore, we must have that \(N_{3}=G_{3}\), so \(\{1\}\times\{1\}\times G_{3}\subset A\). Similar arguments show that \(\{1\}\times G_{2}\times\{1\}\) and \(G_{1}\times\{1\}\times\{1\}\) are contained in \(A\) and, thus, \(A=G\).

**Solution to 6.6.6:** The obvious isomorphism \(F\colon{\rm Aut}(G)\times{\rm Aut}(H)\to{\rm Aut}(G\times H)\) is defined by

\[F(\alpha_{G},\alpha_{H})(g,h)=(\alpha_{G}(g),\alpha_{H}(h)).\]

Since \(\alpha_{G}\) and \(\alpha_{H}\) are automorphisms of \(G\) and \(H\), it is clear that \(F(\alpha_{G},\alpha_{H})\) is an automorphism of \(G\times H\). Let us prove now that \(F\) is an isomorphism.

* \(F\) is injective: Let \(F(\alpha_{G},\alpha_{H})={\rm id}_{G\times H}\). Then \(\alpha_{G}={\rm id}_{G}\) and \(\alpha_{H}={\rm id}_{H}\) by definition of \(F\). Hence, \(\ker F\) is trivial so \(F\) is injective.
* \(F\) is surjective: Choose \(\alpha\in{\rm Aut}(G\times H)\). Define \(\alpha_{G}\), \(\alpha_{H}\) by \[\alpha_{G}(g)=\pi_{G}(\alpha(g,{\rm id}_{H}))\qquad\mbox{and}\qquad\alpha_{H }(h)=\pi_{H}(\alpha({\rm id}_{G},h))\] where \(\pi_{G}\) and \(\pi_{H}\) are the quotient maps. Thus, \[\alpha(g,h)=(\alpha_{G}(g),\alpha_{H}(h))=F(\alpha_{G},\alpha_{H})(g,h).\] Since the situation is symmetric between \(G\) and \(H\); and \(G\) is finite, we need only show that \(\alpha_{G}\) is injective. Let \(\alpha_{G}(g)={\rm id}_{G}\). Then \(\alpha(g,{\rm id}_{H})=({\rm id}_{G},h)\) for some \(h\in H\). Suppose \(n=|G|\). Then \[({\rm id}_{G},h^{n})=\alpha(g,{\rm id}_{H})^{n}=\alpha(g^{n},{\rm id}_{H})=({ \rm id}_{G},{\rm id}_{H}).\] Hence, \(h^{n}={\rm id}_{H}\), so the order of \(h\) divides \(|G|\). But, by Lagrange's Theorem [Her75, pag. 41], the order of \(h\) also divides \(|H|\), which is relatively prime to \(|G|\), so the order of \(h\) is one and \(h={\rm id}_{H}\).

### 6.7 Free Groups, Products, Generators, and Relations

**Solution to 6.7.2:** Suppose \({\mathbb{Q}}\) is finitely generated, with generators

\[\alpha_{1}/\beta_{1},\ldots,\alpha_{k}/\beta_{k}\qquad\alpha_{i},\beta_{i}\in{ \mathbb{Z}}.\]

Then any element of \({\mathbb{Q}}\) can be written as \(\sum n_{i}\alpha_{i}/\beta_{i}\), where the \(n_{i}\)'s are integers. This sum can be written as a single fraction with denominator \(s=\beta_{1}\cdots\beta_{k}\). Consider a prime \(p\) which does not divide \(s\). Then we have \(1/p=r/s\) for some integer \(r\), or \(pr=s\), contradicting the fact that \(p\) does not divide \(s\). Hence, \({\mathbb{Q}}\) cannot be finitely generated.

_Solution 2._ Suppose \({\mathbb{Q}}\) is finitely generated, then using the solution to Part 1 of Problem 6.3.1, \({\mathbb{Q}}\) is cyclic, which is a contradiction.

**Solution to 6.7.4:**\(x^{5}y^{3}=x^{8}y^{5}\) implies \(x^{3}y^{2}=1\). Then \(x^{5}y^{3}=x^{3}y^{2}\) and \(x^{2}y=1\). Hence, \(x^{3}y^{2}=x^{2}y\), so \(xy=1\). But then \(xy=x^{2}y\), so we have that \(x=1\). This implies that \(y=1\) also, and \(G\) is trivial.

**Solution to 6.7.5:** We start with the given relations

\[(1)\quad a^{-1}b^{2}a=b^{3}\qquad\hbox{and}\qquad(2)\quad b^{-1}a^{2}b=a^{3}.\]

From (1), we get \(a^{-1}b^{4}a=b^{6}\) and

\[a^{-2}b^{4}a^{2}=a^{-1}b^{6}a=(a^{-1}b^{2})b^{4}a=b^{3}(a^{-1}b^{4}a)=b^{3}b^{6 }=b^{9}\]

using the relation just obtained and (2), we get

\[b^{9}=(a^{-2})b^{4}a^{2}=ba^{-3}b^{-1}b^{4}(a^{2})=ba^{-3}b^{-1}b^{4}ba^{3}b^{- 1}=ba^{-3}b^{4}a^{3}b^{-1},\]

and we conclude that

\[a^{-3}b^{4}a^{3}=b^{9}=a^{-2}b^{4}a^{2}\]

from which we obtain \(ab^{4}=b^{4}a\). This, combined with the square of relation \((1)\,(a^{-1}b^{4}a=b^{6})\), gives \(b^{2}=1\) and substitution back in (1) shows that \(b=1\); then, substituting that into relation (2), we see that \(a=1\), so the group is trivial.

**Solution to 6.7.6:** Let \(G=\langle a,b\mid a^{2}=b^{2}=1\rangle\) and \(H=\langle ab,ba\rangle\). Since \(ab=(ba)^{-1}\), it is clear that \(H\) is the subgroup of \(G\) which consists of all words of even length: \(abab\cdots ab\) and \(baba\cdots ba\). So \(H\neq G\), but \(G=H\cup aH\). Hence, \(H\) has index 2 in \(G\).

Suppose now that \(G^{\prime}\) is any such group. Then

\[G^{\prime}=G/R\]

where \(R\) is the normal _relation subgroup_. Let \(H^{\prime}=H/R\). We have

\[|G^{\prime}/H^{\prime}|=|G/R|/|H/R|=|G/H|=2.\]

Hence, \(H^{\prime}\) is the desired subgroup.

**Solution to 6.7.8:** We use the Induction Principle [MH93, pag. 7]. For \(n=1\), the result is obvious.

Suppose \(g_{1},\ldots,g_{n}\) generate the group \(G\) and let \(H\) be a subgroup of \(G\). If \(H\subset\langle g_{2},\ldots,g_{n}\rangle\), by the induction hypothesis, \(H\) is generated by \(n-1\) elements or fewer. Otherwise let

\[y=g_{1}^{m_{1}}\cdots g_{n}^{m_{n}}\in H\]

be such that \(|m_{1}|\) is minimal but nonzero. We can assume, without loss of generality, that \(m_{1}>0\). For any \(z\in H\),

\[z=g_{1}^{k_{1}}\cdots g_{n}^{k_{n}}\]there are integers \(q\) and \(r\) such that \(k_{1}=qm_{1}+r\) and \(0\leq r<m_{1}\). Then the exponent of \(g_{1}\) in \(zy^{-q}\) is \(r\), and, by the choice of \(m_{1}\), we obtain \(r=0\). Hence,

\[H=\langle y,K\rangle\quad\text{where}\quad K=H\cap\langle g_{2},\ldots,g_{n}\rangle.\]

By the induction hypothesis, \(K\) is generated by, at most, \(n-1\) elements, and the result follows.

**Solution to 6.7.10:** By the Structure Theorem for finite abelian groups [11, pag. 109], there are integers \(m_{1},\ldots,m_{k}\), \(m_{j}|m_{j+1}\) for \(1\leq j\leq k-1\), such that \(A\) is isomorphic to \(\mathbb{Z}_{m_{1}}\oplus\cdots\oplus\mathbb{Z}_{m_{k}}\). We identify \(A\) with this direct sum. Clearly \(m=m_{k}\). Therefore, \(S\) must contain the elements of the form \((0,0,\ldots,1)\) and \((0,\ldots,0,1,0,\ldots,1)\), where the middle \(1\) is in the \(j^{th}\) position, \(1\leq j\leq k-1\). Hence, using elements in \(S\), we can generate all the elements of \(A\) which are zero everywhere except in the \(j^{th}\) position. These, in turn, clearly generate \(A\), so \(S\) generates \(A\) as well.

### 6.8 Finite Groups

**Solution to 6.8.1:** Any group with one element must be the trivial group.

By Lagrange's Theorem [11, pag. 41], any group with prime order is cyclic and so abelian. Therefore, by the Structure Theorem for abelian groups [11, pag. 109], every group of orders \(2\), \(3\), or \(5\) is isomorphic to \(\mathbb{Z}_{2}\), \(\mathbb{Z}_{3}\), or \(\mathbb{Z}_{5}\), respectively.

If a group \(G\) has order \(4\), it is either cyclic, and so abelian, or each of its elements has order \(2\). In this case, we must have \(1=(ab)^{2}=abab\) or \(ba=ab\), so the group is abelian. Then, again by the Structure Theorem for abelian groups, a group of order \(4\) must be isomorphic to \(\mathbb{Z}_{4}\) or \(\mathbb{Z}_{2}\oplus\mathbb{Z}_{2}\). These two groups of order \(4\) are not isomorphic since only one of them has an element of order \(4\).

Since groups of different orders can not be isomorphic, it follows that all of the groups on this list are distinct.

**Solution to 6.8.2:** The trivial group is clearly abelian. Groups of prime order are cyclic, by Lagrange's Theorem [11, pag. 41] and so must be abelian. Hence, groups of orders \(2\), \(3\), and \(5\) are abelian. This leaves only groups of order \(4\). Every group of order \(4\) can have nontrivial elements of orders \(2\) or \(4\). If such a group has an element of order \(4\), it is cyclic, and so abelian. If every element is of order \(2\), it is also abelian, since, given any two elements \(a\) and \(b\),

\[abab=(ab)^{2}=1=a^{2}b^{2},\]

and canceling yields \(ba=ab\). The group of symmetries of the triangle, \(D_{3}\), has \(6\) elements and is nonabelian.

Solution to 6.8.5:By the Structure Theorem for finitely generated abelian groups [19, pag. 109], there are three: \(\mathbb{Z}_{8}\), \(\mathbb{Z}_{2}\times\mathbb{Z}_{4}\), and \(\mathbb{Z}_{2}\times\mathbb{Z}_{2}\times\mathbb{Z}_{2}\).

1. \((\mathbb{Z}_{15})^{\star}=\{1,2,4,7,8,11,13,14\}\). By inspection, we see that every element is of order \(2\) or \(4\). Hence, \((\mathbb{Z}_{15})^{\star}\simeq\mathbb{Z}_{2}\times\mathbb{Z}_{4}\)
2. \((\mathbb{Z}_{17})^{\star}=\{1,2,\ldots,16\}=\{\pm 1,\pm 2,\ldots,\pm 8\}\), passing to the quotient \((\mathbb{Z}_{17})^{\star}/\{\pm 1\}=\{1,2,\ldots,8\}\) which is generated by \(3\), so \((\mathbb{Z}_{17})^{\star}\simeq\mathbb{Z}_{8}\).
3. The roots form a cyclic group of order \(8\) isomorphic to \(\mathbb{Z}_{8}\).
4. \(\mathbf{F}_{8}\) is a field of characteristic \(2\), so every element added to itself is \(0\). Hence, \[\mathbf{F}_{8}^{+}\cong\mathbb{Z}_{2}\times\mathbb{Z}_{2}\times\mathbb{Z}_{2}.\]
5. \((\mathbb{Z}_{16})^{\star}=\{1,3,5,7,9,11,13,15\}\cong\mathbb{Z}_{2}\times \mathbb{Z}_{4}\).

Solution to 6.8.6:Order \(24\): The groups \(S_{4}\) and \(S_{3}\times\mathbb{Z}_{4}\) are nonabelian of order \(24\). They are not isomorphic since \(S_{4}\) does not contain any element of order \(24\) but \(S_{3}\times\mathbb{Z}_{4}\) does.

Order \(30\): The groups \(D_{3}\times\mathbb{Z}_{5}\) and \(D_{5}\times\mathbb{Z}_{3}\) have different numbers of Sylow \(2\)-subgroups, namely \(3\) and \(5\), respectively.

Order \(40\): There are two examples where the Sylow \(2\)-subgroup is normal: The direct product of \(\mathbb{Z}_{5}\) with a nonabelian group of order \(8\). Such order \(8\) groups are the dihedral group of symmetries of the square (which has only two elements of order \(4\)), and the group of the quaternions \(\{\pm 1,\pm i,\pm j,\pm k\}\) (which has six elements of order \(4\)). There are also several other examples where the Sylow \(2\)-subgroup is not normal.

Solution to 6.8.8:The number of Sylow \(3\)-subgroups is congruent to \(1\) mod \(3\) and divides \(5\); hence, there is exactly one such subgroup, which is normal in the group. It is an abelian group of order \(9\). The abelian groups of this order are the cyclic group of order \(9\) and the direct product of two cyclic groups of order \(3\).

The number of Sylow \(5\)-subgroups is congruent to \(1\) mod \(5\) and divides \(9\); hence, there is exactly one such subgroup, which is the (normal) cyclic group of order \(5\). The Sylow \(3\)-subgroup and the Sylow \(5\)-subgroup intersect trivially so their direct product is contained in the whole group, and a computation of the order shows that the whole group is exactly this direct product. Therefore, there are, up to isomorphism, two possibilities

\[\mathbb{Z}_{9}\times\mathbb{Z}_{5}\,\qquad\mathbb{Z}_{3}\times\mathbb{Z}_{3} \times\mathbb{Z}_{5}\.\]

**Solution to 6.8.11:** If \(p=2\), then the group is either cyclic and so isomorphic to \(\mathbb{Z}_{4}\), or every element has order \(2\) and so is abelian and isomorphic to \(\mathbb{Z}_{2}\oplus\mathbb{Z}_{2}\).

Now suppose \(p>2\) and let \(G\) have order \(2p\). By Sylow's Theorems [Her75, pag. 91], the \(p\)-Sylow subgroup of \(G\) must be normal, since the number of such subgroups must divide \(2p\) and be congruent to \(1\bmod p\). Since the \(p\)-Sylow subgroup has order \(p\), it is cyclic; let it be generated by \(g\). A similar argument shows that the number of \(2\)-Sylow subgroups is odd and divides \(2p\); hence, there is a unique, normal \(2\)-Sylow subgroup, or there are \(p\) conjugate \(2\)-Sylow subgroups. Let one of the \(2\)-Sylow subgroups be generated by \(h\).

In the first case, the element \(ghg^{-1}h^{-1}\) is in the intersection of the \(2\)-Sylow and the \(p\)-Sylow subgroups since they are both normal; these are cyclic groups of different orders, so it follows that \(ghg^{-1}h^{-1}=1\), or \(hg=gh\). Since \(g\) and \(h\) must generate \(G\), we see that \(G\) is abelian and isomorphic to \(\mathbb{Z}_{2}\oplus\mathbb{Z}_{p}\).

In the second case, a counting argument shows that all the elements of \(G\) can be written in the form \(g^{i}h^{j}\), \(0\leq i<p\), \(0\leq j<2\). Since all the elements of the form \(g^{i}\) have order \(p\), it follows that all the \(2\)-Sylow subgroups are generated by the elements \(g^{i}h\). Hence, all of these elements are of order \(2\); in particular, \(ghgh=1\), or \(hg=g^{-1}h\). Thus, \(G=\langle g,h\mid g^{p}=h^{2}=1,hg=g^{-1}h\rangle\) and so \(G\) is the dihedral group \(D_{n}\).

**Solution to 6.8.12:** By Cayley's Theorem [Her75, pag. 71], every group of order \(n\) is isomorphic to a subgroup of \(S_{n}\), so it is enough to show that \(S_{n}\) is isomorphic to a subgroup of \(\mathbb{O}(n)\). For each \(\sigma\in S_{n}\), consider the matrix \(A_{\sigma}=(a_{ij})\), where \(a_{\sigma(i)\,i}=1\) and all other entries are zero. Let \(\varphi\) be defined by \(\sigma\mapsto\varphi(\sigma)=A_{\sigma}\). The matrix \(A_{\sigma}\) has exactly one \(1\) in each row and column. Hence, both the rows and columns form an orthonormal basis of \(\mathbb{R}^{n}\), so \(A_{\sigma}\) is orthogonal. \(\varphi\) maps \(S_{n}\) into \(\mathbb{O}(n)\). Let \(A_{\sigma}=(a_{ij})\) and \(B_{\tau}=(b_{ij})\). Then

\[A_{\sigma}B_{\tau}=(c_{ij})=\left(\sum_{k=1}^{n}a_{ik}b_{kj}\right).\]

An element of this matrix is \(1\) if and only if \(i=\sigma(k)\) and \(k=\tau(j)\) for some \(k\); equivalently, if and only if \(i=\sigma(\tau(j))\). Hence, \(c_{\sigma(\tau(i))\,i}=1\) and all the other entries are \(0\). Therefore, \((c_{ij})=A_{\sigma\cdot\tau}\), so \(\varphi\) is a homomorphism.

If \(A_{\sigma}\) equals the identity matrix, then \(\sigma(i)=i\) for \(1\leq i\leq n\), so \(\sigma\) is the identity permutation. Thus, \(\varphi\) has trivial kernel and is one-to-one hence an isomorphism.

**Solution to 6.8.13:** 1. For any set \(X\) let \(S_{X}\) be the group of bijections \(\sigma:X\to X\). If \(X\) is a finite set with \(n\) elements then \(S_{X}\) is isomorphic to \(S_{n}\), the group of all permutations of \(\{1,2,\ldots,n\}\).

For any group \(G\) and any element \(g\in G\), define a mapping \(\varphi_{g}:G\to G\) by \(\varphi_{g}(x)=gx\) for all \(x\in G\). For any \(g,h,x\in G\), \((\varphi_{g}\cdot\varphi_{h})(x)=\varphi_{g}(\varphi_{h}(x))=\varphi_{g}(hx)=g(hx )=(gh)x=\varphi_{gh}(x)\). This shows that \(\varphi_{gh}=\varphi_{g}\cdot\varphi_{h}\).

It follows that, for each \(g\in G\), \(\varphi_{g}:G\to G\) is a bijection, with inverse \(\varphi_{g^{-1}}\). In other words \(\varphi_{g}\in S_{G}\) for all \(g\in G\), defining a map \(\varphi:G\to S_{G}\). Since \(\varphi_{gh}=\varphi_{g}\cdot\varphi_{h}\), \(\varphi:G\to S_{G}\) is a group homomorphism. If \(\varphi_{g}=\varphi_{h}\) for two elements \(g,h\in G\) then \(g=\varphi_{g}(1)=\varphi_{h}(1)=h\), showing that \(\varphi:G\to S_{G}\) is injective. Therefore, \(G\) is isomorphic to the subgroup \(\varphi(G)\) of \(S_{G}\).

2. Since any group of order \(n\) embeds in \(S_{n}\), it suffices to embed \(S_{n}\) into the group of even permutations of \(n+2\) objects. Let \(\varepsilon:S_{n}\to\mathbb{Z}_{2}\) be the homomorphism that maps even permutations to \(0\) and odd permutations to \(1\).

Define \(\theta:S_{n}\to S_{n+2}\) by \(\theta(\sigma)=\sigma\cdot(n+1,n+2)^{\varepsilon(\sigma)}\). Since the transposition \((n+1,n+2)\) commutes with each element \(\sigma\in S_{n}\), \(\theta\) is a homomorphism, clearly injective. Since \(\sigma\) and \((n+1,n+2)^{\varepsilon(\sigma)}\) have the same parity, their product \(\theta(\sigma)\) is even.

### 6.9 Rings and Their Homomorphisms

**Solution to 6.9.3:** Let \(\varphi:\mathbb{C}\,^{n}\to\mathbb{C}\,\) be a ring homomorphism and \(e_{1}=(1,0,0,\ldots,0),e_{2}=(0,1,0,\ldots,0),\ldots,e_{n}=(0,0,0,\ldots,1)\), then \(e_{i}e_{j}=0\) for all \(i\neq j\) and if \(\varphi(e_{1})=\cdots=\varphi(e_{n})=0\),

\[\varphi(x_{1},\ldots,x_{n})=\varphi(x_{1},0,\ldots,0)\varphi(e_{1})+\cdots+ \varphi(0,0,\ldots,x_{n})\varphi(e_{n})=0\]

that is, \(\varphi\) is identically zero.

Suppose now that \(\varphi\) is a nontrivial homomorphism, then \(\varphi(e_{i})\neq 0\) for some \(i\) and in this case \(\varphi(e_{i})=\varphi(e_{i}e_{i})=\varphi(e_{i})\varphi(e_{i})\) and \(\varphi(e_{i})=1\). At the same time \(0=\varphi(e_{i}e_{j})=\varphi(e_{i})\varphi(e_{j})\) we conclude that \(\varphi(e_{j})=0\) for all \(j\neq i\), and \(\varphi\) is determined by its value on the \(i^{th}\) coordinate.

\[\varphi(x_{1},\ldots,x_{i},\ldots,x_{n}) =\varphi(0,\ldots,x_{i},\ldots,0)\varphi(e_{i})\] \[=\varphi(0,\ldots,x_{i},\ldots,0)1\] \[=\varphi(0,\ldots,x_{i},\ldots,0)\]

So for every homomorphism \(\sigma:\mathbb{C}\,\to\mathbb{C}\,\) we can create \(n\) such homomorphisms from \(\mathbb{C}\,^{n}\) to \(\mathbb{C}\,\) by composing \(\varphi(x_{1},\ldots,x_{n})=\sigma(\pi_{i}(x_{1},\ldots,x_{n}))\) where \(\pi_{i}\) is the projection on the \(i^{th}\) coordinate, and the argument above shows that all arise in this way.

**Solution to 6.9.4:** Let \(R\) contain \(k\) elements (\(k<\infty\)) and consider the ring

\[S=\underbrace{R\times R\times\cdots\times R}_{k\text{ copies}}\]Let \(R=\{r_{1},\ldots,r_{k}\}\) and \(\alpha=(r_{1},\ldots,r_{k})\in S\). Now consider the collection of elements \(\alpha\), \(\alpha^{2}\), \(\alpha^{3},\ldots\). Since \(S\) is also a finite ring, by the Pigeon-hole Principle [Her75, pag. 127], there exist \(n\) and \(m\) sufficiently large with \(\alpha^{n}=\alpha^{m}\). Coordinatewise, this means that \(r_{i}^{n}=r_{i}^{m}\) for \(1\leq i\leq k\), and we are done.

**Solution to 6.9.5:** If \(ax=0\) (or \(xa=0\)) with \(a\neq 0\), then \(axa=0a\) or \(a0=0\). If \(b\) is as in the text, then \(a(b+x)a=a\), so, by uniqueness of \(b\), \(b=b+x\) and \(x=0\). Thus, there are no zero divisors.

Fix \(a\) and \(b\) such that \(aba=a\). If \(x\in R\), then \(xaba=xa\) and, as there are no zero divisors, \(xab=x\), so \(ab\) is a right identity. Similarly, \(abax=ax\) implies \(bax=x\) and \(ba\) is a left identity. Since any right identity is equal to any right identity, we get \(ab=ba=1\). Since \(b=a^{-1}\), \(R\) is a division ring.

**Solution to 6.9.6:** Since \((R,+)\) is a finite abelian group with \(p^{2}\) elements, by the Structure Theorem for finite abelian groups [Her75, pag. 109], it is isomorphic to either \(\mathbb{Z}_{p^{2}}\) or \(\mathbb{Z}_{p}\oplus\mathbb{Z}_{p}\). In the first case, there is an element \(x\in R\) such that every element of \(R\) can be written as \(nx\), for \(1\leq n\leq p^{2}\). Since all elements of this form commute, it follows that \(R\) is abelian.

In the second case, every nonzero element must have additive order \(p\). Let \(x\in R\) be any element not in the additive subgroup generated by \(1\). Then it too must have additive order \(p\). Thus, a counting argument shows that every element of \(R\) can be written in the form \(n+kx\), \(1\leq n\leq p\), \(1\leq k\leq p\). Since all elements of this form commute, it follows that \(R\) is commutative.

**Solution to 6.9.7:** One can embed \(R\) in the field of quotients of \(R\); then the finite subgroup of \(R^{*}\) is a finite subgroup of the multiplicative group of the field; it is a finite abelian group, and so can be written as a direct product of \(\mathbb{Z}_{p^{n}}\) for various primes \(p\). If there are two such factors for the same \(p\), then there are at least \(p\) elements of the field satisfying the equation \(x^{p}-1=0\). However, in a field, due to the uniqueness of factorization in the polynomial ring, there are, at most, \(n\) solutions to any \(n^{th}\) degree polynomial equation in one variable. Thus, in the factorization of our group, each prime \(p\) occurs at most once, therefore, any such group is cyclic.

**Solution to 6.9.8:**\(1\Rightarrow 2\) : There exist \(v_{1}\neq v_{2}\) such that \(uv_{1}=uv_{2}=1\); thus, \(u(v_{1}-v_{2})=0\) and \(u\) is a zero divisor.

\(2\Rightarrow 3\) : Suppose that \(u\) is a unit with inverse \(v\). If the \(uv=0\) then \(w=(vu)w=v(uw)=v0=0\) and, therefore, \(u\) is not a left zero divisor.

\(3\Rightarrow 1\) : Let \(v\) be a right inverse for \(u\), that is, \(uv=1\). Since \(u\) is not a unit \(vu\neq 1\) implying \(vu-1\neq 0\). Now consider the element \(v^{\prime}=v+(vu-1)\neq v\), and we have

\[uv^{\prime}=uv+u(vu-1)\]\[=1-(uv)u-u\] \[=1+u-u=1\]

showing that \(u\) has more than one right inverse.

**Solution to 6.9.9:** The identity element of such a ring would belong to the additive group of the ring, which is a torsion group; thus there is some finite \(n\) such that if you add the identity element, \(1\), to itself \(n\) times, you get \(0\). In other words, the ring would have some finite characteristic \(n\). But this implies that the additive order of every element of the ring divides \(n\), and this is false, for example, for the element \(1/(n+1)\).

**Solution to 6.9.11:** The degree-\(2\) polynomial \(x^{2}+y^{2}-1\) does not factor into the product of two linear ones (since the circle \(x^{2}+y^{2}=1\) is not a union of two lines). This implies that the ideal \(\langle x^{2}+y^{2}-1\rangle\) is prime and, thus, the ring \(R=\mathbb{Q}\left[x,y\right]/\langle x^{2}+y^{2}-1\rangle\) is an integral domain.

Consider now the _stereographic projection_\((x,y)\mapsto(1,y/(x+1))\) (at half of the speed of the standard one, in order to make the expressions simpler) of the circle from the point (-1,0) to the line \((1,t)\). It provides a homomorphism \(t=y/(x+1)\) of \(\mathbb{Q}\left(t\right)\) to the field of fractions of \(R\). The inverse homomorphism is given by the formulas \(x=(1-t^{2})/(1+t^{2})\) and \(y=2t/(1+t^{2})\).

### 6.10 Ideals

**Solution to 6.10.3:** We will first show that for all \(n\), \(M_{n\times n}(\mathbf{F})\) has no nontrivial proper ideals. This will show that any ring homomorphism from \(M_{(n+1)\times(n+1)}(\mathbf{F})\) onto \(M_{n\times n}(\mathbf{F})\) must be an isomorphism. We will then show that this is not possible.

Assume that \(\mathfrak{I}\) is a nontrivial ideal. Let \(M_{ij}\) be the \(n\times n\) matrix with \(1\) in the \((i,j)^{th}\) position and zeros elsewhere. Choose \(A\in\mathfrak{I}\) such that \(a=a_{ij}\neq 0\). Then, for \(1\leq k\leq n\), \(M_{ki}AM_{jk}\) is a matrix which has \(a\) in the \((k,k)^{th}\) entry and \(0\) elsewhere. Since \(\mathfrak{I}\) is an ideal, \(M_{ki}AM_{jk}\in\mathfrak{I}\). The sum of these matrices is \(a\mathfrak{I}\) and so this matrix is also in \(\mathfrak{I}\). However, since \(\mathbf{F}\) is a field, \(a\) is invertible, so \(\mathfrak{I}=M_{n}(\mathbf{F})\).

\(M_{n\times n}(\mathbf{F})\) is an \(\mathbf{F}\)-vector field, and if we identify \(\mathbf{F}\) with \(\{a\mathfrak{I}\,|\,a\in\,\mathbf{F}\}\), we see that any ring homomorphism induces a vector space homomorphism. Hence, if \(M_{n\times n}(\mathbf{F})\) and \(M_{(n+1)\times(n+1)}(\mathbf{F})\) are isomorphic as rings, they are isomorphic as vector spaces. However, they have different dimensions (\(n^{2}\) and \((n+1)^{2}\), respectively), so this is impossible.

**Solution to 6.10.4:** Each element of \(\mathbf{F}\) induces a constant function on \(X\), and we identify the function with the element of \(\mathbf{F}\). In particular, the function \(1\) is the unit element in \(R(X,\mathbf{F})\).

Let \(\mathfrak{I}\) be a proper ideal of \(R(X,\mathbf{F})\). We will prove that there is a nonempty subset \(Y\) of \(X\) such that \(\mathfrak{I}=\{f\in R(X,\mathbf{F})\,|\,f(x)=0\ \forall x\in Y\}=\mathfrak{I}_{Y}\). Suppose not. Then either \(\mathfrak{I}\subset\mathfrak{I}_{Y}\) for some set \(Y\) or, for every point \(x\in X\), there is a function \(f_{x}\) in \(\mathfrak{I}\) such that \(f_{x}(x)=a\neq 0\). In the latter case, since \(\mathfrak{I}\) is an ideal and \(\mathbf{F}\) is a field, we can replace \(f_{x}\) by the function \(a^{-1}f_{x}\), so we may assume that \(f_{x}(x)=1\). Multiplying \(f_{x}\) by the function \(g_{x}\), which maps \(x\) to \(1\) and all other points of \(X\) to \(0\), we see that \(\mathfrak{I}\) contains \(g_{x}\) for all points \(x\in X\). But then, since \(X\) is finite, \(\mathfrak{I}\) contains \(\sum g_{x}\equiv 1\), which implies that \(\mathfrak{I}\) is not a proper ideal.

Hence, there is a nonempty set \(Y\) such that \(\mathfrak{I}\subset\mathfrak{I}_{Y}\). Let \(Y\) be the largest such set. As for every \(x\not\in Y\), there is an \(f_{x}\in\mathfrak{I}\) such that \(f_{x}(x)\neq 0\) (otherwise we would have \(\mathfrak{I}\subset\mathfrak{I}_{Y\cup\{x\}}\)) by an argument similar to the above, \(\mathfrak{I}\) contains all the functions \(g_{x}\), \(x\not\in Y\). But, from these, we can construct any function in \(\mathfrak{I}_{Y}\), so \(\mathfrak{I}_{Y}\subset\mathfrak{I}\).

Let \(\mathfrak{I}\) and \(\mathfrak{I}\) be two ideals, and the associated sets be \(Y\) and \(Z\). Then \(\mathfrak{I}\subset\mathfrak{I}\) if and only if \(Z\subset Y\). Therefore, an ideal is maximal if and only if its associated set is as small as possible without being empty. Hence, the maximal ideals are precisely those ideals consisting of functions which vanish at one point of \(X\).

**Solution to 6.10.5:** Let \(\mathfrak{I}=\langle a^{n}-1,a^{m}-1\rangle\) and \(\mathfrak{I}=\langle a^{d}-1\rangle\). For \(n=rd\) the polynomial \(x^{n}-1\) factors into \((x^{d}-1)(x^{r(d-1)}+x^{r(d-2)}+\cdots+x^{r}+1)\). Therefore, in \(R\), \(a^{n}-1=(a^{d}-1)(a^{r(d-1)}+a^{r(d-2)}+\cdots+a^{r}+1)\). A similar identity holds for \(a^{m}-1\). Hence, the two generators of \(\mathfrak{I}\) are in \(\mathfrak{I}\), so \(\mathfrak{I}\subset\mathfrak{I}\).

Since \(d=\gcd\{n,m\}\), there exist positive integers \(x\) and \(y\) such that \(xn-ym=d\). A calculation gives

\[a^{d}-1 = a^{d}-1-a^{d+ym}+a^{xn}\] \[= -a^{d}(a^{ym}-1)+a^{xn}-1\] \[= -a^{d}(a^{m}-1)(a^{y(m-1)}+\cdots+a^{y}+1)\] \[+(a^{n}-1)(a^{x(n-1)}+\cdots+a^{x}+1).\]

Hence, \(a^{d}-1\) is in \(\mathfrak{I}\), so \(\mathfrak{I}\subset\mathfrak{I}\) and the two ideals are equal.

**Solution to 6.10.6:** 1. If there is an ideal \(\mathfrak{I}\neq R\) of index, at most, \(4\), then there is also a maximal ideal of index, at most, \(4\), \(\mathfrak{M}\), say. Then \(R/\mathfrak{M}\) is a field of cardinality less than \(5\) containing an element \(\alpha\) with \(\alpha^{3}=\alpha+1\), namely \(\alpha=a+\mathfrak{M}\). By direct inspection, we see that none of the fields \(\mathbf{F}_{2}\), \(\mathbf{F}_{3}\), \(\mathbf{F}_{4}\) contains such an element. Therefore, \(\mathfrak{I}=R\).

2. Let \(R=\mathbb{Z}_{5}\), \(a=2\) (mod \(5\)), and \(\mathfrak{I}=\{0\}\).

_Solution 2._ Since \(R/\mathfrak{I}\) has order less than \(5\), two of the elements \(0,1,a,a^{2},a^{3}\) have the same image in \(R/\mathfrak{I}\). Then \(\mathfrak{I}\) contains one of their differences, that is, one of

\[1\,,\,a\,,\,a^{2}\,,\,a^{3}\,,\,a-1\,,\,a^{2}-1\,,\,a^{3}-1\,,\,a(a-a)\,,\,a(a ^{2}-1)\,,\,a^{2}(a-1).\]But all these elements are units, since

\[a(a-1)(a+1)=a(a^{2}-1)=1,\qquad a^{3}-1=a.\]

Therefore, \(\mathfrak{I}\) contains a unit, so \(\mathfrak{I}=R\).

**Solution to 6.10.7:** Let \(\mathfrak{I}\) be such an ideal. Consider \(\varphi:R\to R/\mathfrak{I}\), the quotient map. Since \(R/\mathfrak{I}\) is a three element ring with \(1\), it must be isomorphic to \(\mathbb{Z}_{3}\). If \(u\in R^{*}\) is a unit then so is \(\varphi(u)\). Hence, \(\varphi(u)=\pm 1\), and \(\varphi(u^{2})=1\). As the squares of the units generate the additive group of \(R\), this uniquely determines \(\varphi\) so there is, at most, one such \(\mathfrak{I}\).

**Solution to 6.10.8:** It suffices to show that if \(ab-ba\) is any generator of \(\mathfrak{I}\) and if \(c\) is any element of \(R\), then \(abc-bac\) is in \(\mathfrak{I}\). By the definition of \(\mathfrak{I}\), \(a(bc)-(bc)a\) is an element of \(\mathfrak{I}\). Further, since \(\mathfrak{I}\) is a left ideal, \(b(ca-ac)=bca-bac\) is an element of \(\mathfrak{I}\). Therefore, \(abc-bac=abc-bca+bca-bac\) is in \(\mathfrak{I}\), and we are done.

**Solution to 6.10.9:** The fact that this map is a ring homomorphism follows from the fact that the inclusion map \(R\to S\) is a ring homomorphism mapping \(mR\) into \(mS\). Let \(1=an+bm\), with integers \(a\), \(b\). Let \(r\in R\) be in the kernel. Then \(r=ms\) for some \(s\in S\), so \(r=(am+bn)r=m(ar+bns)\). Since \(R\) has index \(n\) in \(S\), we have \(ns\in R\) and so \(r\in mR\). This shows that the map is an injection. Now suppose \(s\in S\). Then \(s=(am+bn)s\equiv b(ns)\bmod mS\). As \(ns\in R\), the map is a surjection.

**Solution to 6.10.11:** We have \(\mathfrak{I}=\langle i\rangle\) and \(\mathfrak{I}=\langle j\rangle\), for some \(i,j\in R\). Suppose first that \(\mathfrak{I}+\mathfrak{I}=R\). Then \(1\in\mathfrak{I}+\mathfrak{I}\), so \(1=ri+sj\) for some \(r,s\in R\). Therefore, the greatest common divisor of \(i\) and \(j\) is \(1\). Now \(\mathfrak{I}\) and \(\mathfrak{I}\cap\mathfrak{I}\) are both ideals and, clearly, have generators \(ij\) and \(k\), respectively, where \(k\) is the least common multiple of \(i\) and \(j\). But the greatest common divisor of \(i\) and \(j\) is \(1\), so \(ij=k\), and \(\mathfrak{I}\mathfrak{I}=\mathfrak{I}\cap\mathfrak{I}\). Since every implication in the previous argument can be reversed, if \(\mathfrak{I}\mathfrak{I}=\mathfrak{I}\cap\ \mathfrak{I}\), then \(\mathfrak{I}+\mathfrak{I}=R\) and we are done.

### 6.11 Polynomials

**Solution to 6.11.2:** If \(P(z)\) is a polynomial of degree \(n\) with \(\alpha\) as a root, then \(z^{n}P(1/z)\) is a polynomial of degree \(n\) with \(1/\alpha\) as a root.

**Solution to 6.11.3:** Since \(\zeta\) is a primitive seventh root of unity, we have

\[\zeta^{6}+\zeta^{5}+\cdots+\zeta+1=0.\]

Dividing this by \(\zeta^{3}\), we get

\[(\zeta^{3}+\zeta^{-3})+(\zeta^{2}+\zeta^{-2})+(\zeta+\zeta^{-1})+1=0.\]As \((\zeta+\zeta^{-1})^{2}=(\zeta^{2}+\zeta^{-2})+2\) and \((\zeta+\zeta^{-1})^{3}=(\zeta^{3}+\zeta^{-3})+3(\zeta+\zeta^{-1})\), the above equation becomes, letting \(\alpha=(\zeta+\zeta^{-1})\),

\[\alpha^{3}+\alpha^{2}-2\alpha-1=0.\]

**Solution to 6.11.4:** 1. Let \(x=\sqrt{5}+\sqrt{7}\). Squaring and rearranging successively, we get

\[x-\sqrt{5} =\sqrt{7}\] \[x^{2}-2\sqrt{5}x+5 =7\] \[x^{2}-2 =2\sqrt{5}x\] \[x^{4}-24x^{2}+4 =0\]

This calculation shows that \(\sqrt{5}+\sqrt{7}\) is a root of \(f(x)=x^{4}-24x^{2}+4\).

2. If \(f\) had a linear factor, then it would have a rational root, but a calculation shows that none of \(\pm 1\), \(\pm 2\) is such a root (if \(p/q\) in lowest terms is a root of \(a_{n}x^{n}+\cdots+a_{0}\) then, \(p|a_{0}\) and \(q|a_{n}\)). Suppose now that for some \(a,b,c,d\in\mathbb{Z}\),

\[f(x)=(x^{2}+ax+b)(x^{2}+cx+d).\]

Since the coefficient of \(x^{3}\) in \(f\) is zero, \(c=-a\), so we have

\[f(x)=(x^{2}+ax+b)(x^{2}-ax+d).\]

As the coefficient of \(x\) in \(f\) is zero, we get \(ad-ab=0\). If \(a=0\), then \(f(x)=(x^{2}+b)(x^{2}+d)=x^{4}+(b+d)x^{2}+bd\), but the equations \(bd=4\), \(b+d=-24\) have no integer solutions. If \(b=d\), then \(f(x)=(x^{2}+ax+b)(x^{2}-ax+b)=x^{4}+(2b-a^{2})x^{2}+b^{2}\), so \(b^{2}=4\) and \(2b-a^{2}=-24\), which also have no solutions in \(\mathbb{Z}\).

**Solution to 6.11.5:** It is easy to see that \(\sqrt{2}+\sqrt[3]{3}\) is a zero of a monic polynomial \(p\in\mathbb{Z}[x]\) (use the process described on Problem 6.11.4.) If it were a rational number, it would have to be an integer, since its denominator would divide the leading coefficient of \(p\). As \(\sqrt{2}+\sqrt[3]{3}\) is strictly between 2 and 3, it must be irrational.

_Solution 2._ Suppose \(\sqrt{2}+\sqrt[3]{3}\in\mathbb{Q}\). Then \(\mathbb{Q}\left(\sqrt{2}\right)=\mathbb{Q}\left(\sqrt[3]{3}\right)\). However, this contradicts the fact that the fields \(\mathbb{Q}\left(\sqrt{2}\right)\) and \(\mathbb{Q}\left(\sqrt[3]{3}\right)\) have degrees 2 and 3 over \(\mathbb{Q}\), respectively, since by Eisenstein Criterion [Her75, pag. 160], the polynomials \(x^{2}-2\) and \(x^{3}-3\) are irreducible over \(\mathbb{Q}\).

**Solution to 6.11.6:** Suppose that \(\omega\) is a primitive \(k^{th}\) root of unity and that \(\omega_{i}=\omega^{i}\) for \(1\leq i\leq k\). Let \(P(z)=a_{0}+a_{1}z+\cdots+a_{j}z^{j}\) (\(j<k\)); we have

\[\frac{1}{k}\sum_{i=1}^{k}P(\omega^{i})=\frac{1}{k}\sum_{i=1}^{k}\sum_{r=0}^{j }a_{r}\omega^{ir}=\frac{1}{k}\sum_{r=0}^{j}a_{r}\sum_{i=1}^{k}\omega^{ir}\]Since \(\omega^{k}=1\), we have \(\omega^{rk}-1=0\) for \(1\leq r\leq j\). Factoring and replacing \(1\) by \(\omega^{rk}\), we get

\[0=(\omega^{r}-1)(\omega^{rk}+\omega^{r(k-1)}+\cdots+\omega^{r}).\]

Since \(r<k\) and \(\omega\) is a primitive root of unity, \(\omega^{r}\neq 1\). Therefore,

\[\omega^{rk}+\omega^{r(k-1)}+\cdots+\omega^{r}=0.\]

Substituting this into the above equality gives

\[\frac{1}{k}\sum_{i=1}^{k}P(\omega^{i})=\frac{1}{k}\sum_{i=1}^{k}a_{0}\omega^{0 i}=a_{0}=P(0).\]

**Solution to 6.11.7:** By the Euclidean Algorithm, the vector space \(V=\mathbb{Q}\left[x\right]/\langle f\rangle\) has dimension \(d=\deg(f)\). Therefore, the infinitely many equivalence classes

\[\bar{x}^{2},\bar{x}^{3},\bar{x}^{5},\ldots\]

are linearly dependent in \(V\), so we can let \(q_{i}\) be a finite collection of rational numbers not all zero and satisfying

\[q_{2}\bar{x}^{2}+q_{3}\bar{x}^{3}+q_{5}\bar{x}^{5}+\cdots=0.\]

This means that

\[q_{2}x^{2}+q_{3}x^{3}+q_{5}x^{5}+\cdots=f(x)g(x)\]

for some nonzero \(g\in Q[x]\).

**Solution to 6.11.8:** First, note that each polynomial \(p(x)\) in \(\mathbb{Z}[x]\) is congruent modulo \(x-7\) to a unique integer, namely the remainder one obtains by using the division algorithm to divide \(x-7\) into \(p(x)\). (Only integer coefficients arise in the process, because the coefficient of \(x\) in \(x-7\) is \(1\).) If \(p(x)\) lies in \(\mathfrak{I}\), then so does the preceding remainder. However, the only members of \(\mathfrak{I}\cap\mathbb{Z}\) are the integers that are divisible by \(15\). In fact, if \(k\) is in \(\mathfrak{I}\cap\mathbb{Z}\), say \(k=(x-7)q(x)+15r(x)\), then \(k=15r(7)\). Hence, we get a well defined map from \(\mathbb{Z}[x]/\mathfrak{I}\) into \(\mathbb{Z}_{15}\) by sending \(p(x)+\mathfrak{I}\) to \(k+15\mathbb{Z}\), where \(k\) is the remainder one gets when dividing \(p(x)\) by \(x-7\). The map is clearly a homomorphism. If \(p(x)\) is not a unit in \(\mathfrak{I}\), then the remainder is clearly not divisible by \(15\), from which we conclude that the map is one-to-one. The map is obviously surjective. It is, thus, the required isomorphism.

_Solution 2._ The map \(\varphi:\mathbb{Z}[x]\to\mathbb{Z}[x]\) defined by \(\varphi\left(p(x)\right)=p(x+7)\) is a ring automorphism and it maps \(\mathfrak{I}\) onto the ideal generated by \(x\) and \(15\). The quotient ring \(\mathbb{Z}[x]/\varphi(\mathfrak{I})\) is isomorphic to \(\mathbb{Z}_{15}\) under the map \(p(x)\mapsto p(0)+15\mathbb{Z}\), implying the desired conclusion.

**Solution to 6.11.9:**\(\mathfrak{I}\) is prime. To show this we will prove that the quotient ring \(\mathbb{Z}[x]/\mathfrak{I}\) is a field. Since \(5\in\mathfrak{I}\), this quotient ring is isomorphic to \(\mathbb{Z}_{5}[x]/\langle x^{3}+x+1\rangle\). So it suffices to show that \(x^{3}+x+1\) is irreducible (mod \(5\)). If it were reducible, it would have a linear factor, and, hence, a zero. But we can evaluate this polynomial for each \(x\in\mathbb{Z}_{5}\) as follows:

\[\begin{array}{c|c}x&x^{3}+x+1\\ \hline\\ 0&1\\ 1&3\\ 2&1\\ 3&1\\ 4&4\end{array}\]

Since there is no zero, the polynomial is irreducible, and the quotient ring \(\mathbb{Z}_{5}[x]/\langle x^{3}+x+1\rangle\) is a field.

**Solution to 6.11.12:** Case 1: \(p=2\). In this case, define a map of \(\mathbf{F}_{2}[x]\) into itself by \(\varphi(1)=1\) and \(\varphi(x)=x+1\), and extend it in the obvious way. Since constants are fixed and \(\varphi(x+1)=x\), it is clear that this is a ring isomorphism. Further, \(\varphi(x^{2}-2)=(x-1)^{2}-2=x^{2}+1=x^{2}-3\); we see that \(\varphi\) maps the ideal \(\langle x^{2}-2\rangle\) onto the ideal \(\langle x^{2}-3\rangle\). It follows immediately from this that the two rings \(\mathbf{F}_{2}[x]/\langle x^{2}-2\rangle\) and \(\mathbf{F}_{2}[x]/\langle x^{2}-3\rangle\) are isomorphic.

Case 2: \(p=5\). By checking all the elements of \(\mathbf{F}_{5}\), we see that \(x^{2}-2\) and \(x^{2}-3\) are both irreducible polynomials in \(\mathbf{F}_{5}[x]\). Therefore, the ideals they generate are maximal and the quotient rings \(\mathbf{F}_{5}[x]/\langle x^{2}-2\rangle\) and \(\mathbf{F}_{5}[x]/\langle x^{2}-3\rangle\) are fields. The Euclidean Algorithm [Her75, pag. 155] shows that each is a finite field with \(25\) elements. Since finite fields of the same order are isomorphic, the quotient rings in this case are isomorphic.

Case 3: \(p=11\). In this case, checking all the elements of \(\mathbf{F}_{11}\) shows that \(x^{2}-2\) is irreducible, but \(x^{2}-3=(x-5)(x+5)\) is not. Hence, the quotient ring \(\mathbf{F}_{11}[x]/\langle x^{2}-2\rangle\) is a field, whereas \(\mathbf{F}_{11}[x]/\langle x^{2}-3\rangle\) is not, so the two quotient rings are not isomorphic in this case.

**Solution to 6.11.13:** Since \(x-3\) is a monic polynomial, given any polynomial \(r(x)\) in \(\mathbb{Z}[x]\), there exist polynomials \(t(x)\) and \(s(x)\) such that \(r(x)=t(x)(x-3)+s(x)\) and \(\deg s(x)<\deg(x-3)=1\). Hence, \(s(x)\) is a constant, and so it is congruent modulo \(7\) to some \(\alpha\), \(0\leq\alpha\leq 6\). Hence, \(r(x)-\alpha=t(x)(x-3)+(s(x)-\alpha)\), and the right-hand term is clearly an element of \(\mathfrak{I}\).

In the special case where \(r(x)=x^{250}+15x^{14}+x^{2}+5\), we have, by the Euclidean Algorithm [Her75, pag. 155], \(r(x)=t(x)(x-3)+\alpha\). Substituting \(x=3\), we get \(r(3)=\alpha\). Since we only need to know \(\alpha\) modulo \(7\), we reduce \(r(3)\) mod \(7\) using the fact that \(n^{7}\equiv n\pmod{7}\), getting \(r(3)\equiv 3^{4}+3^{2}+3^{2}+5\equiv 6\pmod{7}\). Hence, \(\alpha=6\) is the desired value.

**Solution to 6.11.14:** Let \(\varphi:\mathbb{Z}[x]\to\mathbb{Z}_{13}\) be the unique ring homomorphism such that \(\varphi(x)=4\). A polynomial \(\alpha(x)\in\mathbb{Z}[x]\) is in the kernel of \(\varphi\) if and only if \(\alpha(4)\equiv 0\pmod{13}\). This occurs if and only if \(\alpha(x)\equiv(x-4)\beta(x)\pmod{13}\) for some \(\beta(x)\in\mathbb{Z}[x]\), i.e., exactly when \(\alpha(x)=(x-4)\beta(x)+13\gamma(x)\) for some \(\gamma(x)\in\mathbb{Z}[x]\), in other words if and only if \(\alpha(x)\in\mathfrak{I}\).

Set \(f(x)=(x^{26}+x+1)^{73}\in\mathbb{Z}[x]\); then \(f(x)-m\in\mathfrak{I}\) if and only if \(\varphi(f(x)-m)=0\), which holds if and only if \(f(4)\equiv m\pmod{13}\).

By Fermat's Little Theorem [14, pag. 80], [10, pag. 44], if \(a\in\mathbb{Z}\) is not divisible by the prime \(p\) then \(a^{p-1}\equiv 1\pmod{p}\). This gives \((4^{26}+4+1)\equiv(4^{2}+5)\equiv 8\pmod{13}\), and \(f(4)\equiv 8^{73}\equiv 8\pmod{13}\). So \(m=8\) is the unique integer in the range \(0\leq m\leq 12\) such that \((x^{26}+x+1)^{73}-m\in\mathfrak{I}\).

**Solution to 6.11.16:** Let \(\varphi:\mathbb{Z}[x]\to\mathbb{Z}[x]\) be any automorphism. Since \(\varphi\) is determined by the value of \(x\), every element of \(\mathbb{Z}[x]\) must be a polynomial in \(\varphi(x)\). In order to get \(x\) in the image of \(\varphi\), we see that \(\varphi(x)\) must be of the form \(\pm x+\alpha\) for some constant \(\alpha\).

**Solution to 6.11.20:** If the fraction \(p/q\) in lowest terms is a zero of \(x^{10}+x^{9}+x^{8}+\cdots+x+1\), then \(p|1\) and \(q|1\), so the possible rational zeros are \(\pm 1\). A calculation shows that neither of these is a zero, so the given polynomial is irreducible over \(\mathbb{Q}\). \(-1\) is a zero of the second polynomial, so it is reducible over \(\mathbb{Q}\).

**Solution to 6.11.21:** Note that \(539=7^{2}\cdot 11\), \(511=7\cdot 23\), and \(847=7\cdot 11^{2}\). Thus, all the coefficients except the leading one are divisible by \(7\), but the constant term is not divisible by \(7^{2}\). Since \(7\) is a prime, by Eisenstein Criterion [10, pag. 160], the polynomial is irreducible in \(\mathbb{Z}[x]\).

**Solution to 6.11.22:** By the Gauss Lemma [1, pag. 85], an integral polynomial that can be factored over rationals can be factored into polynomials of the same degree over the integers. Since \(\pm 1\) are not roots (and they are the only ones possible because \(a_{0}=a_{n}=1\)), there are no linear terms and the only possible factorizations are in polynomials of degree \(2\).

* \((x^{2}+ax+1)(x^{2}+bx+1)\)
* \((x^{2}+ax-1)(x^{2}+bx-1)\)

In the first, case we get \(x^{4}+(a+b)x^{3}+(2+ab)x^{2}+(a+b)x+1\), which implies that the coefficients of the terms of degree \(1\) and \(3\), are the same, a contradiction. The other case is analogous, showing that the polynomial is irreducible over \(\mathbb{Q}\).

**Solution to 6.11.23:** We will use Eisenstein Criterion [10, pag. 160]. Let \(x=y+1\). We have

\[x^{p-1}+x^{p-2}+\cdots+1=(y+1)^{p-1}+(y+1)^{p-2}+\cdots+1\]\[=\frac{(y+1)^{p}-1}{(y+1)-1}\] \[=\frac{\sum_{k=0}^{p}\left(\begin{array}{c}p\\ k\end{array}\right)y^{k}-1}{y}\] \[=\sum_{k=1}^{p}\left(\begin{array}{c}p\\ k\end{array}\right)y^{k-1}\] \[=y^{p-1}+py^{p-2}+\cdots+p.\]

Since the prime \(p\) divides all the coefficients except the first and \(p^{2}\) does not divide the last, it follows that the polynomial is irreducible in \(\mathbb{Q}[x]\). Therefore, the given polynomial must also be irreducible, since if it were not, the same change of variables would give a factorization of the new polynomial.

**Solution to 6.11.24:** Put \(x=y+1\) to get

\[f(x)=\frac{x^{5}-1}{x-1}+5x=\frac{(y+1)^{5}-1}{y}+5y+5.\]

The coefficients of \(y^{3}\), \(y^{2}\), \(y\), and \(1\) are integers divisible by \(p=5\) and the constant term is \(10\), which is not divisible by \(p^{2}\). Thus, by Eisenstein Criterion [10, pag. 160], \(f\) is irreducible over \(\mathbb{Q}\).

**Solution to 6.11.25:** Let \(f(x)=x^{3}+x+2\). A calculation shows that \(2\) is a zero of \(f(x)\) over \(\mathbb{Z}_{3}\), but \(0\) and \(1\) are not. Hence, we get the factorization \(f(x)=(x-2)(x^{2}+2x+2)=(x-2)g(x)\). Clearly, \(0\) and \(1\) are not roots of \(g(x)\) since they are not roots of \(f(x)\); another calculation shows that \(2\) is not a root of \(g(x)\). Hence, \(g(x)\) is irreducible, and the above factorization is the desired one.

**Solution to 6.11.30:** Suppose, to the contrary, that \(x^{p}-a\) has nontrivial factors \(f(x)\) and \(g(x)\) in \(\mathbb{F}[x]\). Let \(\mathbb{K}\) be a splitting field of \(x^{p}-a\). Then, in \(\mathbb{K}\), there are elements \(a_{1},\ldots,a_{p}\) such that \(x^{p}-a=(x-a_{1})\cdots(x-a_{p})\). We may assume without loss of generality that \(f(x)=(x-a_{1})\cdots(x-a_{k})\) and \(g(x)=(x-a_{k+1})\cdots(x-a_{p})\). Therefore, \(A=a_{1}\cdots a_{k}=\pm f(0)\) and \(B=a_{k+1}\cdots a_{p}=\pm g(0)\) are both elements of \(\mathbb{F}\). Further, since the \(a_{j}\)'s are zeros of \(x^{p}-a\), \(a_{j}^{p}=a\) for all \(j\). Hence, \(A^{p}=a^{k}\) and \(B^{p}=a^{p-k}\). Since \(k\) and \(p\) are relatively prime, there exist integers \(x\) and \(y\) such that \(kx+py=1\). Let \(r=-y\) and \(s=x+y\). Then \(A^{s}/B^{r}\) is an element of \(\mathbb{F}\) and

\[\left(\frac{A^{s}}{B^{r}}\right)^{p}=\frac{a^{s}k}{a^{rp-rk}}=a^{kx+py}=a.\]

Hence, \(a\) is a \(p^{th}\) power, contradicting our assumptions. Therefore, \(x^{p}-a\) must be irreducible over \(\mathbb{F}\).

**Solution to 6.11.31:** Suppose \(g(x)\) (or \(h(x)\)) is not irreducible. Then \(x^{4}+1\) has a linear factor and, hence, a zero. In other words, there is an element \(a\in\mathbb{Z}_{p}\) with \(a^{4}=-1\). It follows that \(a^{8}=1\), and since \(a^{4}\neq 1\) (\(p\) is odd), \(a\) has order \(8\) in the multiplicative group \(\mathbb{Z}_{p}^{\star}\) of the field with \(p\) elements. But \(\mathbb{Z}_{p}^{\star}\) is a group of order \(p-1\equiv 2\pmod{4}\), so \(8\) cannot divide \(p-1\), and we have a contradiction.

**Solution to 6.11.32:** Let \(\deg f=n\). Then the collection of all real polynomials of \(\deg\leq n-1\) is an \(m\)-dimensional vector space. Hence, any collection of \(n+1\) polynomials of degree \(\leq n-1\) is linearly dependent. By the Euclidean Algorithm [Her75, pag. 155], we have

\[\begin{array}{rcl}x^{2^{0}}&=&q_{0}(x)f(x)+r_{0}(x)\quad\text{with }\deg r_{0}<n\\ x^{2^{1}}&=&q_{1}(x)f(x)+r_{1}(x)\quad\text{with }\deg r_{1}<n\\ &\vdots\\ x^{2^{n}}&=&q_{n}(x)f(x)+r_{n}(x)\quad\text{with }\deg r_{n}<n.\end{array}\]

The polynomials \(r_{0},\ldots,r_{n}\) are linearly dependent, so, for some \(\alpha_{i}\in\mathbb{R}\), we have

\[\sum\alpha_{i}r_{i}(x)=0.\]

Therefore,

\[p(x)=\sum\alpha_{i}x^{2^{i}}=f(x)\sum\alpha_{i}q_{i}(x)\]

and \(f(x)|p(x)\).

**Solution to 6.11.33:** Fix \(f\in R\setminus\mathbf{F}\) of least degree \(n\), say. Choose polynomials \(f_{1},f_{2},\ldots,f_{n-1}\) in \(R\) such that \(\deg f_{j}\equiv j\pmod{n}\) and such that each \(f_{j}\) is of least degree with this property, \(1\leq j\leq n-1\), if such a polynomial exists, otherwise take \(f_{j}=0\). Let \(f_{n}=f\). We will prove that \(R=\mathbf{F}[f_{1},f_{2},\ldots,f_{n}]\). Suppose not, and fix \(g\in R\setminus\mathbf{F}[f_{1},f_{2},\ldots,f_{n}]\) of least degree, and suppose \(\deg g\equiv j\pmod{n}\). For some \(k\geq 0\), \(\deg g=\deg(f_{n}^{k}f_{j})\). Hence, \(g-\alpha f_{n}^{k}f_{j}\) is of lower degree than \(g\) for some \(\alpha\in\mathbf{F}\), and, by the minimality of \(g\), must lie in \(\mathbf{F}[f_{1},f_{2},\ldots,f_{n}]\). However, this implies that \(g\in\mathbf{F}[f_{1},f_{2},\ldots,f_{n}]\) as well.

### 6.12 Fields and Their Extensions

**Solution to 6.12.1:** Since the \(2\times 2\) matrices over a field form a ring, to show that \(R\) is a commutative ring with \(1\) it suffices to show that it is closed under addition and multiplication, commutative with respect to multiplication, and contains \(I\). The first and the last are obvious, and the second follows almost as quickly fromThe inverse of a nonzero element in \(R\) is given by

\[\frac{1}{a^{2}+b^{2}}\left(\begin{array}{cc}a&b\\ -b&a\end{array}\right)\]

which lies in \(R\) provided that \(a^{2}+b^{2}\neq 0\). If \(\mathbf{F}=\mathbb{Q}\), then \(a^{2}+b^{2}>0\) for \(a\) and \(b\) not both equal to \(0\); hence, every nonzero element of \(R\) has an inverse, so \(R\) is a field. If \(\mathbf{F}=\mathbb{C}\), then the matrix

\[\left(\begin{array}{cc}i&-1\\ 1&i\end{array}\right)\]

has no inverse since \(i^{2}+1^{2}=0\). Therefore, in this case, \(R\) is not a field. Similarly, if \(\mathbf{F}=\mathbb{Z}_{5}\), we have that \(2^{2}+1^{2}=0\), so there exists a noninvertible matrix in \(R\) and so \(R\) is not a field. Finally, if \(\mathbf{F}=\mathbb{Z}_{7}\), the equation \(a^{2}+b^{2}=0\) has no nonzero solutions, so every nonzero element of \(R\) has an inverse and \(R\) is a field.

**Solution to 6.12.2:** Let \(R\) be a finite integral domain. Let \(0\neq b\in R\) and enumerate the elements of \(R\) by \(c_{1},c_{2}\ldots,c_{n}\). Since \(R\), has no zero divisors, cancellation shows that the elements \(bc_{i}\) are distinct. Since there are \(n\) of them, it follows that there is an element \(c_{i_{0}}\) such that \(bc_{i_{0}}=1\). Hence, \(c_{i_{0}}\) is the inverse of \(b\) and we are done.

**Solution to 6.12.3:** Since \(a\) and \(b\) are algebraic over \(\mathbf{F}\), there exist integers \(n\) and \(m\) such that \([\mathbf{F}(a):\mathbf{F}]=n\) and \([\mathbf{F}(b):\mathbf{F}]=m\). Because \(b\) is algebraic over \(\mathbf{F}\), it must also be algebraic over \(\mathbf{T}=\mathbf{F}(a)\) of degree, at most, \(m\). Hence, \([\mathbf{T}(b):\mathbf{F}(a)]\leq m\), which implies

\[[\mathbf{T}(b):\mathbf{F}]=[\mathbf{T}(b):\mathbf{F}(a)][\mathbf{F}(a): \mathbf{F}]\leq nm.\]

Therefore, \(\mathbf{T}(b)\) is a finite extension of \(\mathbf{F}\). \(\mathbf{T}(b)\) contains \(a+b\) and so contains \(\mathbf{F}(a+b)\); the latter must, therefore, be a finite extension of \(\mathbf{F}\), so \(a+b\) is algebraic over \(\mathbf{F}\).

**Solution to 6.12.4:** From the fact that the group is finite, we can see that all elements are in the unit circle, otherwise consecutive powers would make an infinite sequence.

All elements of the group arc roots of unity (maybe of different dcgrees), since a high enough power will end up in \(1\) (the order of an element always divides the order of the group). We will prove that they are all roots of unity of the same degree. Let \(\alpha\) be the element with smallest positive argument (\(\arg\alpha\in(0,2\pi)\)). We will show that this element generates the whole group. Suppose that there is an element \(\beta\) that is not in the group generated by \(\alpha\). There is a \(p\in\mathbb{N}\) such that

\[\arg\alpha^{p}<\arg\beta<\arg\alpha^{p+1}\]therefore,

\[\arg(\beta\alpha^{-p})<\arg\alpha\]

which contradicts the minimality of \(\arg\alpha\). We conclude then that the group is generated by \(\alpha\). See also the Solution to Problem 6.12.5.

**Solution to 6.12.5:** Let \(G\) be a finite subgroup of \(\mathbf{F}^{*}\) of order \(n\). By the Structure Theorem for finite abelian groups [Her75, pag. 109], there are integers \(m_{1}|m_{2}|\cdots|m_{k}\) such that \(G\) is isomorphic to \(\mathbb{Z}_{m_{1}}\oplus\cdots\oplus\mathbb{Z}_{m_{k}}\). To show that \(G\) is cyclic, it suffices to show that \(m_{k}=n\). Suppose that \(m_{k}<n\). From the structure of \(G\) we know that \(g^{m_{k}}=1\) for every \(g\in G\). Hence, the polynomial \(x^{m_{k}}-1\) has \(n\) roots, contradicting the fact that a polynomial over a field has no more roots than its degree. Hence, \(m_{k}=n\) and \(G\) is cyclic.

**Solution to 6.12.6:** Since \(x^{3}-2\) is irreducible over \(\mathbb{Q}\left[x\right]\), \(\langle x^{3}-2\rangle\) is a maximal ideal in \(\mathbb{Q}\left[x\right]\), so \(\mathbf{F}=\mathbb{Q}\left[x\right]/\langle x^{3}-2\rangle\) is a field. Using the relationship \(\bar{x}^{3}=2\), we get that every element of \(\mathbf{F}\) can be written in the form \(a+b\bar{x}+c\bar{x}^{2}\), where \(a,b,c\in\mathbb{Q}\). Further, such a representation is unique, since otherwise we could find \(a,b,c\in\mathbb{Q}\), not all \(0\), with \(a+b\bar{x}+c\bar{x}^{2}=0\). On pulling back to \(\mathbb{Q}\left[x\right]\), we find that \(x^{3}-2\) divides \(a+bx+cx^{2}\), a contradiction.

Consider the map \(\varphi:\mathbf{F}\rightarrow\mathbf{F}\) given by \(\varphi(a)=a\) if \(a\in\mathbb{Q}\), and \(\varphi(\sqrt[3]{2}\,)=\bar{x}\). Since \((\sqrt[3]{2}\,)^{3}=2\) and \(\bar{x}^{3}=2\) this extends to a ring epimorphism in the obvious way. It is also one-to-one, since if \(\varphi(a+b\sqrt[3]{2}+c\sqrt[3]{4}\,)=0\) then \(a+b\bar{x}+c\bar{x}^{2}=0\), so \(a=b=c=0\). Hence, \(\mathbf{F}\) is the isomorphic image of a field, and it is field.

Further, by the isomorphism we see that every element can be expressed uniquely in the desired form. In particular, \((1-\sqrt[3]{2}\,)(-1-\sqrt[3]{2}-\sqrt[3]{4}\,)=1\).

**Solution to 6.12.7:** Consider the ring homomorphism \(\varphi:\mathbb{Z}\rightarrow\mathbf{F}\) that satisfies \(\varphi(1)=1\). Since \(\mathbf{F}\) is finite, \(\ker\varphi\neq 0\). Since \(\mathbf{F}\) is a field, it has characteristic \(p\), where \(p\) is a prime number. Hence, \(\ker\varphi\) contains the ideal \(\langle p\rangle\), which is maximal. Therefore, \(\ker\varphi=\langle p\rangle\), and the image of \(\mathbb{Z}\) is a subfield of \(\mathbf{F}\) isomorphic to \(\mathbb{Z}_{p}\). Identify \(\mathbb{Z}_{p}\) with this subfield. Then \(\mathbf{F}\) is a vector space over \(\mathbb{Z}_{p}\), and it must be of finite dimension since \(\mathbf{F}\) is finite. Let \(\dim\mathbf{F}=r\). A counting argument shows that \(\mathbf{F}\) has \(p^{r}\) elements.

**Solution to 6.12.8:** Since \(\mathbf{F}\) has characteristic \(p\), it contains a subfield isomorphic to \(\mathbb{Z}_{p}\), which we identify with \(\mathbb{Z}_{p}\). For \(j\in\mathbb{Z}_{p}\), \(\alpha+j\) is an element of \(\mathbf{F}(\alpha)\). Using the identity \((\alpha+j)^{p}=\alpha^{p}+j^{p}\), we get

\[f(\alpha+j)=\alpha^{p}-\alpha+3+j^{p}-j=0.\]

Therefore, \(f\) has \(p\) roots in \(\mathbf{F}(\alpha)\), which are clearly distinct.

**Solution to 6.12.9:** Notice that \(\mathbb{Q}\left[x\right]\) is an Euclidean domain, so the ideal \(\langle f,g\rangle\) is generated by a single polynomial, \(h\) say. \(f\) and \(g\) have a common root if and only if that root is also a root of \(h\). We can use the Euclidean algorithm to find \(h=x^{2}+3x+1\), which has roots \(-3/2\pm\sqrt{5}/2\). Therefore, \(f\) and \(g\) have exactly two common roots, both in \(\mathbb{Q}\left(\sqrt{5}\,\right)\).

**Solution to 6.12.10:** Let \(x\) be an element of \(\mathbf{F}\) that is not in \(\mathbb{Q}\,\). Then \(x\) satisfies an equation \(ax^{2}+bx+c=0\) with \(a\), \(b\), and \(c\in\mathbb{Q}\,\). Completing the square, we see that \(\left(x+\frac{a}{2}\right)^{2}\in\mathbb{Q}\,\), whereas \(\left(x+\frac{a}{2}\right)\not\in\mathbb{Q}\,\). Let \(\xi=\left(x+\frac{a}{2}\right)\). As \(\xi^{2}\in\mathbb{Q}\,\), we can write it as \(\frac{c^{2}}{d^{2}}m\), where \(c,d,m\in\mathbb{Z}\) and \(m\) is square free (i.e., \(m\) has no multiple prime factors). As \(\mathbf{F}=\mathbb{Q}\,\left(\xi\right)=\mathbb{Q}\,\left(\frac{d}{c}\xi\right)\), we get an isomorphism \(\mathbf{F}\rightarrow\mathbb{Q}\,\left(\sqrt{m}\right)\) by sending \(r+s\left(\frac{d}{c}\xi\right)\) to \(r+s\sqrt{m}\). The uniqueness of \(m\) follows from the fact that the elements of \(\mathbf{F}\) that are not in \(\mathbb{Q}\,\) but whose squares are in \(\mathbb{Q}\,\) are those of the form \(k\xi\) for some nonzero \(k\in\mathbb{Q}\,\).

**Solution to 6.12.11:** Let \(p_{1}=2\), \(p_{2}=3\),..., be the prime numbers and \(\mathbf{F}_{i}=\mathbb{Q}\,\left(\sqrt{p_{i}}\,\right)\). Claim: The fields \(\mathbf{F}_{i}\) are pairwise nonisomorphic. Indeed, if \(\mathbf{F}_{i}\) were isomorphic to \(\mathbf{F}_{j}\), then there would exist \(r\in\mathbf{K}_{j}\) such that \(r^{2}=p_{i}\). Write such an \(r\) in the form

\[r=a+b\sqrt{p_{j}}\qquad a,b\in\mathbb{Q}\,.\]

Then

\[r^{2}=a^{2}+b^{2}p_{j}+2ab\sqrt{p_{j}}=p_{i}\]

if and only if \(ab=0\). Therefore, either \(p_{i}=c^{2}\) or \(p_{j}=c^{2}\) for some \(c\in\mathbb{Q}\,\), which contradicts the primality of \(p_{i}\) and \(p_{j}\).

**Solution to 6.12.12:**

\[\left(\cos\frac{\theta}{3}+i\sin\frac{\theta}{3}\right)^{3} = \cos\theta+i\sin\theta\] \[\Rightarrow 3\sin\frac{\theta}{3}-4\sin^{3}\frac{\theta}{3}=\sin\theta\] \[\Rightarrow E_{\theta}\supset F_{\theta}\]

All the possibilities can occur. For example

\[\dim_{F_{\theta}}E_{\theta} = 1\quad\text{if}\quad\theta=\frac{\pi}{2}\] \[\dim_{F_{\theta}}E_{\theta} = 2\quad\text{if}\quad\theta=\pi\] \[\dim_{F_{\theta}}E_{\theta} = 3\quad\text{if}\quad\theta=\frac{\pi}{6}\]

In the last example, \(4x^{3}-3x+1/2\) or \(8x^{3}-6x+1\) is irreducible because \(\pm 1\), \(\pm 1/2\), \(\pm 1/4\), and \(\pm 1/8\) are not roots of the above polynomial.

**Solution to 6.12.13:** 1. A \(2\times 2\) matrix over \(\mathbf{F}\) is invertible if and only if the first column is nonzero and the second is not a \(\mathbf{F}\)-multiple of the first.

This gives \(|{\bf F}|^{2}-1=p^{2n}-1\) possibilities for the first column of an invertible matrix, and, given the first column, \(|{\bf F}|^{2}-|{\bf F}|=p^{2n}-p^{n}\) for the second, hence the result. See also Problem 7.1.1 for a more general solution.

2. The map \({\bf F}\to G\) sending \(a\) to \(\left(\begin{smallmatrix}1&a\\ 0&1\end{smallmatrix}\right)\) is easily checked to be an injective group homomorphism. Its image is a subgroup \(S\) of \(G\) that is isomorphic to the additive group of \({\bf F}\) and that, consequently, has order \(p^{n}\). By 1., this is the largest power of \(p\) dividing the order of \(G\). Hence, \(S\) is, in fact, a \(p\)-Sylow subgroup of \(G\). Since all \(p\)-Sylow subgroups of a finite group are conjugate (and hence isomorphic), this implies the result.

**Solution to 6.12.14:** The zero element of \({\bf F}_{p}\) obviously has a unique square root and a unique cube root. Let \({\bf F}_{p}^{*}\) denote the multiplicative group of nonzero elements of \({\bf F}_{p}\). It is a cyclic group of order \(p-1\). Since \(p-1\) is even, the homomorphism \(x\to x^{2}\) of \({\bf F}_{p}^{*}\) into itself has a kernel of order \(2\), which means that its range has order \((p-1)/2\). There are, thus, \(1+(p-1)/2\) elements of \({\bf F}_{p}\) with square roots.

If \(p-1\) is not divisible by \(3\), the homomorphism \(x\to x^{3}\) of \({\bf F}_{p}^{*}\) into itself has a trivial kernel, and so every element of \({\bf F}_{p}\) has a cube root. If \(3\) divides \(p-1\), then the preceding homomorphism has a kernel of order \(3\), so its range has order \((p-1)/3\). In this case, there are \(1+(p-1)/3\) elements of \({\bf F}_{p}\) with cube roots.

**Solution to 6.12.15:** All functions are polynomials. A polynomial with the value \(1\) at \(0\) and \(0\) elsewhere is \(p(x)=1-x^{q-1}\); from this one, we can construct any function by considering sums \(\sum f_{i}\cdot p(x-x_{i})\). Thus, there are \(q^{q}\) such functions, and that many polynomials. Another way is to observe that all polynomials of degree, at most, \(q-1\) define nonzero functions unless the polynomial is the zero polynomial.

**Solution to 6.12.16:** Let \({\bf K}\) be that subfield. The homomorphism of multiplicative groups \({\bf F}^{*}\to{\bf K}^{*}\) sending \(x\) to \(x^{3}\) has a kernel of order, at most, \(3\), so \(|{\bf K}^{*}|\geq|{\bf F}^{*}|/3\), that is, \((|{\bf F}|-1)/(|{\bf K}|-1)\leq 3\). Also, if the extension degree \([{\bf F}:{\bf K}]\) equals \(n\), then \(n\geq 2\), so \(|{\bf F}|=|{\bf K}|^{n}\geq|{\bf K}|^{2}\), and \((|{\bf F}|-1)/(|{\bf K}|-1)\geq|{\bf K}|+1\), with equality if and only if \(n=2\). Thus, \(3\geq|{\bf K}|+1\), which gives \(|{\bf K}|=2\), \(n=2\), and \(|{\bf F}|=2^{2}=4\).

**Solution to 6.12.17:** As \(A\) has dimension at least \(2\) as a vector space over \({\mathbb{C}}\,\), it contains an element \(a\) which is not in the subspace spanned by the identity element \(1\in A\). Since \(A\) has finite dimension over \({\mathbb{C}}\,\), there exists a complex number \(\lambda\) such that \((a-\lambda 1)x=0\) for some nonzero \(x\in A\). Let \({\mathfrak{E}}\) be the ideal generated by \(b=a-\lambda 1\), and \({\mathfrak{F}}=\{x\in A\,|\,bx=0\}\) the annihilator of \(b\). We have \({\mathfrak{E}}\cap{\mathfrak{F}}=\{0\}\) since all the elements of \({\mathfrak{E}}\cap{\mathfrak{F}}\) have zero square. As the dimensions of \({\mathfrak{E}}\) and \({\mathfrak{F}}\) add up to the dimension of \(A\) we must have \(A={\mathfrak{E}}\oplus{\mathfrak{F}}\) as vector spaces over \({\mathbb{C}}\,\). Since \({\mathfrak{E}}\) and \({\mathfrak{F}}\) are ideals in \(A\), \(A={\mathfrak{E}}\oplus{\mathfrak{F}}\) as rings. Let \(1=e+f\) with \(e\in{\mathfrak{E}}\) and \(f\in{\mathfrak{F}}\). Then \(e^{2}=e\), \(f^{2}=f\) and neither of them is zero or \(1\).

### 6.13 Elementary Number Theory

**Solution to 6.13.1:** Let the six people be Aline, Laura, Lucia, Manuel, Raquel, and Stephanie. Fix one of them, Manuel, say. The five girls form two sets: \(X\) (Manuel's friends) and \(Y\) (the others). By the Pigeonhole Principle [Her75, pag. 127], one of these sets has cardinality at least 3. Suppose it is \(X\) that contains at least three elements, say \(\{\)Aline, Laura, Stephanie\(\}\subset X\). If Aline, Laura, and Stephanie are pairwise strangers, we are done. Otherwise, two of them are friends of each other, Stephanie and Aline, say. Then Manuel, Aline, and Stephanie are mutual friends. If the set with three or more elements is \(Y\), a similar argument leads to the same conclusion.

**Solution to 6.13.3:** If \(a=0\), the congruence has the trivial solution \(x=0\). For \(1\leq a\leq p-1\), if \(x^{2}\equiv a\pmod{p}\), we have

\[(p-x)^{2}=p^{2}-2xp+x^{2}\equiv a\pmod{p}\]

so, for \(a\neq 0\), there are two solutions of the quadratic congruence in each complete set of residues mod p. We conclude, then, that the total number is \(1+(p-1)/2=(p+1)/2\).

**Solution to 6.13.4:** By Fermat's Little Theorem [Sta89, pag. 80], [Her75, pag. 44], we have, raising both sides of the congruence \(-1\equiv x^{2}\pmod{p}\) to the power \((p-1)/2\),

\[(-1)^{\frac{p-1}{2}}\equiv x^{p-1}\equiv 1\pmod{p}\]

which implies that \((p-1)/2\) is even, and the result follows.

**Solution to 6.13.5:** Let \(f(n)=2^{n}+n^{2}\). If \(f(n)\) is prime, then it is congruent with 1, or 5 \(\pmod{6}\). Suppose \(f(n)=6k+1\) for some integer \(k\). We have

\[2^{f(n)}+f(n)^{2}=2^{6k+1}+36k^{2}+12k+1=\left(2^{2}\right)^{3k}2+36k^{2}+12k+1\]

which is a multiple of 3. If \(f(n)=6k+5\), we have

\[2^{f(n)}+f(n)^{2}=\left(2^{2}\right)^{3k}2^{2}2+36k^{2}+60k+25\equiv 2+1\equiv 0 \pmod{3}\]

so \(f(n)\) is a composite as well.

**Solution to 6.13.6:** 1. It is enough to show that the set of units is closed for multiplication. Let \(a\) and \(b\) be units with \(a\alpha\equiv 1\pmod{n}\), \(b\beta\equiv 1\pmod{n}\). Then, clearly, \(\alpha\) and \(\beta\) are also units, and we have

\[(ab)(\beta\alpha)\equiv 1\pmod{n}\]

so \(ab\) is also a unit.

2. The congruence \(ka\equiv 1\pmod{n}\) is equivalent to the equation \(ka=mn+1\) for some integer \(m\). As all integer linear combinations of \(k\) and \(n\) are multiples of \(\gcd\{k,n\}\), the first congruence has a solution iff \(\gcd\{k,n\}=1\).

3. Let \(\varphi\) be Euler's totient function [Sta89, pag. 77], [Hcr75, pag. 43]. As \(\varphi\) is multiplicative, we have

\[\varphi(n)=\varphi(p)\varphi(q)=(p-1)(q-1).\]

**Solution to 6.13.7:** Let \(p(t)=3t^{3}+10t^{2}-3t\) and \(n/m\in\mathbb{Q}\) ; \(\gcd\{n,m\}=1\). We can assume \(m\neq\pm 1\). If \(p(n/m)=k\in\mathbb{Q}\), then \(m|3\) and \(n|k\). Therefore, we have \(m=\pm 3\).

Suppose \(m=3\). We have

\[p\left(\frac{n}{3}\right)=n\left(\frac{n^{2}}{9}+10\frac{n}{9}-1\right).\]

This expression represents an integer exactly when \(n^{2}+10n=n(n+10)\equiv 0\pmod{9}\). As \(\gcd\{n,3\}=1\), this means \(n+10\equiv 0\pmod{9}\), that is, \(n\equiv 8\pmod{9}\).

A similar argument for the case \(m=-3\) shows that the numbers \(n/(-3)\) with \(n\equiv 1\pmod{9}\) produce integer values in \(p\).

**Solution to 6.13.8:**

\[\binom{1/2}{n} =\frac{(\frac{1}{2})(\frac{1}{2}-1)\cdots(\frac{1}{2}-(n-1))}{n!} =\frac{(-1)^{n-1}\cdot 3\cdot 5\cdots(2n-1)}{2^{n}n!}\] \[=\frac{(-1)^{n-1}\cdot 2\cdot 3\cdot 4\cdot 5\cdots 2n}{(2^{n}n!)^{ 2}}=\frac{(-1)^{n-1}}{2^{2n}}\cdot\binom{2n}{n}\]

**Solution to 6.13.9:** A counting argument shows that the power of 2 which divides \(n!\) is given by

\[\sum_{k\geq 1}\left\lfloor\frac{n}{2^{k}}\right\rfloor,\]

where \(\lfloor x\rfloor\) denotes the largest integer less than or equal to \(x\). Since \(c_{n}=(2n)!/(n!)^{2}\), to show that \(c_{n}\) is even it suffices to show that

\[\sum_{k\geq 1}\left\lfloor\frac{2n}{2^{k}}\right\rfloor>2\sum_{k\geq 1}\left\lfloor \frac{n}{2^{k}}\right\rfloor.\]

Suppose \(2^{r}\leq n<2^{r+1}\). For \(k\leq r\), there is an \(r_{k}\), \(0\leq r_{k}<1\), such that

\[\frac{n}{2^{k}}=\left\lfloor\frac{n}{2^{k}}\right\rfloor+r_{k}\]or

\[\frac{2n}{2^{k}}=2\left\lfloor\frac{n}{2^{k}}\right\rfloor+2r_{k}\]

so

\[\left\lfloor\frac{2n}{2^{k}}\right\rfloor\geq 2\left\lfloor\frac{n}{2^{k}}\right\rfloor\]

and equality holds if and only if \(n\) is a power of \(2\). For \(k=r+1\), we have that \(\left\lfloor n/2^{r+1}\right\rfloor=0\) while \(\left\lfloor 2n/2^{r+1}\right\rfloor=1\). Finally, for \(k>r\), the terms in both sums are \(0\). Hence, we see that the above inequality holds. Further, we see that the left side is \(2\) or more greater than the right side (i.e., \(c_{n}\) is divisible by \(4\)) if and only \(n\) is not a power of \(2\).

**Solution to 6.13.10:** We may assume that \(n>3\). Converting the sum into a single fraction, we get

\[\frac{n!/1+n!/2+\cdots+n!/n}{n!}.\]

Let \(r\) be such that \(2^{r}|n!\) but \(2^{r+1}\) does not divide \(n!\), and \(s\) be such that \(2^{s}\) is the largest power of \(2\) less than or equal to \(n\). Since \(n>3\), \(r>s>0\). The only integer in \(1,\ldots,n\), divisible by \(2^{s}\) is \(2^{s}\). Hence, for \(1\leq k\leq n\), \(n!/k\) is divisible by \(2^{r-s}\), and every term except \(1\) is divisible by \(2^{r-s+1}\). So

\[\frac{n!/1+n!/2+\cdots+n!/n}{n!}=\frac{2^{r-s}(2j+1)}{2^{r}k}=\frac{2j+1}{2^{s}k}\]

for some integers \(j\) and \(k\). The numerator is odd and the denominator is even, so this fraction is never an integer.

**Solution to 6.13.11:** Recall that if \(p_{1},p_{2},\ldots\) is the sequence of prime numbers and \(x=\prod p_{i}^{\xi_{i}}\) and \(y=\prod p_{i}^{\eta_{i}}\), we have

\[\gcd\{x,y\}=\prod p_{i}^{\min\{\xi_{i},\eta_{i}\}}\qquad\operatorname{lcm}\{x, y\}=\prod p_{i}^{\max\{\xi_{i},\eta_{i}\}}.\]

Let

\[a=\prod p_{i}^{\alpha_{i}}\quad b=\prod p_{i}^{\beta_{i}}\quad c=\prod p_{i}^{ \gamma_{i}}\]

we have

\[\gcd\{a,\operatorname{lcm}\{b,c\}\} =\prod p_{i}^{\min\{\alpha_{i},\max\{\beta_{i},\gamma_{i}\}\}}\] \[=\prod p_{i}^{\max\{\min\{\alpha_{i},\beta_{i}\},\min\{\alpha_{i },\gamma_{i}\}\}}\] \[=\operatorname{lcm}\{\gcd\{a,b\},\gcd\{a,c\}.\}\]

**Solution to 6.13.12:** There are nine prime numbers \(\leq 25\):

\[p_{1}=2,\quad p_{2}=3,\quad p_{3}=5,\quad p_{4}=7,\quad p_{5}=11,\]\[p_{6}=13,\quad p_{7}=17,\quad p_{8}=19,\quad p_{9}=23.\]

By unique factorization, for each \(1\leq a\leq 25\) there is an integer sequence \(v(a)=(v_{j}(a))_{j=1}^{9}\) with \(a=\prod_{j=1}^{9}p_{j}^{v_{j}(a)}.\) The 10 sequences \(v(a_{i})\in\mathbb{Q}^{9}\) must be linearly dependent, so

\[\sum_{i=1}^{10}n_{i}v_{j}(a_{i})=0\]

for all \(j\), for some rational numbers \(n_{i}\) which are not all 0. Multiplying by a common multiple of the denominators, we can assume that the \(n_{i}\)'s are integers. So

\[\prod_{i=1}^{10}a_{i}^{n_{i}}=\prod_{j=1}^{9}p_{j}^{\sum_{i=1}^{10}n_{i}v_{j}( a_{i})}=1,\]

as required.

**Solution to 6.13.13:** Denote the given number by \(n\) and let \(n=a^{13}.\) By counting digits, we see that \(n<10^{26},\) so \(a<100.\) As \(8^{13}=7934527488,\) we have \(80^{13}<n\) and \(a>80.\) Note that \(n\equiv 9\pmod{10}.\) The integers \(c<10\) such that \(c^{k}\equiv 9\pmod{10}\) for some \(k\) are 3, 7 and 9. But \(3^{4}\equiv 7^{4}\equiv 9^{4}\equiv 1\pmod{10}\) and \(13=3\cdot 4+1,\) so \(c^{13}\equiv c^{3\cdot 4}c\equiv c\equiv 9\pmod{10}\) so \(c=9.\) Hence, \(a=89\) or \(a=99.\) As 3 does not divide \(n,\) 3 does not divide \(a.\) Hence, \(a=89.\)

**Solution to 6.13.14:** Since \(17\equiv 7\pmod{10},\)

\[A\equiv 7^{17^{17}}\pmod{10}.\]

Since \((7,10)=1,\) we can apply Euler's Theorem [14, pag. 80], [17, pag. 43]:

\[7^{\varphi(10)}\equiv 1\pmod{10}.\]

The numbers \(k\) such that \(1\leq k\leq 10\) and \((k,10)=1\) are precisely 1, 3, 7, and 9, so \(\varphi(10)=4.\) Now \(17\equiv 1\pmod{4},\) so \(17^{17}\equiv 1\pmod{4}.\) Thus,

\[7^{17^{17}}\equiv 7^{1}\equiv 7\pmod{10}\]

and the rightmost decimal digit of \(A\) is 7.

**Solution to 6.13.15:** As \(23\equiv 3\pmod{10},\) it suffices to find \(3^{23^{23^{23}}}\pmod{10}.\) We have \(\varphi(10)=4,\) where \(\varphi\) is Euler's totient function, and, by Euler's Theorem [14, pag. 80], \([\text{Her75, pag.\ 43}],3^{r}\equiv 3^{s}\pmod{10}\) when \(r\equiv s\pmod{4}.\) So we will find \(23^{23^{23}}\pmod{4}.\) We have \(23\equiv 3\pmod{4},\) so \(23^{23^{23}}\equiv 3^{23^{23}}\pmod{4}.\) As \(-1\equiv 3\pmod{4},\)\(3^{23^{23}}\equiv(-1)^{23^{23}}\equiv-1\pmod{4},\) because \(23^{23}\) is odd. Hence, \(23^{23^{23}}\equiv 3\pmod{4},\) and \(3^{23^{23^{23}}}\equiv 3^{3}\equiv 7\pmod{10}.

**Solution to 6.13.16:** Let

\[\begin{array}{rcl}N_{0}&=&\{0,1\}\cup\{4,5,6\}\cup\{11,12,13,14,15\}\cup\cdots\\ N_{1}&=&\{2,3\}\cup\{7,8,9,10\}\cup\{16,17,18,19,20,21\}\cup\cdots\end{array}\]

We have

\[N_{0}\cap N_{1}=\emptyset,\qquad N_{0}\cup N_{1}=\mathbb{Z}_{+}\]

and, clearly, neither can contain an arithmetic progression.

**Solution to 6.13.17:** Consider the ring \(\mathbb{Z}_{a^{k}-1}\). Since \(a>1\), \((a,a^{k}-1)=1\), so \(a\in\mathbb{Z}_{a^{k}-1}^{*}\). Further, it is clear that \(k\) is the least integer such that \(a^{k}\equiv 1\pmod{a^{k}-1}\), so \(k\) is the order of \(a\) in \(\mathbb{Z}_{a^{k}-1}^{*}\). Hence, by Lagrange's Theorem [10, pag. 41], \(k\) divides the order of the group \(\mathbb{Z}_{a^{k}-1}^{*}\), which is \(\varphi(a^{k}-1)\).

**Solution to 6.13.18:** Let \(N\) be the desired greatest common divisor. By Fermat's Little Theorem [12, pag. 80], [10, pag. 44], we have

\[n^{13}\equiv(n^{6})^{2}n\equiv(n^{3})^{2}n\equiv n^{4}\equiv n^{2}\equiv n \pmod{2}.\]

Hence, \(2|(n^{13}-n)\) for all \(n\), so \(2|N\). An identical calculation shows that \(p|N\) for \(p\in\{3,5,7,13\}\). Since these are all prime, their product, \(2730\), divides \(N\). However, \(2^{13}-2=8190=3\cdot 2730\), so \(N\) is either \(2730\) or \(3\cdot 2730\). As \(3^{13}-3=3(3^{12}-1)\) is not divisible by \(9\), \(N=2730\).

**Solution to 6.13.19:** Let

\[n=p_{1}^{k_{1}}p_{2}^{k_{2}}\cdots p_{n}^{k_{n}}\]

be the factorization into a product of prime powers (\(p_{1}<p_{2}<\cdots<p_{n}\)) for \(n\). The positive integer divisors of \(n\) are then the numbers

\[p_{1}^{j_{1}}p_{2}^{j_{2}}\cdots p_{n}^{j_{n}}\qquad 0\leq j\leq k_{j}.\]

It follows that \(d(n)\) is the number of \(r\)-tuples \((j_{1},j_{2},\ldots,j_{r})\) satisfying the preceding conditions. In other words,

\[d(n)=(k_{1}+1)(k_{2}+1)\cdots(k_{n}+1),\]

which is odd iff each \(k_{i}\) is even; in other words, iff \(n\) is a perfect square.

## 7 Linear Algebra

### Vector Spaces

**Solution to 7.1.1:** 1. Every element of \(V\) can be uniquely written in the form \(a_{1}v_{1}+\cdots+a_{n}v_{n}\), where the \(v_{i}\)'s form a basis of \(V\) and the \(a_{i}\)'s are elements of \(\mathbf{F}\). Since \(\mathbf{F}\) has \(q\) elements it follows that \(V\) has \(q^{n}\) elements.

2. A matrix \(A\) in \(GL_{n}(\mathbf{F})\) is nonsingular if and only if its columns are linearly independent vectors in \(\mathbf{F}^{n}\). Therefore, the first column \(A_{1}\) can be any nonzero vector in \(\mathbf{F}^{n}\), so there are \(q^{n}-1\) possibilities. Once the first column is chosen, the second column, \(A_{2}\), can be any vector which is not a multiple of the first, that is, \(A_{2}\neq cA_{1}\), where \(c\in\mathbf{F}\), leaving \(q^{n}-q\) choices for \(A_{2}\). In general, the \(i^{th}\) column \(A_{i}\) can be any vector which cannot be written in the form \(c_{1}A_{1}+c_{2}A_{2}+\cdots+c_{i-1}A_{i-1}\) where \(c_{j}\in\mathbf{F}\). Hence, there are \(q^{n}-q^{i-1}\) possibilities for \(A_{i}\). By multiplying these together we see that the order of \(GL_{n}(\mathbf{F})\) is \((q^{n}-1)(q^{n}-q)\cdots(q^{n}-q^{n-1})\).

3. The determinant clearly induces a homomorphism from \(GL_{n}(\mathbf{F})\) onto the multiplicative group \(\mathbf{F}^{*}\), which has \(q-1\) elements. The kernel of the homomorphism is \(SL_{n}(\mathbf{F})\), and the cosets with respect to this kernel are the elements of \(GL_{n}(\mathbf{F})\) which have the same determinant. Since all cosets of a group must have the same order, it follows that the order of \(SL_{n}(\mathbf{F})\) is \(|GL_{n}(\mathbf{F})|/(q-1)\).

**Solution to 7.1.2:** If \(p\) is prime then the order of \(GL_{2}(\mathbb{Z}_{p})\) is the number of ordered bases of a two-dimensional vector space over the field \(\mathbb{Z}_{p}\), namely \((p^{2}-1)(p^{2}-p)\), as in the solution to Part 2 of Problem 7.1.1 above.

A square matrix \(A\) over \(\mathbb{Z}_{p^{n}}\) is invertible when \(\det(A)\) is invertible modulo \(p^{n}\), which happens exactly when \(\det(A)\) is not a multiple of \(p\). Let \(\rho(A)\) denote the matrix over \(\mathbb{Z}_{p}\) obtained from \(A\) by reducing all its entries modulo \(p\). We have \(\det(\rho(A))\equiv\det(A)\pmod{p}\), thus

\[A\in GL_{2}\left(\mathbb{Z}_{p^{n}}\right)\quad\text{iff}\quad\rho(A)\in GL_{2 }\left(\mathbb{Z}_{p}\right),\]

giving a surjective homomorphism

\[\rho:GL_{2}\left(\mathbb{Z}_{p^{n}}\right)\to GL_{2}\left(\mathbb{Z}_{p} \right).\]

The kernel of \(\rho\) is composed of the \(2\times 2\) matrices that reduce to the Identity modulo \(p\) so the diagonal entries come from the set \(\{1,p+1,2p+1,\ldots,p^{n}-p+1\}\) and the off-diagonal are drawn from the set that reduce to \(0\) modulo \(p\), that is, \(\{0,p,2p,\ldots,p^{n}-p\}\). Both sets have cardinality \(p^{n-1}\), so the order of the kernel is \((p^{n-1})^{4}\), and order of \(GL_{2}\left(\mathbb{Z}_{p}\right)\) is

\[p^{4n-4}(p^{2}-1)(p^{2}-p)=p^{4n-3}(p-1)(p^{2}-1).\]

**Solution to 7.1.3:** Let \(\mathbf{F}=\{0,1,a,b\}\). The lines through the origin can have slopes \(0\), \(1\), \(a\), \(b\), or \(\infty\), so \(S\) has cardinality \(5\). Let \(L_{s}\) be the line through the origin with slope \(y\). Suppose \(\gamma\in G\) fixes all these lines, to be specific say

\[\gamma=\left(\begin{matrix}x&y\\ z&w\end{matrix}\right).\]

Then

\[\gamma L_{0}=L_{0}\]

implies that

\[\gamma(1,0)^{t}=(x,z)^{t}=(c,0)^{t}\]

for some \(c\neq 0\). Thus, \(z=0\). Similarly, the invariance of \(L_{\infty}\) implies \(y=0\) and of \(L_{1}\) implies \(x=w\). Then \(\det(\gamma)=x^{2}=1\) and since \(\mathbf{F}\) has characteristic \(2\), we must have \(x=1\) and \(\gamma\) is the identity.

**Solution to 7.1.4:**\(1\). \(\mathbf{F}[x]\) is a ring under polynomial addition and multiplication because \(\mathbf{F}\) is a ring. The other three axioms of vector addition - associativity, uniqueness of the zero, and inverse - are trivial to verify; as for scalar multiplication, there is a unit (same as in \(\mathbf{F}\)) and all four axioms are trivial to verify, making it a vector field.

\(2\). To see this, observe that the set \(\{1,x,x^{2},\ldots,x^{n}\}\) form a basis for this space, because any linear combination will be zero, if and only if, all coefficients are zero, by looking at the degree on both sides.

\(3\). An argument as above shows that

\[a_{0}1+a_{1}(x-a)+\cdots+a_{n}(x-a)^{n}=0\]only if the coefficients are all zero.

**Solution to 7.1.5:** Let \(Y\) denote the given intersection. Then \(Y\) is a subspace of \(V\) and, clearly, \(W\subset Y\). Suppose that there exists a nonzero vector \(v\in Y\setminus W\). Since \(v\) is not in \(W\), a set consisting of \(v\) and a basis for \(W\) is linearly independent. Extend this to a basis of \(V\), and let \(Z\) be the \(n-1\)-dimensional subspace obtained by omitting \(v\) from this basis. Then \(W\subset Z\), so \(Z\) is a term in the intersection used to define \(Y\). However, \(v\) is not in \(Z\), so \(v\) cannot be an element of Y, a contradiction. Hence, \(Y\subset W\) and we are done.

**Solution to 7.1.6:** We use the Induction Principle [12, pag. 7] on the dimension of \(V\). If \(\dim V=1\), the only proper subspace is \(\{0\}\), so \(V\) is clearly not the union of a finite number of proper subspaces.

Now suppose the result is true for dimension \(n-1\) and that there is a \(V\), \(\dim V=n\), with

\[V=\bigcup_{i=1}^{k}W_{i},\]

where we may assume \(\dim W_{i}=n-1\), \(1\leq i\leq k\). Suppose that there existed a subspace \(W\) of \(V\) of dimension \(n-1\) which was not equal to any of the \(W_{i}\)'s. We have

\[W=\bigcup_{i=1}^{n}(W\cap W_{i}).\]

But \(\dim(W\cap W_{i})\leq n-2\), and this contradicts our induction hypothesis.

Therefore, to complete the proof, it remains to show that such a subspace \(W\) exists. Fix a basis \(x_{1},\ldots,x_{n}\) of \(V\). For each \(\alpha\in\mathbb{F}\), \(\alpha\neq 0\), consider the \(n-1\)-dimensional subspace given by

\[W_{\alpha}=\{a_{1}x_{1}+\cdots+a_{n}x_{n}\,|\,a_{1}+\cdots+a_{n-1}+\alpha a_{n }=0\}.\]

Any two of these subspaces intersect in a subspace of dimension, at most, \(n-2\), so they are distinct. Since there are infinitely many of these, because \(\mathbb{F}\) is infinite, we can find \(W\) as desired.

_Solution 2._ Suppose that \(V=\cup_{1\leq i\leq k}V_{i}\). After discarding superfluous \(V_{i}\)'s, we may assume that

\[V\neq\bigcup_{i\neq i_{0}}V_{i}\qquad\text{for all}\qquad 1\leq i_{0}\leq k.\]

Then \(k\geq 2\), and there must be vectors \(v_{1},v_{2}\) in \(V\) such that

\[(1)\quad v_{1}\in V_{1}\setminus\bigcup_{i\neq 1}V_{i}\qquad\text{and}\qquad(2) \quad v_{2}\in V_{2}\setminus\bigcup_{i\neq 2}V_{i}.\]

Let \((x_{s})\) be sequence of distinct, nonzero elements of the field. Then, for each \(s\), the vector \(u_{s}=v_{1}+x_{s}v_{2}\) does not lie in \(V_{1}\cup V_{2}\) (if \(u_{s}\in V_{1}\)then \(v_{2}=(u_{s}-v_{1})/x_{s}\in V_{1}\), contradicting (1); similarly, \(u_{s}\not\in V_{2}\).) It follows that, for all \(s\), \(u_{s}\in\cup_{i\neq 1,2}V_{i}\). Since the vectors \(u_{s}\) are all distinct, it follows that, for some \(s\neq s^{\prime}\) and \(i\neq 1,2\), \(u_{s}\) and \(u_{s^{\prime}}\) lie in \(V_{i}\). But then \(v_{2}=(u_{s}-u_{s^{\prime}})/(x_{s}-x_{s^{\prime}})\in V_{i}\), contradicting (2). Hence, \(V\neq\cup_{1\leq i\leq k}V_{i}\).

**Solution to 7.1.7:** Note first that if \(A\) and \(B\) are matrices and \(C\) is an invertible matrix, then

\[AB=BA\quad\text{iff}\quad C^{-1}ACC^{-1}BC=C^{-1}BCC^{-1}AC.\]

Also, if \(D_{1},\ldots,D_{n}\) are linearly independent matrices, so are the matrices \(C^{-1}D_{1}C,\ldots,C^{-1}D_{n}C\). We may then assume that \(A\) is in Jordan Canonical Form [13, pag. 247].

A direct calculation shows that if \(\tilde{A}=\left(\begin{array}{cccc}a&1&\ldots&0\\ &\ddots&\ddots&\\ &&&1\\ 0&&&a\end{array}\right)\) is a \(k\times k\)

Jordan block, then \(\tilde{A}\) commutes with \(\tilde{B}=\left(\begin{array}{cccc}b_{1}&b_{2}&&b_{k}\\ &\ddots&\ddots&b_{2}\\ 0&&&b_{1}\end{array}\right)\).

Therefore, by block multiplication, \(A\) commutes with any matrix of the form

\[B=\left(\begin{array}{cccc}\tilde{B}_{1}&&&\\ &\ddots&\\ &&&\tilde{B}_{r}\end{array}\right)\]

where the \(\tilde{B}_{r}\)'s have the form of \(\tilde{B}\) and the same dimension as the Jordan blocks of \(A\). Since there are \(n\) variables in \(B\), \(\dim C(A)\geq n\).

**Solution to 7.1.8:**\(\operatorname{tr}(AB-BA)=0\), so \(S\) is contained in the kernel of the trace. Since the trace is a linear transformation from \(M_{n\times n}(\mathbb{R})=\mathbb{R}^{n^{2}}\) onto \(\mathbb{R}\), its kernel must have dimension, at most, \(n^{2}-1\). Therefore, it suffices to show that \(S\) contains \(n^{2}-1\) linearly independent matrices.

Let \(M_{ij}\) denote the matrix with a \(1\) in the \((i,j)^{th}\) coordinate and \(0\)'s elsewhere. A calculation shows that for \(i\neq j\), \(M_{ij}=M_{ik}M_{kj}-M_{kj}M_{ik}\), so \(M_{ij}\) is in \(S\). Similarly, for \(2\leq j\leq n\), \(M_{11}-M_{jj}=M_{1j}M_{j1}-M_{j1}M_{1j}\). Together, these \(n^{2}-1\) matrices are clearly a linearly independent set.

**Solution to 7.1.9:** Let \(f,g\in S\) and let \(r\) and \(s\) be scalars. Then, for any \(v\in A\), \((rf+sg)(v)=f(rv)+g(sv)\in A\), since \(A\) is a vector subspace and \(f\) and \(g\) fix \(A\). Similarly \(rf+sg\) fixes \(B\), so \(rf+sg\in S\) and \(S\) is a vector space.

To determine the dimension of \(S\), it suffices to determine the dimension of the space of matrices which fix \(A\) and \(B\). To choose a basis for \(V\), let \(A^{\prime}\) denote a complementary subspace of \(A\cap B\) in \(A\) and let \(B^{\prime}\) denote a complementary subspace of \(A\cap B\) in \(B\). Then, since \(A+B=V\), \(r=a+b-n\) is the dimension of \(A\cap B\). Further, \(\dim A^{\prime}=a-r\) and \(\dim B^{\prime}=b-r\). Take one basis in each of the spaces \(A^{\prime}\), \(B^{\prime}\), and \(A\cap B\). The union of these bases form a basis for \(V\). Since any endomorphism which leaves \(A\) and \(B\) invariant must also fix \(A\cap B\), its matrix in this basis must have the form

\[\left(\begin{array}{ccc}*&*&*\\ 0&*&0\\ 0&0&*\end{array}\right)\]

which has, at most, \(a^{2}+b^{2}+n^{2}-an-bn\) nonzero entries, so the dimension of \(S\) is \(a^{2}+b^{2}+n^{2}-an-bn\).

**Solution to 7.1.10:** Suppose there are scalars such that

\[a_{0}x+a_{1}Tx+\cdots+a_{k}T^{k}x+\cdots+a_{m-1}T^{m-1}x=0\]

applying \(T^{m-1}\) to both sides, we get, since \(T0=0\),

\[a_{0}T^{m-1}x+a_{1}T^{m}x+\cdots+a_{k}T^{m-1+k}x+\cdots+a_{m-1}T^{m-1+m-1}x=0\]

so

\[a_{0}T^{m-1}x=0\]

and \(a_{0}=0\). By the Induction Principle [13, pag. 7] (multiplying by \(T^{m-k-1}\)) we see that all \(a_{k}=0\) and the set is linearly independent.

**Solution to 7.1.12:** Let \(P\) be the change of basis matrix from \((a_{i})\) to \((b_{i})\). A straightforward calculation shows that \(I+2P\) is the matrix taking \((a_{i})\) to \((a_{i}+2b_{i})\). Now \((I+2P)v=\lambda v\) implies that \(Pv=\frac{1}{2}(\lambda-1)v\). So if \(\lambda\) is an eigenvalue of \(I+2P\), then \(\frac{1}{2}(\lambda-1)\) is an eigenvalue of \(P\), and they correspond to the same eigenvectors. The reverse also holds, so there is a one-to-one correspondence between the eigenvalues of \(P\) and those of \(I+2P\). As \((a_{i})\) and \((b_{i})\) are orthonormal bases, \(P\) is orthogonal and therefore, all the eigenvalues of \(P\) are \(\pm 1\). But this implies that the only possible eigenvalues of \(I+2P\) are \(3\) and \(-1\). Hence, \(0\) is not an eigenvalue of \(I+2P\), so it is an invertible matrix and, thus, \((a_{i}+2b_{i})\) is a basis. Further, \(\det P=(-1)^{\alpha}1^{\beta}\), where \(\alpha\) and \(\beta\) are the algebraic multiplicities of \(-1\) and \(1\) as eigenvalues of \(P\). Thus, \(\det(I+2P)=(-1)^{\alpha}3^{\beta}\). Since we are given that \(\det P>0\), \(\alpha\) is even and, thus, \(\det(I+2P)\) is positive as well. Therefore, \((a_{i}+2b_{i})\) has the same orientation as \((a_{i})\).

### 7.2 Rank and Determinants

**Solution to 7.2.1:** 1. Let \(A=(a_{ij})\), and \(R_{i}\) denote the \(i^{th}\) row of \(A\). Let \(r\), \(1\leq r\leq m\), be the row rank of \(A\), and \(S_{i}=(b_{i1},\ldots,b_{in})\), \(1\leq i\leq r\), be a basis for the row space. The rows are linear combinations of the \(S_{i}\)'s:

\[R_{i}=\sum_{j=1}^{r}k_{ij}S_{j},\qquad 1\leq i\leq m.\]

For \(1\leq l\leq n\), isolating the \(l^{th}\) coordinate of each of these equations gives

\[a_{1l} = k_{11}b_{1l}+\cdots+k_{1r}b_{rl}\] \[a_{2l} = k_{21}b_{1l}+\cdots+k_{2r}b_{rl}\] \[\vdots\] \[a_{ml} = k_{m1}b_{1l}+\cdots+k_{mr}b_{rl}.\]

Hence, for \(1\leq l\leq n\) the \(l^{th}\) column of \(A\), \(C_{l}\), is given by the equation

\[C_{l}=\sum_{j=1}^{r}b_{jl}K_{j},\]

where \(K_{j}\) is the column vector \((k_{1j},\ldots,k_{mj})^{t}\). Hence, the space spanned by the columns of \(A\) is also spanned by the \(r\) vectors \(K_{j}\), so its dimension is less than or equal to \(r\). Therefore, the column rank of \(A\) is less than or equal to its row rank. In exactly the same way, we can show the reverse inequality, so the two are equal.

2. Using Gauss elimination we get the matrix

\[\left(\begin{array}{cccc}1&0&3&-2\\ 0&1&-4&4\\ 0&0&2&0\\ 0&0&2&0\\ 0&0&0&0\end{array}\right)\]

so the four columns of \(M\) are linearly independent.

3. If a set of rows of \(M\) is linearly independent over \(\mathbf{F}\), then clearly it is also independent over \(\mathbf{K}\), so the rank of \(M\) over \(\mathbf{F}\) is, at most, the rank of \(M\) over \(\mathbf{K}\).

**Solution to 7.2.2:** As \(A^{t}AV\subset A^{t}V\), it suffices to prove that \(\dim A^{t}AV=\dim A^{t}V\). We know that \(\operatorname{rank}A=\dim(\operatorname{Im}A)\) and that

\[\dim(\operatorname{Im}A)+\dim(\ker A)=n\]

Similar formulas hold for \(A^{t}A\). Therefore, it is enough to show that \(\ker A\) and \(\ker A^{t}A\) have the same dimension. In fact, they are equal. Clearly, \(\ker A\subset\ker A^{t}A\). Conversely, take any \(v\in\ker A^{t}A\). Then

\[0=\langle A^{t}Av,v\rangle=\langle Av,Av\rangle,\]so \(\|Av\|=0\). Hence, \(v\in\ker A\) and we are done.

**Solution to 7.2.3:** Since \(1-P-Q\) is invertible, \(P\) has the same rank as

\[P(1-P-Q)=P-P^{2}-PQ=-PQ.\]

Similarly, \(Q\) has the same rank as

\[(1-P-Q)Q=Q-PQ-Q^{2}=-PQ,\]

so \(P\) and \(Q\) have the same rank.

**Solution to 7.2.4:** 1. _and_ 2. Since \(T\) is symmetric it is diagonalizable, so \(\mathbb{R}^{n}\) can be written as the direct sum of the eigenspaces of \(T\). It suffices to show that any eigenspace has dimension, at most, 1. For if this is the case, then the kernel has dimension, at most, 1, and, by the Rank-Nullity Theorem [13, pag. 71], \(T\) has rank at least \(n-1\), and there must be \(n\) distinct eigenspaces, so there are \(n\) distinct eigenvalues associated with them.

Let \(\lambda\in\mathbb{R}\), and consider the system of equations \(Tx=\lambda x\). The first equation is \(a_{1}x_{1}+b_{1}x_{2}=\lambda x_{1}\). Since \(b_{1}\neq 0\), we can solve for \(x_{2}\) in terms of \(x_{1}\). Suppose that we can solve the first \(i-1\) equations for \(x_{2},\ldots,x_{i}\) in terms of \(x_{1}\). Then, since \(b_{i}\neq 0\), we can solve the \(i^{th}\) equation \(b_{i-1}x_{i-1}+a_{i}x_{i}+b_{i}x_{i+1}=\lambda x_{i}\) for \(x_{i+1}\) in terms of \(x_{1}\). Therefore, by the Induction Principle [12, pag. 7], we can solve the first \(n-1\) equations for \(x_{2},\ldots,x_{n}\) in terms of \(x_{1}\).

The last equation, \(b_{n-1}x_{n-1}+a_{n}x_{n}=\lambda x_{n}\), is either consistent with this or is not. If not, \(\lambda\) is not an eigenvalue; if it is, then \(\lambda\) is an eigenvalue and we have one degree of freedom in determining eigenvectors. Hence, in either case the associated eigenspace has dimension, at most, 1 and we are done.

_Solution 2._ 1. The submatrix one obtains by deleting the first row and the first column is upper triangular with nonzero diagonal entries, so its determinant is nonzero. Thus, the first \(n-1\) columns of \(T\) are linearly independent.

2. By the Spectral Theorem [13, pag. 335], [14, pag. 235], \(\mathbb{R}^{n}\) has a basis consisting of eigenvectors of \(T\). If \(\lambda\) is an eigenvalue of \(T\), then \(T-\lambda I\) has rank \(n-1\) by Part 1, so \(\ker(T-\lambda I)\) has dimension 1. Since the eigenspaces span \(\mathbb{R}^{n}\) and each has dimension 1, there must be \(n\) of them.

**Solution to 7.2.6:** 1. Write the characteristic polynomial of \(A\), \(\det(A-\lambda I)\), as \((-1)^{r}\lambda^{r}+c_{1}\lambda^{r-1}+\cdots+c_{r}\). Since the entries of \(A\) are integers, each \(c_{k}\) is an integer, and \(c_{r}=\det A\). If \(\lambda\) is an integer eigenvalue, then \(\det(A-nI)=0\), so

\[\det A=(-1)^{r-1}n^{r}+c_{1}n^{r-1}+\cdots+c_{r-1}n\]showing that \(n\) divides \(\det A\).

2. Under the given hypotheses, \(n\) is an eigenvalue with eigenvector \((1,1,\ldots,1)^{t}\), so Part 1 applies.

**Solution to 7.2.7:** We use the Induction Principle [11, pag. 32] in the order of the matrix. If \(n=2\),

\[A=\left(\begin{array}{cc}1&x_{1}\\ 1&x_{2}\end{array}\right)\]

which has determinant \((x_{2}-x_{1})\).

Suppose the result holds for all \(k<n\), and let \(A\) be the \(n\times n\) Vandermonde matrix [12, pag. 125]. Treating the indeterminates \(x_{1},\ldots,x_{n-1}\) as _constants_ and expanding the determinant of \(A\) along the last row, we see that \(\det A\) is an \((n-1)^{th}\) degree polynomial in \(x_{n}\), which can have, at most, \(n-1\) roots. If we let \(x_{n}=x_{i}\) for \(1\leq i\leq n-1\), \(A\) would have two identical rows, so \(\det A\) would equal 0. Hence, the \(x_{i}\)'s are the roots of \(\det A\) as a polynomial in \(x_{n}\). In other words, there exists a constant \(c>0\) such that

\[\det A=c\prod_{i=1}^{n-1}(x_{n}-x_{i}).\]

\(c\) is the coefficient of the \(x_{n}^{n-1}\) term, which, when we expand the determinant, is equal to the determinant of the \((n-1)\times(n-1)\) Vandermonde matrix. So, by the induction hypothesis,

\[\det A=\prod_{j<i\leq n-1}(x_{i}-x_{j})\prod_{i=1}^{n-1}(x_{n}-x_{i})=\prod_{i> j}(x_{i}-x_{j}).\]

**Solution to 7.2.8:** 1. As shown in the solution of Problem 7.2.7, the determinant of the matrix is

\[\prod_{i>j}(a_{i}-a_{j})\]

which is nonzero if the \(a_{i}\) are all different.

2. The function \(f\) given by

\[f(x)=\sum_{i=0}^{n}\frac{(x-a_{0})\cdots(x-a_{i-1})b_{i}(x-a_{i+1})\cdots(x-a_ {n})}{(a_{i}-a_{0})\cdots(a_{i}-a_{i-1})b_{i}(a_{i}-a_{i+1})\cdots(a_{i}-a_{n})}\]

has degree \(n\) and takes \(f(a_{i})\) into \(b_{i}\). Now, if \(\psi(x)\) is another such polynomial of degree \(n\), the polynomial

\[f(x)-\psi(x)\]has degree \(n\) with \(n+1\) different roots (the \(a_{i}\)'s), so it has to be the zero polynomial and \(f\) is unique.

**Solution to 7.2.9:** Consider the function \(v(t)=(1,t,t^{2})\). To show that \(v(t_{1})\), \(v(t_{2})\), and \(v(t_{3})\) form a basis for \(\mathbb{R}^{3}\) whenever the \(t_{i}\)'s are distinct, it will suffice to show that the matrix which has these vectors as rows has nonzero determinant. But this matrix is

\[\left(\begin{array}{ccc}1&t_{1}&t_{1}^{2}\\ 1&t_{2}&t_{2}^{2}\\ 1&t_{3}&t_{3}^{2}\end{array}\right)\]

which is the \(3\times 3\) Vandermonde matrix [13, pag. 125]. Its determinant is given by

\[(t_{3}-t_{2})(t_{3}-t_{1})(t_{2}-t_{1})\]

which is nonzero whenever the \(t_{i}\)'s are distinct.

**Solution to 7.2.10:** Let \(G\) be the matrix with entries

\[G_{ij}=\int_{a}^{b}f_{i}(x)f_{j}(x)dx.\]

If the determinant of \(G\) vanishes, then \(G\) is singular; let \(a\) be a nonzero \(n\)-vector with \(Ga=0\). Then

\[0=a^{T}Ga=\sum_{i=1}^{n}\sum_{i=j}^{n}\int_{a}^{b}a_{i}f_{i}(x)a_{j}f_{j}(x)dx =\int_{a}^{b}\left(\sum_{i=1}^{n}a_{i}f_{i}(x)\right)^{2}dx\,\]

so, since the \(f_{i}\)'s are continuous functions, the linear combination \(\sum a_{i}f_{i}\) must vanish identically. Hence, the set \(\{f_{i}\}\) is linearly dependent on \([a,b]\). Conversely, if \(\{f_{i}\}\) is linearly dependent, some \(f_{i}\) can be expressed as a linear combination of the rest, so some row of \(G\) is a linear combination of the rest and \(G\) is singular.

**Solution to 7.2.11:** Identify \(M_{2\times 2}\) with \(\mathbb{R}^{4}\) via

\[\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)\leftrightarrow\left(\begin{array}{c}a\\ b\\ c\\ d\end{array}\right)\]

and decompose \(L\) into the multiplication of two linear transformations,

\[M_{2\times 2}\simeq\mathbb{R}^{4}\stackrel{{ L_{A}}}{{\longrightarrow}}\mathbb{R}^{4}\stackrel{{ L_{B}}}{{\longrightarrow}}\mathbb{R}^{4}\simeq M_{2\times 2}\]

where \(L_{A}(X)=AX\) and \(L_{B}(X)=XB\).

The matrices of these two linear transformations on the canonical basis of \(\mathbb{R}^{4}\) is

\[L_{A}=\left(\begin{array}{rrrr}1&0&2&0\\ 0&1&0&2\\ -1&0&3&0\\ 0&-1&0&3\end{array}\right)\quad\text{and}\quad L_{B}=\left(\begin{array}{rrrr} 2&0&0&0\\ 1&4&0&0\\ 0&0&2&0\\ 0&0&1&4\end{array}\right)\]

then \(\det L=\det L_{A}\cdot\det L_{B}=(9+6+2(2+3))\cdot(2\cdot 32)=2^{6}\cdot 5^{2}\), and to compute the trace of \(L\), we only need the diagonal elements of \(L_{A}\cdot L_{B}\), that is,

\[\operatorname{tr}L=2+4+6+12=24.\]

**Solution to 7.2.12:** Let \(X=(x_{ij})\) be any element of \(M_{3}(\mathbb{R})\). A calculation gives

\[T(X)=\left(\begin{array}{rrrr}x_{11}&3x_{12}/2&x_{13}\\ 3x_{21}/2&2x_{22}&3x_{23}/2\\ x_{31}&3x_{32}/2&x_{33}\end{array}\right).\]

It follows that the basis matrices \(M_{ij}\) are eigenvectors of \(T\). Taking the product of their associated eigenvalues, we get \(\det T=2(3/2)^{4}=81/8\).

**Solution to 7.2.13:** Since the minimal polynomial of \(A\) splits into distinct linear factors, \(\mathbb{R}^{3}\) has a basis \(\{v_{1},v_{2},v_{3}\}\) of eigenvectors of \(A\). Since \(\det A=32\), two of those, say \(v_{1}\) and \(v_{2}\), are associated with the eigenvalue \(4\), and one, \(v_{3}\), is associated with the eigenvalue \(2\). Now consider the nine matrices \(E_{ij}\), \(1\leq i,j\leq 3\), whose \(i^{th}\) column is the vector \(v_{j}\) and whose other columns are zero. Since the \(v_{i}\)'s are linearly independent, the matrices \(E_{ij}\) are linearly independent in \(M_{3\times 3}\) and form a basis of \(M_{3\times 3}\). Further, a calculation shows that \(AE_{ij}=\lambda_{j}E_{ij}\), where \(\lambda_{1}=\lambda_{2}=4\) and \(\lambda_{3}=2\). Hence, \(M_{3\times 3}\) has a basis of eigenvectors of \(L_{A}\), so it follows that \(\operatorname{tr}L_{A}=6\cdot 4+3\cdot 2=30\).

**Solution to 7.2.15:** We have

\[\dim\operatorname{range}T=\dim M_{7\times 7}-\dim\ker T=49-\dim\ker T\]

so it suffices to find the dimension of \(\ker T\); in other words, the dimension of the subspace of matrices that commute with \(A\). Let \(E_{+}\) be the eigenspace of \(A\) for the eigenvalue \(1\) and \(E_{-}\) be the eigenspace of \(A\) for the eigenvalue \(-1\). Then \(\mathbb{R}^{7}=E_{+}\oplus E_{-}\). A matrix that commutes with \(A\) leaves \(E_{+}\) and \(E_{-}\) invariant, so, as linear transformations on \(\mathbb{R}^{7}\), can be expressed as the direct sum of a linear transformation on \(E_{+}\) with a linear transformation on \(E_{-}\). Moreover, any matrix that can be so expressed commutes with \(A\). Hence, the space of matrices that commute with \(A\) is isomorphic to \(M_{4\times 4}\oplus M_{3\times 3}\)and so has dimension \(16+9=25\). It follows that \(\dim\operatorname{range}T=49-25=24\).

**Solution to 7.2.16:**\(m>n\). We write \(T=T_{1}T_{2}\), where \(T_{2}:M_{n\times m}\to M_{m\times m}\) is defined by \(T_{2}(X)=BX\) and \(T_{1}:M_{n\times n}\to M_{m\times n}\) is defined by \(T_{1}(Y)=AY\). Since \(\dim\,M_{n\times m}=nm>n^{2}=\dim\,M_{n\times n}\), the transformation \(T_{2}\) has a nontrivial kernel, by the Rank-Nullity Theorem [13, pag. 71]. Hence, \(T\) also has a nontrivial kernel and is not invertible.

\(m<n\). We write \(T=T_{2}T_{1}\), where \(T_{1}:M_{n\times m}\to M_{m\times m}\) is defined by \(T_{1}(X)=AX\) and \(T_{2}:M_{m\times m}\to M_{m\times n}\) is defined by \(T_{2}(Y)=BY\). Now we have \(\dim\,M_{n\times m}=nm>m^{2}=\dim\,M_{m\times m}\), so \(T_{1}\) has a nontrivial kernel, and we conclude as before that \(T\) is not invertible.

### 7.3 Systems of Equations

**Solution to 7.3.2:** 1. Through linear combinations of rows, reduce the system of equations to a row-reduced echelon form, that is, a system where:

* the first nonzero entry in each nonzero row is equal to 1;
* each column which contains the leading nonzero entry of some row has all its other entries 0;
* every row which has all entries 0 occurs below every row that has a nonzero entry;
* if rows \(1,\ldots,r\) are the nonzero rows and if the leading nonzero entry of row \(i\) occurs in column \(k_{i}\), \(i=1,\ldots,r\), then \(k_{i}<k_{2}<\cdots<k_{r}\).

This new system has a number of nonzero rows \(r\leq m<n\) and it is easy to see that it has nonzero solution.

Since the original system is equivalent to the row-reduced one, they have exactly the same solutions.

2. Let \(V\) be a vector space spanned by \(m\) vectors \(\beta_{1},\ldots,\beta_{m}\). We will show that every subset \(S=\{\alpha_{1},\ldots,\alpha_{n}\}\) of \(V\) with \(n>m\) vectors is linear dependent.

Since \(\beta_{1},\ldots,\beta_{m}\) span \(V\), there are scalars \(A_{ij}\) in the field \(\mathbf{F}\) such that

\[\alpha_{i}=\sum_{i=1}^{m}A_{ij}\beta_{i}\.\]

For any set of scalar \(x_{1},\ldots,x_{n}\) in \(\mathbf{F}\), we have

\[x_{1}\alpha_{1}+\cdots+x_{n}\alpha_{n}=\sum_{j=1}^{n}x_{j}\alpha_{j}\]
### 7.4 Linear Transformations

**Solution to 7.4.1:** 1. We need to show that vector addition and scalar multiplication are closed in \(S(E)\), but this is a trivial verification because if \(v=S(x)\) and \(w=S(y)\) are vectors in \(S(E)\), then

\[v+w=S(x+y)\ \ \ \text{and}\ \ \ cv=S(cx)\]

are also in \(S(E)\).

2. If \(S\) is not injective, then two different vectors \(x\) and \(y\) have the same image \(S(x)=S(y)=v\), so

\[S(x-y)=S(x)-S(y)=v-v=0\]

that is, \(x-y\neq 0\) is a vector in the kernel of \(S\). On the other hand, if \(S\) is injective, it only takes \(0\in E\) into \(0\in F\), showing the result.

3. Assuming that \(S\) is injective, the application \(S^{-1}:S(E)\to E\) is well defined. Given \(av+bw\in S(E)\) with \(v=S(x)\) and \(w=S(y)\), we have

\[\eqalign{S^{-1}(av+w)&=S^{-1}(aS(x)+bS(y))\cr&=S^{-1}(S(ax+by))\cr&=ax+by\cr&=aS^ {-1}(v)+bS^{-1}(w)\cr}\]

therefore, \(S^{-1}\) is linear.

**Solution to 7.4.2:** Let \(\{\alpha_{1},\ldots,\alpha_{k}\}\) be a basis for \(\ker T\) and extend it to \(\{\alpha_{1},\ldots,\alpha_{k},\ldots,\alpha_{n}\}\), a basis of \(V\). We will show that \(\{T\alpha_{k+1},\ldots,T\alpha_{n}\}\) is a basis for the range of \(T\). It is obvious they span the range since \(T\alpha_{j}=0\) for \(j\leq k\). Assume

\[\sum_{i=k+1}^{n}c_{i}(T\alpha_{i})=0\]

which is equivalent to

\[T\left(\sum_{i=k+1}^{n}c_{i}T\alpha_{i}\right)=0\]

that is, \(\alpha=\sum_{i=k+1}^{n}c_{i}\alpha_{i}\) is in the kernel of \(T\). We can then write \(\alpha\) as \(\alpha=\sum_{i=1}^{k}b_{i}\alpha_{i}\) and have

\[\sum_{i=1}^{k}b_{i}\alpha_{i}-\sum_{i=k+1}^{n}c_{i}T\alpha_{i}=0\]

which implies all \(c_{i}=0\), and the vectors \(T\alpha_{k+1},\ldots,T\alpha_{n}\) form a basis for the range of \(T\).

**Solution to 7.4.3:** Let \(v_{1}\),..., \(v_{n}\) be a basis for \(V\) such that \(v_{1}\),..., \(v_{k}\) is a basis for \(W\). Then the matrix for \(L\) in terms of this basis has the form \(\left(\begin{smallmatrix}M&N\\ 0&0\end{smallmatrix}\right)\), where \(M\) is a \(k\times k\) matrix and \(N\) is \(k\times(n-k)\). It follows that \(M\) is the matrix of \(L_{W}\) with respect to the basis \(v_{1}\),..., \(v_{k}\). As the matrix of \(1-tL\) is \(\left(\begin{smallmatrix}1-tM&-tN\\ 0&1\end{smallmatrix}\right)\), it follows that \(\det(1-tL)=\det(1-tM)=\det(1-tL_{W})\).

**Solution to 7.4.4:** Let \(V_{i}=\{v\in V\,|\,\chi_{i}(L)(v)=0\}\), for \(i=1\), \(2\). Clearly, each \(V_{i}\) is a subspace of \(V\) with \(\chi_{i}(L)V_{i}=0\). To show that \(V\) is the direct sum of \(V_{1}\) and \(V_{2}\), choose polynomials \(a\) and \(b\) over \({\bf F}\) for which \(a\chi_{1}+b\chi_{2}=1\). Then \(a(L)\chi_{1}(L)+b(L)\chi_{2}(L)=1\). If \(v\in V_{1}\cap V_{2}\), then \(v=1\cdot v=a(L)\chi_{1}(L)+b(L)\chi_{2}(L)v=a(L)0+b(L)0=0\), so \(V_{1}\cap V_{2}=\{0\}\). If \(v\in V\), then by Cayley-Hamilton Theorem [13, pag. 194], we have \(\chi(L)v=0\). Hence, \(v_{1}=a(L)\chi_{1}(L)v\) is annihilated by \(\chi_{2}(L)\) and, therefore, belongs to \(V_{2}\). Likewise, \(v_{2}=b(L)\chi_{2}(L)v\) belongs to \(V_{1}\). Since \(v=v_{1}+v_{2}\), this shows that \(V=V_{1}+V_{2}\).

**Solution to 7.4.8:** Since the linear transformation \(f\) has rank \(n-1\), we know that \(f(\mathbb{R}^{m})\) is an \(n-1\)-dimensional subspace of \(\mathbb{R}^{n}\). Hence, there exist real constants \(\lambda_{1},\ldots,\lambda_{n}\), not all zero, such that

\[\sum_{i=1}^{n}\lambda_{i}f_{i}(v)=0\]

for all \(v\in\mathbb{R}^{m}\). The \(\lambda_{i}\)'s are unique up to constant multiples. Further, this equation determines the subspace: If \(w\in\mathbb{R}^{n}\) satisfies it, then \(w\in f(\mathbb{R}^{m})\).

Now suppose that the \(\lambda_{i}\)'s all have the same sign, or, without loss of generality, that they are all nonnegative. Then if there existed \(v\in\mathbb{R}^{m}\) with \(f_{i}(v)>0\) for all \(i\), we would have \(\sum\lambda_{i}f_{i}(v)>0\), a contradiction. Hence, there can be no such \(v\).

Conversely, suppose that two of the \(\lambda_{i}\)'s, say \(\lambda_{1}\) and \(\lambda_{2}\), have different signs. Let \(x_{3}=x_{4}=\cdots=x_{n}=1\), and choose \(x_{1}>0\) sufficiently large so that

\[\sum_{i\neq 2}\lambda_{i}x_{i}>0.\]

Then there is a real number \(x_{2}>0\) such that

\[\sum_{i=1}^{n}\lambda_{i}x_{i}=0.\]

But then we know that there exists \(v\in f(\mathbb{R}^{m})\) such that \(f(v)=(x_{1},\ldots,x_{n})\). Since each of the \(x_{i}\)'s is positive, we have found the desired point \(v\).

**Solution to 7.4.9:** Let \(\langle\,\ \rangle\) denote the ordinary inner product. From \(d(s,t)^{2}=d(s,0)^{2}+d(t,0)^{2}-2\langle s,t\rangle\) and the hypothesis, it follows that

\[\langle\varphi(s),\varphi(t)\rangle=\langle s,t\rangle\qquad\text{for all}\ \ s,t\in S.\]

Let \(V\subset\mathbb{R}^{n}\) denote the subspace spanned by \(S\), and choose a subset \(T\subset S\) that is a basis of \(V\). Clearly, there is a unique linear map \(f:V\to V\) that agrees with \(\varphi\) on \(T\). Then one has \(\langle f(t),f(t^{\prime})\rangle=\langle t,t^{\prime}\rangle\) for all \(t\) and \(t^{\prime}\in T\). By bilinearity, it follows that \(\langle f(v),f(v^{\prime})\rangle=\langle v,v^{\prime}\rangle\) for all \(v\) and \(v^{\prime}\in V\). Taking \(v=v^{\prime}\), one finds that \(f(v)\neq 0\) for \(v\neq 0\), so \(f\) is injective, and \(f(V)=V\). Taking \(v=s\in S\) and \(v^{\prime}=t\in T\), one finds that

\[\langle f(s),f(t)\rangle=\langle s,t\rangle=\langle\varphi(s),\varphi(t) \rangle=\langle\varphi(s),f(t)\rangle,\]

so \(f(s)-\varphi(s)\) is orthogonal to \(f(t)\) for all \(t\in T\), and hence to all of \(f(V)=V\). That is, for all \(s\in S\), one has \(f(s)-\varphi(s)\in V^{\perp}\); but also \(f(s)-\varphi(s)\in V\), so \(f(s)-\varphi(s)=0\). This shows that \(f\) agrees with \(\varphi\) on \(S\). It now suffices to extend \(f\) to a linear map \(\mathbb{R}^{n}\to\mathbb{R}^{n}\), which one can do by supplementing \(T\) to a basis for \(\mathbb{R}^{n}\) and defining \(f\) arbitrarily on the new basis vectors.

**Solution to 7.4.11:** We use Complete Induction [11, pag. 32] on the dimension of \(V\). If \(\dim V=1\), then \(V\) has a single basis vector \(f_{1}\neq 0\), so there is \(x_{1}\in X\) such that \(f_{1}(x_{1})\neq 0\). Hence, the map \(f\mapsto f(x_{1})\) is the desired isomorphism.

Now suppose the result is true for dimensions less than \(n\) and let \(\dim V=n\). Fix a basis \(f_{1},f_{2},\ldots,f_{n}\) of \(V\). Then, by the induction hypothesis, there are points \(x_{1},x_{2},\ldots,x_{n-1}\) such that the map \(f\mapsto(f(x_{1}),\ldots,f(x_{n-1}),0)\) is an isomorphism of the subspace of \(V\) spanned by \(f_{1},\ldots,f_{n-1}\) onto \(\mathbb{R}^{n-1}\subset\mathbb{R}^{n}\). In particular, the vector \((f_{n}(x_{1}),\ldots,f_{n}(x_{n-1}),0)\) is a linear combination of the basis vectors \(\{(f_{i}(x_{1}),\ldots,f_{i}(x_{n-1}),0),1\leq i\leq n-1\}\), so there exists a unique set of \(\lambda_{i}\)'s, \(1\leq i\leq n\), such that

\[\sum_{i=1}^{n}\lambda_{i}f_{i}(x_{j})=0,\ \ \ \ 1\leq j\leq n-1.\]

Suppose there is no point \(x\in X\) such that the given map is an isomorphism from \(V\) onto \(\mathbb{R}^{n}\). This implies that the set \(\{(f_{i}(x_{1}),\ldots,f_{i}(x_{n-1}),f_{i}(x)),\)\(1\leq i\leq n\}\) is linearly dependent for all \(x\). But because of the uniqueness of the \(\lambda_{i}\)'s, this, in turn, implies that for all \(x\),

\[\sum_{i=1}^{n}\lambda_{i}f_{i}(x)=0.\]

Hence, the \(f_{i}\)'s are linearly dependent in \(V\), a contradiction. Therefore, such an \(x_{n}\) exists and we are done.

**Solution to 7.4.13:** Since the formula holds, irrespective of the values of \(c_{k}\), for the polynomials \(x^{2n+1}\), it suffices, by linearity, to restrict to the vector space \(P_{2n}\) of polynomials of degree, at most, \(2n\). This vector space has dimension \(2n+1\) and the map \(P_{2n}\to\mathbb{R}^{2n+1}\) given by \(p\mapsto(p(-n),p(-n+1),\ldots,p(n))\) is an isomorphism. As the integral is a linear function on \(\mathbb{R}^{2n+1}\), there exist unique real numbers \(c_{-n},c_{-n+1},\ldots,c_{n}\) such that

\[\int_{-1}^{1}p(x)dx=\sum_{k=-n}^{n}c_{k}p(k)\qquad\mbox{for all }p\in P_{2n}.\]

We have

\[\int_{-1}^{1}p(x)dx=\int_{-1}^{1}p(-x)dx=\sum_{k=-n}^{n}c_{k}p(k)\quad\mbox{for all }p\in P_{2n},\]

so \(c_{k}=c_{-k}\) by uniqueness of the \(c_{k}\), and, therefore,

\[\int_{-1}^{1}p(x)dx=c_{0}p(0)+\sum_{k=1}^{n}c_{k}\left(p(k)+p(-k)\right)\qquad \mbox{for all }p\in P_{2n}.\]Setting \(p=1\), we find that

\[2=c_{0}+\sum_{k=1}^{n}2c_{k}\]

so, upon eliminating \(c_{0}\),

\[\int_{-1}^{1}p(x)dx=2p(0)+\sum_{k=1}^{n}c_{k}\left(p(k)+p(-k)-2p(0)\right).\]

**Solution to 7.4.14:** Let \(v_{1},v_{2},\ldots,v_{n}\) be a basis for \(\mathbb{R}^{n}\) consisting of eigenvectors of \(T\), say \(Tv_{n}=\lambda_{n}v_{n}\). Let \(u_{1},u_{2},\ldots,u_{n}\) be the orthonormal basis one obtains from \(v_{1},v_{2},\ldots,v_{n}\) by the Gram-Schmidt Procedure [13, pag. 280]. Then, for each index \(k\), the vector \(u_{k}\) is a linear combination of \(v_{1},\ldots,v_{k}\), say

\[u_{k}=c_{k1}v_{1}+c_{k2}v_{2}+\cdots+c_{kk}v_{k}\.\]

Also, each \(v_{k}\) is a linear combination of \(u_{1},\ldots,u_{k}\). (This is guaranteed by the Gram-Schmidt Procedure; in fact, \(u_{1},\ldots,u_{k}\) is an orthonormal basis for the subspace generated by \(v_{1},\ldots,v_{k}\).) We have

\[Tu_{k} =c_{k1}Tv_{1}+c_{k2}Tv_{2}+\cdots+c_{kk}Tv_{k}\] \[=c_{k1}\lambda_{1}v_{1}+c_{k2}\lambda_{2}v_{2}+\cdots+c_{kk} \lambda_{k}v_{k}\.\]

In view of the preceding remark, it follows that \(Tu_{k}\) is a linear combination of \(u_{1},\ldots,u_{k}\), and, thus, \(T\) has an upper-triangular matrix in the basis \(u_{1},u_{2},\ldots,u_{n}\).

**Solution to 7.4.17:** 1. The characteristic polynomial of \(T\) has degree 3 so it has at least one real root. The space generated by the eigenvector associated with this eigenvalue is invariant under \(T\).

2. The linear transformation \(T-\lambda I\) has rank 0, 1, or 2. If the rank is 0 then \(T=\lambda I\) and all subspaces are invariant, if it is 1 then \(\ker(T-\lambda I)\) will do and if it is 2 the image of \((T-\lambda I)\) is the desired subspace. This is equivalent to the Jordan Canonical Form [13, pag. 247] of \(T\) being either a diagonal matrix with three \(1\times 1\) blocks or with one \(1\times 1\) and one \(2\times 2\) block, in both cases there is a 2-dimensional invariant subspace.

**Solution to 7.4.19:** Clearly, both \(R\) and \(S\) are rotations and so have rank 3. Therefore, \(T\), their composition, is a rank 3 operator. In particular, it must have trivial kernel. Since \(T\) is an operator on \(\mathbb{R}^{3}\), its characteristic polynomial is of degree 3, and so it has a real root. This root is an eigenvalue, which must be nontrivial since \(T\) has trivial kernel. Hence, the associated eigenspace must contain a line which is fixed by \(T\).

**Solution to 7.4.20:** Let \(x=(x_{1},x_{2},x_{3})\) in the standard basis of \(\mathbb{R}^{3}\). The line joining the points \(x\) and \(Tx\) intersects the line containing \(e\) at the point \(f=\langle e,x\rangle e\) and is perpendicular to it. We then have \(Tx=2(f-x)+x=2f-x\), or, in the standard basis, \(Tx=(2\langle e,x\rangle a-x_{1},2\langle e,x\rangle b-x_{2},2\langle e,x\rangle c -x_{3})\). With respect to the standard basis for \(\mathbb{R}^{3}\), the columns of the matrix of \(T\) are \(Te_{1}\), \(Te_{2}\), and \(Te_{3}\). Applying our formula and noting that \(\langle e,e_{1}\rangle=a\), \(\langle e,e_{2}\rangle=b\), and \(\langle e,e_{3}\rangle=c\), we get that the matrix for \(T\) is

\[\left(\begin{array}{ccc}2a^{2}-1&2ab&2ac\\ 2ab&2b^{2}-1&2bc\\ 2ac&2bc&2c^{2}-1\end{array}\right).\]

**Solution to 7.4.21:** Since the minimal polynomial divides the characteristic polynomial and this last one has degree 3, it follows that the characteristic polynomial of \(T\) is \((t^{2}+1)(t-10)\) and the eigenvalues \(\pm i\) and \(10\).

Now \(T(1,1,1)=\lambda(1,1,1)\) implies that \(\lambda=10\) because \(10\) is the unique real eigenvalue of \(T\).

The plane perpendicular to \((1,1,1)\) is generated by \((1,-1,0)\) and \((\frac{1}{2},\frac{1}{2},-1)\) since these are perpendicular to each other and to \((1,1,1)\).

Let

\[\begin{array}{rcl}f_{1}&=&(1,1,1)\\ f_{2}&=&(1,-1,0)/\sqrt{2}\\ f_{3}&=&\left(\frac{1}{2},\frac{1}{2},-1\right)/\sqrt{\frac{1}{4}+\frac{1}{4}+1 }=\left(\frac{1}{2},\frac{1}{2},-1\right)/\sqrt{\frac{3}{2}}\end{array}\]

we have \(Tf_{1}=10f_{1}\) and, for \(\pm i\) to be the other eigenvalues of \(T\), \(Tf_{2}=f_{3}\), and \(Tf_{3}=-f_{2}\).

The matrix of \(T\) in the basis \(\{f_{1},f_{2},f_{3}\}=\beta\) is then

\[[T]_{\beta}=\left(\begin{array}{ccc}10&0&0\\ 0&0&1\\ 0&-1&0\end{array}\right)\]

The matrix that transforms the coordinates relative to the basis \(\beta\) into the coordinates relative to the canonical basis is

\[P=\left(\begin{array}{ccc}1&1/\sqrt{2}&\sqrt{6}/4\\ 1&-1/\sqrt{2}&\sqrt{6}/4\\ 1&0&-\sqrt{6}/2\end{array}\right)\]

and a calculation gives

\[P^{-1}=\left(\begin{array}{ccc}1/3&1/3&1/3\\ \sqrt{2}/2&-\sqrt{2}/2&0\\ 2/3\sqrt{6}&2/3\sqrt{6}&-4/3\sqrt{6}\end{array}\right).\]

Therefore, the matrix of \(T\) in the canonical basis is

\[[T]=P[T]_{\beta}P^{-1}=\left(\begin{array}{ccc}\frac{10}{3}+\frac{1}{3\sqrt {3}}&\frac{10}{3}+\frac{13}{36}\sqrt{3}&\frac{10}{3}-\frac{2}{3\sqrt{3}}\\ \frac{10}{3}-\frac{1}{3\sqrt{3}}&\frac{10}{3}+\frac{5\sqrt{3}}{36}&\frac{10}{ 3}+\frac{2}{3\sqrt{3}}\\ \frac{10}{3}+\frac{\sqrt{3}}{2}&\frac{10}{3}-\frac{\sqrt{3}}{2}&\frac{10}{3} \end{array}\right).\]

**Solution to 7.4.23:** For \(n=1,2,\ldots\), let \(P_{n}\) be the space of polynomials whose degrees are, at most, \(n\). The subspaces \(P_{n}\) are invariant under \(E\), they increase with \(n\), and their union is \(P\). To prove \(E\) is invertible (i.e., one-to-one and onto), it will suffice to prove that each restriction \(E|_{P_{n}}\) is invertible. The subspace \(P_{n}\) is of dimension \(n+1\), it has the basis \(1,x,x^{2},\ldots,x^{n}\), with respect to which the matrix of \(E|_{P_{n}}\) is

\[\left(\begin{array}{cccccc}1&1&0&0&\cdots&0\\ 0&1&2&0&\cdots&0\\ 0&0&1&3&\cdots&0\\ \vdots&\vdots&\vdots&\ddots&\ddots&\vdots\\ 0&0&0&0&1&n\\ 0&0&0&0&0&1\end{array}\right)\.\]

In particular, the matrix is upper-triangular, with \(1\) at every diagonal entry, so its determinant is \(1\). Thus, \(E|_{P_{n}}\) is invertible, as desired. Alternatively, since \(\deg\,Ef=\deg\,f\), the kernel of \(E\) is trivial, so its restriction to any finite dimensional invariant subspace is invertible.

_Solution 2._ We can describe \(E\) to be \(I+D\), where \(I\) is the identity operator and \(D\) is the derivative operator, on the vector space of all real polynomials \(P\). For any element \(f\) of \(P\), there exists \(n\) such that \(D^{n}(f)=0\); namely \(n=\deg p+1\). Thus, the inverse of \(E\) can be described as \(I-D+D^{2}-D^{3}+\cdots\).

Specifically, writing elements of \(P\) as polynomials in \(x\), we have \(E^{-1}(1)=1,\ \ E^{-1}(x)=x-1,\ \ E^{-1}(x^{2})=x^{2}-2x+2\), etc.

**Solution to 7.4.24:** Given the polynomial \(\pi(x)\), there are constants \(a\) and \(r>0\) and a polynomial \(\varphi(x)\) such that \(\pi(x)=x^{r}\varphi(x)+a\). If \(\varphi(x)\equiv 0\), then \(\pi(D)=aI\), it follows that the minimal polynomial of the operator \(\pi(D)\) is \(x-a\). If \(\varphi(x)\) is not zero, then for any polynomial \(f\in P_{n}\), by the definition of \(D\), \((\pi(D)-aI)(f(x))=g(x)\), where \(g(x)\) is some polynomial such that \(\deg g=\max(\deg f-r,0)\). Hence, letting \(E=\pi(D)-aI\), we have \(e^{\lfloor n/r\rfloor+1}(f)=0\) for all \(f\in P_{n}\). (\(\lfloor n/r\rfloor\) denotes the greatest integer less than or equal to \(n/r\).) The polynomial \(f(x)=x^{n}\) shows that \(\lfloor n/r\rfloor+1\) is the minimal degree such that this is true. It follows from this that the minimal polynomial of \(\pi(D)\) is \((x-a)^{\lfloor n/r\rfloor+1}\).

### 7.5 Eigenvalues and Eigenvectors

**Solution to 7.5.1:** 1. The minimal polynomial of \(M\) divides \(x^{3}-1=(x-1)(x^{2}+x+1)\); since \(M\neq I\), the minimal polynomial (and characteristic as well) is \((x-1)(x^{2}+x+1)\) and the only possible real eigenvalue is \(1\).

2. \[\left(\begin{array}{ccc}1&0&0\\ 0&\cos\frac{2\pi}{3}&\sin\frac{2\pi}{3}\\ 0&-\sin\frac{2\pi}{3}&\cos\frac{2\pi}{3}\end{array}\right)\]

**Solution to 7.5.2:** Suppose such \(X\) exists; then the characteristic polynomial for \(X\) is \(\chi_{X}(t)=t^{n}\), but this is a contradiction since \(X^{2n-1}\neq 0\) and \(2n-1>n\).

**Solution to 7.5.3:** Since \(A^{m}=0\) for some \(m\), \(A\) is a root of the polynomial \(p(x)=x^{m}\). By the definition of the minimal polynomial, \(\mu_{A}(t)|p(t)\), so \(\mu_{A}(t)=t^{k}\) for some \(k\leq n\), then \(A^{n}=A^{k}=0\).

**Solution to 7.5.4:** As \(M^{p}=I\), the minimal polynomial of \(M\) divides \(t^{p}-1=(t-1)(t^{p-1}+t^{p-2}+\cdots+t+1)\). Since \(M\) fixes no nontrivial vector, \(1\) is not an eigenvalue of \(M\), so it cannot be a root of the minimal polynomial. Therefore, \(\mu_{M}(t)|(t^{p-1}+t^{p-2}+\cdots+t+1)\). Since \(p\) is prime, the polynomial on the right is irreducible, so \(\mu_{M}(t)\) must equal it. The minimal and characteristic polynomials of \(M\) have the same irreducible factors, so \(\chi_{M}(t)=\mu_{M}(t)^{k}\) for some \(k\geq 1\). Therefore,

\[\dim V=\deg\chi_{M}(t)=k(p-1)\]

and we are done.

**Solution to 7.5.5:** 1. Let \(d=\deg\,\mu\). Since \(\mu(T)v=0\), the vector \(T^{d}v\) is linearly dependent on the vectors \(v,Tv,\ldots,T^{d-1}v\). Hence, \(T^{d+n}v\) is linearly dependent on \(T^{n}v,T^{n+1}v,\ldots,T^{n+d-1}v\) and so, by the Induction Principle [MH93, pag. 7], on \(v,Tv,\ldots,T^{d-1}v\)\((n=1,2,\ldots)\). Thus, \(v,Tv,\ldots,T^{d-1}v\) span \(V_{1}\), so \(\dim\,V_{1}\leq d\).

On the other hand, the minimum polynomial of \(T|_{V_{1}}\) must divide \(\mu\) (since \(\mu(T|_{V_{1}})=0\)), so it equals \(\mu\) because \(\mu\) is irreducible. Thus, \(\dim\,V_{1}\geq d\). The desired equality, \(\dim\,V_{1}=d\), now follows.

2. In the case \(V_{1}\neq V\), let \(T_{1}\) be the linear transformation on the quotient space \(V/V_{1}\) induced by \(T\). (It is well defined because \(V_{1}\) is \(T\)-invariant.) Clearly, \(\mu(T_{1})=0\), so the minimum polynomial of \(T_{1}\) divides \(\mu\), hence equals \(\mu\). Therefore, by Part 1, \(V/V_{1}\) has a \(T_{1}\)-invariant subspace of dimension \(d\), whose inverse image under the quotient map is a \(T\)-invariant subspace \(V_{2}\) of \(V\) of dimension \(2d\). In the case \(V_{2}\neq V\), we can repeat the argument to show that \(V\) has a \(T\)-invariant subspace of dimension \(3d\), and so on. After finitely many repetitions, we find \(\dim\,V=kd\) for some integers \(k\).

**Solution to 7.5.6:** Since the matrix is real and symmetric, its eigenvalues are real. As the trace of the matrix is \(0\), and equal to the sum of its eigenvalues, it has at least one positive and one negative eigenvalue.

The matrix is invertible because the span of its columns has dimension 4. In fact, the space of the first and last columns contains all columns of the form

\[\left(\begin{array}{c}0\\ *\\ *\\ 0\end{array}\right).\]

The span of all four columns thus contains

\[\left(\begin{array}{c}5\\ 0\\ 0\\ 1\end{array}\right)\quad\text{and}\quad\left(\begin{array}{c}1\\ 0\\ 0\\ 5\end{array}\right),\]

which together span all columns of the form

\[\left(\begin{array}{c}*\\ 0\\ 0\\ *\end{array}\right).\]

Since the matrix is invertible it does not have 0 as an eigenvalue. There are now only three possibilities:

* three positive and one negative eigenvalues;
* two positive and two negative eigenvalues;
* one positive and three negative eigenvalues.

A calculation shows that the determinant is positive. Since it equals the product of the eigenvalues, we can only have two positives and two negatives, completing the proof.

**Solution to 7.5.7:** A calculation shows that the characteristic polynomial of the given matrix is

\[-x(x^{2}-3x-2(1.00001^{2}-1))\]

so one of the eigenvalues is 0 and the product of the other two is \(-2(1.00001^{2}-1))<0\), so one is negative and the other is positive.

**Solution to 7.5.8:** Denote the matrix by \(A\). A calculation shows that \(A\) is a root of the polynomial \(p(t)=t^{3}-ct^{2}-bt-a\). In fact, this is the minimal polynomial of \(A\). To prove this, it suffices to find a vector \(x\in\mathbf{F}^{3}\) such that \(A^{2}x\), \(Ax\), and \(x\) are linearly independent. Let \(x=(1,0,0)\). Then \(Ax=(0,1,0)\) and \(A^{2}x=(0,0,1)\); these three vectors are linearly independent, so we are done.

**Solution to 7.5.9:**

[MISSING_PAGE_FAIL:391]

which is clearly invariant under \(S\).

3. To express the Fibonacci sequence in the basis above, we have just to find the constants \(k_{1}\) and \(k_{2}\) that satisfy

\[\left\{\begin{array}{ccc}1&=&k_{1}\varphi-k_{2}\varphi^{-1}\\ 1&=&k_{1}\varphi^{2}+k_{2}\varphi^{-2}\end{array}\right.\]

which give \(k_{1}=1/\sqrt{5}=-k_{2}\). We then have, for the Fibonacci numbers,

\[f_{n}=\frac{1}{\sqrt{5}}\left(\left(\frac{1+\sqrt{5}}{2}\right)^{n}-\left( \frac{1-\sqrt{5}}{2}\right)^{n}\right).\]

**Solution to 7.5.16:**

\[A=uu^{t}-I\quad\text{where}\quad u=\left(\begin{array}{c}1\\ \vdots\\ 1\end{array}\right)\]

and \(I\) is the identity matrix. If \(Ax=\lambda x\), where \(x\neq 0\), then

\[uu^{t}x-x=(u^{t}x)u-x=\lambda x\]

so \(x\) is either perpendicular or parallel to \(u\). In the latter case, we can suppose without loss of generality that \(x=u\), so \(u^{t}uu-u=\lambda u\) and \(\lambda=n-1\). This gives a 1-dimensional eigenspace spanned by \(u\) with eigenvalue \(n-1\). In the former case \(x\) lies in a \(n-1\)-dimensional eigenspace which is the nullspace of the rank-1 matrix \(uu^{t}\), so

\[Ax=(uu^{t}-I)x=-Ix=-x\]

and the eigenvalue associated with this eigenspace is \(-1\), with multiplicity \(n-1\). Since the determinant is the product of the eigenvalues, we have \(\det(A)=(-1)^{n-1}(n-1)\).

**Solution to 7.5.17:** Since \(A\) is positive definite, there is an invertible Hermitian matrix \(C\) such that \(C^{2}=A\). Thus, we have \(C^{-1}(AB)C=C^{-1}C^{2}BC=CBC\). By taking adjoints, we see that \(CBC\) is Hermitian, so it has real eigenvalues. Since similar matrices have the same eigenvalues, \(AB\) has real eigenvalues.

**Solution to 7.5.20:** The characteristic polynomial of \(A\) is

\[\chi_{A}(t)=t^{2}-(a+d)t+(ad-bc).\]

which has roots

\[t=\frac{1}{2}(a+d)\pm\frac{1}{2}\sqrt{(a-d)^{2}+4bc}=\frac{1}{2}\left(a+d\pm \sqrt{\Delta}\right).\]\(\Delta\) is positive, so \(A\) has real eigenvalues. Let \(\lambda=\frac{1}{2}\left(a+d+\sqrt{\Delta}\right)\) and let \(v=(x,y)\) be an eigenvector associated with this eigenvalue with \(x>0\). Expanding the first entry of \(Av\), we get

\[ax+by=\frac{1}{2}\left(a+d+\sqrt{\Delta}\right)x\]

or

\[2by=\left(d-a+\sqrt{\Delta}\right)x.\]

Since \(b>0\), to see that \(y>0\) it suffices to show that \(d-a+\sqrt{\Delta}>0\), or \(\sqrt{\Delta}>a-d\). But this is immediate from the definition of \(\sqrt{\Delta}\) and we are done.

**Solution to 7.5.21:** It suffices to show that \(A\) is positive definite. Let \(x=(x_{1},\ldots,x_{n})\), we have

\[\langle Ax,x\rangle =2x_{1}^{2}-x_{1}x_{2}-x_{1}x_{2}+2x_{2}^{2}-x_{2}x_{3}-\cdots-x_ {n-1}x_{n}+2x_{n}^{2}\] \[=x_{1}^{2}+(x_{1}-x_{2})^{2}+(x_{2}-x_{3})^{2}+\cdots+(x_{n-1}-x_ {n})^{2}+x_{n}^{2}.\]

Thus, for all nonzero \(x\), \(\langle Ax,x\rangle\geq 0\). In fact, it is strictly positive, since one of the center terms is greater than \(0\), or \(x_{1}=x_{2}=\cdots=x_{n}\) and all the \(x_{i}\)'s are nonzero, so \(x_{1}^{2}>0\). Hence, \(A\) is positive definite and we are done.

_Solution 2._ Since \(A\) is symmetric, all eigenvalues are real. Let \(x=(x_{i})_{1}^{n}\) be an eigenvector with eigenvalue \(\lambda\). Since \(x\neq 0\), we have \(\max_{i}|x_{i}|>0\). Let \(k\) be the least \(i\) with \(|x_{i}|\) maximum. Replacing \(x\) by \(-x\), if necessary, we may assume \(x_{k}>0\). We have

\[\lambda x_{k}=-x_{k-1}+2x_{k}-x_{k+1}\]

where nonexistent terms are taken to be zero. By the choice of \(x_{k}\), we have \(x_{k-1}<x_{k}\) and \(x_{k+1}\leq x_{k}\), so we get \(\lambda x_{k}>0\) and \(\lambda>0\).

**Solution to 7.5.22:** Let \(\lambda_{0}\) be the largest eigenvalue of \(A\). We have

\[\lambda_{0}=\max\left\{\langle Ax,x\rangle\,|\,x\in\mathbb{R},\,\|x\|=1\right\}\,,\]

and the maximum it attained precisely when \(x\) is an eigenvector of \(A\) with eigenvalue \(\lambda_{0}\). Suppose \(v\) is a unit vector for which the maximum is attained, and let \(u\) be the vector whose coordinates are the absolute values of the coordinates of \(v\). Since the entries of \(A\) are nonnegative, we have

\[\langle Au,u\rangle\geq\langle Av,v\rangle=\lambda_{0},\]

implying that \(\langle Au,u\rangle=\lambda_{0}\) and so that \(u\) is an eigenvector of \(A\) for the eigenvalue \(\lambda_{0}\).

**Solution to 7.5.23:** Let \(\lambda\) be an eigenvalue of \(A\) and \(x=(x_{1},\ldots,x_{n})^{t}\) a corresponding eigenvector. Let \(x_{i}\) be the entry of \(x\) whose absolute value is greatest. We have

\[\lambda x_{i}=\sum_{j=1}^{n}a_{ij}x_{j}\]

so

\[|\lambda||x_{i}|\leq\sum_{j=1}^{n}a_{ij}|x_{j}|\leq|x_{j}|\sum_{j=1}^{n}a_{ij}= |x_{i}|.\]

Hence, \(|\lambda|\leq 1\).

**Solution to 7.5.24:** Since \(A\) is Hermitian, by Rayleigh's Theorem [19, pag. 418], we have

\[\lambda_{\min}\leq\frac{\langle x,Ax\rangle}{\langle x,x\rangle}\leq\lambda_{ \max}\]

for \(x\in\mathbb{C}^{\ m}\), \(x\neq 0\), where \(\lambda_{\min}\) and \(\lambda_{\max}\) are its smallest and largest eigenvalues, respectively. Therefore,

\[a\leq\frac{\langle x,A_{x}\rangle}{\langle x,x\rangle}\leq a^{\prime}\]

Similarly for \(B\):

\[b\leq\frac{\langle x,Bx\rangle}{\langle x,x\rangle}\leq b^{\prime}\]

Hence,

\[a+b\leq\frac{\langle x,(A+B)x\rangle}{\langle x,x\rangle}\leq a^{\prime}+b^{\prime}\]

However, \(A+B\) is Hermitian since \(A\) and \(B\) are, so the middle term above is bounded above and below by the largest and smallest eigenvalues of \(A+B\). But, again by Rayleigh's Theorem, we know these bounds are sharp, so all the eigenvalues of \(A+B\) must lie in \([a+b,a^{\prime}+b^{\prime}]\).

**Solution to 7.5.25:** Let \(v=(1,1,0,\ldots,0)\). A calculation shows that \(Av=(k+1,k+1,1,0,\ldots,0)\), so

\[\frac{\langle Av,v\rangle}{\langle v,v\rangle}=k+1.\]

Similarly, for \(u=(1,-1,0,\ldots,0)\), we have \(Au=(k-1,1-k,-1,0,\ldots,0)\) and so

\[\frac{\langle Au,u\rangle}{\langle u,u\rangle}=k-1.\]

By Rayleigh's Theorem [19, pag. 418], we know that

\[\lambda_{\min}\leq\frac{\langle Av,v\rangle}{\langle v,v\rangle}\leq\lambda_{ \max}.\]for all nonzero vectors \(v\), and the desired conclusion follows.

**Solution to 7.5.26:** As \(B\) is positive definite, there is an invertible matrix \(C\) such that \(B=C^{t}C\), so

\[\frac{\langle Ax,x\rangle}{\langle Bx,x\rangle}=\frac{\langle Ax,x\rangle}{ \langle C^{t}Cx,x\rangle}=\frac{\langle Ax,x\rangle}{\langle Cx,Cx\rangle}.\]

Let \(Cx=y\). The right-hand side equals

\[\frac{\langle AC^{-1}y,C^{-1}y\rangle}{\langle y,y\rangle}=\frac{\langle(C^{-1 })^{t}AC^{-1}y,y\rangle}{\langle y,y\rangle}.\]

Since the matrix \(\left(C^{-1}\right)^{t}AC^{-1}\) is symmetric, by Rayleigh's Theorem [19, pag. 418], the right-hand side is bounded by \(\lambda\), where \(\lambda\) is the largest eigenvalue of \(\left(C^{-1}\right)^{t}AC^{-1}\). Further, the maximum is attained at the associated eigenvector. Let \(y_{0}\) be such an eigenvector. Then \(G(x)\) attains its maximum at \(x=C^{-1}y_{0}\), which is an eigenvector of the matrix \(\left(C^{-1}\right)^{t}A\).

**Solution to 7.5.27:** Let \(y\neq 0\) in \(\mathbb{R}^{n}\). \(A\) is real symmetric, so there is an orthogonal matrix, \(P\), such that \(B=P^{t}AP\) is diagonal. Since \(P\) is invertible, there is a nonzero vector \(z\) such that \(y=Pz\). Therefore,

\[\frac{\langle A^{m+1}y,y\rangle}{\langle A^{m}y,y\rangle}=\frac{\langle A^{m+ 1}Pz,Pz\rangle}{\langle A^{m}Pz,Pz\rangle}=\frac{\langle P^{t}A^{m+1}Pz,z \rangle}{\langle P^{t}A^{m}Pz,z\rangle}=\frac{\langle B^{m+1}z,z\rangle}{ \langle B^{m}z,z\rangle}.\]

Since \(A\) is positive definite, we may assume without loss of generality that \(B\) has the form

\[\left(\begin{array}{cccc}\lambda_{1}&0&\cdots&0\\ 0&\lambda_{2}&\cdots&0\\ \vdots&\vdots&\ddots&\vdots\\ 0&0&\cdots&\lambda_{n}\end{array}\right)\]

where \(\lambda_{1}\geq\lambda_{2}\geq\cdots\geq\lambda_{n}>0\). Let \(z=(z_{1},\ldots,z_{n})\neq 0\), and \(i\leq n\) be such that \(z_{i}\) is the first nonzero coordinate of \(z\). Then

\[\frac{\langle B^{m+1}z,z\rangle}{\langle B^{m}z,z\rangle} = \frac{\lambda_{i}^{m+1}z_{i}^{2}+\cdots+\lambda_{n}^{m+1}z_{n}^{2 }}{\lambda_{i}^{m}z_{i}^{2}+\cdots+\lambda_{n}^{m}z_{n}^{2}}\] \[= \lambda_{i}\left(\frac{z_{i}^{2}+(\lambda_{i+1}/\lambda_{i})^{m+1 }z_{i+1}^{2}+\cdots+(\lambda_{n}/\lambda_{i})^{m+1}z_{n}^{2}}{z_{i}^{2}+( \lambda_{i+1}/\lambda_{i})^{m}z_{i+1}^{2}+\cdots+(\lambda_{n}/\lambda_{1})^{m} z_{n}^{2}}\right)\] \[\sim \lambda_{i}\qquad(m\to\infty).\]

### 7.6 Canonical Forms

**Solution to 7.6.1:** The minimal polynomial of \(A\) divides \(x^{k}-1\) so it has no multiple roots, which implies that \(A\) is diagonalizable.

**Solution to 7.6.2:** Assume \(A^{m}\) is diagonalizable. Then its minimal polynomial, \(\mu_{A^{m}}(x)\), has no repeated roots, that is,

\[\mu_{A^{m}}(x)=(x-a_{1})\cdots(x-a_{k})\]

where \(a_{i}\neq a_{j}\) for \(i\neq j\).

The matrix \(A^{m}\) satisfies the equation

\[(A^{m}-a_{1}I)\cdots(A^{m}-a_{k}I)=0\]

so \(A\) is a root of the polynomial \((x^{m}-a_{1})\cdots(x^{m}-a_{k})\), therefore, \(\mu_{A}(x)\) divides this polynomial. To show that \(A\) is diagonalizable, it is enough to show this polynomial has no repeated roots, which is clear, because the roots of the factors \(x^{m}-a_{i}\) are different, and different factors have different roots.

This proves more than what was asked; it shows that if \(A\) is an invertible linear transformation on a finite dimensional vector space over a field \(\mathbf{F}\) of characteristic not dividing \(n\), the characteristic polynomial of \(A\) factors completely over \(\mathbf{F}\), and if \(A^{n}\) is diagonalizable, then \(A\) is diagonalizable.

On this footing, we can rewrite the above proof as follows: We may suppose that the vector space \(V\) has positive dimension \(m\). Let \(\lambda\) be an eigenvalue of \(A\). Then \(\lambda\neq 0\). We may replace \(V\) by the largest subspace of \(V\) on which \(A-\lambda I\) is nilpotent, so that we may suppose the characteristic polynomial of \(A\) is \((x-\lambda)^{m}\). Since \(A^{n}\) is diagonalizable, we must have \(A^{n}=\lambda^{n}I\) since \(\lambda^{n}\) is the only eigenvalue of \(A^{n}\). Thus, \(A\) satisfies the equation \(x^{n}-\lambda^{n}=0\). Since the only common factor of \(x^{n}-\lambda^{n}\) and \((x-\lambda)^{n}\) is \(x-\lambda\), and as the characteristic of \(\mathbf{F}\) does not divide \(n\), \(A=\lambda I\) and, hence, is diagonal.

**Solution to 7.6.4:** The characteristic polynomial of \(A\) is \(\chi_{A}(x)=x^{2}-3\), so \(A^{2}=3I\), and multiplying both sides by \(A^{-1}\), we have

\[A^{-1}=\frac{1}{3}A.\]

**Solution to 7.6.5:** 1. Subtracting the second line from the other three and expanding along the first line, we have

\[\det A_{x} =(x-1)\left|\begin{array}{ccc}x&1&1\\ 1-x&x-1&0\\ 1-x&0&x-1\end{array}\right|+(x-1)\left|\begin{array}{ccc}1&1&1\\ 0&x-1&0\\ 0&0&x-1\end{array}\right|\] \[=(x-1)^{3}(x+3).\]2. Suppose now that \(x\neq 1\) and \(-3\). Then \(A_{x}\) is invertible and the characteristic polynomial is given by:

\[\chi_{A_{x}}(t) =\left|\begin{array}{cccc}t-x&-1&-1&-1\\ -1&t-x&-1&-1\\ -1&-1&t-x&-1\\ -1&-1&-1&t-x\end{array}\right|=\left|\begin{array}{cccc}x-t&1&1&1\\ 1&x-t&1&1\\ 1&1&x-t&1\\ 1&1&1&x-t\end{array}\right|\] \[=(x-t-1)^{3}(x-t+3)\]

Now an easy substitution shows that the minimal polynomial is

\[\mu_{A_{x}}(t)=(x-t-1)(x-t-3)\]

so substituting \(t\) by \(A_{x}\), we have

\[((x-1)I_{4}-A_{x})((x+3)I_{4}-A_{x}) =0\] \[(x-1)(x+3)I_{4}-2(x+1)A_{x}-A_{x}^{2} =0\]

multiplying both sides by \(A_{x}^{-1}\),

\[(x-1)(x+3)A_{x}^{-1} =2(x+1)I_{4}-A_{x}\] \[=-A_{-x-2}\]

so

\[A_{x}^{-1}=-(x-1)^{-1}(x+3)^{-1}A_{-x-2}.\]

**Solution to 7.6.6:** The characteristic polynomial of \(A\) is \(\chi_{A}(t)=t^{3}-8t^{2}-20t-16=(t-4)(t-2)^{2}\) and the minimal polynomial is \(\mu_{A}(t)=(t-2)(t-4)\). By the Euclidean Algorithm [Her75, pag. 155], there is a polynomial \(p(t)\) and constants \(a\) and \(b\) such that

\[t^{10}=p(t)\mu_{A}(t)+at+b.\]

Substituting \(t=2\) and \(t=4\) and solving for \(a\) and \(b\) yields \(a=2^{9}(2^{10}-1)\) and \(b=-2^{11}(2^{9}-1)\). Therefore, since \(A\) is a root of its minimal polynomial,

\[A^{10}=aA+bI=\left(\begin{array}{cccc}3a+b&a&a\\ 2a&4a+b&2a\\ -a&-a&a+b\end{array}\right).\]

**Solution to 7.6.7:** The characteristic polynomial of \(A\) is \(\chi_{A}(t)=t^{2}-2t+1=(t-1)^{2}\). By the Euclidean Algorithm [Her75, pag. 155], there is a polynomial \(q(t)\) and constants \(a\) and \(b\) such that \(t^{100}=q(t)(t-1)^{2}+at+b\).

Differentiating both sides of this equation, we get \(100t^{99}=q^{\prime}(t)(t-1)^{2}+2q(t)(t-1)+a\). Substituting \(t=1\) into each equation and solving for \(a\) and \(b\), we get \(a=100\) and \(b=-99\). Therefore, since \(A\) satisfies its characteristic equation, substituting it into the first equation yields \(A^{100}=100A-99I\), or

\[A^{100}=\left(\begin{array}{cc}51&50\\ -50&-49\end{array}\right).\]

An identical calculation shows that \(A^{7}=7A-6I\), so

\[A^{7}=\left(\begin{array}{cc}9/2&7/2\\ -7/2&-5/2\end{array}\right).\]

From this it follows immediately that

\[A^{-7}=\left(\begin{array}{cc}-5/2&-7/2\\ 7/2&9/2\end{array}\right).\]

**Solution to 7.6.8:** Counterexample: Let

\[A=\left(\begin{array}{cc}0&1\\ 0&0\end{array}\right)=B^{2}=\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)=\left(\begin{array}{cc}a^{2}+bc&ab+bd\\ ca+dc&cb+d^{2}\end{array}\right).\]

Equating entries, we find that \(c(a+d)=0\) and \(b(a+d)=1\), so \(b\neq 0\) and \(a+d\neq 0\). Thus, \(c=0\). The vanishing of the diagonal entries of \(B^{2}\) then implies that \(a^{2}=d^{2}=0\) and, thus, \(a+d=0\). This contradiction proves that no such \(B\) can exist, so \(A\) has no square root.

_Solution 2._ Let

\[A=\left(\begin{array}{cc}0&1\\ 0&0\end{array}\right).\]

Any square root \(B\) of \(A\) must have zero eigenvalues, and since it cannot be the zero matrix, it must have Jordan Canonical Form [HK61, pag. 247]\(JBJ^{-1}=A\). But then \(B^{2}=J^{-1}A^{2}J=0\) since \(A^{2}=0\), so no such \(B\) can exist.

**Solution to 7.6.9:** 1. Let

\[A=\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)\]

then

\[A^{2}=\left(\begin{array}{cc}a^{2}+bc&(a+d)b\\ (a+d)c&bc+d^{2}\end{array}\right).\]

Therefore, \(A^{2}=-I\) is equivalent to the system

\[\left\{\begin{array}{ccc}a^{2}+bc&=&-1\\ (a+d)b&=&0\\ (a+d)c&=&0\\ bc+d^{2}&=&-1\end{array}\right.\]if \(a+d\neq 0\), the second equation above gives \(b=0\), and from the fourth, we obtain \(d^{2}=-1\), which is absurd. We must then have \(a=-d\) and the result follows.

2. The system that we get in this case is

\[\left\{\begin{array}{ccc}a^{2}+bc&=&-1\\ (a+d)b&=&0\\ (a+d)c&=&0\\ bc+d^{2}&=&-1-\varepsilon\end{array}\right.\]

As above, we cannot have \(a\neq-d\). But combining \(a=-d\) with the first and fourth equations of the system, we get \(\varepsilon=0\), a contradiction. Therefore, no such matrix exists.

**Solution to 7.6.10:** Suppose such a matrix \(A\) exists. One of the cingenvalues of \(A\) would be \(w\) and the other \((1+\varepsilon)^{1/20}w\) where \(w\) is a twentieth root of \(-1\). From the fact that \(A\) is real we can see that both eigenvalues are real or form a complex conjugate pair, but neither can occur because none the twentieth root of \(-1\) are real and the fact that

\[|w|=1\neq(1+\varepsilon)^{1/20}\]

make it impossible for them to be a conjugate pair, so no such a matrix exist.

**Solution to 7.6.11:**\(A^{n}=I\) implies that the minimal polynomial of \(A\), \(\mu(x)\in\mathbb{Z}[x]\), satisfies \(\mu(x)|(x^{n}-1)\). Let \(\zeta_{1},\ldots,\zeta_{n}\) be the distinct roots of \(x^{n}-1\) in \(\mathbb{C}\). We will separate the two possible cases for the degree of \(\mu\):

* \(\deg\mu=1\). We have \(\mu(x)=x-1\) and \(A=I\), or \(\mu(x)=x+1\) and \(A=-I\), \(A^{2}=I\).
* \(\deg\mu=2\). \(\zeta_{i}\) and \(\zeta_{j}\) are roots of \(\mu\) for some \(i\neq j\), in which case \(\zeta_{j}=\overline{\zeta_{i}}=\zeta\) say, since \(\mu\) has real coefficients. Thus, \(\mu(x)=(x-\zeta)\left(x-\overline{\zeta}\right)=x^{2}-2\Re(\zeta)x+1\). In particular, \(2\Re(\zeta)\in\mathbb{Z}\), so the possibilities are \(\Re(\zeta)=0\), \(\pm 1/2\), and \(\pm 1\). We cannot have \(\Re(\zeta)=\pm 1\) because the corresponding polynomials, \((x-1)^{2}\) and \((x+1)^{2}\), have repeated roots, so they are not divisors of \(x^{n}-1\). \(\Re(\zeta)=0\). We have \(\mu(x)=x^{2}+1\) and \(A^{2}=-I\), \(A^{4}=I\). \(\Re(\zeta)=1/2\). In this case \(\mu(x)=x^{2}-x+1\). \(\zeta\) is a primitive sixth root of unity, so \(A^{6}=I\). \(\Re(\zeta)=-1/2\). We have \(\mu(x)=x^{2}+x+1\). \(\zeta\) is a primitive third root of unity, so \(A^{3}=I\).

From the above, we see that if \(A^{n}=I\) for some \(n\in\mathbb{Z}_{+}\), then one of the following holds:

\[A=I,\ A^{2}=I,\ A^{3}=I,\ A^{4}=I,\ A^{6}=I.\]Further, for each \(n=2\), \(3\), \(4\), and \(6\) there is a matrix \(A\) such that \(A^{n}=I\) but \(A^{k}\neq I\) for \(0<k<n\):

* \(n=2\). \[\left(\begin{array}{cc}1&0\\ 0&1\end{array}\right)\]
* \(n=3\). \[\left(\begin{array}{cc}0&1\\ -1&-1\end{array}\right)\]
* \(n=4\). \[\left(\begin{array}{cc}0&1\\ -1&0\end{array}\right)\]
* \(n=6\). \[\left(\begin{array}{cc}0&1\\ -1&1\end{array}\right)\]

**Solution to 7.6.12:** Since \(A\) is upper-triangular, its eigenvalues are its diagonal entries, that is, \(1\), \(4\), and \(9\). It can, thus, be diagonalized, and in, fact, we will have

\[S^{-1}AS=\left(\begin{array}{ccc}1&0&0\\ 0&4&0\\ 0&0&9\end{array}\right)\]

where \(S\) is a matrix whose columns are eigenvectors of \(A\) for the respective eigenvalues \(1\), \(4\), and \(9\). The matrix

\[B=S\left(\begin{array}{ccc}1&0&0\\ 0&2&0\\ 0&0&3\end{array}\right)S^{-1}\]

will then be a square root of \(A\).

Carrying out the computations, one obtains

\[S=\left(\begin{array}{ccc}1&1&1\\ 0&1&1\\ 0&0&1\end{array}\right)\quad\mbox{and}\quad S^{-1}=\left(\begin{array}{ccc}1& -1&0\\ 0&1&-1\\ 0&0&1\end{array}\right)\]

giving

\[B=\left(\begin{array}{ccc}1&1&-1\\ 0&2&1\\ 0&0&3\end{array}\right).\]

The number of square roots of \(A\) is the same as the number of square roots of its diagonalization, \(D=S^{-1}AS\). Any matrix commuting with preserves its eigenspaces and so is diagonal. In particular, any square root of \(D\) is diagonal. Hence, \(D\) has exactly eight square roots, namely

\[\sqrt{\left(\begin{array}{ccc}1&0&0\\ 0&4&0\\ 0&0&9\end{array}\right)}=\left(\begin{array}{ccc}\pm 1&0&0\\ 0&\pm 4&0\\ 0&0&\pm 9\end{array}\right).\]

**Solution to 7.6.13:**\(n=1\). There is the solution \(X=A\).

\(n=2\). \(A\) is similar to the matrix

\[\left(\begin{array}{cccc}0&0&1&0\\ 0&0&0&0\\ 0&0&0&0\\ 0&0&0&0\end{array}\right)\]

under the transformation that interchanges the third and fourth basis vectors and leaves the first and second basis vectors fixed. The latter matrix is the square of

\[\left(\begin{array}{cccc}0&1&0&0\\ 0&0&1&0\\ 0&0&0&0\\ 0&0&0&0\end{array}\right).\]

Hence, \(A\) is the square of

\[\left(\begin{array}{cccc}0&1&0&0\\ 0&0&0&1\\ 0&0&0&0\\ 0&0&0&0\end{array}\right).\]

\(n=3\). The Jordan matrix [HK61, pag. 247]

\[X=\left(\begin{array}{cccc}0&1&0&0\\ 0&0&1&0\\ 0&0&0&1\\ 0&0&0&0\end{array}\right)\]

is a solution.

\(n\geq 4\). If \(X^{k}=A\), then \(X\) is nilpotent since \(A\) is. Then the characteristic polynomial of \(X\) divides \(x^{4}\), so that \(X^{4}=0\), and, a fortiori, \(X^{n}=0\) for \(n\geq 4\). There is, thus, no solution for \(n\geq 4\).

**Solution to 7.6.14:** Suppose such a matrix \(A\) exists. Its minimal polynomial must divide \(t^{2}+2t+5\). However, this polynomial is irreducible over \(\mathbb{R}\), so \(\mu_{A}(t)=t^{2}+2t+5\). Since the characteristic and minimal polynomials have the same irreducible factors, \(\chi_{A}(t)=\mu_{A}(t)^{k}\). Therefore, \(\deg\chi_{A}(t)=n\) must be even.

Conversely, a calculation shows that the \(2\times 2\) real matrix

\[A_{0}=\left(\begin{array}{cc}0&-5\\ 1&-2\end{array}\right)\]

is a root of this polynomial. Therefore, any \(2n\times 2n\) block diagonal matrix which has \(n\) copies of \(A_{0}\) on the diagonal will satisfy this equation as well.

**Solution to 7.6.15:** Let \(p(t)=t^{5}+t^{3}+t-3\). As \(p(A)=0\), we have \(\mu_{A}(t)|p(t)\). However, since \(A\) is Hermitian, its minimal polynomial has only real roots. Taking the derivative of \(p\), we see that \(p^{\prime}(t)=5t^{4}+3t^{2}+1>0\) for all \(t\), so \(p(t)\) has exactly one real root. A calculation shows that \(p(1)=0\), but \(p^{\prime}(1)\neq 0\). Therefore, \(p(t)=(t-1)q(t)\), where \(q(t)\) has only nonreal complex roots. It follows that \(\mu_{A}(t)|(t-1)\). Since \(t-1\) is irreducible, \(\mu_{A}(t)=t-1\) and \(A=I\).

**Solution to 7.6.17:** Note that

\[A=\left(\begin{array}{ccc}2&0&0\\ 0&2&0\\ 0&-1&1\end{array}\right)\]

can be decomposed into the two blocks (2) and \(\left(\begin{array}{cc}2&0\\ -1&1\end{array}\right)\), since the space spanned by \(\left(1\,0\,0\right)^{t}\) is invariant. We will find a \(2\times 2\) matrix \(C\) such that \(C^{4}=\left(\begin{array}{cc}2&0\\ -1&1\end{array}\right)=D\), say.

The eigenvalues of \(D\) are 2 and 1, and the corresponding Lagrange Polynomials [MH93, pag. 286] are \(p_{1}(x)=(x-2)/(1-2)=2-x\) and \(p_{2}(x)=(x-1)/(2-1)=x-1\). Therefore, the spectral projection of \(D\) can be given by

\[P_{1}=-\left(\begin{array}{cc}2&0\\ -1&1\end{array}\right)+2\left(\begin{array}{cc}1&0\\ 0&1\end{array}\right)=\left(\begin{array}{cc}0&0\\ 1&1\end{array}\right)\]

\[P_{2}=-\left(\begin{array}{cc}1&0\\ 0&1\end{array}\right)+\left(\begin{array}{cc}2&0\\ -1&1\end{array}\right)=\left(\begin{array}{cc}1&0\\ -1&0\end{array}\right)\]

We have

\[D=\left(\begin{array}{cc}0&0\\ 1&1\end{array}\right)+2\left(\begin{array}{cc}1&0\\ -1&0\end{array}\right).\]

As \(P_{1}\cdot P_{2}=P_{2}\cdot P_{1}=0\) and \(P_{1}^{2}=P_{1}\), \(P_{2}^{2}=P_{2}\), letting \(C=\left(\begin{array}{cc}0&0\\ 1&1\end{array}\right)+2^{1/4}\left(\begin{array}{cc}1&0\\ -1&0\end{array}\right)=1P_{1}+2^{1/4}P_{2}\), we get

\[C^{4}=P_{1}^{4}+\underbrace{\cdots}_{0}+(2^{1/4}P_{2})^{4}=P_{1}+2P_{2}=D.\]Then

\[C=\left(\begin{array}{cc}2^{1/4}&0\\ 1-2^{1/4}&1\end{array}\right)\]

and \(B\) is

\[\left(\begin{array}{cc}2^{1/4}&0&0\\ 0&2^{1/4}&0\\ 0&1-2^{1/4}&1\end{array}\right).\]

**Solution to 7.6.18:** It suffices to show that every element \(w\in W\) is a sum of eigenvectors of \(T\) in \(W\). Let \(a_{1},\ldots,a_{n}\) be the distinct eigenvalues of \(T\). We may write

\[w=v_{1}+\cdots+v_{n}\]

where each \(v_{i}\) is in \(V\) and is an eigenvector of \(T\) with eigenvalue \(a_{i}\). Then

\[\prod_{i\neq j}(T-a_{j})w=\prod_{i\neq j}(a_{i}-a_{j})v_{i}.\]

This element lies in \(W\) since \(W\) is \(T\) invariant. Hence, \(v_{i}\in W\) for all \(i\) and the result follows.

_Solution 2._ To see this in a matrix form, take an ordered basis of \(W\) and extend it to a basis of \(V\); on this basis, a matrix representing \(T\) will have the block form

\[[T]_{\mathcal{B}}=\left(\begin{array}{cc}A&C\\ 0&B\end{array}\right)\]

because of the invariance of the subspace \(W\) with respect to \(T\).

Using the block structure of \(T\), we can see that the characteristic and minimal polynomials of \(A\) divide the ones for \(T\). For the characteristic polynomial, it is immediate from the fact that

\[\det(xI-[T]_{\mathcal{B}})=\det(xI-A)\,\det(xI-B)\]

For the minimal polynomial, observe that

\[[T]_{\mathcal{B}}^{k}=\left(\begin{array}{cc}A^{k}&C_{k}\\ 0&B^{k}\end{array}\right)\]

where \(C_{k}\) is some \(r\times(n-r)\) matrix. Therefore, any polynomial that annihilates \([T]\) also annihilates \(A\) and \(B\); so the minimal polynomial of \(A\) divides the one for \([T]\).

Now, since \(T\) is diagonalizable, the minimal polynomial factors out in different linear terms and so does the one for \(A\), proving the result.

**Solution to 7.6.20:** Let \(\lambda\) be an eigenvalue of \(A\) and \(v\) a vector in the associated eigenspace, \(A_{\lambda}\). Then \(A(Bv)=BAv=B(\lambda v)=\lambda(Bv)\), so \(Bv\in A_{\lambda}\). Now fix an eigenvalue \(\lambda\) and let \(C\) be the linear transformation obtained by restricting \(B\) to \(A_{\lambda}\). Take any \(v\in A_{\lambda}\). Then, since \(C\) is the restriction of \(B\),

\[m_{B}(C)v=m_{B}(B)v=0,\]

so \(C\) is a root of \(m_{B}(t)\). It follows from this that \(m_{C}(t)|m_{B}(t)\). But \(B\) was diagonalizable, so \(m_{B}(t)\) splits into distinct linear factors. Therefore, \(m_{C}(t)\) must split into distinct linear factors as well and so \(A_{\lambda}\) has a basis of eigenvectors of \(C\). As \(A\) is diagonalizable, \(V\) can be written as the direct sum of the eigenspaces of \(A\). However, each of these eigenspaces has a basis which consists of vectors which are simultaneously eigenvectors of \(A\) and of \(B\). Therefore, \(V\) itself must have such a basis, and this is the basis which simultaneously diagonalizes \(A\) and \(B\).

_Solution 2._ (This one, in fact, shows much more; it proves that a set of \(n\times n\) diagonalizable matrices over a field \(\mathbf{F}\) which commute with each other are all simultaneously diagonalizable.) Let \(S\) be a set of \(n\times n\) diagonalizable matrices over a field \(\mathbf{F}\) which commute with each other. Let \(V=\mathbf{F}^{n}\). Suppose \(T\) is a maximal subset of \(S\) such that there exists a decomposition of

\[V=\oplus_{i}V_{i}\]

where \(V_{i}\) is a nonzero eigenspace for each element of \(T\) such that for \(i\neq j\), there exists an element of \(T\) with distinct eigenvalues on \(V_{i}\) and \(V_{j}\). We claim that \(T=S\). If not, there exists an \(N\in S-T\). Since \(N\) commutes with all the elements of \(T\), \(NV_{i}\subset V_{i}\). Indeed, there exists a function \(a_{i}:T\to\mathbf{F}\) such that \(v\in V_{i}\), if and only if \(Mv=a_{i}(M)v\) for all \(M\in T\). Now if \(v\in V_{i}\) and \(M\in T\),

\[MNv=NMv=Na_{i}(M)=a_{i}(M)Nv\]

so \(Nv\in V_{i}\). Since \(N\) is diagonalizable on \(V\), it is diagonalizable on \(V_{i}\). (See Problem 7.6.18; it satisfies a polynomial with distinct roots in \(\mathbf{K}\).) This means we can decompose each \(V_{i}\) into eigenspaces \(V_{i,j}\) for \(N\) with distinct eigenvalues. Hence, we have a decomposition of the right sort for \(T\cup N\),

\[V=\oplus_{i}\oplus_{j}V_{i,j}.\]

Hence, \(T=S\). We may now make a basis for \(V\) by choosing a basis for \(V_{i}\) and taking the union. Then \(A\) will be the change of basis matrix.

**Solution to 7.6.22:** The characteristic polynomial of \(A\) is

\[\chi_{A}(x)=\left|\begin{array}{cc}x-7&-15\\ 2&x+4\end{array}\right|=(x-1)(x-2)\]

so \(A\) is diagonalizable and a short calculation shows that eigenvectors associated with the eigenvalues \(1\) and \(2\) are \((5,-2)^{t}\) and \((3,-1)^{t}\), so the matrix \(B\) is \(\left(\begin{smallmatrix}5&3\\ -2&-1\end{smallmatrix}\right)\). Indeed, in this case, \(B^{-1}AB=\left(\begin{smallmatrix}1&0\\ 0&2\end{smallmatrix}\right)\).

**Solution to 7.6.24:** The characteristic polynomial of \(A\) is \(\chi_{A}(t)=(t-1)(t-4)^{2}\). Since the minimal polynomial and the characteristic polynomial share the same irreducible factors, another calculation shows that \(\mu_{A}(t)=(t-1)(t-4)^{2}\). Therefore, the Jordan Canonical Form [10, pag. 247] of \(A\) must have one Jordan block of order \(2\) associated with \(4\) and one Jordan block of order \(1\) associated with \(1\). Hence, the Jordan form of \(A\) is

\[\left(\begin{array}{ccc}1&0&0\\ 0&4&1\\ 0&0&4\end{array}\right).\]

**Solution to 7.6.26:** Combining the equations, we get \(\mu(x)^{2}=\mu(x)(x-i)(x^{2}+1)\) and, thus, \(\mu(x)=(x-i)^{2}(x+i)\). So the Jordan blocks of the Jordan Canonical Form [10, pag. 247]\(J_{A}\), correspond to the eigenvalues \(\pm i\). There is at least one block of size \(2\) corresponding to the eigenvalue \(i\) and no larger block corresponding to \(i\). Similarly, there is at least one block of size \(1\) corresponding to \(-i\). We have \(\chi(x)=(x-i)^{3}(x+i)\), so \(n=\deg\chi=4\), and the remaining block is a block of size \(1\) corresponding to \(i\), since the total dimension of the eigenspace is the degree with which the factor appears in the characteristic polynomial. Therefore,

\[J_{A}=\left(\begin{array}{cccc}i&1&0&0\\ 0&i&0&0\\ 0&0&i&0\\ 0&0&0&-i\end{array}\right).\]

**Solution to 7.6.27:** 1. As all the rows of \(M\) are equal, \(M\) must have rank \(1\), so its nullity has dimension \(n-1\). It is easy to see that \(M^{2}=nM\), or \(M(M-nI)=0\), so the characteristic polynomial is \(\chi_{M}=x(x-n)\).

2. If \(\operatorname{char}\mathbf{F}=0\) or if \(\operatorname{char}\mathbf{F}=p\) and \(p\) does not divide \(n\), then \(0\) and \(n\) are the two distinct eigenvalues, and since the minimal polynomial does not have repeated roots, \(M\) is diagonalizable.

If \(\operatorname{char}\mathbf{F}=p\), \(p|n\), then \(n\) is identified with \(0\) in \(\mathbf{F}\). Therefore, the minimal polynomial of \(M\) is \(\mu_{M}(x)=x^{2}\) and \(M\) is not diagonalizable.

3. In the first case, since the null space has dimension \(n-1\), the Jordan form [10, pag. 247] is

\[\left(\begin{array}{cccc}n&0&\cdots&0\\ 0&0&\cdots&0\\ \vdots&\vdots&\ddots&\vdots\\ 0&0&\cdots&0\end{array}\right).\]If \(\mathop{\rm char}\nolimits{\bf F}=p\), \(p|n\), then all the eigenvalues of \(M\) are 0, and there is one 2-block and \(n-1\) 1-blocks in the Jordan form:

\[\left(\begin{array}{cccc}0&1&\cdots&0\\ 0&0&\cdots&0\\ \vdots&\vdots&\ddots&\vdots\\ 0&0&\cdots&0\end{array}\right).\]

**Solution to 7.6.28:** A computation gives

\[T\left(\begin{array}{cc}x_{11}&x_{12}\\ x_{21}&x_{22}\end{array}\right)=\left(\begin{array}{cc}-x_{21}&x_{11}-x_{22} \\ 0&x_{21}\end{array}\right).\]

In particular, for the basis elements

\[E_{1}=\left(\begin{array}{cc}1&0\\ 0&0\end{array}\right),\quad E_{2}=\left(\begin{array}{cc}0&1\\ 0&0\end{array}\right),\quad E_{3}=\left(\begin{array}{cc}0&0\\ 1&0\end{array}\right),\quad E_{4}=\left(\begin{array}{cc}0&0\\ 0&1\end{array}\right)\]

we have

\[TE_{1}=\left(\begin{array}{cc}0&1\\ 0&0\end{array}\right)=E_{2},\quad TE_{2}=0\,,\]

\[TE_{3}=\left(\begin{array}{cc}-1&0\\ 0&1\end{array}\right)=-E_{1}+E_{4},\quad TE_{4}=\left(\begin{array}{cc}0&-1\\ 0&0\end{array}\right)=-E_{2}.\]

The matrix for \(T\) with respect to the basis \(\{E_{1},E_{2},E_{3},E_{4}\}\) is then

\[S=\left(\begin{array}{cccc}0&0&-1&0\\ 1&0&0&-1\\ 0&0&0&0\\ 0&0&1&0\end{array}\right).\]

A calculation shows that the characteristic polynomial of \(S\) is \(\lambda^{4}\). Thus, \(S\) is nilpotent. Moreover, the index of nilpotency is 3, since we have

\[T^{2}E_{1}=T^{2}E_{2}=T^{2}E_{4}=0\,,\quad T^{2}E_{3}=-2E_{2}.\]

The only \(4\times 4\) nilpotent Jordan matrix [HK61, pag. 247] with index of nilpotency 3 is

\[\left(\begin{array}{cccc}0&0&0&0\\ 0&0&1&0\\ 0&0&0&1\\ 0&0&0&0\end{array}\right)\]

which is, therefore, the Jordan Canonical Form of \(T\). A basis in which \(T\) is represented by the preceding matrix is 

**Solution to 7.6.29:** A direct calculation shows that \((A-I)^{3}=0\) and this is the least positive exponent for which this is true. Hence, the minimal polynomial of \(A\) is \(\mu_{A}(t)=(t-1)^{3}\). Thus, its characteristic polynomial must be \(\chi_{A}(t)=(t-1)^{6}\). Therefore, the Jordan Canonical Form [13, pag. 247] of \(A\) must contain one \(3\times 3\) Jordan block associated with \(1\). The number of blocks is the dimension of the eigenspace associated with \(1\). Letting \(x=(x_{1},\ldots,x_{6})^{t}\) and solving \(Ax=x\), we get the two equations \(x_{1}=0\) and \(x_{2}+x_{3}+x_{4}+x_{5}=0\). Since \(x_{6}\) is not determined, these give four degrees of freedom, so the eigenspace has dimension \(4\). Therefore, the Jordan Canonical Form of \(A\) must contain four Jordan blocks and so it must be

\[\left(\begin{array}{cccccc}1&1&0&0&0&0\\ 0&1&1&0&0&0\\ 0&0&1&0&0&0\\ 0&0&0&1&0&0\\ 0&0&0&0&1&0\\ 0&0&0&0&0&1\end{array}\right).\]

**Solution to 7.6.35:** Since \(A\) is nonsingular, \(A^{t}A\) is positive definite. Let \(B=\sqrt{A^{t}A}\). Consider \(P=BA^{-1}\). Then \(PA=B\), so it suffices to show that \(P\) is orthogonal, for in that case, \(Q=P^{-1}=P^{\star}\) will be orthogonal and \(A=QB\). We have

\[P^{t}P=(A^{t})^{-1}B^{t}BA^{-1}=(A^{t})^{-1}B^{2}A^{-1}=(A^{t})^{-1}A^{t}AA^{-1} =1.\]

Suppose that we had a second factorization \(A=Q_{1}B_{1}\). Then

\[B^{2}=A^{t}A=B_{1}^{t}Q_{1}^{t}Q_{1}B_{1}=B_{1}^{2}.\]

Since a positive matrix has a unique positive square root, it follows that \(B=B_{1}\). As \(A\) is invertible, \(B\) is invertible, and canceling gives \(Q=Q_{1}\).

**Solution to 7.6.36:** An easy calculation shows that \(A\) has eigenvalues \(0\), \(1\), and \(3\), so \(A\) is similar to the diagonal matrix with entries \(0\), \(1\), and \(3\). Since clearly the problem does not change when \(A\) is replaced by a similar matrix, we may replace \(A\) by that diagonal matrix. Then the condition on \(a\) is that each of the sequences \((0^{n})\), \((a^{n})\), and \(((3a)^{n})\) has a limit, and that at least one of these limits is nonzero. This occurs if and only if \(a=1/3\).

**Solution to 7.6.37:** Let \(g\) be an element of the group. Consider the Jordan Canonical Form [13, pag. 247] of the matrix \(g\) in \({\bf F}_{p^{2}}^{\star}\) a quadratic extension of \({\bf F}_{p}\). The characteristic polynomial has degree \(2\) and is either irreducible in \({\bf F}_{p}\) and the canonical form is diagonal with two conjugate entries in the extension or reducible with the Jordan Canonical Form havingthe same diagonal elements and a \(1\) in the upper right-hand corner. In the first case, we can see that \(g^{p^{2}-1}=I\) and in the second \(g^{p(p-1)}=I\).

### 7.7 Similarity

**Solution to 7.7.1:** A simple calculation shows that \(A\) and \(B\) have the same characteristic polynomial, namely \((x-1)^{2}(x-2)\). However,

\[A-I=\left(\begin{array}{ccc}0&0&0\\ -1&0&1\\ -1&0&1\end{array}\right)\,\qquad\qquad B-I=\left(\begin{array}{ccc}0&1&0\\ 0&0&0\\ 0&0&1\end{array}\right)\.\]

Since \(A-I\) has rank \(1\) and \(B-I\) has rank \(2\), these two matrices are not similar, and therefore, neither are \(A\) and \(B\).

**Solution to 7.7.5:** The eigenvalues of \(A\) an \(B\) are either \(\pm 1\) and neither is \(I\) or \(-I\), since the equation \(AB+BA=0\) would force the other matrix to be zero. Therefore, \(A\) and \(B\) have distinct eigenvalues and are both diagonalizable. Let \(S\) be such that \(SAS^{-1}=\left(\begin{smallmatrix}1&0\\ 0&-1\end{smallmatrix}\right)\). Multiplying on the left by \(S\) and on the right by \(S^{-1}\) the relations above we see that \(C=SBS^{-1}\) satisfies \(C^{2}=I\) and \((SAS^{-1})(SBS^{-1})+(SBS^{-1})(SAS^{-1})=0\). We get

\[C=\left(\begin{array}{cc}0&1/c\\ c&0\end{array}\right)\quad\mbox{for}\quad c\neq 0\]

and taking \(D=\left(\begin{smallmatrix}ck&0\\ 0&k\end{smallmatrix}\right)\) we can easily see that \(T=DS\) satisfies

\[TAT^{-1}=\left(\begin{array}{cc}1&0\\ 0&-1\end{array}\right)\quad\ TBT^{-1}=\left(\begin{array}{cc}0&1\\ 1&0\end{array}\right).\]

**Solution to 7.7.9:**\(1\). Let \(A\) be any element of the group:

* Every element in a finite group has finite order, so there is an \(n>0\) such that \(A^{n}=I\). Therefore, \((\det A)^{n}=\det(A^{n})=1\). But \(A\) is an integer matrix, so \(\det A\) must be \(\pm 1\).
* If \(\lambda\) is an eigenvalue of \(A\), then \(\lambda^{n}=1\), so each eigenvalue has modulo \(1\), and at the same time, \(\lambda\) is a root of a second degree monic characteristic polynomial \(\chi_{A}(x)=x^{2}+ax+b\) for \(A\). If \(|\lambda|=1\) then \(b=\pm 1\) and \(a=0\), \(\pm 1\), and \(\pm 2\) since all roots are in the unit circle. Writing out all \(10\) polynomials and eliminating the ones whose roots are not in the unit circle, we are left with \(x^{2}\pm 1\), \(x^{2}\pm x+1\), and \(x^{2}\pm 2x+1\), and the possible roots are \(\lambda=\pm 1\), \(\pm i\), and \(\frac{1\pm\sqrt{3}i}{2}\) and \(\frac{-1\pm\sqrt{3}i}{2}\), the sixth roots of unity.

3. The Jordan Canonical Form [11, pag. 247] of \(A\), \(J_{A}\), must be diagonal, otherwise it would be of the form \(J_{A}=\left(\begin{smallmatrix}x&1\\ 0&x\end{smallmatrix}\right)\), and the subsequent powers \((J_{A})^{k}=\left(\begin{smallmatrix}x^{k}&kx^{k-1}\\ 0&x^{k}\end{smallmatrix}\right)\), which is never the identity matrix since \(kx^{k-1}\neq 0\) (remember \(|x|=1\)). So the Jordan Canonical Form of \(A\) is diagonal, with the root above and the complex roots occurring in conjugate pairs only. The Rational Canonical Form [11, pag. 238] can be read off from the possible polynomials.
4. \(A\) can only have order 1, 2, 3, 4, or 6, depending on \(\lambda\).

**Solution to 7.7.10:** Let \(R_{A}\) and \(R_{B}\) be the Rational Canonical Forms [11, pag. 238] of \(A\) and \(B\), respectively, over \(\mathbb{R}\); that is, there are real invertible matrices \(K\) and \(L\) such that

\[R_{A} =KAK^{\sim 1}\] \[R_{B} =LBL^{-1}.\]

Observe now that \(R_{A}\) and \(R_{B}\) are also the Rational Canonical Forms over \(\mathbb{C}\) as well, and by the uniqueness of the canonical form, they must be the same matrices. If \(KAK^{-1}=LBL^{-1}\) then \(A=K^{-1}LB(K^{-1}L)^{-1}\), so \(K^{-1}L\) is a real matrix defining the similarity over \(\mathbb{R}\). Observe that the proof works for any subfield; in particular, two _rational_ matrices that are similar over \(\mathbb{R}\) are similar over \(\mathbb{Q}\).

_Solution 2._ Let \(U=K+iL\) where \(K\) and \(L\) are real and \(L\neq 0\) (otherwise we are done). Take real and imaginary parts of

\[A(K+iL)=AU=UB=(K+iL)B\]

and add them together after multiplying the imaginary part by \(z\) to get

\[A(K+zL)=(K+zL)B\]

for any complex \(z\). Let \(p(z)=\det(K+zL)\). Since \(p\) is a polynomial of degree \(n\), not identically zero (\(p(i)\neq 0\)), it has, at most, \(n\) roots. For real \(z_{0}\) not one of the roots of \(p\), \(V=K+z_{0}L\) is real and invertible and \(A=VBV^{-1}\).

**Solution to 7.7.11:** The minimal polynomial of \(A\) divides \((x-1)^{n}\), so \(I-A\) is nilpotent, say of order \(r\). Thus, \(A\) is invertible with

\[A^{-1}=(I-(I-A))^{-1}=\sum_{j=0}^{r-1}\left(I-A\right)^{j}.\]Suppose first that \(A\) is just a single Jordan block [13, pag. 247], say with matrix

\[\left(\begin{array}{ccccc}1&1&0&\cdots&0\\ 0&1&1&\cdots&0\\ \vdots&\vdots&\vdots&\ddots&\vdots\\ 0&0&0&\cdots&1\end{array}\right)\]

relative to the basis \(\{v_{1},v_{2},\ldots,v_{n}\}\). Then \(A^{-1}\) has the same matrix relative to the basis \(\{v_{1},v_{1}+v_{2},\cdots,v_{1}+v_{2}+\cdots+v_{n}\}\), so \(A\) and \(A^{-1}\) are similar.

In the general case, by the theory of Jordan Canonical Form, the vector space can be written as a direct sum of \(A\)-invariant subspaces on each of which \(A\) acts as a single Jordan block. By the formula above for \(A^{-1}\), each subspace in the decomposition is \(A^{-1}\)-invariant, so the direct sum decomposition of \(A\) is also one of \(A^{-1}\). The general case thus reduces to the case where \(A\) is a single Jordan block.

**Solution to 7.7.12:** The statement is true. First of all, \(A\) is similar to a Jordan matrix [13, pag. 247], \(A=S^{-1}JS\), where \(S\) is invertible and \(J\) is a direct sum of Jordan blocks. Then \(A^{t}=S^{t}J^{t}(S^{t})^{-1}\) (since \((S^{-1})^{t}=(S^{t})^{-1}\)); that is, \(A^{t}\) is similar to \(J^{t}\). Moreover, \(J^{t}\) is the direct sum of the transposes of the Jordan blocks whose direct sum is \(J\). It will, thus, suffice to prove that each of these Jordan blocks is similar to its transpose. In other words, it will suffice to prove the statement for the case where \(A\) is a Jordan block.

Let \(A\) be an \(n\times n\) Jordan block:

\[A=\left(\begin{array}{ccccc}\lambda&1&0&\cdots&0\\ 0&\lambda&1&\cdots&\vdots\\ \vdots&\vdots&\ddots&\ddots&0\\ 0&0&\cdots&\lambda&1\end{array}\right)\]

Let \(e_{1},\ldots,e_{n}\) be the standard basis vectors for \(\mathbb{C}\)\({}^{n}\), so that \(Ae_{j}=\lambda e_{j}+e_{j-1}\) for \(j>1\) and \(Ae_{1}=\lambda e_{1}\). Let the matrix \(S\) be defined by \(Se_{j}=e_{n-j+1}\). Then \(S=S^{-1}\), and

\[S^{-1}ASe_{j} = SAe_{n-j}\] \[= \left\{\begin{array}{ll}S(\lambda e_{n-j+1}+e_{n-j})\,&j<n\\ S(\lambda e_{n-j+1})\,&j=n\end{array}\right.\] \[= \left\{\begin{array}{ll}\lambda e_{j}+e_{j+1}\,&j<n\\ \lambda e_{j}\,&j=n\end{array}\right.\]

which shows that \(S^{-1}AS=A^{t}\).

**Solution to 7.7.14:** Using the first condition the Jordan Canonical Form [13, pag. 247] of this matrix is a \(6\times 6\) matrix with five 1's and one -1on the diagonal. The blocks corresponding to the eigenvalue \(1\) arc either \(1\times 1\) or \(2\times 2\), by the second condition, with at least one of them having dimension \(2\). Thus, there could be three \(1\)-blocks and one \(2\)-block (for the eigenvalue \(1\)), or one \(1\)-block and two \(2\)-blocks. In this way, we get the following two possibilities for the Jordan Form of the matrix:

\[\left(\begin{array}{cccccc}1&0&0&0&0&0\\ 0&1&0&0&0&0\\ 0&0&1&0&0&0\\ 0&0&0&1&1&0\\ 0&0&0&0&1&0\\ 0&0&0&0&0&-1\end{array}\right),\qquad\left(\begin{array}{cccccc}1&0&0&0&0&0 \\ 0&1&1&0&0&0\\ 0&0&1&0&0&0\\ 0&0&0&1&1&0\\ 0&0&0&0&1&0\\ 0&0&0&0&0&-1\end{array}\right).\]

**Solution to 7.7.15:** Since \(A\) and \(B\) have the same characteristic polynomial, they have the same \(n\) distinct eigenvalues \(l_{1},\ldots,l_{n}\). Let \(\chi(x)=(x-l_{1})^{c_{1}}\cdots(x-l_{n})^{c_{n}}\) be the characteristic polynomial and let \(\mu(x)=(x-l_{1})^{m_{1}}\cdots(x-l_{n})^{m_{n}}\) be the minimal polynomial. Since a nondiagonal Jordan block [HK61, pag. 247] must be at least \(2\times 2\), there can be, at most, one nondiagonal Jordan block for \(N\leq 3\). Hence, the Jordan Canonical Form is completely determined by \(\mu(x)\) and \(\chi(x)\) for \(N\leq 3\). If \(\mu(x)=\chi(x)\), then each distinct eigenvalue corresponds to a single Jordan block of size equal to the multiplicity of the eigenvalue as a root of \(\chi(x)\), so the Jordan Canonical Form is completely determined by \(\chi(x)\), and \(A\) and \(B\) must then be similar.

### 7.8 Bilinear, Quadratic Forms, and Inner Product Spaces

**Solution to 7.8.2:** Every vector in \(W\) is orthogonal to \(v=(a,b,c)\). Let \(Q\) be the orthogonal projection of \(\mathbb{R}^{3}\) onto the space spanned by \(v\), identified with its matrix. The columns of \(Q\) are \(Qe_{j}\), \(1\leq j\leq 3\), where the \(e_{j}\)'s are the standard basis vectors in \(\mathbb{R}^{3}\). But

\[Qe_{1}=\langle v,e_{1}\rangle v=(a^{2},ab,ac)\]

\[Qe_{2}=\langle v,e_{2}\rangle v=(ab,b^{2},bc)\]

\[Qe_{3}=\langle v,e_{3}\rangle v=(ac,bc,c^{2}).\]

Therefore, the orthogonal projection onto \(W\) is given by

\[P=I-Q=\left(\begin{array}{ccc}1-a^{2}&-ab&-ac\\ -ab&1-b^{2}&-bc\\ -ac&-bc&1-c^{2}\end{array}\right).\]

**Solution to 7.8.3:** 1. The monomials \(1,t,t^{2},\ldots,t^{n}\) form a basis for \(P_{n}\). Applying the Gram-Schmidt Procedure [13, pag. 280] to this basis gives us an orthonormal basis \(p_{0},p_{1},\ldots,p_{n}\). The \((k+1)^{th}\) vector in the latter basis, \(p_{k}\), is a linear combination of \(1,t,\ldots,t^{k}\), the first \(k+1\) vectors in the former basis, with \(t^{k}\) having a nonzero coefficient. (This is built into the Gram-Schmidt Procedure.) Hence, \(\deg p_{k}=k\).

2. Since \(p_{k}^{\prime}\) has degree \(k-1\), it is a linear combination of \(p_{0},p_{1},\ldots,p_{k-1}\), for those functions form an orthonormal basis for \(P_{k-1}\). Since \(p_{k}\) is orthogonal to \(p_{0},p_{1},\ldots,p_{k-1}\), it is orthogonal to \(p_{k}^{\prime}\).

**Solution to 7.8.5:** Let \(n=\dim E\), and choose a basis \(v_{1},\ldots,v_{n}\) for \(E\). Define the \(n\times n\) matrix \(A=(a_{jk})\) by \(a_{jk}=B(v_{k},v_{j})\). The linear transformation \(T_{A}\) on \(E\) induced by \(A\) is determined by the relations

\[T_{A}v_{k}=\sum_{j}a_{jk}v_{j}=\sum_{j}B(v_{k},v_{j})v_{j}\,\qquad k=1,\ldots, n\,\]

implying that \(T_{A}v=\sum_{j}B(v,v_{j})v_{j}\) (\(v\in E\)). It follows that \(E_{1}=\ker T_{A}\). By similar reasoning, \(E_{2}=\ker T_{A^{t}}\), where \(A^{t}\) is the transpose of \(A\). By the Rank-Nullity Theorem [13, pag. 71], \(\dim E_{1}\) equals \(n\) minus the dimension of the column space of \(A\), and \(\dim E_{2}\) equals \(n\) minus the dimension of the row space of \(A\). Since the row space and the column space of a matrix have the same dimension, the desired equality follows.

**Solution to 7.8.7:** 1. Since \(A\) is positive definite, one can define a new inner product \(\langle\,,\rangle_{A}\) on \(\mathbb{R}^{n}\) by

\[\langle x,y\rangle_{A}=\langle Ax,y\rangle.\]

The linear operator \(A^{-1}B\) is a symmetric with respect to this inner product, that is,

\[\langle A^{-1}Bx,y\rangle_{A} =\langle Bx,y\rangle=\langle x,B^{t}y\rangle=\langle x,By\rangle\] \[=\langle A^{-1}Ax,By\rangle=\langle Ax,A^{-1}By\rangle=\langle x,A^{-1}By\rangle_{A}\]

So there is a basis \(\{v_{1},...v_{n}\}\) of \(\mathbb{R}^{n}\), orthonormal with respect to \(\langle\,,\rangle_{A}\), in which the matrix for \(A^{-1}B\) is diagonal. This is the basis we are looking for; in particular, \(v_{i}\) is an eigenvector for \(A^{-1}B\), with eigenvalue \(\lambda_{i}\) and

\[\langle v_{i},v_{j}\rangle_{A}=\delta_{ij}\]

\[\langle Bx,v_{j}\rangle=\langle A^{-1}Bv_{i},v_{j}\rangle_{A}=\langle\lambda_ {i}v_{i},v_{j}\rangle_{A}=\lambda_{i}\delta_{ij}.\]

2. Let \(U\) be the matrix which takes the standard basis to \(\{v_{1},...v_{n}\}\) above, that is, \(Ue_{i}=v_{i}\). Since the \(e_{i}\) form an orthonormal basis, for any matrix\(M\),

\[Mx=\sum_{j=1}^{n}\langle Mx,e_{j}\rangle e_{j}\]

in particular

\[U^{t}AUe_{i} =\sum_{j=1}^{n}\langle U^{t}AUe_{i},e_{j}\rangle e_{j}\] \[=\sum_{j=1}^{n}\langle AUe_{i},Ue_{j}\rangle e_{j}\] \[=\sum_{j=1}^{n}\langle Av_{i},v_{j}\rangle e_{j}\] \[=\sum_{j=1}^{n}\delta_{ij}e_{j}=e_{i}\]

showing that \(U^{t}AU=I\).

Using the same decomposition for \(U^{t}BU\), we have

\[U^{t}BUE_{i} =\sum_{j=1}^{n}\langle U^{t}BUe_{i},e_{j}\rangle e_{j}\] \[=\sum_{j=1}^{n}\langle Bv_{i},v_{j}\rangle e_{j}\] \[=\sum_{j=1}^{n}\lambda_{i}\delta_{ij}e_{i}=\lambda_{i}e_{i}\]

so \(U^{t}BU\) is diagonal.

**Solution to 7.8.13:** Suppose we have such \(u\) and \(v\). By Cauchy-Schwarz Inequality [13, pag. 69], we have

\[(u_{1}v_{1}+u_{2}v_{2})^{2}\leq(u_{1}^{2}+u_{2}^{2})(v_{1}^{2}+v_{2}^{2}).\]

Since \(u\cdot v=0\), \((u_{1}v_{1}+u_{2}v_{2})^{2}=(ab)^{2}\); since \(\|u\|=\|v\|=1\), \(1-a^{2}=u_{1}^{2}+u_{2}^{2}\), and \(1-b^{2}=v_{1}^{2}+v_{2}^{2}\). Combining these, we get

\[(ab)^{2}\leq(1-a^{2})(1-b^{2})=1-a^{2}-b^{2}+(ab)^{2},\]

which implies \(a^{2}+b^{2}\leq 1\).

Conversely, suppose that \(a^{2}+b^{2}\leq 1\). Let \(u=(0,\sqrt{1-a^{2}},a)\). \(\|u\|=1\), and we now find \(v_{1}\) and \(v_{2}\) such that \(v_{1}^{2}+v_{2}^{2}+b^{2}=1\) and \(u_{2}v_{2}+ab=0\). If \(a=1\), then \(b=0\), so we can take \(v=(0,1,0)\). If \(a\neq 1\), solving the second equation for \(v_{2}\), we get

\[v_{2}=\frac{-ab}{\sqrt{1-a^{2}}}.\]Using this to solve for \(v_{1}\), we get

\[v_{1}=\frac{\sqrt{1-a^{2}-b^{2}}}{\sqrt{1-a^{2}}}.\]

By our condition on \(a\) and \(b\), both of these are real, so \(u\) and \(v=(v_{1},v_{2},b)\) are the desired vectors.

### General Theory of Matrices

**Solution to 7.9.4:** We will use a powerful result on the structure of real normal operators, not commonly found in the literature. We provide also a second solution, not using the normal form, but which is inspired on it.

**Lemma (Structure of Real Normal Operators):** Given a normal operator on an euclidean space \(\mathbb{R}^{n}\), \(\Lambda\), there exists an orthonormal basis in which the matrix of \(\Lambda\) has the form

\[\left(\begin{array}{ccc}\left(\begin{array}{cc}\sigma_{1}&\tau_{1}\\ -\tau_{1}&\sigma_{1}\end{array}\right)\\ &\left(\begin{array}{cc}\sigma_{2}&\tau_{2}\\ -\tau_{2}&\sigma_{2}\end{array}\right)\\ &&\ddots\\ &&\left(\begin{array}{cc}\sigma_{k}&\tau_{k}\\ -\tau_{k}&\sigma_{k}\end{array}\right)\\ &&\lambda_{2k+1}\\ &&\ddots\\ &&\lambda_{n}\end{array}\right)\]

where the numbers \(\lambda_{j}=\sigma_{j}+i\tau_{j}\), \(j=1,\ldots,k\) and \(\lambda_{2k+1},\ldots,\lambda_{n}\) are the characteristic values of \(\Lambda\).

The proof is obtained by embedding each component of \(\mathbb{R}^{n}\) as the real slice of each component of \(\mathbb{C}\,^{n}\), extending \(\Lambda\) to a normal operator on \(\mathbb{C}\,^{n}\), and noticing that the new operator has the same real matrix (on the same basis) and over \(\mathbb{C}\,^{n}\) has basis of characteristic vectors. A change of basis, picking the new vectors as the real and imaginary parts of the eigenvectors associated with the imaginary eigenvalues, reduces it to the desired form. For details on the proof we refer the reader to [22, pag. 265-271] or [25, pag. 117].

The matrix of an anti-symmetric operator \(\Lambda\) has the property

\[a_{ij}=\langle Ae_{i},e_{j}\rangle=\langle e_{i},A^{*}e_{j}\rangle=\langle e_{i },-Ae_{j}\rangle=-\overline{\langle Ae_{j},e_{i}\rangle}=-\overline{a_{ji}}\,.\]

Since anti-symmetric operators are normal, they have a basis of characteristic values, these satisfy the above equality and are all pure imaginary.

Thus, in the standard decomposition described above all characteristic values are pure imaginary, i.e., \(\sigma_{1}=\cdots=\sigma_{k}=\lambda_{2k+1}=\cdots=\lambda_{n}=0\) and the decomposition in this case is

\[\left(\begin{array}{ccc}\left(\begin{array}{cc}0&\tau_{1}\\ -\tau_{1}&0\end{array}\right)\\ &\left(\begin{array}{cc}0&\tau_{2}\\ -\tau_{2}&0\end{array}\right)\\ &&\ddots\\ &&\left(\begin{array}{cc}0&\tau_{k}\\ -\tau_{k}&0\end{array}\right)\\ &&0\\ &&\ddots\\ &&0\end{array}\right)\]

which obviously has even rank.

_Solution 2._ Consider \(\hat{A}\) the _complexification_ of \(A\), that is, the linear operator from \(\mathbb{C}\,^{n}\) to \(\mathbb{C}\,^{n}\) with the same matrix as \(A\) with respect to the standard basis. Since \(A\) is skew-symmetric, all its eigenvalues are pure imaginary and from the fact that the characteristic polynomial has real coefficients, the non-real eigenvalues show up in conjugate pairs, therefore, the polynomial has the form

\[\chi_{A}(t)=t^{k}p_{1}(t)^{n_{1}}\cdots p_{r}(t)^{n_{r}},\]

where the \(p_{i}\)'s are real, irreducible quadratics.

From the diagonal form of \(\hat{A}\) over \(\mathbb{C}\,\) we can see that the minimal polynomial has the factor in \(t\) with power \(1\), that is, of the form

\[\mu_{A}(t)=\mu_{\hat{A}}(t)=tp_{1}(t)^{m_{1}}\cdots p_{r}(t)^{m_{r}}.\]

Now consider the Rational Canonical Form [10, pag. 238] of \(A\). It is a block diagonal matrix composed of blocks of even size and full rank, together with a block of a zero matrix corresponding to the zero eigenvalues, showing that \(A\) has even rank.

**Solution to 7.9.5:** Since \(A\) is symmetric it can be diagonalized: Let

\[A=QDQ^{-1}\]

where \(D=\mathrm{diag}(d_{1},\ldots,d_{n})\) and each \(d_{i}\) is nonnegative. Then

\[0=Q^{-1}(AB+BA)Q=DC+CD\]

where \(C=Q^{-1}BQ\). Individual entries of this equation read

\[0=(d_{i}+d_{j})\mathrm{c}_{ij}\]so for each \(i\) and \(j\) we must have either \(c_{ij}=0\) or \(d_{i}=d_{j}=0\). In either case,

\[d_{i}c_{ij}=d_{j}c_{ij}=0\]

which is the same as

\[DC=CD=0.\]

Hence, \(AB=BA=0\).

Example:

\[A=\left(\begin{array}{cc}1&0\\ 0&0\end{array}\right)\qquad B=\left(\begin{array}{cc}0&0\\ 0&1\end{array}\right).\]

_Solution 2._ Since \(A\) is symmetric, it is diagonalizable. Let \(v\) be an eigenvector of \(A\) with \(Av=\lambda v\), then

\[A(Bv)=-BAv=-\lambda Bv\]

that is, \(Bv\) is an eigenvector of \(A\) with eigenvalue \(-\lambda\).

Using one of the conditions we get \(\langle A\,Bv,Bv\rangle\geq 0\) but on the other hand \(\langle A\,Bv,Bv\rangle=-\lambda\langle Bv,Bv\rangle\leq 0\), so either \(\lambda=0\) or \(Bv=0\). Writing \(A\) and \(B\) on this basis, that diagonalizes \(A\), ordered with the zero eigenvalues in a first block we have

\[A=\left(\begin{array}{cccc}\parbox{142.26378pt}{\includegraphics[width=142.2637 8pt]{A1.eps}}&\\ &\lambda_{1}&&\\ &&\ddots&\\ &&&\lambda_{k}\end{array}\right)\qquad B=\left(\begin{array}{cccc}\parbox{142.26378pt}{\includegraphics[width=142.26378pt]{A2.eps}}&\\ &0&&\\ &&\ddots&\\ &&&0\end{array}\right)\]

which implies that \(AB=0\) and similarly that \(BA=0\).

**Solution to 7.9.11:** Let \(Y=AD-BC\). We have

\[\left(\begin{array}{cc}A&B\\ C&D\end{array}\right)\left(\begin{array}{cc}D&-B\\ -C&A\end{array}\right)=\left(\begin{array}{cc}AD-BC&-AB+BA\\ CD-DC&-CB+DA\end{array}\right)=\left(\begin{array}{cc}Y&0\\ 0&Y\end{array}\right).\]

If \(Y\) is invertible, then so are \(\left(\begin{array}{cc}Y&0\\ 0&Y\end{array}\right)\) and \(X\).

Assume now that \(X\) is invertible, and let \(v\) be vector in the kernel of \(Y\) : \((AD-BC)v=0\). Then

\[\left(\begin{array}{cc}A&B\\ C&D\end{array}\right)\left(\begin{array}{c}Dv\\ -Cv\end{array}\right)=0=\left(\begin{array}{cc}A&B\\ C&D\end{array}\right)\left(\begin{array}{c}-Bv\\ Av\end{array}\right)\]

implying that \(Dv=Cv=Bv=Av=0\). But then \(X\left(\begin{array}{c}v\\ v\end{array}\right)=0\), so, by the invertibility of \(X\), \(v=0\), proving that \(Y\) is invertible.

**Solution to 7.9.12:** If \(\det B=0\), then \(\det B\equiv 0\pmod{2}\). Hence, if we can show that \(\det B\neq 0\) over the field \(\mathbb{Z}_{2}\), we are done. In the field \(\mathbb{Z}_{2}\), \(1=-1\), so \(B\) is equal to the matrix with zeros along the diagonal and \(1\)'s everywhere else. Since adding one row of a matrix to another row does not change the determinant, we can replace \(B\) by the matrix obtained by adding the first nineteen rows of \(B\) to the last row. Since each column of \(B\) contains exactly nineteen \(1\)'s, \(B\) becomes

\[\left(\begin{array}{cccccc}0&1&1&\cdots&1&1\\ 1&0&1&\cdots&1&1\\ \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ 1&1&1&\cdots&0&1\\ 1&1&1&\cdots&1&1\end{array}\right).\]

By adding the last row of \(B\) to each of the other rows, \(B\) becomes

\[\left(\begin{array}{cccccc}1&0&0&\cdots&0&0\\ 0&1&0&\cdots&0&0\\ \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ 0&0&0&\cdots&1&0\\ 1&1&1&\cdots&1&1\end{array}\right).\]

This is a lower-triangular matrix, so its determinant is the product of its diagonal elements. Hence, the determinant of \(B\) is equal to \(1\) over \(\mathbb{Z}_{2}\), and we are done.

_Solution 2._ In the matrix modulo \(2\), the sum of all columns except column \(i\) is the \(i^{th}\) standard basis vector, so the span of the columns has dimension \(20\), and the matrix is nonsingular.

**Solution to 7.9.13:** Let \(\mathcal{C}\) be the set of real matrices that commute with \(A\). It is clearly a vector space of dimension, at most, \(4\). The set \(\{sI+tA\,|\,s,t\in\mathbb{R}\}\) is a two-dimensional subspace of \(\mathcal{C}\), so it suffices to show that there are two linearly independent matrices which do not commute with \(A\). A calculation show that the matrices \(\left(\begin{smallmatrix}0&1\\ 1&0\end{smallmatrix}\right)\) and \(\left(\begin{smallmatrix}0&1\\ -1&0\end{smallmatrix}\right)\) are such matrices.

**Solution to 7.9.14:** Let

\[A=\left(\begin{array}{cc}a&b\\ c&d\end{array}\right)\qquad\text{and}\qquad X=\left(\begin{array}{cc}x&y\\ z&w\end{array}\right).\]

If \(AX=XA\), we have the three equations: \(bz=yc\), \(ay+bw=xb+yd\), and \(cx+dz=za+wc\).

* \(b=c=0\). Since \(A\) is not a multiple of the identity, \(a\neq d\). The above equations reduce to \(ay=dy\) and \(dz=az\), which, in turn, imply that \(y=z=0\). Hence, \[X=\left(\begin{array}{cc}x&0\\ 0&w\end{array}\right)=\left(x-\frac{a}{a-d}(x-w)\right)\mathrm{I}+\left(\frac{ x-w}{a-d}\right)A.\]* \(b\neq 0\) or \(c\neq 0\). We can assume, without loss of generality, that \(b\neq 0\), as the other case is identical. Then \(z=cy/b\) and \(w=x-y(a-d)/b\). Hence, \[X=\frac{1}{b}\left(\begin{array}{cc}bx-ay+ay&by\\ cy&bx-ay+dy\end{array}\right)=\left(\frac{bx-ay}{b}\right)\mathrm{I}+\frac{y}{b }A.\]

**Solution to 7.9.17:** Define the norm of a matrix \(X=(x_{ij})\) by \(\|X\|=\sum_{i,j}|x_{ij}|\). Notice that if \(B_{k}\), \(k=0,1,\ldots\), are matrices such that \(\sum\|B_{k}\|<\infty\), then \(\sum B_{k}\) converges, because the convergence of the norms clearly implies the absolute entrywise convergence.

In our case, we have \(B_{k}=A^{k}\). The desired result follows from the fact that \(\sum\|A\|^{k}/k!\) converges for any matrix \(A\).

**Solution to 7.9.18:** Note that, if \(A\) is an invertible matrix, we have

\[Ae^{M}A^{-1}=e^{AMA^{-1}}\]

so we may assume that \(M\) is upper triangular. Under this assumption \(e^{M}\) is also upper triangular, and if \(a_{1},\ldots,a_{n}\) are \(M\)'s diagonal entries, then the diagonal entries of \(e^{M}\) are

\[e^{a_{1}},\ldots,e^{a_{n}}\]

and we get

\[\det\left(e^{M}\right)=\prod_{i=1}^{n}e^{a_{i}}=e^{\sum_{i=1}^{n}a_{i}}=e^{ \operatorname{tr}(M)}.\]

**Solution to 7.9.23:** 1. Let \(\alpha=\frac{1}{n}\mathrm{tr}(M)\), so that \(\mathrm{tr}(M-\alpha I)=0\). Let

\[A=\frac{1}{2}(M-M^{t}),\qquad S=\frac{1}{2}(M+M^{t})-\alpha I.\]

The desired conditions are then satisfied.

2. We have

\[M^{2}=A^{2}+S^{2}+\alpha^{2}I+2\alpha A+2\alpha S+AS+SA.\]

The trace of \(M\) is the sum of the traces of the seven terms on the right. We have \(\mathrm{tr}(A)=\mathrm{tr}(B)=0\). Also,

\[\mathrm{tr}(AS)=\mathrm{tr}\left((AS)^{t}\right)=\mathrm{tr}\left(S^{t}A^{t} \right)=\mathrm{tr}(-SA)=-\mathrm{tr}(SA),\]

so \(\mathrm{tr}(AS+SA)=0\) (in fact, \(\mathrm{tr}(AS)=0\) since \(\mathrm{tr}(AS)=\mathrm{tr}(SA)\)). The desired equality now follows.

**Solution to 7.9.25:** We will prove the equivalent result that the kernel of \(A\) is trivial. Let \(x=(x_{1},\ldots,x_{n})^{t}\) be a nonzero vector in \(\mathbb{R}^{n}\). We have

\[Ax\cdot x =\sum_{i,j=1}^{n}a_{ij}x_{i}x_{j}\] \[=\sum_{i=1}^{n}a_{ii}x_{i}^{2}+\sum_{i\neq j}a_{ij}x_{i}x_{j}\] \[\geq\sum_{i=1}^{n}x_{i}^{2}-\sum_{i\neq j}|a_{ij}x_{i}x_{j}|\] \[\geq\sum_{i=1}^{n}x_{i}^{2}-\sqrt{\sum_{i\neq j}a_{ij}^{2}\sum_{i \neq j}x_{i}^{2}x_{j}^{2}}\] \[>\sum_{i=1}^{n}x_{i}^{2}-\sqrt{\sum_{i\neq j}x_{i}^{2}x_{j}^{2}}\] \[\geq\sum_{i=1}^{n}x_{i}^{2}-\sqrt{\sum_{i=1}^{n}x_{i}^{2}\sum_{j =1}^{n}x_{j}^{2}}\] \[\geq 0.\]

So \(\langle Ax,x\rangle\neq 0\) and \(Ax\neq 0\), therefore, the kernel of \(A\) is trivial.

**Solution to 7.9.26:** Suppose \(x\) is in the kernel. Then

\[a_{ij}x_{i}=-\sum_{j\neq i}a_{ij}x_{j}\]

for each \(i\). Let \(i\) be such that \(|x_{i}|=\max_{k}|x_{k}|=M\), say. Then

\[|a_{ii}|M\leq\sum_{j\neq i}|a_{ij}||x_{j}|\leq\sum_{j\neq i}|a_{ij}|M\]

so

\[\left(|a_{ii}|\sum_{j\neq i}|a_{ij}|\right)M\leq 0\.\]

Since the therm inside the parenthesis is strictly positive by assumption, we must have \(M=0\), so \(x=0\) and \(A\) is invertible.

**Solution to 7.9.27:** It will suffice to prove that \(\ker(I-A)\) is trivial. Let \(x=(x_{1},x_{2},\cdots,x_{n})^{t}\) be a nonzero vector in \(\mathbb{R}^{n}\), and let \(y=(I-A)x\). Pick \(k\) such that \(|x_{k}|=\max\{|x_{1}|,\ldots,|x_{n}|\}\). Then

\[|y_{k}|=|x_{k}-\sum_{j=1}^{n}a_{kj}x_{j}|\]\[\geq|x_{k}|-\sum_{j=1}^{n}|a_{kj}|\ |x_{j}|\] \[\geq|x_{k}|-\sum_{j=1}^{n}|a_{kj}|\ |x_{k}|\] \[=|x_{k}|\left(1-\sum_{j=1}^{n}|a_{kj}|\right)>0\.\]

Hence, \(y\neq 0\), as desired.

_Solution 2._ Let \(\alpha<1\) be a positive number such that, for all \(i\), we have \(\sum_{j=1}^{n}|a_{ij}|\leq\alpha\). Then,

\[\sum_{j,k}|a_{ij}a_{jk}|=\sum_{j}\left(|a_{ij}|\sum_{k}|a_{jk}|\right)\leq \alpha\sum_{j}|a_{ij}|\leq\alpha^{2}\.\]

And so, inductively, the sum of the absolute values of the terms in one row of \(A^{n}\) is bounded by \(\alpha^{n}\). Thus, the entries in the infinite sum

\[I+A+A^{2}+A^{3}+\cdots\]

are all bounded by the geometric series \(1+\alpha+\alpha^{2}+\cdots\), and so are absolutely convergent; thus, this sum exists and the product

\[(I-A)(I+A+A^{2}+\cdots)=I\]

is valid, so that the inverse of \(I-A\) is this infinite sum.

**Solution to 7.9.28:** 1. If \(A\) is symmetric then, by the Spectral Theorem [10, pag. 335], [29, pag. 235], there is an orthonormal basis \(\{e_{1},e_{2},\ldots,e_{n}\}\) for \(\mathbb{R}^{n}\) with respect to which \(A\) is diagonal: \(Ae_{j}=\lambda_{j}e_{j}\), \(j=1,\ldots,n\). Let \(x\) be any vector in \(\mathbb{R}^{n}\). We can write \(x=c_{1}e_{1}+\cdots+c_{n}e_{n}\) for some scalars \(c_{1},\ldots,c_{n}\), and have \(Ax=\lambda_{1}c_{1}e_{1}+\cdots+\lambda_{n}c_{n}e_{n}\). Moreover,

\[\|x\|^{2} = c_{1}^{2}+\cdots+c_{n}^{2}\] \[\|Ax\|^{2} = \lambda_{1}^{2}c_{1}^{2}+\cdots+\lambda_{n}^{2}c_{n}^{2}\] \[\leq \max\{\lambda_{1}^{2},\ldots,\lambda_{n}^{2}\}(c_{1}^{2}+\cdots+c_ {n}^{2})=M^{2}\|x\|^{2}\,\]

which is the desired inequality.

2. The matrix \(\left(\begin{array}{cc}0&1\\ 0&0\end{array}\right)\) gives a counterexample with \(n=2\). Its only eigenvalue is \(0\), yet it is not the zero matrix.

## Appendix A How to Get the Exams

### On-line

Open a Web browser of your choice, on the URL

[http://math.berkeley.edu/](http://math.berkeley.edu/)

and choose Preliminary Exams on the main page. You can then proceed to explore the set of exams or download them in several of the formats available. When this page changes, you can do a search on the words Berkeley Preliminary Exam and you should be guided to a possible new location by one of the net search engines.

To suggest improvements, comments, or submit a solution, you can send e-mail to the authors. If you are submitting a new solution, make sure you include your full name, so we can cite you, if you so wish.

### Off-line, the Last Resort

Even if you do not have access to the net, you can reconstruct each of the exams using the following tables. This method should be used only as a last resort, since some of the problems have been slightly altered to uniformize notation and/or correct some errors in the original text.

[MISSING_PAGE_EMPTY:422]

[MISSING_PAGE_EMPTY:423]

[MISSING_PAGE_EMPTY:424]

[MISSING_PAGE_EMPTY:425]

## References

* [1]Appendix B

Passing Scores

The passing scores and data presented here go back to the first Preliminary Examination, which was held on January 1977.

\begin{tabular}{||c c|c c c c||} \hline \hline Date & \multicolumn{2}{c}{Minimum} & \# of students & \# of students & \% passing \\  & \multicolumn{1}{c}{passing score} & \multicolumn{1}{c}{taking} & \multicolumn{1}{c}{passing} & \multicolumn{1}{c||}{the exam} \\ \hline \hline Spring & 98 & 71/120 & 15 & 9 & 60.0\% \\ Fall & 97 & 64/120 & 41 & 28 & 68.3\% \\ \hline Spring & 97 & 70/120 & 10 & 5 & 50.0\% \\ Fall & 96 & 80/120 & 24 & 17 & 70.8\% \\ \hline Spring & 96 & 84/120 & 17 & 13 & 76.5\% \\ Fall & 95 & 64/120 & 41 & 19 & 46.3\% \\ \hline Spring & 95 & 65/120 & 10 & 4 & 40.0\% \\ Fall & 94 & 71/120 & 28 & 16 & 57.1\% \\ \hline Spring & 94 & 70/120 & 11 & 5 & 45.5\% \\ Fall & 93 & 79/120 & 40 & 28 & 70.0\% \\ \hline Spring & 93 & 69/120 & 22 & 17 & 77.3\% \\ Fall & 92 & 71/120 & 53 & 34 & 64.2\% \\ \hline Spring & 92 & 58/120 & 27 & 13 & 48.1\% \\ Fall & 91 & 66/120 & 66 & 42 & 63.6\% \\ \hline \hline \end{tabular}

## Appendix B Passing Scores

## Appendix C The Syllabus

The syllabus is designed around a working knowledge and understanding of an **honors** undergraduate mathematics major. A student taking the examination should be familiar with the material outlined below.

## Calculus

Basic first- and second-year calculus. Derivatives of maps from \(\mathbb{R}^{m}\) to \(\mathbb{R}^{n}\), gradient, chain rule; maxima and minima, Lagrange multipliers; line and surface integrals of scalar and vector functions; Gauss', Green's and Stokes' theorems. Ordinary differential equations; explicit solutions of simple equations.

### Classical Analysis

Point-set topology of \(\mathbb{R}^{n}\) and metric spaces; properties of continuous functions, compactness, connectedness, limit points; least upper bound property of \(\mathbb{R}\). Sequences and series, Cauchy sequences, uniform convergence and its relation to derivatives and integrals; power series, radius of convergence, Weierstrass \(M\)-test; convergence of improper integrals. Compactness in function spaces. Inverse and Implicit Function Theorems and applications; the derivative as a linear map; existence and uniqueness theoremsfor solutions of ordinary differential equations; elementary Fourier series. Texts: [11], [12], [13], [14], [15].

## Abstract Algebra

Elementary set theory, e.g., uncountability of \(\mathbb{R}\). Groups, subgroups, normal subgroups, homomorphisms, quotient groups, automorphisms, groups acting on sets, Sylow theorems and applications, finitely generated abelian groups. Examples: permutation groups, cyclic groups, dihedral groups, matrix groups. Basic properties of rings, units, ideals, homomorphisms, quotient rings, prime and maximal ideals, fields of fractions, Euclidean domains, principal ideal domains and unique factorization domains, polynomial rings. Elementary properties of finite field extensions and roots of polynomials, finite fields. Texts: [16], [17], [18].

## Linear Algebra

Matrices, linear transformations, change of basis; nullity-rank theorem. Eigenvalues and eigenvectors; determinants, characteristic and minimal polynomials, Cayley-Hamilton Theorem; diagonalization and triangularization of operators; Jordan normal form, Rational Canonical Form; invariant subspaces and canonical forms; inner product spaces, hermitian and unitary operators, adjoints. Quadratic forms. Texts: [19], [10], [11].

## Complex Analysis

Basic properties of the complex number system. Analytic functions, conformality, Cauchy-Riemann equations, elementary functions and their basic properties (rational functions, exponential function, logarithm function, trigonometric functions, roots, e.g., \(\sqrt{z}\)). Cauchy's Theorem and Cauchy's integral formula, power series and Laurent series, isolation of zeros, classification of isolated singularities (including singularity at \(\infty\)), analyticity of limit functions. Maximum Principle, Schwarz's Lemma, Liouville's Theorem, Morera's Theorem, Argument Principle, Rouche's Theorem. Basic properties of harmonic functions in the plane, connection with analytic functions, harmonic conjugates, Mean Value Property, Maximum Principle. Residue Theorem, evaluation of definite integrals. Mapping properties of linear fractional transformations, conformal equivalences of the unit disc with itself and with the upper half-plane. Texts: [12], [13], [14].

## References

* [Ahl79] L. V. Ahlfors. _Complex Analysis, an Introduction to the Theory of Analytic Functions of One Complex Variable_. International Series in Pure and Applied Mathematics. McGraw-Hill, New York, 1979.
* [AM95] G. L. Alexanderson and D. H. Mugler, editors. _Lion Hunting & Other Mathematical Pursuits, A Collection of Mathematics, Verse, and Stories by Ralph P. Boas, Jr._, volume 15 of _The Dolciani Mathematical Expositions_. Mathematical Association of America, Washington, DC, 1995.
* [Bar76] R. G. Bartle. _The Elements of Real Analysis_. John Wiley & Sons Inc., New York, 1976. Also available in Spanish [Bar82].
* [Bar82] R. G. Bartle. _Introduccion al analisis matematico_. Limusa, Mexico, 1982. English original in [Bar76].
* [BD65] W. E. Boyce and R. C. DiPrima. _Elementary Differential Equations and Boundary Value Problems_. John Wiley & Sons Inc., New York, 1965. Also available in Spanish [BD79].
* [BD79] W. E. Boyce and R. C. DiPrima. _Ecuaciones diferenciales y problemas con valores en la frontera_. Limusa, Mexico, 1979. English original in [BD65].
* [BML61] G. Birkhoff and S. Mac Lane. [1961]. English original in [BML97].

[MISSING_PAGE_FAIL:432]

[MISSING_PAGE_FAIL:433]

[MISSING_PAGE_FAIL:434]

* [Kra90] S. G. Krantz. _Complex Analysis: The Geometric Viewpoint_, volume 23 of _Carus Mathematical Monographs_. Mathematical Association of America, Washington, 1990.
* [Lan77] S. Lang. _Algebra_. Coleccion ciencia y tecnica : seccion matematicas y estadistica. Aguilar, Madrid, 1977. English original in [Lan94].
* [Lan78] S. Lang. _Algebra_. Addison-Wesley, Reading, Mass., 1978. English original in [Lan94].
* [Lan84] S. Lang. _Algebra_. Panstwowe Wydawnictwo Naukowe (PWN), Warsaw, 1984. English original in [Lan94].
* [Lan94] S. Lang. _Algebra_. Addison-Wesley, Menlo Park, CA, 1994. Also available in French [Lan78], Polish [Lan84], and Spanish [Lan77].
* [Lim82] E. L. Lima. _Curso de Analise_, volume 2 of _Projeto Euclides_. Instituto de Matematica Pura e Aplicada, Washington, 1982.
* [Lip68] S. Lipschutz. _Linear Algebra_. Schaum's Outlines. McGraw-Hill, New York, 1968. Also available in Portuguese [Lip94].
* [Lip94] S. Lipschutz. _Algebra Linear: teoria e problemas_. Colecao Schaum. Makron Books, Sao Paulo, 1994. English original in [Lip68].
* [LR70] N. Levinson and R. M. Redheffer. _Complex Variables_. Holden-Day Series in Mathematics. Holden-Day, San Francisco, 1970. Also available in Spanish [LR75].
* [LR75] N. Levinson and R. M. Redheffer. _Curso de variable compleja_. Reverte, Barcelona, 1975. English original in [LR70].
* [MH87] J. E. Marsden and M. J. Hoffman. _Basic Complex Analysis_. W. H. Freeman, New York, 1987. Also available in Spanish [MH96].
* [MH93] J. E. Marsden and M. J. Hoffman. _Elementary Classical Analysis_. W. H. Freeman, New York, 1993.
* [MH96] J. E. Marsden and M. J. Hoffman. _Analisis basico de variable compleja_. Editorial F. Trillas, S.A., Mexico, 1996. English original in [MH87].
* [ND86] B. Noble and J. W. Daniel. _Algebra Linear Aplicada_. Prentice-Hall do Brasil, Rio de Janeiro, 1986. English original in [ND88].
* [ND88] B. Noble and J. W. Daniel. _Applied Linear Algebra_. Prentice-Hall, Englewood Cliffs, NJ, 1988. Also available in Portuguese [ND86] and Spanish [ND89].

* [ND89] B. Noble and J. W. Daniel. _Algebra lineal aplicada_. Prentice-Hall Hispanoamericana, Mexico, 1989. English original in [ND88].
* [NZ69] I. M. Niven and H. S. Zuckerman. _Introduccion a la teoria de los numeros_. Limusa, Mexico, 1969. English original in [NZM91].
* [NZM91] I. M. Niven, H. S. Zuckerman, and H. L. Montgomery. _An Introduction to the Theory of Numbers_. John Wiley & Sons Inc., New York, 1991. Also available in Spanish [NZ69].
* [PMJ85] M. H. Protter and C. B. Morrey Jr. _Intermediate Calculus_. Undergraduate Texts in Mathematics. Springer-Verlag, New York, 1985.
* [Ros86] M. Rosenlicht. _Introduction to Analysis_. Dover, New York, 1986. Previously published by Scott, Foresman & Co. in 1968.
* [Rud66] W. Rudin. _Principios de analisis matematico_. McGraw-Hill, New York, 1966. English original in [Rud87].
* [Rud71] W. Rudin. _Principios de Analise Matematica_. Ao Livro Tecnico, Rio de Janeiro, 1971. English original in [Rud87].
* [Rud76] W. Rudin. _Osnovy matematicheskogo analiza_. Uzd-vo. Mir, Moskva, 1976. English original in [Rud87].
* [Rud79] W. Rudin. _Singularity of the \(\mathbb{R}^{n}\)_., 1979. English original in [Rud87].
* [Rud80] W. Rudin. _Analysis_. Physik Verlag, Weinheim, 1980. English original in [Rud87].
* [Rud87] W. Rudin. _Principles of Mathematical Analysis_. International Series in Pure and Applied Mathematics. McGraw-Hill, 1987. Also available in Chinese [Rud79], French [Rud95], German [Rud80], Portuguese [Rud71], Russian [Rud76], and Spanish [Rud66].
* [Rud95] W. Rudin. _Principes d'analyse mathematique_. Ediscience international, Paris, 1995. English original in [Rud87].
* [San79] D. A. Sanchez. _Ordinary Differential Equations and Stability Theory; An Introduction_. Dover, New York, 1979. Previously published by W. H. Freeman & Co. in 1968.
* [Shi69] G. E. Shilov. _Matematicheskii analiz: Konechnomernie linehes prostranstva_. Nauka, Moskva, 1969. Also available in English [Shi77].

* [Shi77] G. E. Shilov. _Linear Algebra_. Dover, New York, 1977. Previously published by Prentice-Hall in 1971. Russian original in [Shi69].
* [Sta89] H. M. Stark. _An Introduction to Number Theory_. MIT Press, Cambridge, Mass., 1989. Previously published by Markham Pub. Co. in 1970.
* [Str80] G. Strang. _Juniemans azebera u ee primenenii. Iizl-vo. Mir_, Moskva, 1980. English original in [Str93].
* [Str82] G. Strang. _Algebra lineal y sus aplicaciones_. Fondo Educativo Interamericano, Mexico, 1982. English original in [Str93].
* [Str90] G. Strang.,, 1990. English original in [Str93].
* [Str93] G. Strang. _Linear Algebra and its Applications_. Wellesley-Cambridge Press, San Diego, 1993. Previously published by Academic Press in 1976 and Harcourt, Brace, Jovanovich in 1980, also available in Chinese [Str90], Russian [Str80], and Spanish [Str82].
* [Yue96] Feng Yuefeng. Proof Without Words: Jordan's Inequality. _Math. Mag._, 169:126, 1996.

[MISSING_PAGE_FAIL:438]

Fibonacci numbers. 11, 119, 392 Fixed Point Theorem. 158, 245 Fubini's Theorem. 261 function, concave convex harmonic. 158, 245 orthonormal polynomial proper real analytic semicontinuous. 147, 316, 317, 319 286, 289 of Calculus. 149 Gauss Lemma. 358 Theorem. 217 Gauss-Lucas Theorem. 290, 292 Gram-Schmidt Procedure. 386, 412 Green's Theorem. 298 group action, faithful group of permutations, transitive group, fixed point Heine-Borel Theorem. 154, 239, 240, 243 Hurwitz Theorem. 256 Identity Theorem. 254, 273, 275, 276, 279 Implicit Function Theorem. 211, 222 Induction Principle. 140, 150, 158-161, 163, 167, 171, 342, 346, 373, 375, 377, 378, 389, 391 Induction, Complete. 140, 385 Intermediate Value Theorem. 142, 153, 174, 178, 201, 225, 267, 292 Inverse Function Theorem. 203-205, 211-213, 220, 278 Jordan Canonical Form 159, 313, 322, 374, 386, 398, 401, 405-411 Lemma of. 147, 316, 317, 319 L'Hopital's Rule Lagrange multipliers polynomials. 206 Theorem of. 336, 345, 347, 369 Laplace expansion. 213, 214 Laplacian, eigenfunction Laurent expansion. 38 Leibniz Criterion Liouville's Theorem. 275, 279, 280, 298, 299 Maclaurin expansion. 145, 162, 165, 179, 256, 260, 262, 271, 273, 296, 297 map closed compact strict contraction matrix, axis column rank commutant of a finite order index order n orthogonal positive definite row rank skew-symmetric tridiagonal Maximum Modulus Principle 266, 267, 270, 280, 298, 299 Mean Value Property. 263

\begin{tabular}{l r}  & \\ Theorem & 148, 152, 168, 176, 185, 206, 207 & ring index unit 106 \\  & \\ Method of Undetermined Coefficients & 225 \\ Morera's Theorem & 262, 283 \\ Nested Set Property & 245 \\ norm & 30 \\ Nyquist diagram & 291 \\ Open Mapping Theorem & 259 \\ Parseval Identity & 196, 197 \\ Picard's Theorem & 219, 220, 222- 224, 226, 227, 232, 233 \\ Pigeonhole Principle & 351, 365 \\ Poisson's formula & 307 \\ Rank Theorem & 211 \\ Rank-Nullity Theorem & 377, 381, 412 \\ Rational Canonical Form & 409 \\ Rayleigh's Theorem & 234, 394, 395 \\ Residue Theorem & 300-306, 308, 310, 311, 317, 319, 324, 325, 328, 330, 331, 333 \\ Riemann sums & 162 \\ Riemann-Lesbesgue Lemma & 197 \\ ring index unit & 100 \\  & 106 \\ Rolle's Theorem & 143, 147, 168, 172, 173 \\ Rouche's Theorem & 264, 281, 287-289, 291-293, 295, 296, 303 \\ Schwarz & 266-270 \\ Reflection Principle & 275 \\ Theorem & 204 \\ Spectral Theorem & 377, 420 \\ Stokes' Theorem & 216 \\ Stone-Weierstrass & 216 \\ Approximation Theorem & 183, 187, 195, 198, 260 \\ Structure Theorem & 337, 347, 348, 351, 362 \\ Taylor formula & 141, 143, 145, 173, 204, 296 \\ Triangle Inequality & 161, 243, 244, 292 \\ Weierstrass & \\ M-test & 192-194 \\ Theorem & 155, 199 \\ \end{tabular}
